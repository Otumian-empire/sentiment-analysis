,0
0,"Hey y'all 👋Hope you all have wonderful weekends!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugShopping for new clothes 👗"
1,"Do you actively contribute to open source projects? What motivates you to contribute, and what are the benefits of participating in the open source community?This week we're exploring the experiences of seasoned developers:  their stories, hurdles, and successes. Like what you're reading? Follow the DEVteam for more discussions like this!The DEV TeamFollow        The team behind this very platform. 😄      "
2,"Open Source thrives through shared efforts. Whether you're a newcomer or a veteran, we're here to encourage your contributions, motivate your endeavors, and provide valuable assistance to maintainers. Together, we are building amazing things!  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy contributing!"
3,"In the age of burgeoning data complexity and high-dimensional information, traditional databases often fall short when it comes to efficiently handling and extracting meaning from intricate datasets. Enter vector databases, a technological innovation that has emerged as a solution to the challenges posed by the ever-expanding landscape of data.   Understanding Vector DatabasesVector databases have gained significant importance in various fields due to their unique ability to efficiently store, index, and search high-dimensional data points, often referred to as vectors. These databases are designed to handle data where each entry is represented as a vector in a multi-dimensional space. The vectors can represent a wide range of information, such as numerical features, embeddings from text or images, and even complex data like molecular structures. Let's represent the vector database using a 2D grid where one axis represents the color of the animal (brown, black, white) and the other axis represents the size (small, medium, large).In this representation:Image A: Brown color, Medium sizeImage B: Black color, Small sizeImage C: White color, Large sizeImage E: Black color, Large sizeYou can imagine each image as a point plotted on this grid based on its color and size attributes. This simplified grid captures the essence of how a vector database could be represented visually, even though the actual vector spaces might have many more dimensions and use sophisticated techniques for search and retrieval.  Explain Vector Databases Like I’m 5Imagine you have a bunch of different types of fruit, like apples, oranges, bananas, and grapes. You love the taste of apples and want to find other fruits that taste similar to apples. Instead of sorting the fruits by their colors or sizes, you decide to group them based on how sweet or sour they are.So, you put all the sweet fruits together, like apples, grapes, and ripe bananas. You put the sour fruits in another group, like oranges and unripe bananas. Now, when you want to find fruits that taste like apples, you just look in the group of sweet fruits because they're more likely to have a similar taste.But what if you're looking for something specific, like a fruit that's as sweet as an apple but also has a tangy flavor like an orange? It might be a bit hard to find in your groups, right? That's when you ask someone who knows a lot about different fruits, like a fruit expert. They can suggest a fruit that matches your unique taste request because they know about the flavors of many fruits.In this case, that knowledgeable person is acting like a ""vector database."" They have a lot of information about different fruits and can help you find one that fits your special taste, even if it's not based on the usual things like colors or shapes.Similarly, a vector database is like this helpful expert for computers. It's designed to remember lots of details about things, like foods, in a special way. So, if you're looking for a food that's similar in taste to something you love, or a food with a combination of flavors you enjoy, this vector database can quickly find the right options for you. It's like having a flavor expert for computers that knows all about tastes and can suggest great choices based on what you're craving, just like that knowledgeable person with fruit.  How Do Vector Databases Store Data?Vector databases store data by using vector embeddings. Vector embeddings in vector databases refer to a way of representing objects, such as items, documents, or data points, as vectors in a multi-dimensional space. Each object is assigned a vector that captures various characteristics or features of that object. These vectors are designed in such a way that similar objects have vectors that are closer to each other in the vector space, while dissimilar objects have vectors that are farther apart.Think of vector embeddings like a special code that describes the important aspects of an object. Imagine you have different animals, and you want to represent them in a way that similar animals have similar codes. For instance, cats and dogs might have codes that are quite close, as they share common features like being four-legged and having fur. On the other hand, animals like fish and birds would have codes that are further apart, reflecting their differences.In a vector database, these embeddings are used to store and organize objects. When you want to find objects that are similar to a given query, the database looks at the embeddings and calculates the distances between the query's embedding and the embeddings of other objects. This helps the database quickly identify objects that are most similar to the query.For example, in a music streaming app, songs could be represented as vectors using embeddings that capture musical features like tempo, genre, and instruments used. When you search for songs similar to your favorite track, the app's vector database would compare the embeddings to find songs that match your preferences closely.Vector embeddings are a way of turning complex objects into numerical vectors that capture their characteristics, and vector databases use these embeddings to efficiently search and retrieve similar or relevant objects based on their positions in the vector space.  How Do Vector Databases Work? Image credits: KDnuggets  User Query:You input a question or request into the ChatGPT application.  Embedding Creation:The application converts your input into a compact numerical form called a vector embedding.This embedding captures the essence of your query in a mathematical representation.  Database Comparison:The vector embedding is compared with other embeddings stored in the vector database.Similarity measures help identify the most related embeddings based on content.  Output Generation:The database generates a response composed of embeddings closely matching your query's meaning.  User Response:The response, containing relevant information linked to the identified embeddings, is sent back to you.  Follow-up Queries:When you make subsequent queries, the embedding model generates new embeddings.These new embeddings are used to find similar embeddings in the database, connecting back to the original content.  How Vector Databases Know Which Vectors are Similar?A vector database determines the similarity between vectors using various mathematical techniques, with one of the most common methods being cosine similarity. When you search for ""Best cricket player in the world"" on Google and it shows a list of top players, there are several steps involved, of which, cosine similarity is the main one.The vector representation of the search query is compared to the vector representations of all the player profiles in the database using cosine similarity. The more similar the vectors are, the higher the cosine similarity score.Note: Well, this is just for the sake of an example. it's important to note that search engines like Google use complex algorithms that go beyond simple vector similarity. They consider various factors such as the user's location, search history, authority of the sources, and more to provide the most relevant and personalized search results.  Vector Database CapabilitiesThe significance of vector databases lies in their capabilities and applications:  - Efficient Similarity Search:Vector databases excel at performing similarity searches, where you can retrieve vectors that are most similar to a given query vector. This is crucial in various applications like recommendation systems (finding similar products or content), image and video retrieval, facial recognition, and information retrieval.  - High-Dimensional Data:Traditional relational databases struggle with high-dimensional data because of the ""curse of dimensionality,"" where distances between data points become less meaningful as the number of dimensions increases. Vector databases are designed to handle high-dimensional data more efficiently, making them suitable for applications like natural language processing, computer vision, and genomics.  - Machine Learning and AI:Vector databases are often used to store embeddings generated by machine learning models. These embeddings capture the essential features of the data and can be used for various tasks, such as clustering, classification, and anomaly detection.  - Real-time Applications:Many vector databases are optimized for real-time or near-real-time querying, making them suitable for applications that require quick responses, such as recommendation systems in e-commerce, fraud detection, and monitoring IoT sensor data.  - Personalization and User Profiling:Vector databases enable personalized experiences by allowing systems to understand and predict user preferences. This is crucial in platforms like streaming services, social media, and online marketplaces.  - Spatial and Geographic Data:Vector databases can handle geographic data, such as points, lines, and polygons, efficiently. This is essential in applications like geographical information systems (GIS), location-based services, and navigation applications.  - Healthcare and Life Sciences:In genomics and molecular biology, vector databases are used to store and analyze genetic sequences, protein structures, and other molecular data. This helps in drug discovery, disease diagnosis, and personalized medicine.  - Data Fusion and Integration:Vector databases can integrate data from various sources and types, enabling more comprehensive analysis and insights. This is valuable in scenarios where data comes from multiple modalities, such as combining text, image, and numerical data.  - Multilingual Search:Vector databases can be used to create powerful multilingual search engines by representing text documents as vectors in a common space, enabling cross-lingual similarity searches.  - Graph Data:Vector databases can represent and process graph data efficiently, which is crucial in social network analysis, recommendation systems, and fraud detection.  The Crucial Role of Vector Databases in Today's Data LandscapeVector databases are experiencing high demand due to their essential role in tackling the challenges posed by the explosion of high-dimensional data in modern applications. As industries increasingly adopt technologies like machine learning, artificial intelligence, and data analytics, the need to efficiently store, search, and analyze complex data representations has become paramount. Vector databases enable businesses to harness the power of similarity search, personalized recommendations, and content retrieval, driving enhanced user experiences and improved decision-making. With applications ranging from e-commerce and content platforms to healthcare and autonomous vehicles, the demand for vector databases stems from their ability to handle diverse data types and deliver accurate results in real time. As data continues to grow in complexity and volume, the scalability, speed, and accuracy offered by vector databases position them as a critical tool for extracting meaningful insights and unlocking new opportunities across various domains.  SingleStore as a Vector Database:Harness the robust vector database capabilities of SingleStoreDB, tailored to seamlessly serve AI-driven applications, chatbots, image recognition systems, and more. With SingleStoreDB at your disposal, the necessity for maintaining a dedicated vector database for your vector-intensive workloads becomes obsolete.Diverging from conventional vector database approaches, SingleStoreDB takes a novel approach by housing vector data within relational tables alongside diverse data types. This innovative amalgamation empowers you to effortlessly access comprehensive metadata and additional attributes pertaining to your vector data, all while leveraging the extensive querying prowess of SQL.SingleStoreDB has been meticulously architected with a scalable framework, ensuring unfaltering support for your burgeoning data requirements. Say goodbye to limitations and embrace a solution that grows in tandem with your data demands.  Example of Face Matching with SQL in SingleStoreWe loaded 16,784,377 rows into this table:create table people(  id bigint not null primary key,  filename varchar(255),  vector blob);Enter fullscreen modeExit fullscreen modeEach row represents one image of a celebrity, and contains a unique ID number, the file name where the image is stored and a 128-element floating point vector representing the meaning of the face. This vector was obtained using facenet, a pre-trained neural network for creating vector embeddings from a face image.Don't worry, you don't need to understand the AI to use this kind of approach – you just need to use somebody else's pre-trained neural network, or any tool that can provide you summary vectors for an object.Now, we query this table using:select vectorinto @vfrom peoplewhere filename = ""Emma_Thompson/Emma_Thompson_0001.jpg"";select filename, dot_product(vector, @v) as scorefrom people where score > 0.1order by score desclimit 5;Enter fullscreen modeExit fullscreen modeThe first query gets a query vector @v for the image Emma_Thompson_0001.jpg. The second query finds the top five closest matches:Emma_Thompson_0001.jpg is a perfect match for itself, so the score is close to 1. But interestingly, the next closest match is Emma_Thompson_0002.jpg. Here are the query image and closest match:Moreover, the search speed we obtained was truly incredible. The 2nd query took only 0.005 seconds on a 16 vcpu machine. And it processed all 16M vectors. This is a rate of over 3.3 billion vector matches per second. Know more about this experiment in the original article.Image Matching in SQL With SingleStoreDBNow, it is time for you to play around with SingleStore. Sign up to SigleStore & claim your $600 worth of free usage.The significance of vector databases stems from their ability to handle complex, high-dimensional data while offering efficient querying and retrieval mechanisms. As data continues to grow in complexity and volume, vector databases are becoming increasingly vital in a wide range of applications across industries.Note & Disclaimer: I have taken the help of ChatGPT in writing some parts of this article."
4,"We're thrilled to announce a powerful integration between LangChain and Memgraph, bringing you an unparalleled natural language interface to your Memgraph database. Say goodbye to complex queries and welcome a seamless and intuitive way to interact with your data.  Memgraph QA chain tutorialIf you've ever wanted to effortlessly query your Memgraph database using natural language, this tutorial is for you. This step-by-step guide will walk you through the process, ensuring you have all the tools you need to get started.  PrerequisitesBefore you dive in, make sure you have Docker and Python 3.x installed on your system.  Get startedLaunch a Memgraph Instance: With a few simple commands, you can have your Memgraph instance up and running using Docker. Just follow our script to set it up.Install dependencies: We've got you covered with the required packages. Use pip to install langchain, openai, neo4j, and gqlalchemy. Don't forget the --user flag to ensure smooth permissions.Code playtime: Whether you prefer working within this notebook or want to use a separate Python file, the tutorial offers code snippets to guide you through the process.  What's insideExplore the rich features and functionalities that LangChain and Memgraph offer together:API reference: We provide an overview of the key components you'll be working with, such as ChatOpenAI, GraphCypherQAChain, and MemgraphGraph.Populating the database: Learn how to populate your Memgraph database effortlessly using the Cypher query language. We guide you through the process of seeding data that serves as the foundation for your work.Refresh graph schema: Familiarize yourself with refreshing the graph schema, a crucial step in setting up the Memgraph-LangChain graph for Cypher queries.Querying the database: Discover how to interact with the OpenAI API and configure your API key. We'll show you how to utilize the GraphCypherQAChain to ask questions and receive informative responses.Chain modifiers: Customize your chain's behavior with modifiers like return_direct, return_intermediate_steps, and top_k. Tailor the experience to your preferences.Advanced querying: Delve into advanced querying techniques and uncover tips for refining your prompts to improve query accuracy.Ready to take your data interaction to the next level? Join us in exploring the seamless synergy between LangChain and Memgraph. No more wrangling with queries – just natural language and meaningful insights. Simplify complexity, elevate your insights, and share your projects in our community. "
5,"If you could interview a tech visionary, who would it be? What intriguing questions would you ask them about their coding journey and technological outlook?Join us on a journey that's all about newbies sharing, learning, and growing together. Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
6,"Yes it's out, yes people are using it, but now it's time for it to say hello! 👋Introducing, Sailhouse ⛵️!  Our mission and objectivesSailhouse is pub sub on easy mode. No infra, no clusters, no regions, no sizing. Just events, topics and subscriptions.Event-driven applications are a proven winner, Sailhouse is about making it as simple as possible to build them. With an intuitive CLI, powerful dashboard and slick integrations — you focus on building apps, we handle the plumbing.It's all quite simple really — making complex, reliable, and performant applications as easy to build as possible.Yes yes, big dreams, whatever.  The Sailhouse teamSailhouse is being built by people with experience, and passion, for developer tooling. With experience at industry/category-defining developer-focused companies such as Netlify, we know how to build a strong offering.Ed Stephinson, founder, tech lead of composable tooling at NetlifySalma Alam-Naylor, advisor, former DX at Netlify, soon to be somewhere exciting 👀  Where are we now?It’s a feature packed launch, but we’re in a great place to innovate.You can use the CLI or dashboard to manage your whole events system. From creating topics in a flash with sailhouse topics create or managing the Stripe integration from the dashboard, it’s tooling focused on usecases, not implementation detail.We’re focusing on our free-to-use beta. This is capped at 200 events a month (soft limit, with increasingly snarky emails the more you go over), while we fine tune what we’ve got.It can handle scale too, there was one 24 hour period processing over 40,000 events without us even noticing.We’ve got native SDKs for both Go and TypeScript (plus JavaScript, fear not), with more on the way.  What’s in store for the next 12 monthsAt a high level, here are our objectives for the next 12 months.Rollout Sailhouse from Beta -> StableBuild useful features, grounded in real-world usesIntegrations are a key part of thisIntroduce more SDKsFocus on stability and performanceRollout to more edge locationsMost importantly, build a rich, diverse and engaged community  Is Sailhouse Open Source?Yes, kinda.It's probable the core will always remain closed. That's both a business and practical decision. However, much like how Sentry have some of their services open-source, we may follow that route.  Go get started, like now, go!Our docs are open source! If you'd like to contribute, PRs and issues are actively welcomed. We're also building a community on discord for more real-time interaction. Otherwise, our trusty GitHub Discussions board is the place to raise feature requests and more."
7,"I was trying to post and dev.to was down for me.When you make a change, how do you know when an update is a bad break?Have you ever had a bad deployment?"
8,"Alex Lee, Frontend Engineer at Amazon, came on the podcast yesterday to discuss building a great resume, helping others navigate their careers, and evolving as an engineer.On the podcast, Alex shared:  Another common mistake [I see for folks new in the industry] is thinking that your resume isn’t going to really do much. You really need to focus on your resume because the resume’s the thing that most recruiters are going to look at.Alex shared a bunch of other tips in the podcast, but we want to hear what you think. It's always job hunting season and I'm sure we have a fair amount of folks here either looking for jobs or looking to give advice!What are your best resume tips?What is the most important advice you received when getting your first job as a developer?How can other developers level up their LinkedIn and resume when looking for a job?How can you make your LinkedIn stand out?ICYMI— find that episode below or wherever you get your podcasts:""The Journey from a Bootcamp to a FAANG"": CodeNewbie Podcast S25E2Sloan the DEV Moderator for CodeNewbie ・ Aug 23#podcast#career#codenewbie#beginnersSend us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
9,"How it started, How it's going and How you can do it too!Hello beautiful people, 🙋‍♀️I recently asked you on Twitter: ""what kind of articles would you like to read by me"" and one of the answers was ""from coder to public speaker"". Since I get this question quite often in DMs or in in-person conversations, I thought to publicly share it here too.  How It StartedIt all started on the last day of December 2017 when I wrote this article. 👇          What I Gained After 1 Year of #100DaysOfCode | by Eleftheria Batsou | Prototypr                  I am a slow walker, but I never walk back — Abraham Lincoln                blog.prototypr.io      Or should I say even earlier, when I took part in the challenge #100DaysOfCode (31 December 2016).Ok, let's start again!  My 1st timeOn the last day of 2017, I published an article on Medium where I shared my experience with #100DaysOfCode (which I finished in April 2017). I mentioned what exactly I studied, my projects, and in the end, I encouraged people to take part in the challenge too.That article later got the attention of Prototypr, and they asked me if they could share it in their publication too.But most importantly (for my public speaking career) it got noticed by the founder of the Umbraco framework! 😱The founder sent me an email (yes, I kept his emails from 2018) saying he enjoyed my article and asking me if I could present the same thing at a conference!At that time, I didn't know anything about conferences... not even meetups... heck, I didn't even have a developer's job! 😵‍💫So how would I go abroad (with no money and no experience) talking in front of a big experienced crowd.... The imposter syndrome kicked hard...But I'm not gonna lie, I was also super excited! I called my then-boyfriend and my parents to announce this big achievement!Me: ""Mom, I wrote an article and now they're calling me to speak at a conference in Denmark.""Me: ""Dad, I want to go, please let's go!""After asking the founder if they could cover my expenses (Denmark is an expensive country), and having him explain to me that there are ""Sponsors"", hence they can do it, I was super excited to book my flight tickets.My Dad came with me. He took this photo of me:Photo: 25 May 2018. Odense, Denmark. A few hours after my 1st presentation.By the way, you watch here the presentation. After a few months, it was reshared in #FreeCodeCamp's YouTube channel (another personal big win ~ more than 183K people have watched it 🤯).  My 2nd TimeI explained above my 1st time, but how about my 2nd? Did I keep writing articles, hoping someone would notice them?!Not exactly...A few months after my 1st talk, I received an email asking me if I wanted to present the same talk in Germany. The event was organized once again by the Umbraco community (so they had seen my work in Denmark) but this time they weren't covering my expenses as it was a community event (and not a conference with big sponsors). I politely declined.I thought that was it. I was never going to speak at conferences...And then, after a few months, I received another email. They were asking me the same thing only this time they were covering my expenses and the conference was in the Netherlands!I immediately said ""yes"".Photo: 12 October ‎2018, Utrecht, The Netherlands. During my talk.  How Did I Continue?Okay, now I explained my 1st and 2nd time. But how did I really continue?That night in Utrecht, after my talk, a few speakers and organizers got together in a cute little bar-restaurant. If you know me (even through social media) you know I'm super shy ~ which means I didn't wanna go...But thank god I did! 🙏Photo: 12 October ‎2018, Utrecht, The Netherlands. I'm the one in the blue circle.During the evening I asked the other speakers about their public speaking journeys and they suggested a few practical tips on how I can do it. The conversation was mostly about how I can find conferences and apply to them (more about that a bit later, in the section ""How you can do it too"").  Was It Luck or Hard Work?I used to ask myself ""Is it luck or hard work?""Yes, a part of it may be luck.I mean what are the chances a founder reads your article, finds it suitable enough for his conferences, and asks you to join them in a conference as a 1st time speaker?!But now, let's go back to the last day of 2016 (1st photo), where I publicly shared I'm taking part in the #100DaysOfCode challenge.Not only did I successfully finish the challenge but later I wrote an article about it.In the meantime, I kept practicing and doing other coding challenges.I found a developer's job that I really liked.I started using Twitter more and more and I also started posting YouTube videos with what I was learning (which fun fact: this led me to my 1st contract job).If I didn't do these things would I ever be a public speaker? I honestly doubled that...(Feel free to comment below if you have a different opinion.)  How It's Going?My excitement every time they invite me to a conference is still as big as it was the first time. I'm thankful for these opportunities and I don't take them for granted.I started in 2018 and I'm planning to keep going as long as I have something valuable to share.I visited more than 20 countries, and 3 continents (Europe, Africa, and the USA). 🌍I met people from all over the world. 👯I wouldn't change anything. 💓  How You Can Do It TooDo you want to be a public speaker? Here is the tea: 🍵Find a topic that you like to talk about. It can be a hot topic, a recent project that you think is super cool and people must know about it, etc.Create a presentation or at least a written plan of what you want to talk about.Now go to sessionize.com or papercall.io and create your ""speaker's profile"". This means you have to add some basic information about yourself AND you can add the topic you want to talk about.Last but not least, scan for conferences and apply.Note: I don't want to lie ~ Just because there are 4 steps it doesn't mean it's super easy or you'll spend a couple of minutes and then organizers will start calling you.No. Spend time refining your profile and your proposal.You'll get many rejections too and that's ok. Most of us do, and I guess even very experienced speakers do.One of the most important factors to get selected is to have a topic that aligns with the conference's topics.For example, I may want to talk about security, but the conference is about JavaScript. Even if I have the perfect presentation, they'll never select me!P.S. A few years ago I wrote this article, if you get selected as a speaker, do check it. 😇Public Speaking: 15 Practical Tips For Your Presentation | by Eleftheria Batsou | MediumEleftheria Batsou ・ Feb 16, 2020 ・               eleftheriabatsou.Medium      Public Speaking: 15 Practical Tips For Your Presentation  Fun FactI did mention that my 1st talk was in Denmark ~ Well, now that I'm writing this article I'm in Denmark again!No, I don't live here, but we had a company event.  QuestionsLet me know if you have any questions and I'd love to answer them for you.👋 Hello, I'm Eleftheria, devrel and content creator.🥰 If you liked this article, consider sharing it.🌈 All links | Twitter | LinkedIn | Book a meeting"
10,"Written by Clara Ekekenta✏️In this tutorial, we’ll use the Bun Bundler to create a fast, Next.js-like blog application with server-side rendering (SSR) and client-side hydration. We’ll also explore Bun’s new JavaScript Macros feature, which is part of the tighter integration that Bun aims for between its bundler and runtime to boost speed. Let’s get started! Jump ahead: Prerequisites What is Bun? What is Bun Bundler? Manually bundling a project with Bun Setting up the environment Setting up the Node.js project Creating the application files Bundling the application Running the application Automatically bundling a project with Bun Creating a new Bun project Understanding SSR and hydration Creating pages Creating a post page Adding interactivity Adding styling Using Bun Macros  PrerequisitesTo follow along with this tutorial, you’ll need the following:  Node.js v14 or later installed on your machine  npm; this is usually bundled with Node.js  CURL; you can install it with the following command: sudo apt install curl  A basic understanding of Typescript, React, and web development principles will be beneficial but is not required  What is Bun?Bun is a sophisticated JavaScript runtime that is equipped with inbuilt Web APIs, including Fetch and WebSockets, among many others. It incorporates JavaScriptCore, an engine renowned for its speed and memory efficiency, even though it's typically more challenging to embed compared to popular engines like V8. Bun is designed to expedite the JavaScript development process to unprecedented speeds. As an all-inclusive tool, Bun doesn't just enhance compilation and parsing rates, it also comes with its own suite of tools for dependency management and bundling. This makes Bun a comprehensive, one-stop solution for developers looking to optimize their workflow and improve efficiency.  What is Bun Bundler?Bun Bundler is a fast native bundler that is part of the Bun ecosystem. It is designed to reduce the complexity of JavaScript by providing a unified plugin API that works with both the bundler and the runtime. This means any plugin that extends Bun's bundling capabilities can also be used to extend Bun's runtime capabilities. Bun Bundler is designed to be fast, with benchmarks showing it to be significantly faster than other popular bundlers. It also provides a great developer experience, with an API designed to be unambiguous and unsurprising. Bun Bundler supports a variety of file types and module systems, and it has inbuilt support for tree shaking, source maps, and minification. It also has experimental support for React Server Components.  Manually bundling a project with Bun To get started with this tutorial, let’s walk through the process of setting up a project and manually bundling and running it with Bun.  Setting up the environment First, we’ll need to install Bun on our Linux machine. Let’s run the following command on the terminal:curl -fsSL https://bun.sh/install | bashEnter fullscreen modeExit fullscreen mode Once installation is complete, we’ll run the following commands to add Bun to $PATH and confirm the build:exec /bin/zsh bun --help Enter fullscreen modeExit fullscreen mode  Setting up the Node.js project Next, we’ll need to set up our project environment. Let’s start by creating a new directory for our project and navigate into it:mkdir bun-blog && cd bun-blogEnter fullscreen modeExit fullscreen modeThen, we’ll initialize a new Node.js project:npm init -yEnter fullscreen modeExit fullscreen mode  Creating the application files For this tutorial, we'll start by creating a simple client-side rendered React app. We’ll create two files, index.tsx and Blog.tsx, and then add the following code to the Blog.tsx file:export function Blog(props: {title: string, content: string}) {  return (    <div>      <h2>{props.title}</h2>      <p>{props.content}</p>    </div>  );}Enter fullscreen modeExit fullscreen modeNow, let’s import the the Blog function in the index.tsx file:import * as ReactDOM from 'react-dom/client';import React from 'react';import { Blog } from './Blog.tsx';const root = ReactDOM.createRoot(document.getElementById('root'));root.render( <Blog title=""My First Blog Post"" content=""This is the content of my first blog post."" />)Enter fullscreen modeExit fullscreen mode  Bundling the application Next, we’ll bundle our application using the following command:bun build ./index.tsx --outdir ./outEnter fullscreen modeExit fullscreen modeThe bun build command tells Bun to generate a new bundle from the index.tsx file and write it to the ./out directory. The bundled file will be ./out/index.js. Let’s create an index.html file in the ./out directory to run the file with the code snippet below:<!DOCTYPE html><html lang=""en""><head>    <meta charset=""UTF-8"">    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">    <title>My App</title></head><body>    <div id=""root""></div>    <script type=""module"" src=""./index.js""></script></body></html>Enter fullscreen modeExit fullscreen mode  Running the application To run our application, we’ll need to serve the ./out directory. We can do this by using the bunx serve command, like so:bunx serve outEnter fullscreen modeExit fullscreen modeTo see the bundled app in action, visit http://localhost:5000.  Automatically bundling a project with Bun Instead of manually creating the application files and bundling them as we did previously, we can leverage the bun create react-ssr command, which has been updated to use Bun.build under the hood. This will enable us to easily scaffold a new SSR project.  Creating a new Bun project To start, we’ll need to create a new Bun React server-side rendered project with the command below:bun create react-ssrEnter fullscreen modeExit fullscreen modeNext, let’s navigate to the project folder and run the application:cd react-ssrbun installbun run devEnter fullscreen modeExit fullscreen modeAfter running the above command, the Bun application will run on http://localhost:3000:  Let’s take a look at the important files in this newly created project: dev.tsx: This file is instrumental in the development process. It constructs a browser version of all pages via Bun.build. When the development server is active, it responds to incoming requests by rendering the corresponding page from the pages directory into static HTML. This HTML output includes a <script> tag that sources a bundled version of the hydrate.tsx file hydrate.tsx: The primary role of this file is to reinvigorate the static HTML sent back by the server, ensuring a smooth and dynamic user experience on the frontend pages/*.tsx: This directory comprises various pages that align with Next.js routing conventions; the system routes incoming requests based on the defined pages in this directory  Understanding SSR and hydration When we talk about modern web applications, two terms that frequently come up are server-side rendering and hydration. Let’s take a closer look to gain a better understanding: SSR: In traditional web applications, rendering often takes place on the client side, but with SSR the server plays a more proactive role. When a user makes a request, the server pre-renders the page into HTML and sends this static HTML as a response. This results in faster initial page load times and better SEO performance. In our project, the dev.tsx file handles this process, ensuring that the appropriate page in the pages directory is converted to static HTML for incoming requests Hydration: While SSR provides the initial speed, we don't want our app to remain static; we want it to be interactive. This is where hydration comes in. After SSR sends the static HTML page to the browser, the associated JavaScript (in our case, the hydrate.tsx file) runs to “hydrate"" this static page, attaching event listeners and making it fully interactive. This creates a seamless transition from a static page to a dynamic app without reloading the browserTogether, SSR and hydration give us the best of both worlds — a fast initial load time with a rich, dynamic user experience.  Creating pagesBun adopts a file system-based routing approach, similar to Next.js. Here we’ll update the react-ssr/pages/index.tsx file to fetch some blogs from the JSONPlaceholder API. Then we’ll create another page to handle the creation of new blog posts. Let’s start by updating the react-ssr/pages/index.tsx file with the following code:import { useEffect, useState } from ""react"";import { Layout } from ""../Layout"";import { IBlog } from ""../interface"";export default function () {  const [posts, setPosts] = useState([]);  useEffect(() => {    async function getPosts() {      const res = await fetch(""https://jsonplaceholder.typicode.com/posts"");      const posts = await res.json();      console.log(posts);      setPosts(posts);    }    getPosts();  }, []);  return (    <Layout title=""Home"">      <div className=""posts-container"">        <a href=""/posts"">Create New Post</a>        {posts?.map((post: IBlog) => (          <article key={post.id} className=""post-article"">            <h2 className=""post-title"">{post.title}</h2>            <p className=""post-content"">{post.body}</p>          </article>        ))}      </div>    </Layout>  );}Enter fullscreen modeExit fullscreen modeHere, useEffect fetches posts from the API whenever the Home component is mounted. The posts are stored in the component's local state and are displayed on the screen. This ensures that the displayed data is fresh every time the component is rendered, making it suitable for data that updates frequently. Now, let’s create an IBlog interface in the react-ssr/interface folder and add the following code:export interface IBlog {    id: string;    title: string;    body: string;}Enter fullscreen modeExit fullscreen mode  Creating a post pageTo allow authors to create new posts, we’ll need to build a post page. Let’s create a posts/index.tsx file in the react-ssr/pages/ folder, like so:import { Layout } from ""../../Layout"";export default function () {  return <Layout title=""Create a new Post""></Layout>;}Enter fullscreen modeExit fullscreen mode  Adding interactivityTo bring our blog to life, we’ll need to add some interactive elements. We'll start with a simple form on our posts/index.tsx page to gather information for new posts. Since we do not have a backend for this application, we’ll store the posts in the JSONPlaceholder API:import { useState } from ""react"";import { Layout } from ""../../Layout"";export default function () {  const [title, setTitle] = useState("""");  const [body, setContent] = useState("""");  const handleSubmit = (e: { preventDefault: () => void }) => {    e.preventDefault();    // we'll handle the submission logic here later  };  return (    <Layout title=""Create a new Post"">      <div>        <form onSubmit={handleSubmit}>          <label>            Title:            <input              type=""text""              value={title}              onChange={(e) => setTitle(e.target.value)}            />          </label>          <label>            Content:            <textarea              value={body}              onChange={(e) => setContent(e.target.value)}            />          </label>          <button type=""submit"">Submit</button>        </form>      </div>    </Layout>  );}Enter fullscreen modeExit fullscreen modeThe above code defines a React functional component named CreatePost. It uses the useState Hook to manage local state for the title and content of a new post, initially setting both to an empty string. It also sets up a handleSubmit function to be used when the form is submitted, although we have not yet implemented the form submission. The component's render function returns a form with two input fields, for the title and content, and a submit button. The state of the title and content is linked to their respective input fields, with their state being updated whenever the input field value changes. Next, let’s update the handleSubmit function in the posts/index.tsx file to store the new post:...import { IBlog } from 'interface/IBlog';...  const handleSubmit = async (e: { preventDefault: () => void; }) => {    e.preventDefault();    const id = Math.random().toString(36).substr(2, 9);    const newPost: IBlog = { id, title, body };    // Send a POST request to the JSONPlaceholder API    const res = await fetch('https://jsonplaceholder.typicode.com/posts', {      method: 'POST',      body: JSON.stringify(newPost),      headers: {        'Content-type': 'application/json; charset=UTF-8',      },    });    const data = await res.json();    console.log(data);    setTitle("""");    setContent("""");  };...Enter fullscreen modeExit fullscreen modeThe handleSubmit function that we mentioned previously is an event handler for form submissions. It first prevents the default form event; then it generates a unique id and creates a new post with the title and body from the state. The new post is then sent to the JSONPlaceholder API via a POST request. The response from the server is logged to the console, and the form is reset by clearing the title and content states.  Adding stylingNow we’ll add some styling to our blog application to make it visually appealing. Let’s update the public/index.css file to style all the components in the application, like so:.posts-container {  display: flex;  flex-direction: column;  align-items: center;  margin: 2rem auto;  padding: 1rem;}.post-article {  width: 80%;  margin-bottom: 2rem;  border: 1px solid #ddd;  border-radius: 10px;  padding: 1rem;  box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);}.post-title {  font-size: 2rem;  color: #333;  margin-bottom: 1rem;}.post-content {  font-size: 1rem;  color: #666;}Enter fullscreen modeExit fullscreen mode  Using Bun MacrosBun Macros is a powerful feature in Bun that allows us to replace parts of our code with other code at build time. This can be useful for a variety of scenarios, such as optimizing performance, removing code that isn't needed in a particular build, or improving code readability. In our blog application, we‘ll use Bun Macros to replace the API URL with a local storage key when we're running tests. Not having to make actual API calls during testing will make our tests faster and more reliable. First, we’ll create a macro.ts file and then use the createMacro function from bun.macro to create the macro. In this tutorial, we'll create a macro that replaces the API URL with a local storage key:export const apiUrl = () => {  if (process.env.NODE_ENV === 'test') {    return 'localStorageKey';  } else {    return 'https://jsonplaceholder.typicode.com/posts';  }};Enter fullscreen modeExit fullscreen modeNow, we can use this macro in our handleSubmit function:...import {apiURL} from './macro.ts' with { type: 'macro' }...   const handleSubmit = async (e: { preventDefault: () => void; }) => {    e.preventDefault();    const id = Math.random().toString(36).substr(2, 9);    const newPost: IBlog = { id, title, body };    // Use the apiUrl macro    const res = await fetch(apiUrl(), {      method: 'POST',      body: JSON.stringify(newPost),      headers: {        'Content-type': 'application/json; charset=UTF-8',      },    });    const data = await res.json();    setTitle("""");    setContent("""");  };...Enter fullscreen modeExit fullscreen modeWith this, our blog application is complete! We've used Bun Bundler to create a fast, Next.js-like blog application with server-side rendering and client-side hydration.  ConclusionIn this tutorial, we demonstrated how to set up a project using Bun, create a simple application, bundle it using Bun Bundler, and serve it using Bun's inbuilt server. We also showed how to simplify the process of setting up a new project using the bun create command, which uses Bun.build under the hood. Bun Bundler is a powerful tool that can help reduce the complexity of your JavaScript projects and improve your development speed. Its integration with the Bun runtime and its support for a wide range of file types and module systems make it a versatile tool for any JavaScript developer. Whether you're building a simple client-side app or a complex full-stack application, Bun Bundler has the features and performance to meet your needs.  Are you adding new JS libraries to improve performance or build new features? What if they’re doing the opposite?There’s no doubt that frontends are getting more complex. As you add new JavaScript libraries and other dependencies to your app, you’ll need more visibility to ensure your users don’t run into unknown issues.LogRocket is a frontend application monitoring solution that lets you replay JavaScript errors as if they happened in your own browser so you can react to bugs more effectively.LogRocket works perfectly with any app, regardless of framework, and has plugins to log additional context from Redux, Vuex, and @ngrx/store. Instead of guessing why problems happen, you can aggregate and report on what state your application was in when an issue occurred. LogRocket also monitors your app’s performance, reporting metrics like client CPU load, client memory usage, and more.Build confidently — Start monitoring for free."
11,"AMA Day has arrived! Fire away with your questions! What pressing queries would you direct at our skilled moderators and experienced community members, all geared up to provide guidance?Join us on a journey that's all about newbies sharing, learning, and growing together. Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
12,"  Hello there!This post here is to go through (with you) my thought process when trying to create and release a side-project idea. It's really important to try to get around the chaos of the creative process and stablish a structured process for any project. After reading my thoughts on this, feel free to engage the discussion and comment something below 👍If you just want to check what was the project made, you can check it here.  The first step: The IDEAThis is where many of you can suffer a lot. I think we can divide the general programming public in two segments: the more creative ones and the more pragmatic ones, generally, more pragmatic people will have difficulties having an idea while creative people will  have difficulties taking it out of the paper. My approach to this is generally think of problems that impact my daily basis, all those problems require solutions and solving it for you can help others with the same problem too! Taking problems that exists within hobbies or trying to create solutions to problems that people you know have can be a great way to get your mind started.The most important tip here is just to start creating. Sometimes we spent so much time thinking about the perfect idea that we end don't creating anything. Always remember: Not-perfect is better than inexistent.  The second step: The planningAfter defining the ideia, you should go to plan before the code (sometimes, when the project is really, REALLY small, you can skip this and go direct to code, but beware, if you skip this step when you should not, it's going to bite you later).The planning stage is kinda simple, get a somewhat free tool like Figma, or draw.io and put your idea in the white canvas. Don't worry too much if it does not make a lot of sense, the whole idea of this step is to achieve this.Draw flows, databases, pages, start creating and don't have fear of making some mistakes. Don't forget to look into references too, they can give you a lot of inspiration!   The third step: The refinementAfter you created the draft, it's time to create the definitive version of your project prototype. Define a scope and gather everything you think it's useful within that scope, refining the flows in order to have a good UX - this is majorly important, even with small projects (sometimes, we, as developers, can overlook the experience of the application, but whenever you'll need to show this project to someone, the UX that is what is going to be evaluated).Since UX is really important, gather this Laws of UX and try to create a good consistent design.If the project you are creating does not includes front-end and UX is not the problem, this doesn't mean you can create in the most chaotic way possible. Anytime you are creating something, spend some time to improve your skills and learn new things, unit and e2e testing, design patterns and architectural patterns can make a whole lot of difference and can be really fun to learn (you can check here to learn more)  The fourth step: The codeCode until it's done or until you are happy with the result (always remember, you can finish the project in another day)  The fifth step: The releaseAfter you are done with the first version of the product, make a release plan! Where are you going to discuss about it? Never underestimate the power of organic conversion, many people can see your project even when you don't expect to.Think of metrics that will gather good insights for creating more things for the product later and track them using analytics services like umami or others.  The practical case:The problem: I really did not like the experience of searching for specific items in the wiki of Warframe (a game that I enjoy). I would like to have a better experience when searching for items and where to get them.The idea: Create a website that would get data from Warframe's item API and would inform things that are useful for the user looking to get them (like price value, drop location, and things like that).The planning: Started to sketch the flow in draw.io until it looked reasonably nice. After that, started playing around with the UI components that Skeleton UI have until I was satisfied with the appearance of it.The refinement: I defined a more ambitious scope, while started to research how I could get things from the API. After that, the whole project was already kinda structured and we could start to code for realThe code: Decided to use Svelte and SvelteKit (since I'm learning both of them) and started to code! Created a git repo, initialized the dev environment and created things like I planned before.The release: Expected to release it in the reddit community of Warframe and see what kind of reactions I got! The sheer number of views and most visualized pages were interesting enough data for me to track.The post:The statistics:And now, I'm posting it here (and probably will update this to reflect how other DEVs react to the post! Thanks for reading! You can see the project live here"
13,"Problem StatementSometimes, you got a challenge on labeling or tagging of various Kubernetes resources, including Pods, Deployments, StatefulSets, and PersistentVolumeClaims (PVCs). Consequently, you are unable to enforce admission webhooks or AWS Security Control Policies on Volumes. In Kubernetes resource management, labels play a pivotal role. Labels are key-value pairs affixed to Kubernetes resources, enabling effective categorization, organization, and resource selection based on diverse criteria. They empower you to add metadata to resources, thereby streamlining operations, facilitating monitoring, and enhancing access control.SolutionYou can write a bash script that utilizes the Kubernetes Command line tool. This solution entails implementing a labeling strategy, enabling you to effectively categorize and tag your Kubernetes resources. Consequently, you can apply AWS Security Control Policies and manage your resources more efficiently.Example Bash Script for Resource LabelingYou can execute a bash script to apply labels to Kubernetes resources within the namespace. Below is an illustrative script that iterates through Deployments in a given namespace and applies customized labels using a patch operation:#!/bin/bashwhile true; do    for deployment in $(kubectl -n $namespace get deployment | awk '{print $1}');    do        kubectl patch deployment $deployment -n $namespace --patch-file=""patch-labels.yaml"";    done;doneEnter fullscreen modeExit fullscreen modeThe content of ""patch-labels.yaml"" could be:spec:  template:    metadata:      labels:        ApplicationID: APP-1234        Environment: nonprod        Owner: VictorLeungEnter fullscreen modeExit fullscreen modeOnce all the resources are patched, it could be terminated by Ctrl + C in the terminal.Script Parameters Explanationwhile true; do: This initiates an infinite loop for continuous monitoring and updating of Deployments.kubectl -n $namespace get deployment: This command retrieves the list of Deployments in the specified namespace (replace ""$namespace"" with the appropriate namespace).for deployment in $(...); do: This loop iterates through the Deployments obtained from the previous command.kubectl patch deployment $deployment -n $namespace --patch-file=""patch-labels.yaml"": This command applies a patch to the deployment specified by the variable $deployment in the given namespace. The patch content is defined in ""patch-labels.yaml"".Adaptation for Different Resource TypesThis script can be adapted for other Kubernetes resource types, such as StatefulSets and PVCs, by modifying the relevant commands and target resources. For instance, for StatefulSets:#!/bin/bashwhile true; do    for sts in $(kubectl -n $namespace get sts | awk '{print $1}');    do        kubectl patch sts $sts -n $namespace --patch-files=""patch-labels.yaml"";    done;doneEnter fullscreen modeExit fullscreen modeSimilarly, for PVCs:#!/bin/bashwhile true; do    for pvc in $(kubectl get pvc | awk '{print $1}');    do        kubectl patch pvc $pvc --patch-file=""patch-labels.yaml"";    done;doneEnter fullscreen modeExit fullscreen modeThe content of ""patch-labels.yaml"" could be:metadata:    labels:    ApplicationID: APP-1234    Environment: nonprod    Owner: VictorLeungEnter fullscreen modeExit fullscreen modeConclusionIntegrating custom labels into Kubernetes resource management offers an effective solution for asset tagging and categorization. Leveraging Kubernetes' flexible labeling mechanism empowers you to better organize, secure, and manage your resources. By using bash scripts as demonstrated, you can bridge the gap, enhancing your overall operational capabilities and ensuring better control over your Kubernetes environments."
14,"I tweeted/posted out a half-joking question the other day about the usage of the <div> tag still.Then I started a small conversation. Then I got to thinking. Why are devs not using <main> more often?  The ""why""I've concluded my accessibility auditing career as of yesterday when I audited an education platform that was extremely inaccessible. The documentation was over 100 pages that I sent back to the client. That is a lot. Not the most, but it is a lot. Usually 100 pages are par for any high-level audit that I have done as a solo consultant.The fact that I saw usage of the <header> and <footer> elements, yet so sign of <main> was there. The elements from HTML5 used were:<header><nav><section><article><aside><footer>No <main> as far as the eyes could see.I mean there was no sign of the element to be found.  The ""What""Is it fear? I mean, I know it really isn't fear, but is it lack of education (yes) or is it lack of understanding semantic HTML and the benefits of using semantic HTML over an element that has no semantic meaning?I have seen a lot of replies when I have asked this in the past and in 25 years of asking it is usually the same repsonses:Don't have time to deal with HTML.Not enough time to deal with it now.It's X framework and I can't change that. (You can if it is open source).It's habit and I just do it that way.What is semantic HTML?I'm using native apps, not hybrid/web app.These are among a lot of reasons. I get it, but I got it 20 years ago. 10 years ago. 5 years ago maybe. But in 2023? Now that HTML5 has been out since 2008 (15 years ago), developers should know about HTML5.Whether they know is one thing. They should. You should. Whether they care or whether you care, is another. You all should care.I mean if you're using other HTML5 elements, why omit <main>? That says to me, that whomever it may be, you're being lazy if you know and if you are uneducated about HTML5, you're not doing the research. <main> is one of those elements that is widely known.  So what? Big Deal.These ""landmarks"" have an impact on accessibility. If you have ever read the bulk of my articles, they are on accessibility. Using HTML5 landmarks as they are intended is  helping out people with disabilities by making the structure of the page accessible to screen reader technology and other assistive technology(AT) e.g., keyboard navigation.When I see this when I am creating a new project in a framework:<!DOCTYPE html><html lang="""">  <head>    ...  </head>  <body>    <div id=""app""></div>  </body></html>Enter fullscreen modeExit fullscreen modeI'll tend to ask when doing an accessibility audit ""why aren't you using <main>?"" and only if it is a web or hybrid app knowing you'd have to file an issue and ask for the <div> to be changed to <main> but that isn't something I'd expect to happen but I am not opposed to it at all.What I would like to see more of is this, if applicable:<!DOCTYPE html><html lang="""">  <head>    ...  </head>  <body>    <main id=""app""></main>  </body></html>Enter fullscreen modeExit fullscreen mode  The BenefitsSkip to content links. When someone using keyboard navigation or AT wants to skip repeated content, they can easily skip to the #main content area.It's the fresh, new, and cool wrapper div! I'd use <div id=""wrapper""> a lot until 2008, then I started to use <main id=""wrapper""> or whatnot when using HTML5 more often in projects. It's a landmark, why not use it?Reader mode looks for the <main> element as well as headings and content structure when converting the content into reader view.<main> is a lot easier for maintenance and code readability. You'll be able to visually spot a <main> element much faster than a <div> within a vast sea of divs in that bowl of div chowder.Using <main> could also possibly save some bytes within your files (CSS or otherwise) in that you can use main in the stylesheet instead of using classes or IDs (e.g., .main or #main).Without <main> assistive technology cannot create an accurate outline (accessibility tree) of the page's content.and I am sure there are more that I'm not listing, but the fact is and let's face it, if you're going to use all the other HTML5 landmarks, just use the main landmark in a web or hybrid web app or if you are authoring a Web page.That's it. Don't be scared of <main> and if you already weren't, just use it if it is applicable in the project.If you are not sure of how to use main, educate yourself. You could read the spec or the MDN docs which should be the de facto resource for researching anything HTML or CSS.I get that there are cases where it is a <div> and what I am saying is moot. I know that, I understand that, I got it. But...If you can use <main>, get it in there and make the experience just a little more accessible.Photo by Jas Min on Unsplash"
15,"People migrate JavaScript applications to TypeScript for many reasons, including helping developers catch errors quickly during development. But, converting a project from JavaScript to TypeScript can be complicated. Luckily, there are tools that can help us with the migration. In this blog post, we'll explore how Copilot Chat aids in migrating your JavaScript application to TypeScript.  What is Copilot Chat?Copilot Chat is a chat interface that allows you to ask coding-related questions and receive answers directly in a supported IDE.   Migrating JavaScript to TypeScriptIn my case, I built an AI-powered task management app built with Next.js and the Web5 SDK. I wanted my Next.js project to use TypeScript. I plan to add more features to this application, and switching to TypeScript can help me manage the application's maintainability. Unfortunately, I couldn’t remember all the steps for converting a JavaScript application to TypeScript because it’s not something I do everyday, so I leaned on Copilot Chat for help.   Step 1: Ask Copilot Chat for assistanceTo get started, I opened my project in my preferred IDE (Codespaces/Visual Studio Code), and I asked Copilot Chat, “Can you help me convert my Next.js project to TypeScript?“ Copilot Chat responded to my query with a step-by-step guide.   Step 2: Install required typesFirst, Copilot Chat recommended running a command in my terminal to install the required types for Next.js and React.npm install --save-dev typescript @types/react @types/node Enter fullscreen modeExit fullscreen mode  Step 3: Rename my filesNext, Copilot Chat then suggested I rename all my files from .js to .tsx. It further explained that using a .tsx file extension helps TypeScript realize the file contains JSX.   Step 4: Create a tsconfig.json fileThen, to configure the TypeScript compiler and specify how TypeScript code should be compiled, Copilot Chat suggested I create a tsconfig.json at the root of my project. It also provided compilerOptions that I could just copy and paste into the file.{  ""compilerOptions"": {    ""target"": ""esnext"",    ""module"": ""commonjs"",    ""lib"": [""dom"", ""dom.iterable"", ""esnext""],    ""allowJs"": true,    ""jsx"": ""preserve"",    ""noEmit"": true,    ""isolatedModules"": true,    ""esModuleInterop"": true,    ""strict"": true,    ""noImplicitAny"": true,    ""moduleResolution"": ""node"",    ""resolveJsonModule"": true,    ""skipLibCheck"": true,    ""forceConsistentCasingInFileNames"": true  },  ""include"": [""next-env.d.ts"", ""**/*.ts"", ""**/*.tsx""],  ""exclude"": [""node_modules""]}Enter fullscreen modeExit fullscreen mode  Step 5: Modify my next.config.js fileCopilot Chat recommended I update my next.config.js file, enabling Webpack to recognize and compile the TypeScript files in my project.module.exports = {  // ...  webpack(config, options) {    config.resolve.extensions.push('.ts', '.tsx');    return config;  },};Enter fullscreen modeExit fullscreen mode  Step 6: Update my package.json fileCopilot Chat suggested I add the following scripts to my package.json{  ""scripts"": {    ""dev"": ""next dev"",    ""build"": ""next build"",    ""start"": ""next start"",    ""type-check"": ""tsc"",    ""lint"": ""eslint . --ext .ts,.tsx""  }}Enter fullscreen modeExit fullscreen mode""type-check"": ""tsc"" runs the TypeScript compiler to check my TypeScript code for errors. ""lint"": ""eslint . --ext .ts,.tsx"" runs the ESLint linter to check my code for style and syntax errors.   Step 7: Convert the code in my index fileThe final step involved converting the code in my index file to TypeScript. Copilot Chat converted my index.js file to use TypeScript syntax. Additionally, Copilot Chat generated two interfaces for a Task and a Subtask to ensure type safety.interface Task {  id: string;  text: string;  subTasks: SubTask[];}interface SubTask {  text: string;  completed: boolean;}Enter fullscreen modeExit fullscreen mode  The Beauty of Copilot ChatHere’s what I love: in addition to streamlining a potentially intimidating migration process, Copilot Chat also provided clear explanations for each change. This helped me make informed decisions about the AI-generated code that I added. I could also ask Copilot Chat follow-up questions for concepts or suggestions that I’m still unclear about. For example, I asked Copilot Chat: “Why do I need to update my package.json?“In response, Copilot Chat informed me that the update would assist me in type-checking my code. It also broke down each line in the new package.json ""dev"": ""next dev"" starts the development server for your Next.js application. ""build"": ""next build"" builds your Next.js application for production. ""start"": ""next start"" starts the production server for your Next.js application. ""type-check"": ""tsc"" runs the TypeScript compiler to check your TypeScript code for errors.""lint"": ""eslint . --ext .ts,.tsx"" runs the ESLint linter to check your code for style and syntax errors.   Looking to try out Copilot Chat?Check out Kedasha Kerr’s blog post on Getting Started with Copilot Chat.   How have you been using generative AI to assist you with your role?Let me know in the comments below!"
16,"  TL;DRI’m an indiehacker that likes creating lots of fun side-projects, like my SaaS app CoverLetterGPT with ~4,000 users. That’s why I've been on the lookout for AI-assisted coding tools to help me kickstart new full-stack web apps as quickly as possible.I tried out a bunch, but found that most of them produced codebases that were too simple to work with, or getting a good result was just about as time consuming as coding it myself.But through the process of trying out different tools and methods, I stumbled across a hack that helped me create comprehensive, functional codebases for full-stack apps with Auth, API routes, Tailwind CSS, DB management, and other more complex features.The trick? Ask ChatGPT to write you a detailed Product Requirement Doc for the app you’d like to create, and then pass this to Wasp’s GPT Web App Generator. The results are really surprising and give you a far better starter codebase than the other tools I’ve tried (mainly due to the specificity of the generator itself). And best of all, its free to use! 🤑  Support us! 🙏⭐️If you wish to express your support for what we are doing, consider giving us a star on Github! Everything we do at Wasp is open source, and your support motivates us and helps us to keep making web app development easier and with less boilerplate.⭐️ Thanks For Your Support 🙏  IntroI’m a self-taught, full-stack web developer and I have a lot of fun building side-projects.For example, the side-project I’m most proud of is an open-source cover letter generator SaaS App, CoverLetterGPT, which has close to 4,000 users!I also have a lot of ridiculous side-project ideas, like this app that can turn your favorite tech influencer’s YouTube videos into a drinking game. 🤣That’s why I’ve been trying out lots of AI-assisted coding tools in an effort to generate fully-functional, full-stack web apps as quickly as possible.There are the obvious tools at the moment, like using ChatGPT and Copilot within your IDE, but there are new ones popping up all the time, especially those that act as AI-assistants or “agents”. I’ve gotten a chance to try out some of them, and I even wrote a long-form comparison piece where I put two such tools to the test, so check that out if you’re interested. But there’s a major problem with these tools: even though they’re able to generate some good boilerplate code, they often include a lot of errors and don’t make the developers job that much easier in the end.  Where the problem liesOn paper, AI-assisted coding tools generally save devs time and effort, especially when it comes to isolated code snippets.On one hand, we have tools like ChatGPT and Copilot, which aid you with refactoring, fixing errors, or generating a snippet of code. It's much like assembling a jigsaw puzzle, where the tools serve you the next piece that fits the immediate gap. But coding isn't just about filling the next available space; it’s about envisioning the entire picture, understanding the broader system and how different pieces interrelate.AI-assisted coding tools that behave more like agents have the potential to understand this broader context needed to generate larger codebases, but it’s easier said than done. Currently, most of the tools out there end up generating code that comes full of errors.Worst of all, some of the code they output can be so messy it actually means more work for you.  How to fix itAI-assistants, much like novice apprentices, need a comprehensive understanding of what they should work towards. To achieve this, you need to craft a detailed outline along with a comprehensive set of instructions to give the AI as much context as possible. You essentially want to be taking on the role of a Product Manager/Designer and be giving the AI a Product Requirement Document (PRD), i.e. an authoritative document that clearly outlines thepurpose,features,functionality,and behaviorof the product to be developed.But supplying the PRD is just half the battle. This is because components of your web app within the frontend and backend need to know about each other. And this is where most of these tools fall short, with tools like Smol-Developer creating decent client and server code that work great on their own, but unfortunately don’t work together!Given this, it seems like an AI-tool that already knows the ins and outs of the whole system, that understands the interconnectedness of various parts of a web app, is our best bet. In short, we need a tool that doesn't just 'do its task' but 'understands the project'.  The Best Tool for the Job: GPT Web App Generator.Remember, I’m focusing on generating comprehensive full-stack codebases here, and for that Wasp’s GPT Web App Generator gets the job done surprisingly well.How does it do this? Well, the full answer lies in how Wasp as a framework is able to help you build full-stack React/NodeJS web apps. It’s beyond the scope of this article to explain it in full detail, but the TL;DR is that Wasp has a compiler that helps build your app based on a config file. The config file is like a set of instructions that its compiler understands and uses to piece together the different parts of the full-stack app for you. This is what makes it easier for the AI to get all the pieces of the app right! Once it writes the fundamental client and server code, along with the main config file, the Wasp compiler takes over and pieces it all together, removing a lot of potential possibilities for errors!In the end, you get a React/NodeJS codebase with features like:full-stack authserver config and API routestailwind css config and stylescron jobs and queuesemail sendingdeploymentWhat’s cool too is that this tool doesn't require you to be highly explicit, because the specifics are baked into the tool itself. In other words, it saves you tons of time and energy without compromising on the quality or coherence of the end product.  The Hack: Getting GPT to write the PRD for youOk, but if you’re like me, you don’t really know how to write a good PRD. Plus, writing a detailed PRD can be pretty time-consuming. But luckily ChatGPT knows how.Thanks, ChatGPT 🙏So to get really great results out of Wasp’s GPT Web App Generator, I first ask ChatGPT (using GPT-4) to write a detailed product requirement doc for me, like this:Write a Product Requirement Document for the following full-stack app:An app where users can track their house plants and their watering schedule.Enter fullscreen modeExit fullscreen modeAnd then I’ll slightly modify ChatGPT’s output before I pass it to GPT Web App Generator:Product Requirements Document for a House Plants Tracking Application1. **Product Title**: GreenLush: Your House Plant Care Companion2. **Purpose**: The GreenLush app is designed to help users manage their house plants and keep track of their watering schedules. This app will serve as a reminder tool, a database for plant types, and a platform for users to know more about house plant care. 3. **Features and Functionality**:    3.1. **User Registration & Profile Management**: To allow users to create and manage their account.    3.2. **Plant Database**: A comprehensive directory of house plants, with visuals and information about each type.    3.3. **Plant Profile**: Users can create a profile for each house plant they own, fill in its type, and assign a custom nickname and photo.    3.4. **Watering Schedule**: By selecting or inputting the type of plant, the app will suggest an ideal watering schedule. Users can confirm or customize this schedule and notifications will be sent when it's time to water each specific plant.     3.5. **House Plant Care Tips**: A section of the app that provides general care tips and recommendations for house plants.4. **Behavior of the Product**:    4.1. Users will be prompted to sign up when they open the app for the first time.     4.2. Once registered, users will be able to browse the plant database, create and manage plant profiles, set watering schedules, and read plant care tips.     4.3. Notification alerts will be sent according to the set watering schedule. Enter fullscreen modeExit fullscreen modeGPT Web App Generator will start generating a plan for your app, execute that plan file by file, and even do some error-checking and fixing.Pretty neat!Then, the generated app code can be reviewed before you download it and run it locally. This is nice, because sometimes it’s useful to tweak the prompt and a few settings to see if you get better results. Best of all, the process is free. You don’t even need to use your own API key!The picture above is the actual generated, working full-stack app I got out-of-the box from the example prompt above. All I had to do was initialize the database, register/log in, and BOOM, the app was up and running!🤩 BTW, If you want to check out the code that GPT Web App Generator created based on the above PRD, go here: https://magic-app-generator.wasp-lang.dev/result/1f28b518-0cca-4352-84e4-69a4ac04d0faThere are more examples of types of apps you can build with this tool, written about here, but it’s probably best to just play around with it yourself and see what you can get!  ConclusionThere are a number of really cool AI-assisted coding tools out there, but for kickstarting a full-stack React/NodeJS app, I’ve found GPT Web App Generator to be the best performing one.It consistently generates functional, comprehensive full-stack starter codebases that need little to no error-fixing, depending on the complexity of the app.Couple that with the “PRD hack”, and you can save yourself a substantial amount of time by avoiding writing a ton of boilerplate.So, if you have any Qs, or know of any other sweet tips like this one, let me know in the comments!  Did you like this?If so, there's a really simple, free, and easy way you can show it: by starring our GitHub repo 🌟We'd really appreciate it if you did! ⭐️ Thanks For Your Support 🙏"
17,"Unlock the Magic of JavaScript Event Handling  IntroductionAs we surf the web, click buttons, hover over images, and type into search bars, we might not realise the amount of activities happening beneath the surface.JavaScript, the dynamic scripting language that powers much of the interactive web, is controlling these actions through a mechanism known as event handling.Whether you’re an experienced developer or just starting out, understanding how JavaScript event handling works and following to recommended practises will dramatically increase your ability to design interesting and interactive user experiences.In this article, we’ll break down the concepts of event handling, explore its different types, delve into best practices for adding event listeners, and provide examples to guide you on your journey towards mastery.  The Magic of Event HandlingImagine you’re building a website and you want a button to trigger a pop-up message when clicked. Or perhaps you want an image to enlarge when a user hovers their cursor over it.Consider JavaScript event handling to be similar to being a football manager. Event handling, similar to how a manager makes tactical decisions during a game, manages operations based on user interactions, delivering a fluid and responsive web experience. It’s like planning the team’s moves to score goals on your website’s digital field.It enables you to capture these interactions, interpret them, and respond accordingly. Without event handling, the web would be a static, unresponsive place.  Different Types of JavaScript EventsSimilar to how various players execute different roles in a football team, diverse types of events unfold in the realm of web development.These events can be broadly categorised into three groups:User eventsDocument eventsand browser events.User events are activities taken by users, such as clicking, hovering, or typing. Document events are events that occur within the document itself, for as when it is fully loaded or resized. Browser events are activities performed on the browser window, such as when it is minimised or maximised.Understanding these event types allows you to better predict and cater to user behaviours.  Best Practices for Adding Event ListenersCreating event listeners is the foundation of event handling in JavaScript, similar to carefully deploying scouts on the field to observe player movements during a football game. Here are a few crucial strategies to consider for seamless gameplay:1. Use Unobtrusive JavaScript: Avoid mixing your HTML and JavaScript. Instead, use external scripts to keep your code clean and maintainable.2. Consider Accessibility: Ensure that your event handling doesn’t create accessibility barriers for users who rely on assistive technologies. Test your interactions with screen readers and keyboard navigation.3. Prevent Default Actions: Sometimes, an event triggers an action you want to prevent (e.g., a form submission). Use the event.preventDefault() method to stop the default action from occurring.4. Remove Unnecessary Event Listeners: If you add an event listener dynamically, remember to remove it when it’s no longer needed. This prevents memory leaks and improves performance.  Examples of Event Handling with Vanilla JavaScriptHere are a few examples of event handling using vanilla JavaScript:Click Event:const button = document.querySelector('#myButton');button.addEventListener('click', () => {  alert('Button clicked!');});Enter fullscreen modeExit fullscreen modeHover Event:const image = document.querySelector('#myImage');image.addEventListener('mouseenter', () => {  image.style.transform = 'scale(1.2)';});image.addEventListener('mouseleave', () => {  image.style.transform = 'scale(1)';});Enter fullscreen modeExit fullscreen modeForm Submission Event:const form = document.querySelector('#myForm');form.addEventListener('submit', (event) => {  event.preventDefault();  const inputValue = form.querySelector('input').value;  alert(`You entered: ${inputValue}`);});Enter fullscreen modeExit fullscreen mode  ConclusionJavaScript event handling is the secret ingredient that turns static web pages into dynamic and interactive experiences.By understanding the types of events, implementing best practices, and experimenting with real-world examples, you can unlock a world of possibilities for creating engaging user interfaces.So, as you set out to master JavaScript event handling, keep in mind that every click, hover, and key press can turn into a beautiful interaction on your online canvas.Whether you’re creating a portfolio, a company website, or the next big web app, JavaScript event handling will be a valuable tool in your toolbox.So go ahead and use the power of event handling to bring your online projects to life! Happy coding!  Further readingLooking to dive deeper into JavaScript Event Handling? Then check out – Event handling (overview) – Event reference | MDN  See alsoWhat exactly is JavaScript?How to find and get HTML Elements in JavaScriptWhat are Functions in JavaScript?If you liked this article, then please share. You can also find me on Twitter for more updates.Ready to take your web development skills to the next level? Check out my latest articles on web development: Max Lockwood | Blog. Your coding journey just got more exciting! "
18,"Time for #DEVDiscuss — right here on DEV 😎Getting started with SCSS - The CSS Preprocessor with SuperpowersAbdullahi Muftau ・ Aug 19#webdev#cssInspired by @classicthedemigod' Top 7 post, tonight’s topic is... Sassy CSS!Have you ever felt there should be a way to make writing CSS easier and faster? This is where SCSS (Sassy CSS) comes in! SCSS (Sassy CSS) is a preprocessor scripting language that is compiled into regular CSS. It extends the capabilities of CSS by adding features like variables, nesting, mix-ins, and more.  Questions:What are the biggest challenges you have faced when working with SCSS?How difficult did you find it to pick up SCSS if you were already familiar with CSS? Any tips for newcomers?Where do you see the future of SCSS going? Do you think CSS will eventually incorporate more features that are currently SCSS-only?Any triumphs, fails, or other stories you'd like to share on this topic?"
19,"Last week I was in San Francisco to attend the launch of Postman Flows. It was a fun event focusing on innovative use cases built entirely on Postman's new visual editor. I walked around from booth to booth talking to different vendors who have built incredibly impressive workflows ranging from online bank management to controlling robotic arms - without a single line of code.After talking with Postman CEO Abhinav Asthana, I realized the power of what they had done. Flows let you drag and drop API requests around on a canvas, linking them together to chain results, mutate variables, and display charts, graphs, and dashboard metrics. This is cool because it puts powerful workflow-building tools in the hands of non-technical folks. But then Abhinav reminded me of something that made the gears in my head start flying. Postman has built a huge API network containing fully documented, functional API requests you can import into your flows. This means you have access to payment APIs from Stripe, text messaging APIs from Twilio, caching APIs from Momento, and hundreds more. They've assembled the world's largest API LEGO set, letting you build basically anything. Software development is changing. Abstractions are getting higher and services are being introduced that handle more of the undifferentiated lifting for you. As we lean more into tech, we do less and less actual coding.Don't believe me? Let's look at what's happening before our very eyes.   Low-Code EditorsPostman isn't the only one exploring this space. We've seen big updates and announcements from AWS around low-code development. The Step Functions workflow studio is probably one of the best visual builders I've ever used. It lets you piece together hundreds of AWS SDK calls while taking advantage of conditional logic and callback functions. Pretty much everything I build these days is backed by a Step Function workflow created and maintained in the designer. We also have AWS App Composer that brings the visual designer to your Infrastructure as Code (IaC). You can create all the resources, permissions, and secrets for your apps without touching code. On the furthest end of the low code spectrum are companies like OutSystems and Bubble. These vendors provide you with visual editors that do everything from building your user interface to configuring and optimizing your database. I've been using OutSystems for years to build rapid prototypes because of how easy they make it to build a website.   Native Cloud ParadigmsIf you haven't seen some of the things Wing and Ampt are doing, it's time to take a look.  While these providers still require you to write code, you have to write a heck of a lot less of it. I originally called frameworks like these Infrastructure from Code, but I feel like they are taking on a bit more than that nowadays (in a good way). After reading a post from Ampt CEO Jeremy Daly about native cloud development, I'm convinced this is going to be the most palatable step for developers from where we are now to ""nobody writes code anymore"". With native cloud development, you don't have to worry about the nitty-gritty details around your infrastructure. You write your business logic and let the framework do the rest. Ampt will even monitor your app and adjust the type of compute it's running on to optimize it automatically.   Generative AIOf course, no article about the future would be complete without mentioning generative AI. The tech wave taking over the world by storm has launched hundreds of startups, enhanced thousands of products, and made possible countless use cases that were never feasible in the past. We've already seen services like GitHub Copilot and Amazon CodeWhisperer creep into our daily lives. They autocomplete our code and offer optimization suggestions as we type, often providing recommendations we never would have considered. We also have Meta about to enter the playing field with Code Llama, potentially offering the next big advancement in code completion. Not only do we have code completion mechanisms, but we're also starting to see from-scratch code generators that use generative AI to interpret and build code from nothing but a prompt. Most, if not all, of these need a person to ""ok"" what was created, but as we continue to advance in the AI space, human interaction is going to be needed less and less often. We're going to be left with prompt engineering.  What Does This Mean?To some, all this might be exciting. To others, it might be horrifying. All the tools, paradigms, and AI generators might take our jobs and leave us, well... out of luck. That's not going to happen. There will always be a need for programmers.However, what we consider ""traditional programming"" might change drastically. The specialty degrees we needed to maintain systems and build top-of-the-line services in the past might not be necessary anymore. Instead, programmers might be spending more of their time on workflow design and prompt engineering. We're a long way away from this being the norm, but it's not out of the question. We live in an age of just do it for me. More and more managed services are coming to market that handle the undifferentiated heavy lifting so we can focus on becoming differentiators. We are building on higher and higher abstractions that are fundamentally changing the way we approach software. More responsibilities are landing in the hands of non-technical contributors. We go from idea to production in record-breaking time and we can iterate faster than ever before.So, is coding on the way out? Maybe the coding we know today. But what's emerging is a set of empowering tools that help us move faster, scale better, and become more resilient to errors. Do I like change? No, not really. But do I like where we're headed? Absolutely.Happy coding!"
20,"Introduction:Python, a popular programming language known for its simplicity and versatility, employs a Global Interpreter Lock (GIL) that influences the execution of multithreaded Python programs. In this article, we delve into the intricacies of the GIL, its impact on parallelism, and strategies to work around its limitations.  Understanding the Global Interpreter Lock (GIL):The GIL is a mutex that restricts the execution of Python bytecode to a single thread at a time within the CPython interpreter. This means that even on multi-core systems, only one thread can execute Python code simultaneously. The GIL was introduced to simplify memory management and safeguard against memory corruption, but it imposes several limitations on Python's concurrency model.  Limitations of the GIL:Limited Parallelism: The GIL restricts the ability of multithreaded Python programs to fully utilize multiple CPU cores, particularly for CPU-bound tasks. This can impact the performance of applications requiring substantial computation.I/O-Bound Tasks: While I/O-bound tasks benefit less from multithreading, Python threads can still be advantageous as they can release the GIL while waiting for I/O operations to complete.  Solutions and Workarounds:Multiprocessing: The multiprocessing module offers a solution by creating separate processes, each with its own Python interpreter and memory space. Processes bypass the GIL, enabling true parallelism for CPU-bound tasks. This approach maximizes CPU utilization but may involve higher memory overhead.Asynchronous Programming: Asynchronous programming using the asyncio module addresses the limitations of the GIL for I/O-bound tasks. It allows a single thread to handle multiple asynchronous I/O operations concurrently, without blocking the entire program.Utilizing External Libraries: Libraries like NumPy, Cython, and Numba provide ways to release the GIL during certain operations. These libraries leverage optimized C or JIT-compiled code to achieve parallelism for numerical computations.Thread-Intensive Libraries: Leveraging libraries designed for thread-intensive tasks alongside the threading module can help extract parallelism from specific use cases.  Pros and Cons of Using Processes Instead of Threads:Benefits of Using Processes:True Parallelism: Processes offer true parallel execution as they operate in separate memory spaces and bypass the GIL. This is particularly advantageous for CPU-bound tasks where multiple cores can be fully utilized, resulting in improved performance.Isolation and Stability: Processes provide strong isolation. If one process crashes or experiences errors, other processes remain unaffected, enhancing system stability and fault tolerance.Versatility for Task Types: Processes are effective for both CPU-bound and I/O-bound tasks, making them suitable for a wide range of applications that demand efficient parallelism.Fault Tolerance: The independence of processes leads to better fault tolerance. If one process fails, others can continue running without being impacted.Drawbacks of Using Processes:Higher Memory Consumption: Each process requires its own memory space, leading to higher memory consumption compared to threads. This can become a concern on memory-constrained systems.Communication Overhead: Inter-process communication (IPC) mechanisms are needed to share data between processes. These mechanisms introduce overhead and complexity compared to the direct memory access enjoyed by threads within a process.Startup and Teardown Overhead: Processes have higher startup and teardown overhead compared to threads, making them less suitable for numerous short-lived tasks.Increased Complexity: Managing processes and IPC mechanisms can be more complex than working with threads, especially for developers less familiar with these concepts.Platform Dependence: Some multiprocessing features might behave differently or be limited across different platforms, requiring careful consideration during deployment.  Conclusion:The Python GIL's impact on parallelism and performance is a topic that developers must be aware of when designing concurrent applications. While the GIL poses challenges, Python provides various strategies to overcome its limitations, ranging from multiprocessing to asynchronous programming and leveraging external libraries. Choosing the right approach depends on your application's characteristics and requirements. By understanding the GIL and making informed decisions, developers can harness Python's strengths while mitigating its limitations."
21,"What steps, if any, have you taken to establish a strong personal brand within the developer community? How has it impacted your career?This week we're exploring the experiences of seasoned developers:  their stories, hurdles, and successes. Like what you're reading? Follow the DEVteam for more discussions like this!The DEV TeamFollow        The team behind this very platform. 😄      "
22,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers!🧠 If you could enroll in a developer's Hogwarts, which programming language would be your chosen 'House,' and why?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
23,"VPN companies have advertisements everywhere, there’s a reason they sponsor most tech YouTubers (they’ve even tried it with me) but you don’t need to buy an expensive plan to use a VPN.Here’s how you can build your own:Step 1: Set Up the ServerFor ease of use, a Linux server at your disposal would be ideal. On there, log in using SSH. If you don’t have one, services like AWS, Google Cloud, or DigitalOcean offer free tiers that you can use for this purpose.ssh username@server_ipEnter fullscreen modeExit fullscreen modeReplace “username” with the actual username you use to log into your server.Replace “server_ip” with the IP address of your server. If you are using a cloud service, look in the server dashboard.Step 2: Install OpenVPN and Easy-RSAOpenVPN is going to be our free VPN solution and I will show you how it supports various encryption protocols. Let’s install it:    sudo apt update    sudo apt install openvpnEnter fullscreen modeExit fullscreen modeDownload Easy-RSA:    sudo apt-get update    sudo apt-get install easy-rsaEnter fullscreen modeExit fullscreen modeStep 3: ConfigurationGenerate the server’s certificates and keys:    cd /usr/share/easy-rsa    sudo ./easyrsa init-pki    sudo ./easyrsa build-ca    sudo ./easyrsa gen-req server nopass    sudo ./easyrsa sign-req server serverEnter fullscreen modeExit fullscreen modeDuring this process, when prompted, you will need to set a password and server username. Once signed, you should see this in the terminal:Now the server is setup, generate the Diffie-Hellman key exchange:    sudo openssl dhparam -out /etc/openvpn/dh.pem 2048Enter fullscreen modeExit fullscreen modeYour terminal should look something like this:Now you need to generate an HMAC signature for a strengthened control channel:    sudo openvpn --genkey secret /etc/openvpn/ta.keyEnter fullscreen modeExit fullscreen modeStep 4: Server ConfigurationCreate a server configuration file /etc/openvpn/server.conf and add the following lines:port 1194proto udpdev tunca /etc/openvpn/easy-rsa/pki/ca.crtcert /etc/openvpn/easy-rsa/pki/issued/server.crtkey /etc/openvpn/easy-rsa/pki/private/server.keydh /etc/openvpn/dh.pemtls-auth /etc/openvpn/ta.key 0server 10.8.0.0 255.255.255.0ifconfig-pool-persist /etc/openvpn/ipp.txtpush ""redirect-gateway def1 bypass-dhcp""push ""dhcp-option DNS 8.8.8.8""user nobodygroup nogrouppersist-keypersist-tunstatus /var/log/openvpn-status.logverb 3Enter fullscreen modeExit fullscreen modeYou can write files in the Linux Terminal by utilising Nano:    cd /etc/openvpn/    sudo nano server.confEnter fullscreen modeExit fullscreen modeEnter the configuration file lines:Then press CTRL + O, ENTER, then CTRL + X and the file will be saved.Step 5: Enable IP ForwardingUncomment the following line in /etc/sysctl.conf to enable IP forwarding:Activate the changes:    sudo sysctl -pEnter fullscreen modeExit fullscreen modeStep 6: Firewall ConfigurationConfigure the firewall to allow VPN traffic:    sudo ufw allow 1194/udp    sudo ufw allow OpenSSH    sudo ufw enableEnter fullscreen modeExit fullscreen modeStep 7: Client ConfigurationGenerate client keys:    cd /usr/share/easy-rsa    sudo ./easyrsa gen-req client nopass    sudo ./easyrsa sign-req client clientEnter fullscreen modeExit fullscreen modeDuring this process, you will again enter the username and use “user” as a placeholder. Then, once prompted, type the word ‘yes’ and enter the password we used earlier in Step 3 for the server’s certificates and keys setup.Lastly, create a client configuration file named client.ovpn in /etc/openvpn/ :clientdev tunproto udpremote your_server_ip 1194resolv-retry infinitenobindpersist-keypersist-tunkey-direction 1remote-cert-tls servertls-auth ta.key 1data-ciphers AES-256-GCM:AES-128-GCMverb 3Enter fullscreen modeExit fullscreen modeCopy down the client certificates and keys to your local machine.Step 8: Connecting to the VPNUse OpenVPN on your local machine to connect to your VPN server:    openvpn --config client.ovpnEnter fullscreen modeExit fullscreen mode"
24,"When using mocks, we often set them up to return values for use in the logic we’re testing. In situations where we have many methods to configure, it’s easy to accidentally forget a setup or two. When this happens, our tests can produce unexpected results and fail. To help narrow down where things go wrong, we can verify the mocks to check that the methods we’ve set up have been called. In previous parts of this series, we’ve seen how this is helpful. However, it can also mean the number of verify statements equals that of the methods set up. In more complex test, we could end up with a lot of code.This week, we’ll explore the concept of Strict mocks and see how they can help in cases like this.  Setting the SceneLet’s imagine we’re writing a system to gather statistics from survey data. To keep things focussed in our example, our data model for a survey participant only has two properties: an ID number, and the participant’s age. We also have a repository with a method to get a participant's age from their ID. And finally, we have a service to calculate the average age of the participants we provide the IDs of.public interface IParticipantRepository{    int GetParticipantAge(int participantId);}public class SurveyParticipant{    public int Age { get; set; }    public int Id { get; set; }}public class SurveyStatisticsService{    private readonly IParticipantRepository        _participantRepository;    public SurveyStatisticsService(        IParticipantRepository participantRepository)    {        _participantRepository = participantRepository;    }    public double GetAverageAge(IList<int> participantIds)    {        double totalAge = 0;        foreach (var id in participantIds)        {            var age = _participantRepository                .GetParticipantAge(id);            totalAge += age;        }        var average = totalAge / participantIds.Count;        return average;    }}Enter fullscreen modeExit fullscreen mode  Writing a TestWith that in place, we want a test to check the logic for calculating the average age of participants. We wrote a few notes with a pen and paper while devising the system and want to encode the data shown in Table 1 into our test.Table 1: Our test data. The average age is 28.5In the following code, you’ll notice we assert the result should be between 28.499 and 28.501. This is because GetAverageAge returns a double; comparing floating-point numbers to a specific value can lead to unexpected results due to how they are represented internally, e.g. 1 vs. 1.00000000000001.[Test]public void CanReturnAverageAge(){    // Arrange    var repositoryMock = new Mock<IParticipantRepository>();    repositoryMock        .Setup(r => r.GetParticipantAge(0))        .Returns(27);    repositoryMock        .Setup(r => r.GetParticipantAge(1))        .Returns(32);    repositoryMock        .Setup(r => r.GetParticipantAge(3))        .Returns(29);    var service = new SurveyStatisticsService(        repositoryMock.Object);    // Act    var result = service.GetAverageAge(        new[] { 0, 1, 2, 3 });    // Assert    Assert.That(result, Is.InRange(28.499, 28.501));}Enter fullscreen modeExit fullscreen modeHowever, we’ll find the test fails when we run it.Expected: in range (28.499,28.501)But was:  22.0dEnter fullscreen modeExit fullscreen modeIs the logic in GetAverageAge wrong?Or is there a problem in the test?If you’re particularly keen-eyed, you may have spotted that we forgot to include a setup for participant 2. We saw in previous discussions that mocks will return an empty value of the corresponding data type if a setup hasn’t been provided. An empty value for double would be 0, and while invalid as a participant’s age, it’s perfectly usable in the context of calculating an average.One way to catch this would be to verify that GetParticipantAge was called with all participant IDs in our test data set. However, as we forgot to add a setup, it’s also plausible that we might forget to add the corresponding verification step. To guard against this, we could use a Strict mock.  Strict MocksMocks can be set up to behave in one of two ways in Moq. The first (and default) is Loose, where empty values are provided in the absence of method setups. We’ve seen this before with null being returned for reference types, and 0 for double.The alternative behaviour is Strict. Instead of returning an empty value, a Strict mock will throw an exception when a method without a corresponding setup is called.A mock’s behaviour can be specified using a constructor parameter and cannot be changed after instantiation. However, we can check its behaviour by looking at its (read-only) Behavior property. The following shows a modified version of our test, where the mock has Strict behaviour.[Test]public void CanReturnAverageAge(){    // Arrange    var repositoryMock = new Mock<IParticipantRepository>(        MockBehavior.Strict);    repositoryMock        .Setup(r => r.GetParticipantAge(0))        .Returns(27);    repositoryMock        .Setup(r => r.GetParticipantAge(1))        .Returns(32);    repositoryMock        .Setup(r => r.GetParticipantAge(3))        .Returns(29);    var service = new SurveyStatisticsService(        repositoryMock.Object);    // Act    var result = service.GetAverageAge(new[] { 0, 1, 2, 3 });    // Assert    Assert.That(result, Is.InRange(28.499, 28.501));}Enter fullscreen modeExit fullscreen modeThe test stills fail when we run it. However, we’ll find the error message to be more indicative of where the problem lies.Moq.MockException: 'IParticipantRepository.GetParticipantAge(2)invocation failed with mock behavior Strict.All invocations on the mock must have a corresponding setup.'Enter fullscreen modeExit fullscreen mode  SummaryBy default, Mocks created in Moq return empty values when calling unconfigured methods. Strict mocks can save you time by highlighting missing setup steps when you run your tests. You can set a mock’s behaviour to Strict by passing the corresponding value as a constructor parameter. The mock will then throw an exception every time that a method without an explicit setup is called. Accidental omissions can be caught quickly, and you won’t end up wasting time unnecessarily debugging production logic.Best of all, you can do this without explicitly writing Verify statements for your entire data set, keeping your test code tidy.Thanks for reading!This article is from my newsletter. If you found it useful, please consider subscribing. You’ll get more articles like this delivered straight to your inbox (once per week), plus bonus developer tips too!"
25,"In our second episode of the CodeNewbie Podcast, @saronyitbarek talks about  about choosing a bootcamp, finding resume tips, and navigating career paths with confidence with Alex Lee, Frontend Engineer at Amazon.      codenewbie.org    Alex is a Frontend Engineer at Amazon based in Los Angeles. He also is a career coach dedicated to helping new and seasoned Software Developers change or advance their career.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!  We will see you next week, happy codingPS: Make sure to subscribe to the CodeNewbie podcast if you haven't yet + review us on your chosen platform!"
26,"Welcome to DEV, CodeNewbies! What's the most exciting thing about starting your coding journey?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
27,"Hello everyone, this is a hangout thread for Rust that I decided to make — it may or may not be a recurring thing.This is an area for Rustaceans to discuss Rust.Feel free to share anything Rust related that you think is interesting.I'll start first...I made hangman in Rust! - Unfortunately it doesn't come with pre-compiled distributions because I can't compile for Windows (yet).So, what's up?Thanks for participating!Cheers!"
28,"Recently my new task at ScyllaDB is to study how to Migrate data between Databases and as I promised before, I'll keep you folks about my latest studies.If you’re just getting started with databases in general or databases, you might want to start off by reading my initial post, Database 101: Data Consistency for Beginners for Beginners. That article captures my own exploration of how many database paradigms exist as I look far beyond my previous experience with just SQL and MySQL. I’m keeping track of my studies in this Database 101 series.  Table Of Contents1. Prologue2. Database Migrations: How to Start3. Why are we doing this migration?4. Proof of Concept: where to start?4.1 PoC: Same Paradigm4.2 PoC: Different Paradigm5. Testing it before it's too late! (seriously)6. Migration Strategies6.1 Strategy: Cold Migration6.2 Strategy: Hot Migration7. Final Considerations  1. PrologueSince I started my journey in this ""database environment"", I have asked myself so many questions that probably will take a few years to be answered. But one of those questions is how to properly perform a database migration, and I still don't have the answer.Actually, when I migrated the He4rt Developers (community I lead) bot, I did my best to make everything on the backend and the database model as perfect as possible. But when I had to migrate everything, it was a real mess. I decided to use the ""Big Bang"" (pull request with 532 files changed) migration approach, and it was one of my bad decisions as an open source maintainer. At that time, I didn't have any knowledge about this topic (database migrations) at all. But I learned a lesson that I'm going to teach you in this article.   2. Database Migrations: How to StartIf you ever considered receive such a task, of investigate and research how properly migrate data from a database to another, you should know a few things before do anything related to code. What do I mean by that? Just throw queries between databases is not where you're going to start the investigation. Let's just ask ourselves a few questions before everything:What is the motivation for database migration?What migration approach should we use on the project?Are we going to jump from one paradigm to another?Does the new database have all the support we need for the things we're currently using?With these four questions in mind, we can start researching until answer all of that and then put hands on queries/code.  3. Why are we doing this migration?When we talk about replacing any part of the stack of a running project, the reason needs to be clear to the entire team that is planning this huge movement inside the product. So what are you looking for in the replacement? A few possibilities:Lower latency for I/O operations;Cheaper database to maintain;Scalable database to keep up with the product.Just a reminder that these are just a few items on the giant list of motivations for why to replace a database, ok? Ask your team/leaders all the details you need to understand the motivation and make sure this is what you're looking for!  4. Proof of Concept: where to start?Good! We have a clear idea of why we are doing this. Now let's figure out the things that will be important to make this work. Do you know the difference between each database paradigm? Well, if you're migrating data between two different databases, it should be a constant concern. Let's understand which type of PoC you will be running.  4.1 PoC: Same ParadigmImagine a few scenarios where you want to migrate from:CassandraDB to ScyllaDB (Wide Column);MySQL to PostgreSQL (Relational);Memcache to Redis (Key-value);MongoDB to DynamoDB or Firebase (document).All of these scenarios are kinda easier to migrate, because they share the same Database Paradigm, which means that they follows the same architecture. So, they have mostly the same features, indexing and data types. Maybe will have slight differences but are things that you can handle by doing tests and migrating from a feature/data type to another. Even when Discord was migrating from CassandraDB to ScyllaDB had a few things to fix, but at the end of the day it's simpler than between different paradigms. To be super honest, if you have a problem during the PoC, remember that it's part of the job. ¯\(ツ)/¯  4.2 PoC: Different ParadigmOk, and if our problem is to go from some document based database to a wide column? Like going from a MongoDB to a ScyllaDB?Sounds like a tough task, and probably will be, and this part especially needs to be carefully designed. When Discord started migrating from Document Based Database to the Wide Column Database in 2017, they had the same issue. How do you split an infinite JSON object? Can you imagine? Check the JSON example below:{  ""servers"": [    {      ""218378123781"": {        ""id"": ""218378123781"",        ""server_name"": ""He4rt Developers"",        ""channels"": [          {            ""78931278921723"": {              ""name"": ""Test Channel 1"",              ""messages"": [                {                  ""312783712867"": {                    ""message_id"": ""312783712867"",                    ""chatter_id"": ""danielhe4rt"",                    ""content"": ""oh hi lol"",                    ""created_at"": ""1691972222"",                    ""updated_at"": ""1691972222""                  }                },                {                  ""312783712867"": {                    ""message_id"": ""312783712867"",                    ""chatter_id"": ""danielhe4rt"",                    ""content"": ""oh hi lol"",                    ""created_at"": ""1691972222"",                    ""updated_at"": ""1691972222""                  }                }              ]            }          }        ]      }    }  ],  ""users"": [    {      ""danielhe4rt"": {        ""chatter_id"": ""danielhe4rt"",        ""joined_at"": ""1691972222""      }    },    {      ""dont_forget_to_follow_me_on_socials"": {        ""chatter_id"": ""dont_forget_to_follow_me_on_socials"",        ""joined_at"": ""1691972222""      }    }  ]}Enter fullscreen modeExit fullscreen modeThis is how a briefly imagined a social modeling like Discord. Yeah, I know. That's far from the reality but let's stick into the problem here, ok? And in fact, if you have a good DBA and architects on your side, it will not be a problem. First, you need the whole team to know more about the paradigm and how to use it. With document-oriented, you can push whatever you want because there's no strong data consistency at all. But if you move to ScyllaDB, you'll need to model tables, focus on what query you want to run, and also understand how things like ""consistency level"" and ""replication factor"" work. At the end we should have something like:CREATE TABLE servers (    server_id bigint    owner_id text    server_name text,    created_at timestamp,    PRIMARY KEY (server_id, created_at));CREATE TABLE channels (    server_id bigint    channel_id bigint    channel_name text,    created_at timestamp    PRIMARY KEY ((server_id), created_at)) WITH CLUSTERING ORDER BY (created_at DESC);CREATE TABLE channel_messages (    message_id bigint    channel_id bigint,    chatter_id text,    content text,    created_at timestamp,    PRIMARY KEY ((message_id, channel_id), created_at)) WITH CLUSTERING ORDER BY (created_at DESC);CREATE TABLE users (    user_id text,    user_name text,    created_at timestamp,    PRIMARY KEY (user_id, created_at));Enter fullscreen modeExit fullscreen modeYeah, CQL (Cassandra Query Language) is very similar to SQL (Structured Query Language). I invite you to have a try doing this ScyllaDB: NoSQL 101 Essentials course. You will learn a bunch of cool things about the Wide Column paradigm :D  5. Testing it before it's too late! (seriously)Ok, we ran our PoC and we know which database and paradigm will be the best for our new environment. Now your team is focused to finish the data modeling ASAP, right? Once that is done, the focus will be on getting all the scripts ready to make this a successful migration. The best thing that you can do is to split your tests with 1% and 5% of your database in a staging environment. Why? If your ""new system"" or ""new version"" of the system crashes with 1% of the database, it will reflect that there's something missing in the data modeling or even at the backend. So, stop the migration scripts and write some tests for your application.Now that you're done with the 1% migration bugs, let's do the same process with 5% of your database. In this step you should test everything carefully, because it will be the last testing step you will do before choosing the migration strategy and executing it.  6. Migration StrategiesOf course, migrating between databases isn't a ""new"" thing, so there are a few things planned and ready to make your life easier. Also, a few rules that together will make your database migration look like it was done by a pro. In this regard, there are two very popular strategies called ""Hot Migration"" and ""Cold Migration"". The names of the strategies themselves say something that we've probably been asking ourselves since the beginning of this research: Should I shut everything down or migrate while the old database is still running? Well, that depends on your needs. The process itself is called ETL (Extract, Transform and Load) in any case btw.   6.1 Strategy: Cold MigrationLet's start with the ""easiest"" and safer migration strategy: Cold Migration. The reason to use this type of migration is understand if you can stop  your system for the time needed without any problem. Basically, know if there's a maintenance period and let users know that. It also may known as ""Big Bang Migration"", since it will be migrated entirely to a new environment that had nothing before.This approach is used on small/medium systems and is usually done at dawn, since it's probably the time of day when fewer users are requesting the system. There's a checklist of things you need to be aware of when doing a cold migration. Let's check it out:1. Planning: what time of day and who will be responsible for this task?2. Extraction: how are we going to dump all this data? Maybe there's specific tooling already done on the target database to be used.3. Transformation: is the data in the right form for the new database? Do both databases have the same structure? Is there any tooling to transform this data for us?4. Load: how do we make sure that our new database gets all of our data? Any broken query? All good?5. Validation: ok, we loaded everything. Now we need to validate if the data matches with the legacy system. Good Luck!6. Testing: let's connect it in the migrated database into the system and run all the test suites. Almost there!!!7. Activation: all good. Now it's time to shut down the legacy database. Congratz, buddy!Basically, this is the migration flow when you have the possibility to shut everything down and now you know how to properly do it.  6.2 Strategy: Hot MigrationOk... If you want to migrate things while your system is still running... Now you're in trouble! Wait, I'm just kidding :pThis is where things get a bit complicated because you have to write to two databases at the same time. So you can imagine that instead of having 1 instance of the database, you will need two, and depending on that We also have a checklist to help us with this. So let's check the flow: 1. Planning: time of the day is not the main issue here, but a proper infrastructure to support the transition between both databases; 2. Replication: both systems need to be feed at the same time while the migration is happening3. Tests and Validation: during the replication, you should validate all the data that you're inserting along with the migrated one. 4. Minimal Interruption: the system should be online all the time, and if any problem occurs, it should not be perceptible by the user.5. Switch: When all the important data is finally migrated, is time to point the app to the new database;6. Activation: all good. Now it's time to shut down the legacy database. Congratz, buddy!This migration strategy is indicated for companies that require high availability and have critical services that cannot be stopped.   7. Final ConsiderationsWell, my task was to understand more about DynamoDB and create some content about the ScyllaDB Alternator, a migration tool that converts any DynamoDB I/O into a ScyllaDB. I'm still working in a PoC to understand more about it, but I certainly learned some really cool things along the way to know more tips, tricks, and last names of things related to migrations.Also there will be an ""NoSQL Database Migration Masterclass"" for free event tomorrow (22/08)! I'll be there on the chat learning more about the topic and invite you to be there with me!I hope that this tutorial could help you to understand briefly this topic! And please, let me know in the comments which things that I should learn about. Don't forget to like and share this article with your friends and go fill your water bottle! Let's keep in touch: Twitter DanielHe4rt PT-BRTwitter DanielHe4rt ENTwitch Channel"
29,"GitHub Copilot Chat is an extension that works in your Code Editor or IDE (VS Code or Visual Studio currently) that allows you to have conversations with GitHub Copilot right from your editor.You're able to get code suggestions, build, debug and tests applications with an AI model that understands natural language right from your editor.   Getting startedTo get started using GitHub Copilot Chat in VSCode, ensure that you have access to the extension by checking your email for access privileges. You get access privileges  through your organization or by being taken off the waitlist for the private beta for individuals. You also need to ensure that you have an active GitHub Copilot subscription.To verify your access, click on your GitHub profile and select ""Try Copilot."" If you have access to GitHub Copilot, you will see a message at the top of your settings page indicating such and if you don't have access, you will be routed to another page to start your 30-day free trial.You have access to GitHub CopilotYou do not have access to GitHub Copilot  Installing GitHub Copilot Chat & asking your first questionOnce you verify those details, follow the steps below to start using GitHub Copilot Chat:Search for ""GitHub Copilot Chat"" in the vscode extension marketplace, and click the blue install button. After the installation, you'll be prompted to login to your GitHub Account to validate your access to copilot chat.Be sure to sign in to the GitHub account that has access to your GitHub Copilot subscription and also that has access to Copilot Chat.Once you've installed the extension, you're ready to use it! You'll see a message/chat icon appear on the side of your code editor, click that icon and start asking programming related questions.You can start by asking a simple question like ""How do I set up a new ruby project?"" and it will provide you with a suggestion.And that's how you start using copilot chat in VSCode.   Slash Commands + GitHub Copilot ChatThere are some really amazing slash commands that you have access to as well that makes it easier to ask for help, create vscode extensions or create unit tests. To start using Slash Commands with GitHub Copilot, type / in the input box and you'll see the multiple options come up.Choose one of the options and then ask a question to get a suggestion.   Asking GitHub Copilot Chat questions about your codeTo ask Copilot Chat specific questions about the code you're working on, open up the file in your editor, and navigate to the chat extension. Let's say for example this is your first time interacting with this particular repository, and you don't quite understand the code, you can ask copilot chat ""what does this file mean?"" and it will provide a suggested explanation of what the code is doing.  Using Code Suggestions from GitHub Copilot ChatWhenever you ask copilot chat for code suggestions, you can accept them by copying the suggestion from the chat interface or clicking the ""Insert at Cursor"" button. You can also insert the suggestion into a new file, or run the code in the terminal if applicable.I was able to use GitHub Copilot Chat to tell me how to insert two images side by side using markdown ☺️ I copied to provided code suggestion and pasted it here and voila! I had two images side-by-side. 💃🏽  Opening a Copilot Chat session in your editorTo make your life a little easier, we've made it possible to open up a copilot chat session right in your editor, so you don't have to go back and forth between the chat interface and your files.To do this, click on the chat icon on the side, and click the three dots at the top and select ""Open session in editor"" this will move the chat into your editor, similar to how a file would be open.If you have any issues, questions, comments or concerns, feel free to leave them below and I'll try as best as possible to get you an answer! I hope you enjoy using GitHub copilot Chat as much as I do!Happy Coding!"
30,"We're starting off the week right with another badge addition. 🙌  Introducing the Icebreaker Badge!This badge rewards those who regularly leave the first comment on other folks' posts, helping to ""break the ice"" and get discussions going.  How it worksThe best thing you can do to earn this badge is to be the first commenter on a post and leave a thoughtful, engaging comment. While dropping a simple ""nice post"" is a kind and welcome addition, to get this badge you'll need to put more thought into your comment. We're going to be keeping a particularly sharp eye on #discuss posts as we really appreciate it when folks help initiate discussions there.  Lastly, note that we will not be rewarding folks this badge for commenting on their own posts!As for logistics, every couple of weeks members of the DEV Team will meet up and pull data on the most frequent first commenters. We'll then manually review those folks, picking out who we believe have shared particularly good ice-breaking comments.     Why did we create this badge?Like the Warm Welcome badge, we designed this badge to reward folks who help us create a kind, warm, and welcoming community. Being the first to comment on a post helps encourage other folks to open up and share their thoughts too. Comments are an essential part of what makes a community — without you all interacting and sharing ideas on each others' works, this would just be a platform for publishing. So, we really want to reward all those out there helping to break the ice and get conversations flowing.We're really siked for this badge and hope you are too! If you have any ideas for badges that you think we should add or actions you feel would be worthy of rewarding, don't hesitate to share your thoughts in this post.Cheers,The DEV Team"
31,"At CodeSandbox, we run your code in our cloud infrastructure, configure the environment for you and keep your code always ready, behind a shareable URL. Give it a try with this Next.js example or import your GitHub repo!You're working on that big new feature and are closer than ever to production-worthy. So, like dozens of times before, you hop on the “staging queue”, hoping that your turn comes quickly enough.If this sounds familiar, you probably also share the frustration of countless other developers who don't particularly enjoy the complexity and time wasted during this process.Long story short—there is a better way. The rise of cloud development environments like CodeSandbox opens the door to dedicated deployment previews for every branch. You always get your own personal staging environment.  Cloud Development EnvironmentsThere is an undeniably growing momentum around shifting development processes to the cloud.Although it might sound like uncharted territory, cloud development environments have been successfully implemented at companies like Uber, Slack, and Pipedrive. A “quiet revolution”, as The Pragmatic Engineer called it.One of the key benefits of cloud development environments is greatly accelerating computation-heavy processes (such as building the code) out of developer laptops with limited specs and into a superpowered VM that accomplishes these tasks in a fraction of the time.As an example, at CodeSandbox we implemented memory snapshotting technology in our microVMs, which means that we resume any dev server in under 2 seconds (as compared to 5, 10 or even 30 minutes of local compilation time—depending on the codebase's complexity). While that brings huge productivity improvements (Pipedrive engineers reported almost 3 hours saved per week), it also paves the way to much, much more. And one of the powerful “side effects” of moving development environments to the cloud is that you get a dedicated deployment preview for every branch.  Deployment Previews in CodeSandboxAt CodeSandbox, we give every branch its own dedicated microVM (with very generous base specs).When you run a task on that environment (like starting a dev server) that opens a server on a port, we expose that port through a dedicated URL such as https://3000-:id.csb.app. In other words, we transform a local dev server into a dedicated staging environment.So, you get a preview environment that is fast, synced with production, and that gives the same experience regardless of the machine of the person accessing it. Need to work on something else and go back to the server later on? No worries—because we hibernate the microVM, the deployment preview resumes in under 2 seconds, just like a traditional staging environment.Want to get continuous feedback on your work without having to rely on screenshots or recordings of your localhost server? Share that preview URL with others and they will be able to use it to provide async feedback at any time (without worrying about the ticking time bomb of staging moving to something else). Wish you could give team members access to the underlying codebase? Send them the URL of your CodeSandbox branch instead, and they will be able to experiment with your code and see the results in real-time.If you're curious to try it out, you can do it in under 5 minutes by importing one of your GitHub repos.  Pull Request PreviewsAfter talking with a lot of our users, we realized that this kind of preview is especially valuable during the PR review process.As a result, we introduced the CodeSandbox GitHub App, which adds links to every PR that lead to the branch running in CodeSandbox—which means that PR reviewers can use the deployment preview to review instead of running their own dev server.If you want to take it up a notch, you can also add another link that leads directly to the preview itself. Check out our Docs for instructions.Once that's done, every new PR in that repo will get these handy links available to all team members, allowing them to get visibility on ongoing work and save hours every week reviewing and testing the PR.  The Joy of Queue-less StagingPreview environments are a much bigger deal than they seem at first glance. Whenever someone asks me why I'm so excited about them, I like to bring up this feedback from one of our users:I looked at a PR, made some changes together, previewed them live and pushed them. All without checking out anything locally. This probably saved me 1 hour right now! — TkDodo, Frontend Tech Lead at AdverityOf course, we get it—not everyone is ready to commit to moving their development infra to the cloud. That's why we made it super easy to test it out by importing a public repo in our free plan (or a private repo with a free trial).Follow our tutorial and you can pretty much try everything in less than 30 minutes. Then, you'll see the joy of never having to wait for a dev server (or on the staging queue) ever again."
32,"Somewhat of a venting post, though I will try to maintain a constructive tone.Today I was contacted by a young company, a Startup that has survived the early years and now seeks to expand their team. So far, so good. The recruiter was exquisite explaining both the current situation and what are they specifically looking for.Then she explained their hiring process:[✅] initial HR callCultural fit: 1h conversation First Tech Interview: 1h tech conversation30 min call with the CTOCode assignment: between 3 and 8 hours - take - home assigment (up to the candidate)1h Code Review with the Teach lead discussing the solution.Final interview with the team. (30m ~ 1h)Look, I get it. Finding the right team fit is crucial. But seriously, this marathon of a process feels like it could do more harm than good. I just didn't start this road. These kind of processes may work for those shiny FANG-level companies. In this case, this particular company wasn't offering a salary over-the-top.Possible changes: remove the code assignment and its review.initial HR callCultural fit: 1h conversation First Tech Interview: 1h tech conversation30 min call with the CTO- Code assignment: between 3 and 8 hours - take - home assigment (up to the candidate)- 1h Code Review with the Teach lead discussing the solution.- Final interview with the team. (30m ~ 1h)+ You're IN; just a friendly conversation with the team, not part of the process.Enter fullscreen modeExit fullscreen modeDoes this hiring process seem like the usual approach to you? -- Thanks for reading 💛."
33,"As GenerativeAI expands its reach, the impact of software development is not left behind. Generative models — particularly Language Models (LMs), such as GPT-3, and those falling under the umbrella of Large Language Models (LLMs) — are increasingly adept at creating human-like text. This includes writing code.This evolution heralds a new era of potential in software development, where AI-driven tools could streamline the coding process, fix bugs, or potentially create entirely new software. But while the benefits of this innovation promise to be transformative, they also present unprecedented security challenges. GenerativeAI and LLM's capabilities could be manipulated to find vulnerabilities in existing software, reverse engineer proprietary systems, or generate malicious code. Thus, the rise of these technologically advanced machine learning models brings significant potential and new concerns about software security and system vulnerabilities.  A prelude to AI hallucinations  What are AI hallucinations?In the context of Large Language Models (LLMs), “hallucinations” refer to instances where the model generates information or data that was not explicitly present in its training data. It could be thought of as the AI ""imagining"" things, providing answers or creating content that holds no factual basis or grounding in the learning it has received. These hallucinations pose an intriguing aspect of AI behavior and offer fascinating possibilities, however, they also present numerous security concerns.Consider the following chat interaction with ChatGPT, in which I instruct it to generate any text it wants, with a specific constraint — the generated text must not include the English letter “e” in it.It failed miserably:Let’s consider another example. I’ll ask it to solve a simple math problem:As you can see, I even tried to prompt it with variations of the text, such as adding the equal symbol “=” to hint that it’s a mathematical expression that needs to be solved. That didn’t help either, and 216 is not the correct answer.  Why do AI and ChatGPT hallucinate?At its core, ChatGPT was not built with a termination condition as you might be familiar with from programming structures such as for-loops. Generally speaking, it will always strive to complete the next token (a word), even if it makes no sense or is completely incorrect.  The interplay between secure coding practices, open source software, and LLMsAt the very heart of software development lies the crucial practice of secure coding – writing programs that are not only robust against functional bugs but also resilient to security threats. However, in today's dynamic and fast-paced development environment, developers often use open source software and code snippets from public forums like StackOverflow to expedite their coding process.Although this practice helps save time, it may unintentionally introduce substantial security risks into production applications and into developers' day-to-day workflows, such as writing code or creating CI/CD build workflows for GitHub Actions. Whether a developer copies code from StackOverflow, a GitHub comment, or a GitHub Copilot auto-complete, blind trust and the lack of proper inspection and validation of the copied code may lead to software security issues.One notable example of this predicament was the ZipSlip vulnerability discovered by Snyk. It was a widespread arbitrary file overwrite critical security vulnerability, which implies that attackers could overwrite executable files and thus take control of a victim’s machine by using a specially crafted archive that holds directory traversal filenames (e.g. ../../evil.sh).The eyebrow-raising thing about this case was that an insecure yet highly upvoted StackOverflow answer was found to be providing the code that was vulnerable to this attack, further indicating the hidden security dangers of unverified code copying from open forums.Adding to this confluence is the emerging use of AI-powered tools, such as GitHub Copilot and ChatGPT. GitHub Copilot is an AI assistant integrated into the VS Code IDE and suggests lines or blocks of code as developers type. Its learning input was essentially all the public code repositories that GitHub can access. Similarly, developers are now using ChatGPT to generate code snippets. However, the widespread adoption of these AI tools also raises new security questions. Given that these LLMs are trained on public repositories and other unverified open source code, it could potentially propagate insecure coding practices and vulnerabilities.  Navigating path traversal vulnerabilities in LLM-generated codeWe’ve established that numerous software development tools leverage sophisticated AI systems known as Large Language Models (LLMs). These LLMs generate code that, despite its practicality, occasionally introduces security issues such as path traversal vulnerabilities into production software. Path traversal vulnerabilities, also known as directory traversal, can allow attackers to read arbitrary files on a server's file system, potentially gaining access to sensitive information. Suppose a developer asks an AI model like ChatGPT to create a function to manipulate or fetch files from a directory with a relative path, handling user input. Let's take a look at an example of the generated Node.js code:const fs = require('fs');const path = require('path');function getFile(fileName) {    const filePath = path.join(__dirname, fileName);    return fs.readFileSync(filePath, 'utf-8');}Enter fullscreen modeExit fullscreen modeThe above is essentially how static files are served in frameworks like Nuxt and Next.js or if you’ve run a local Vite server to serve statically generated files through a web framework like Astro.While the above function getFile may appear perfectly harmless, it actually hides a critical path traversal vulnerability. If a malicious user provides a filename like '../../etc/passwd', it would allow access to sensitive system files outside the intended directory – a classic example of a path traversal attack.Consider the following proof-of-concept:console.log(getFile('../../etc/passwd'));Enter fullscreen modeExit fullscreen modeAI models lack the human ability to recognize security implications in various contexts. Therefore, using AI-generated code without close inspection and modification can lead to critical security risks in software applications. It is essential to sanitize user inputs properly or use safe abstractions offered by the language, libraries, or frameworks to defend against path traversal and other potential vulnerabilities. For our Node.js example, a safer approach could be:function getFileSafe(fileName) {    if (fileName.includes('..')) {        throw new Error('Security alert: illegal file path');    }    const filePath = path.join(__dirname, fileName);    return fs.readFileSync(filePath, 'utf-8');}Enter fullscreen modeExit fullscreen modeThe above, however, is still vulnerable to other attack vectors. Do you know what these could be? If you figured it out or want to take a stab at guessing, we encourage you to ping us on Twitter with your ideas at @snyksec.The following is a real example in which I asked ChatGPT to implement a feature related to serving static files with the wonderful Fastify web application framework on Node.js. Hopefully, at this point, when you’re educated on the dangers of path traversal vulnerabilities, you can spot the security issue that ChatGPT included in its code suggestion:To write secure code, developers must remain aware of the potential for AI-generated code to propagate vulnerabilities. While LLMs like ChatGPT offer the promise of accelerated development, human oversight is still vital to ensure robust, secure codebases. The onus is increasingly on us, the developers and engineers, to understand and manage the security implications when adopting code from untrusted sources.  Large language models and the challenge of identifying secure codeDespite the revolutionary advancements in Large Language Models (LLMs) and the integration of AI in coding practices, a significant challenge remains — LLMs' inability to identify code with inherent security vulnerabilities. Luke Hinds, known for his contributions to supply chain security, shed light on this issue with various examples of code generation with AI models like ChatGPT, demonstrating how these models failed to pick up on potential security vulnerabilities across different programming languages and vulnerability types.Luke Hinds' examples demonstrated the gaps in ChatGPT's ability to identify and avoid potential security pitfalls in the code it generates. Whether it was input validation vulnerabilities in Python, a risky implementation of pseudo-random number generators in Go, or a lack of proper error handling in JavaScript code — none of these risks were caught by the model.For example, when asked to provide insight on a code block that suffered from a TOCTOU (time-of-check time-of-use security issue), it completely failed to mention it or to draw attention to the use of the operating system’s temporary directory use in code, which is a glaring security issue in real-world applications due to the predefined directory paths used by OSS. These examples illustrate the danger of relying solely on AI to generate or identify production-quality code without understanding the full security implications.The core issue lies in how AI LLMs are trained. They learn from vast amounts of data from the internet, which includes both secure and insecure code. They do not inherently understand the context, security principles, or implications surrounding the code they generate. This underscores the importance of a careful and methodical human review process irrespective of the nature of the code — human-written or AI-generated.These insights shared by Luke Hinds shine a necessary spotlight on the inherent risks of using AI in software development. While AI and LLMs provide unprecedented opportunities for speeding up code creation and even automating aspects of software development, it is incumbent upon the developers to diligently review, validate, and ensure that the resulting code adheres to secure coding guidelines.   AI security risks and the path to resilient AI systemsArtificial intelligence (AI) has been transforming how we operate, but as with any technological advancement, it encounters its own security challenges. In their enlightening document, ""Securing the Future of AI and Machine Learning,"" Microsoft sheds light on some of these risks and offers valuable insights into working towards resilient AI systems.Let’s explore three perspectives on these AI security risks:One fascinating point they raise is the vulnerability posed by attackers due to the open nature of datasets used in AI and machine learning (ML). Rather than needing to compromise datasets, attackers can contribute to them directly. Over time, malicious data, if cleverly camouflaged and structured correctly, can transition from low-confidence data to high-confidence, trusted data. This inherent risk poses a significant challenge to secure data-driven AI development.Another predicament exists in the obfuscation of hidden classifiers within deep learning models. With ML models being notorious ""black boxes,"" their inability to explain their reasoning process hinders the ability to provably defend AI/ML findings when scrutinized. This characteristic of AI systems, often known as the lack of explainability, raises issues of trust and acceptance, especially in high-stakes domains.Additionally, the lack of proper forensics reporting capabilities in current AI/ML frameworks exacerbates this issue. Findings from AI/ML models that carry great value can be hard to defend in both legal situations and the court of public opinion without strong verifiable evidence supporting them. This highlights the need for robust auditing and reporting mechanisms within AI systems.Microsoft suggests that to tackle these inherent security risks associated with AI, ML, and GenerativeAI, it's crucial to incorporate ""resiliency"" as a trait in AI systems. These systems should be designed to resist inputs that conflict with local laws, ethics, and values the community and creators hold, bolstering their security and trustworthiness.  Mitigating the security risks in the AI-augmented development landscapeAs we delve into a future where AI, LLM, and GenerativeAI tools become integral to our coding practices and software development process, we must ensure that our zeal for innovation does not overshadow the importance of maintaining robust security practices.To minimize the security risks associated with secure coding and GenerativeAI tools, one strong recommendation would be implementing stringent code reviews. Whether the code is auto-generated by an AI or written by a human, it should undergo rigorous quality checks and critical assessment by skilled developers or code reviewers. This can help not only catch traditional coding errors but also identify security vulnerabilities that might go undetected by AI models.Moreover, integrating tools for static application security testing (SAST) can greatly assist in mitigating potential security threats introduced through LLMs. SAST can scrutinize code from within without needing to execute it and identify potential vulnerabilities in the early stages of the development cycle. Automating such testing tools in the code pipeline can further enhance the identification and mitigation of security vulnerabilities.Snyk’s DeepCode AI was built to utilize multiple AI models, is trained on security-specific data, and is all curated by top security researchers to provide developers with real-time secure coding fixes and insecure code detection while they code in their IDE.The following is a real-world example of a Node.js express web application that uses a database backend with insecure SQL code that's vulnerable to SQL injection attacks. The Snyk IDE extension in VS Code detects insecure code as a JavaScript linter red underlines, prompts the developer for awareness, and, better yet, suggests ways to fix the issue.Lastly, perhaps one of the most vital measures is fostering an environment of continuous learning and adaptation within the development teams. Creating a culture that encourages knowledge sharing about the latest trends in secure coding practices, potential vulnerabilities, and their countermeasures can go a long way in maintaining secure applications.  Closing thoughts on AI securityThe agile incorporation of AI tools like LLM and GenerativeAI models promises a future of rapid, optimized software development.Ultimately, the responsibility of producing secure, reliable, and robust software still lies significantly with human developers. AI code generation tools like ChatGPT should be seen as supportive instruments that need human guidance for generating truly secure, production-quality code.The crux is clear — as we advance further into an AI-assisted era, it's paramount that we balance our enthusiasm for such innovations with caution and vigilance. Secure coding must remain a non-negotiable standard, irrespective of whether code comes directly from a human or is suggested by an AI.As we ride this wave of AI innovation, let's strive to maintain impeccable security standards, protecting our software, systems, and ultimately the users who rely on us."
34,"In July, I participated in a “Build in Public” monthly challenge. My goal was to contribute to an open source project that I hadn’t contributed to yet. Luckily, I found my issue pretty quickly and by one of my favorite methods: I let the community know what my goal was and they had a recommendation. Jessica Wilkins is both a member of the community sharing the challenge and a maintainer for freeCodeCamp Developer Quiz Site. When she shared the issue, I immediately said yes. I knew it would let me dust off my coding skills, have support, and contribute to an organization that I have a special connection to-this is where I started learning to code.  The Repository and the Issue[Feature] - Add ability for users to choose a category  Context“The developerquiz.org site is the companion to Learn to Code RPG Game, a visual novel game developed by freeCodeCamp to help you learn how to code. 😺” The site has over 1000+ multiple-choice questions covering a variety of topics, including HTML, CSS, JavaScript, Linux, Python, Git, SQL, IT, Quality Assurance, Agile, Security, and Computer Science Concepts.Prior to this issue, the questions were generated randomly. Now, because there were enough questions to populate each category, I needed to create a component that allowed the user to choose a category of questions.The project uses TypeScript, and I’m going to be honest, I’m still pretty new to TypeScript. I’ll talk about some of the challenges I had with it and how I navigated those challenges later though.  Approaching a New CodebaseI’ll give an overview of my approach, but I highly recommend Abbey Perini’s Getting Started in a New Codebase as a resource for folks new to contributing.I have to resist the urge to just get started every time I’m in a new codebase. I know, it’s exciting jumping into the code, but it’s important to understand the organization, and repository, and to be able to run the project first.1. Read the Documentation. I took my time to read the Code of Conduct, Contributing guide, and the README. I event went back to the latter two before submitting my PR to make sure there wasn’t anything I missed.2.Get the Project RunningUsing the instructions in the README, I forked and cloned the repository, and then I set up the environment locally. From there I was able to run the project as well.3.Familiarize Myself with the CodebaseI started exploring the existing codebase to understand the project's structure, components, and overall functionality.  Previously, users would select the number of questions, and a random quiz would be generated. My new component would need to come into the flow before this, so I’d have to figure out how the components were being displayed once a user made a selection. I also learned  that the logic for the user’s flow was all in the QuizTemplate Component. 4. Component ImplementationI began by creating a new SelectCategory component, which alloId users to pick a quiz category. I essentially copied the SelectQuiz component, and made updates specific to the categories. Within the QuizTemplate component, I import two components: SelectCategory and SelectQuiz. The SelectCategory component allows the user to choose a quiz category, and the SelectQuiz component lets the user choose the number of questions for the quiz. 5. Logic & CodeNext, I needed to add new state variables to manage the selected category and quiz length:const [selectedCategory, setSelectedCategory] = useState(""""); // Initialize with an empty stringconst [selectedQuiz, setSelectedQuiz] = useState(0); // Initialize with 0Enter fullscreen modeExit fullscreen modeIn order to handle category selection, I created the selectQuiz function. When a user selects a category, the selectedCategory and selectedQuiz state variables update.  showOptions gets set to true to show the quiz options (number of questions) and isResults to false to hide the results component initially. This reflects the current structure of what component was being rendered.The selectQuiz function also filters the questions based on the selected category using the ALL_CATEGORIES array and stores the filtered questions in the filteredQuestions state variable.const selectQuiz = (category: string, index: number) => {  setSelectedCategory(category); // Set the selected category  setSelectedQuiz(selectQuizArr[index]); // Set the selected quiz length  setShowOptions(true); // Show the options for quiz length selection  setIsResults(false); // Set to false to hide the Results component  // Filter questions based on the selected category  const filteredQuiz = ALL_CATEGORIES.filter(q => q.Category === category);  setFilteredQuestions(filteredQuiz);};Enter fullscreen modeExit fullscreen modeI also had to modify the rendering logic to include the SelectCategory component for category selection.return (  <>    <Button      handleClick={QuizProps.home}      text=""Home""      isTransparent={false}      size={""""}    />    <FCCLogo />    {!showOptions ? (      <SelectCategory        selectQuizNumber={(          e: React.MouseEvent<HTMLButtonElement, MouseEvent>,          category: string        ) => selectQuiz(category, 0)}        category={selectedCategory}        selectCategoryArr={selectCategoryArr}        selectQuiz={selectQuiz}        startRandomQuiz={startRandomQuiz}      />    ) : isResults ? (      <Results {...resultsProps} />    ) : isReady ? (      <Questions {...questionProps} {...modalProps} />    ) : (      // Existing SelectQuiz component rendering      <SelectQuiz        startQuiz={startQuiz}        totalQuestions={filteredQuestions.length}        selectQuizArr={selectQuizArr}        {...selectQuizProps}      />    )}  </>);Enter fullscreen modeExit fullscreen modeOne of the most important parts of this issue was making sure that the category the user selected was passed to the SelectQuiz component. Here’s how I made sure that happened.In the return statement of the QuizTemplate component, I conditionally render the SelectCategory component if showOptions is false. I pass several props to SelectCategory:selectQuizNumber: A function that is used when the user selects a category. This function takes two arguments: an event (e) and the selected category. It triggers the selectQuiz function with the selected category and index 0 (since the first quiz length option is by default).category: The currently selected category.selectCategoryArr: An array containing all the available quiz categories.selectQuiz: A function reference to the selectQuiz function defined in the QuizTemplate.These prompts are received in the SelectCategory component, where they are used to display the category buttons and handle user interactions. When a user clicks on a category button, the selectQuizNumber function is called, passing the selected category to it.Now in the SelectQuiz component, the selectedCategory and selectedQuiz props are received from the QuizTemplate.When the user clicks on the ""Start Quiz"" button in the SelectQuiz component, the startQuiz function is called, passing the selected quiz length and triggering the quiz initialization process based on the selected category and quiz length.So the selectedCategory and selectedQuiz state variables in the QuizTemplate component serve as a bridge between the SelectCategory and SelectQuiz components. The SelectCategory component communicates the selected category to the QuizTemplate, which then passes that information along with the selected quiz length to the SelectQuiz component. This way, the SelectQuiz component knows which category and quiz length the user has chosen and can initialize the appropriate quiz based on those selections.For the full code, you can check out my Developer_Quiz_Site fork.And once I was done, I went to my OpenSauced profile to create a highlight to showcase my contribution and do some storytelling about the experience.   Challenges FacedI think it’s always worth talking through the challenges so other contributors know that they aren’t alone if they struggle to contribute to open source.1. Time ManagementBalancing this contribution with my job, community-building activities, and family was a significant challenge. Jessica was patient with me and I knew ahead of time there wasn’t a hard deadline. That took some of the pressure off.2. TypeScript Learning CurveAs a TypeScript beginner, there were sometimes I had no idea what was happening. I’m a big fan of using tools like ChatGPT and GitHub Copilot to help me through the process. I really enjoyed using GitHub Copilot to explain TypeScript code. I learn a lot when I’m doing projects hands-on, and having an AI assistant to help explain what was happening helped me to be more efficient in my learning and coding.  Benefits and TakeawaysIt always feels good when I get a PR merged in, and this wasn’t any different. I was actually pretty excited to find my next issue since Jessica’s feedback was positive and considerate. Even though this wasn’t a huge issue, I definitely grew through this contribution. I gained hands-on experience with type-safe code. I also wrote some Jest tests, which I hadn’t done in a couple of years. It took me longer than I anticipated, but I’m proud of getting my first PR accepted in the freeCodeCamp repository. If you're considering making your first open-source contribution, I encourage you to get started today. Here are some gentle ways to get started in open source: Take our Intro To Open Source Course to learn more about open source and how to get started.Join #100DaysOfOSSIf you have any questions or feedback, drop them in the comments below."
35,"  Introduction:Hey fellow developers! 🚀 Are you tired of writing repetitive validation code for your Go projects? Look no further! Allow me to introduce you to Zogo, a blazing-fast custom validation library that will simplify your life and help you maintain cleaner and more organized code.  What is Zogo?Zogo is a comprehensive validation library crafted specifically for Go developers. With Zogo, you can effortlessly validate various data fields in your applications using a collection of pre-built validation rules. Whether you're validating strings, numbers, emails, booleans, or any other type of data, Zogo has got your back!  Key Features:✅ Ease of Use: Zogo provides a user-friendly API that makes adding validation rules a breeze.⚡ Customizable: Tailor validation rules to your specific project requirements.📋 Available Validation Rules: Min/Max Length, Min/Max Value, String Not Empty, Email, Boolean, and more!🚀 High Performance: Zogo is designed for speed, ensuring minimal impact on your application's performance.🧪 Tested and Reliable: Rigorously tested to ensure stability and reliability.📚 Detailed Documentation: Comprehensive documentation to guide you through usage.  Example: Validating Age with ZogoLet's say you want to validate a person's age, ensuring it's represented as a string of at least 2 characters and not less than 18. With Zogo, achieving this is a breeze:validator := zogo.NewFormValidator()validator.AddRule(""age"", zogo.MinLengthValidator(2)) // Minimum of 2 charactersdata := map[string]interface{}{    ""age"": ""20"", // Age as a string    // ... other fields}if err := validator.Validate(data); err != nil {    fmt.Println(""Validation Error:"", err)} else {    fmt.Println(""Data is valid."")}Enter fullscreen modeExit fullscreen mode  Get Started with Zogo:Getting started with Zogo is super easy! Just install it via:go get github.com/frantchessico/zogoEnter fullscreen modeExit fullscreen modeYou can find detailed usage instructions, examples, and more in the Zogo GitHub repository.  Conclusion:Say goodbye to writing repetitive validation code and embrace the power of Zogo! Experience efficient, customizable, and high-performance validation in your Go projects. Give Zogo a try and unlock a new level of development productivity today. Happy coding! 💻🚀Feel free to tweak the content to suit your preferences and needs. Make sure to replace ""yourusername"" and ""yourproject"" with the actual GitHub username and project name before posting on dev.to. Good luck with your post!"
36,"Hello Everyone, Welcome to Week 2 of showing and sharing new open-source projects to the community. We would be more than glad to share your project on our page next week!If you'd like to be featured on it, don't you forget to share it on the comments, so we can see you!Make sure to help and Star ⭐️We have a special one at the end just for you!   Cal.comAn open source project that allow you to have your calendar in new ways and integrated.Figma Design 🚢Open Bounties 🙌Free 👍Large amount of languages ⛴️GitHub Repository: https://github.com/calcom/cal.com  FormbricksIt's an Open Survey & Experience Management solution for fast-growing companies🔒 All open source, transparent and self-hostable📲 Create in-product surveys with our no code editor with multiple question types🔗 Create shareable link surveys👨‍👩‍👦 Invite your team members to collaborate on your surveys🔌 Integrate Formbricks with Slack, Posthog, Zapier and moreGitHub Repository: https://github.com/formbricks/formbricks  InfisicalOpen-source, end-to-end encrypted secret management platform: distribute secrets/configs across your team/infrastructure and prevent secret leaks.User-friendly dashboard to manage secrets across projects and environments (e.g. development, production, etc.)😊Client SDKs to fetch secrets for your apps and infrastructure on demand⭐Infisical CLI to fetch and inject secrets into any framework in local development💖Native integrations with platforms like GitHub, Vercel, Netlify, and more🤩GitHub Repository: https://github.com/Infisical/infisical  NovuNovu provides a unified API that makes it simple to send notifications through multiple channels, including In-App, Push, Email, SMS, and Chat. 🌈 Single API for all messaging providers (In-App, Email, SMS, Push, Chat)💅 Easily manage notifications over multiple channels🚀 Equipped with a CMS for advanced layouts and design management📦 Easy to set up and integrateGitHub Repository: https://github.com/novuhq/novu  OpenBBOpenBB is committed to build the future of investment research by focusing on an open source infrastructure accessible to everyone, everywhere.Free for everyone 📊Can use to Check on everything on the stock market and crypto coins and ETF's 📈GitHub Repository: https://github.com/OpenBB-finance/OpenBBTerminal  ⭐️IDURAR⭐️IDURAR is Open Source ERP / CRM (Invoice / Inventory / Accounting / HR).Ant design frameworkBuild with Mern stack Node.js / Express.js / MongoDb / React.jsRedux state manager✨ERP/CRMInventory & Accounting Github Repository: https://github.com/idurar/idurar-erp-crmI Would like to thank everyone that is here and got to help all of these projects by leaving a ⭐️ on their GitHub and fork on your own repository :) Make sure to Fork and Star every project that you see on the list so you can help them!Thank You 💖If you'd like us to include your project, don't forget to leave the comment, so we can help you out!see you next Week!"
37,"If you haven't read yet, you can check other articles from this color theme series here.Since I've made a color theme, I also ended up customizing the Extensions that use color schemes like Better Comments and Indent Rainbow and trying to match them with the Nebula Oni Color Theme. So, of course, in order to follow this guide you've got to download them first.Originally, I had made a color scheme for the Bracket Pair Colorization but since I originally launched the theme, Bracket Pair Colorization became part of VSCode - and if I'm not mistaken it's now active by default.  Bracket Pair ColorizationInitially, I was trying to make them different from the Nebula Syntax, so I wouldn't confuse them, but it's hard to use colors that are different enough because if they are close and almost the same color, it kind of bothers me.These 6 colors have the same hue as the colors from Nebula Syntax and I combine them in a way that the colors I prefer appear more often and that each pair can work well together within the iteration cycle.It was quite a hassle, but in the end, I think it works well and it's aesthetically pleasing.Hourglass/SpirographPegasus/CerberusSpirographCerberus  Better CommentsI customized the tags that trigger the colors as well as the colors themselves. They are not the same as the Nebula Syntax but they have a similar hue but are brighter, more saturated.All triggers need the Shift Key except for the strikethrough (double slash: / / ).For the other tags, you basically have 4 triggers in the numbers row, a pair on the far left ~ and ! and another on the far right _ and + and then the 4 colors I use the most are near the Right Shift < and > and then ? and :.But of course, depending on your keyboard layout, it may vary. So if you prefer some other character, you just have to change it on the settings.json file. You might need to reload window for the new trigger characters to take effect.These are the settings I use:    ""better-comments.highlightPlainText"": true,    ""better-comments.tags"": [        {            ""backgroundColor"": ""transparent"",            ""color"": ""#F22468"",            ""strikethrough"": false,            ""tag"": ""!""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#FFA233"",            ""strikethrough"": false,            ""tag"": ""~""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#18F26C"",            ""strikethrough"": false,            ""tag"": ""<""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#E645BD"",            ""strikethrough"": false,            ""tag"": "">""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#E6E648"",            ""strikethrough"": false,            ""tag"": ""?""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#A273FF"",            ""strikethrough"": false,            ""tag"": "":""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#6699FF"",            ""strikethrough"": false,            ""tag"": ""_""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#2EE6E6"",            ""strikethrough"": false,            ""tag"": ""+""        },        {            ""backgroundColor"": ""transparent"",            ""color"": ""#737880"",            ""strikethrough"": true,            ""tag"": ""//""        }    ]Enter fullscreen modeExit fullscreen mode  Indent RainbowIf you want, you can use the same colors as the Bracket Pair Colorization or just use 4 colors like the default settings for Indent Rainbow.I tried to use the same colors as the Bracket Pair Colorizer but I don't know, I didn't think it worked that well so I've tried a few combinations and came up with this.    ""indentRainbow.colors"": [        ""#4DFFFF14"",        ""#FFF04D14"",        ""#C3A6FF14"",        ""#4DFF9214"",        ""#FF99E514""    ],    ""indentRainbow.errorColor"": ""#801B3DA3"",    ""indentRainbow.tabmixColor"": ""#1A5580A3""Enter fullscreen modeExit fullscreen modeAll these settings are part of the settings.json file, just remember to use , where needed but otherwise, it's just a matter of copy and paste.  Panel and TerminalThe bottom Panel is one of the few sections that have a border - same as the pinned tabs - but it's almost imperceptible, it's just enough so you can differentiate where it ends and where the editor starts, making it look like they are on top of the editor.I tried to select colors that are easy to read but it's still compatible with terminal customizations like ZSH shell.For more information on how to customize it, I've followed this tutorial that has instructions for Windows, Mac and Linux.  My Settings    ""debug.console.fontFamily"": ""Liga Meslo LG M DZ"",    ""terminal.integrated.cursorStyle"": ""line"",    ""terminal.integrated.cursorWidth"": 2,    ""terminal.integrated.fontFamily"": ""Liga Meslo LG M DZ"",    ""terminal.integrated.fontWeightBold"": ""normal"",    ""terminal.integrated.lineHeight"": 1.1,Enter fullscreen modeExit fullscreen modeI use these settings but MesloLGS NF, Hack NF and FiraCode NF are also good font options. For more information check Nerd Fonts.  Help Support Nebula Oni Color ThemeTo learn more about the Nebula Oni Color Theme or how to further customize it, take charge and change colors for the Semantic Tokens and Text Mate Tokens yourself, check out this post.If you want to support this theme, would you consider:sharing this theme with friends and colleaguesrating it on Visual Studio Code Market Place and Open VSX Market Placegiving it a star on GithubAnd if you really liked this theme, would you consider buying me a coffee?Thanks,[ psudo.dev ]"
38,"In my experience of building and delivering systems for various clients, depending on their requirements or preferences, it’s inevitable that I may use UI frameworks and libraries like Ant Design and Tailwind. Often, I have to build on top of each components. If you are working alone, it’s not such a big problem. But when working as a team, things get complicated quickly. So, I started looking at different methodologies which can provide development flexibility and system maintainability for the projects I’m leading. I choose Atomic Design methodology and want to share why it works for me. Atomic Design is a methodology for creating design systems that breaks down user interfaces into small, reusable components, namely:AtomsMoleculesOrganismsTemplatesPagesBy following a modular approach to design, atomic design helps teams to create consistent, scalable, and maintainable UIs. In this post, for simplicity, we'll explore how to implement Atomic Design in Vue.js with only HTML. I'll start with the basics of Atomic Design and then demonstrate how to apply its principles in Vue.js. At the end of the article, you will get a page that consists of a header, a form and a footer. You can use the example here to apply to any UI framework.You may notice that each component has borders around it. This is intentional so you can identify whether it's an atom, a molecule, or an organism.   Anatomy of Atomic DesignAtomic Design consists of five levels that represent the building blocks of UIs. For this example, I have created an inverted tree structure to visualizing how each anatomy is connected.- Page - Full Layout Template  - Header Organism    - Logo Atom    - Search Form Molecule      - TextBox Atom      - Button Atom  - Content Organsim    - Form Molecule      - 2x TextBox Atoms      - Button Atom  - Footer Organism    - Copyright Atom    - Subscribe Form Molecule      - TextBox Atom      - Button AtomEnter fullscreen modeExit fullscreen mode1. AtomsAtoms are the smallest units of UI that cannot be broken down further without losing their meaning. Examples of atoms include icons, buttons, labels, inputs, and typography. In Vue.js, atoms can be created as reusable components that accept props to customize their appearance and behavior. For this instance, we have a few atoms to prepare for:Textbox<template><div class=""component-wrapper"" data-name=""textBoxAtom"">  <label>{{ label }}: <input type=""text"" :placeholder=""placeHolder"" /></label></div></template> <script>export default {   name: 'TextBoxAtom',   props: {     label: {      type: String,      default: 'labelName'    },     placeHolder: String,   }, }; </script><style scoped>  input{      padding: 0.75em 2em;  }</style>Enter fullscreen modeExit fullscreen modeButton<template> <div class=""component-wrapper"" data-name=""buttonAtom"">  <button :disabled=""disabled"">     <slot>Button</slot>  </button>  </div></template> <script>export default {   name: 'ButtonAtom',   props: {     type: String,     size: String,     disabled: Boolean,  },  }; </script><style scoped>button {  color: #4fc08d;}button {  background: none;  border: solid 1px;  border-radius: 2em;  font: inherit;  padding: 0.5em 2em;}</style>Enter fullscreen modeExit fullscreen modeLogo<template>  <div class=""component-wrapper"" data-name=""logoAtom"">    <img :src=""computedImageUrl"" alt=""logo""/>  </div></template><script>export default {  props: {    width: {      type: Number,      default: 50    },    height: {      type: Number,      default: 50    }  },  computed: {    computedImageUrl() {      return `https://picsum.photos/${this.width}/${this.height}`    }  }};</script>Enter fullscreen modeExit fullscreen modeFor a closer look, you can check out the codes in the Atoms collection.2. Molecules Molecules are combinations of two or more atoms that work together to perform a specific function. In Vue.js, molecules can be created by composing atoms as child components within a parent component. Examples of molecules include forms, search bars, navigation menus, and cards. Referring to the example above, we will need to combine the atoms to create the following molecules:Subscribe Form Molecule <template>  <form class=""component-wrapper"" data-name=""subscribeFormMolecules"">    <TextboxAtom label=""Email"" />    &nbsp;    <ButtonAtom>Subscribe</ButtonAtom>  </form></template><script>import TextboxAtom from ""https://codepen.io/haroonth/pen/LYXgdKg.js"";import ButtonAtom from ""https://codepen.io/haroonth/pen/BaGqrJg.js"";export default {  components: { ButtonAtom, TextboxAtom }};</script><style scoped>form {  display: inline-flex;}</style>Enter fullscreen modeExit fullscreen modeSearch Form Molecule<template>  <form class=""component-wrapper"" data-name=""searchFormMolecules"">    <InputAtom label=""Search"" />    <ButtonAtom>Search</ButtonAtom>  </form></template><script>import InputAtom from ""https://codepen.io/haroonth/pen/LYXgdKg.js"";import ButtonAtom from ""https://codepen.io/haroonth/pen/BaGqrJg.js"";export default {  components: { ButtonAtom, InputAtom }};</script><style scoped>form {  display: inline-flex;}</style>Enter fullscreen modeExit fullscreen modeForm Molecule<template>  <div class=""form-molecule component-wrapper"" data-name=""formMolecules"">    <div><InputAtom :label=""nameLabel"" :placeholder=""namePlaceholder"" /></div>    <div><InputAtom :label=""emailLabel"" :placeholder=""emailPlaceholder"" /></div>    <p>      <ButtonAtom :disabled=""isSubmitDisabled"">        {{ submitLabel || ""Button"" }}      </ButtonAtom>    </p>  </div></template><script>import InputAtom from ""https://codepen.io/haroonth/pen/LYXgdKg.js"";import ButtonAtom from ""https://codepen.io/haroonth/pen/BaGqrJg.js"";export default {  name: ""FormMolecule"",  components: {    InputAtom,    ButtonAtom  },  props: {    nameLabel: String,    namePlaceholder: String,    emailLabel: String,    emailPlaceholder: String,    submitLabel: String,    isSubmitDisabled: Boolean  }};</script>Enter fullscreen modeExit fullscreen modeYou can find the codes in the Molecules collection.3. OrganismsOrganisms are combinations of molecules that form distinct sections of a UI, such as headers, footers, sidebars, and content blocks. In Vue.js, organisms can be created by composing molecules as child components within a layout component.For this exercise, three organisms are needed.Header Organism<template>  <header class=""component-wrapper"" data-name=""headerOrganism"">    <LogoAtom width=""60"" />    <SearchFormMoecules />  </header></template><script>import SearchFormMoecules from ""https://codepen.io/haroonth/pen/zYMmjqa.js"";import LogoAtom from ""https://codepen.io/haroonth/pen/xxQMbeJ.js"";export default {  components: { SearchFormMoecules, LogoAtom }};</script><style scoped>header {  min-height: 50px;  display: flex;  justify-content: space-between;  align-items: center;}</style>Enter fullscreen modeExit fullscreen modeContent Organism<template>  <div class=""page-organism"">    <div class=""content-wrapper-title"">      <h1><slot name=""title"">Here might be a page title</slot></h1>      <p><slot name=""description"">Here might be a page description</slot></p>    </div>    <slot>...</slot>    <!--   This might includes some molecules or atoms   -->  </div></template><script>export default {  name: ""ContentOrganism"",  components: {}};</script><style scoped>.page-organism {  padding-top: 50px;  padding-bottom: 80px;  box-shadow: inset 0px 10px 15px -3px rgba(0, 0, 0, 0.1);}.content-wrapper-title {  text-align: center;}</style>Enter fullscreen modeExit fullscreen modeFooter Organism<template>  <footer class=""component-wrapper"" data-name=""footerOrganism"">    <CopyrightAtom />    <SubscribeFormMoecules />  </footer></template><script>import SubscribeFormMoecules from ""https://codepen.io/haroonth/pen/ExOrarL.js"";import LogoAtom from ""https://codepen.io/haroonth/pen/xxQMbeJ.js"";import CopyrightAtom from ""https://codepen.io/haroonth/pen/gOQqOBj.js"";export default {  components: { SubscribeFormMoecules, LogoAtom, CopyrightAtom }};</script><style scoped>footer {  display: flex;  justify-content: space-between;  align-items: center;}</style>Enter fullscreen modeExit fullscreen modePer usual, here's a collection of organisms' codes that I've created.4. Templates Templates are the structures that define the layout and composition of pages by specifying the placement and size of organisms within regions, such as headers, footers, and content areas. In Vue.js, templates can be created as parent components that accept named slots for child components. Applying the 3 organisms to the Templates concept, here is how it could look like.<template>  <div class=""full-layout-template"">    <HeaderOrganism />    <ContentOrganism class=""content"">      <template #title>        <slot name=""title"">default title</slot>      </template>      <template #description>        <slot name=""description"">default description</slot>      </template>      <slot />    </ContentOrganism>    <FooterOrganism class=""page-footer"" />  </div></template><script>import HeaderOrganism from ""https://codepen.io/haroonth/pen/WNYaJGR.js"";import ContentOrganism from ""https://codepen.io/haroonth/pen/vYQbOeO.js"";import FooterOrganism from ""https://codepen.io/haroonth/pen/RwqvPRN.js"";export default {  name: ""FullLayoutTemplate"",  components: {    HeaderOrganism,    ContentOrganism,    FooterOrganism  }};</script><style scoped>.full-layout-template {  display: flex;  flex-direction: column;  min-height: 90vh;}.content {  flex: 1 0 auto;}.page-footer {  flex-shrink: 0;}</style>Enter fullscreen modeExit fullscreen modehere is the CodePen's link of the template 5. PagesPages are the final presentation of UIs that combine templates with specific content to form complete views. In Atomic Design, pages are like instances of templates that represent unique experiences for users. In Vue.js, pages can be created by copying a template and replacing its slots with actual content. Although, in this example, I only change the content of Content Organism, you could choose to change all or no content.<template>  <FullLayoutTemplate>    <template #title>{{ title }}</template>    <template #description>{{ description }}</template>    <div class=""fixed-width"">      <FormMolecule nameLabel=""Name"" emailLabel=""Email"" submitLabel=""Save"" />    </div>  </FullLayoutTemplate></template><script>import FullLayoutTemplate from ""https://codepen.io/haroonth/pen/GRwzpxx.js"";import FormMolecule from ""https://codepen.io/haroonth/pen/PoxyRMo.js"";export default {  name: ""HomePage"",  components: {    FullLayoutTemplate,    FormMolecule  },  data() {    return {      title: ""Welcome to my example"",      description: ""This is an example of Atomic Design in Vue.js"",      copyright: ""Copyright © 2023""    };  }};</script><style scoped>* {  font-family: Avenir, Helvetica, Arial, sans-serif;}.fixed-width {  max-width: 350px;  margin: 0 auto;}</style>Enter fullscreen modeExit fullscreen modehere is the CodePen's link of the page   Benefits of Atomic Design in Vue.jsBy using Atomic Design in Vue.js, you can achieve several benefits, such as:Consistency: By creating reusable components, you ensure that your UIs look and behave consistently across all pages. Scalability: By breaking down UIs into small pieces, you can easily add, remove, or update components without affecting other parts of the system. Maintainability: By organizing components into folders and files, you can easily find, edit, or debug them in isolation from other parts of the system. Reusability: By creating standalone components, you can reuse them in other projects or share them with the community, thus saving time and effort. Atomic Design is a powerful methodology that can help you design better UIs in Vue.js. By following its principles, you can create reusable, modular, and scalable components that make your code more maintainable and your users more satisfied. So, go ahead, give it a try, and let me know how it worked for you!  Berryjam: UI components analyzer for Vue 3 & NuxtIf you are interested in finding out more about how you are using UI component or how your front-end team is utilizing the sharable UI component, take a look at Berryjam. It’s free!  Can you please help me?If you are feel this article is useful, could you consider starring Berryjam's Github repo ⭐ ⭐ ⭐ It would mean the world and encourage me to create more content. Thank you in advance! 🙏"
39,"The job of a software developer can be summarized into two words: constantly evolving. Anti-static. The nature of software demands it since modern programs, apps, and websites require us to use a plethora of abstraction layers and tools that we can't always know how they really work. Each tool or layer we bring into our environment abstracts some part of the development process behind its API that we will then use. This is a normal process with the fantastic benefit of enabling the developer to create complex, stable, and beautiful applications and tools that would otherwise require whole teams of experts just a couple of years ago to construct. This phenomenon has a downside that we must be aware of, especially in the modern web world. So many processes and behaviors get abstracted that we begin to learn the APIs of those tools, not the programming itself.Most of the newcomers to the world of software development begin their journey in the web world. The beginnings are rough and hard, and the front end is a great starting point since it provides visual feedback and is the most rewarding part for most people. After spending the humble beginning writing calculators, managing arrays with loops, or handling input and output to the console, the ability to create websites so quickly feels ground-breaking. Naturally, this progress leads a new developer to the UI libraries and frameworks of the modern day: React, Angular, and such.We tend to forget how amazing these tools are and just how much they speed development up. A decent React developer can easily take a Figma design file and recreate the UI and interactivity without breaking a sweat. They help us handle the UI, updating state, routing, and more, and they introduce their APIs to do so. In a rush to get a job and start earning money, this makes new, fresh, and inexperienced developers rush to these tools, sparking the numerous ""What is the best frontend framework to learn"" debates.This has the often forgotten consequence of new developers learning frameworks, not programming itself. They learn the APIs of their tools and how to use them, get a job, and then struggle to keep up with the more complex codebases. Writing UIs and connecting them with backends usually works well, but problems arise when the apps get complicated to the point where custom state management practices are required, reducing the number of requests to the backend should be tackled, or decoupling of the presentation layer from the other code needs to be done, or even rewriting the UI from one library to another. This inevitably brings challenges to the developer, where a clear lack of competence gets shown and the developer struggles to keep up. The pace of modern development doesn't help, making it hard to, between a full-time job and other parts of life, find enough time and energy to try to work on one's personal projects. It is my own opinion that most fresh developers struggle with this, myself included. It's a balancing act all of us need to manage.Software is not easy, and between college and Udemy tutorials there is a lot of sweat, failed projects, and keystrokes needed to grasp the concepts and get stuff done. This brings me to the title of this post: reinvent the wheel. I constantly hear the advice ""Stop going through tutorials, think of an idea, and start working on it"", which is the best way to learn in my opinion. But there is an addition I'd like to recommend - start reinventing the wheel, which will further deepen your understanding of your codebase.Maybe you're using the RxJs library to aid with state management in your front-end project. It's quite a complex library and takes some brain power to grasp the concepts and start using it well. Why not try and recreate its reactive primitives? It's easier than it seems, and the new-found intuition and understanding will reshape your thinking about RxJs. It's incredible how much this practice changes your perspective. They don't say ""To fix it, you first need to know how it works"" with no reason. Maybe you use Express for writing backend apps in Node. Have you ever wondered how the routes work? What's happening underneath the pretty syntax?With the power of understanding the hidden layers comes the benefit of making fewer bugs, quicker debugging, and even the ability to modify some behavior otherwise inaccessible. If one has the time, I strongly recommend to try and tackle an unknown variable in your toolset, and by recreating just the most basic parts of it, you may come out a stronger engineer on the other side."
40,"This post is based on a talk I gave at the Geek Sessions meet-up in Faro, Portugal 🇵🇹 on the 28th of June, 2023.  The full title for this talk was ""Lessons learned from messaging strangers on the internet in a language I did not speak"" and the idea here is to draw some parallels between the idea of learning new (spoken) languages and learning new skills in technology.Back in June 2020 I was very bored and in lockdown, like most folks, and decided that I needed to learn something in order to keep sane. Being the language nerd that I am I decided I was going to learn Spanish.Since I couldn't just learn the basics and then take a two week holiday somewhere in Spain to practice I needed to decide how I was going to approach it before I could get started.  The PlanAs I am a native speaker of Brazilian Portuguese I thought this was going to be a quick and easy exercise. Just how I thought the pandemic and the lockdowns would be over before the end of summer or by halloween. Boy was I wrong...So my idea was simple:I'd exchange at least 50 messages a day with a number of people using language learning chatting appsWatch videos in Spanish with Spanish subtitles. Money Heist taught a great Italian song (and some Spanish too!)Start listening to music, and later podcasts, in SpanishArmed with a sound plan and a fool's confidence, I set my target language to Spanish in HelloTalk and got to work!  How did it go?As it turns out, knowing Portuguese didn't help nearly as much as I thought it would. Brazilian Portuguese has a much simpler grammatical structure, which meant that whilst I could read messages and take a second to understand which grammar tense was being used, I couldn't really keep up with people's audio messages or Youtube videos and series.Added to that, whilst there's an overlap of about 90% of vocabulary between the two languages, this overlap doesn't help as much as you'd think. Some words have slightly different meanings, have fallen out of fashion in one language or the other, or just sound straight up embarrassing and you didn't even know it.I was always looking words up on either SpanishDict or using Google Translate, DeepL and the apps' builtin translation tools.After about 6 months I was already better at writing and didn't need to rely so much on SpanishDict for verb conjugations of regular verbs and the most common irregulars like ser, estar, ver and a few others.At about the 9 to 12-month mark I started being able to speak a few sentences without having to write them down first. My accent was horrible but at least I was able to alternate between audio and written messages during my practice.  ThenAfter about 18 months I started to recall things quicker, expressing myself and having more in-depth conversations with others become much easier. I no longer needed subtitles and became able to listen to audiobooks and podcasts, some even at 1.5 or 2 times the normal playback speed.Around this same time I also started to develop a kind of intuition for verb conjugations I didn't know, and was able to use some of the less common verb conjugations in speech without the need to look them up in a dictionary.  NowAbout three years into this learning journey my language level has oscillated between a good B2 and an acceptable B1.I've had the opportunity to travel to Spain a few times and spend time there with friends speaking mostly Spanish for a number of days in a row each time. After being in a Spanish speaking environment for about a day I am very much back at my best.My accent is still inconsistent, I'll very quickly start mirroring whichever accent is spoken around me and then use expressions and vocabulary that may not be as common or native to where I am, e.g. using Mexican or South American words whilst speaking to a Spanish person.I don't mind this as much as I used to, I would like to have a more consistent accent but I've come a long way and I feel like I have achieved way more than what I had originally set out to achieve.  Parallels between skilling up in technology and learning a spoken languageNow that I've given some context of my learning journey, let's shift our attention to some of the things I've identified in my process that could also be used to improve our experience when learning new skills in tech.Learning can be a very personal experience and different people will have different ways in which they prefer to acquire new skills, for the purposes of my talk I chose to focus on a few more general points in order to try and make it as useful and relatable to as many people as possible. These are the five points I want to touch on:  1. Identify your goalsBefore you start you should identify your goals, this will help you with checking in on your progress along the way. These are a few of the questions you can ask yourself to try and understand:What do you want to do with this new skill?How will you know when you've achieved it?How strict are you about those answers?Will there be a next level after you're done with this one?These questions are not comprehensive but should be a great starting point. I find it specially useful to know how flexible I can be with the goal as I progress and how well documented my goal setting needs to be.For professional goals we're usually required to have a more detailed description and be more strict with our definition of done. Personal goals can go from a mental note to a full blown schedule, depending on what it is that you're aiming for.  2. Take small stepsNow that you've determined what the end of the journey should look like, let's go back to the start. For almost any skill in technology it pays off to really understand the foundations of what you're learning—you should learn to walk before you try to run.If you're learning a programming language you should focus on the basics of its syntax and peculiarities first, e.g. understand the basics of Rust's ownership system, or Javascript's asynchronous nature.It's also a good idea to start with some tutorials or books that will walk you through these basics and then start to experiment with the simpler examples that you see, exploring things in your own way.If you're trying to learn a new skill that is more role specific, like DevOps, then perhaps  you can start with understanding the basics of Docker, Kubernetes and what it takes to deploy a ""hello world"" style app using such technologies. The main goal at this point is to start small so you can find your pace. Learning shouldn't be overwhelming, nor boring.After the talk we had a small QA session and one of the questions was about how can we know whether we're doing too much or too little when trying to learn. A good analogy I came up with for the case of spoken languages was: if you're dreaming in your target language, you're good, if you start losing sleep over it then it is too much.I don't expect anyone to measure their learning effort of Rust or Haskell by how much they dream about these languages but this is still a good analogy in terms of the levels of exposure to the thing you're trying to learn and how much you should make it a part of your daily life.This takes us to the next point...  3. Practice regularly and immerse yourself in the technologyIn order to learn a new skill effectively you need to be able to incorporate as much practice as possible into your daily life. In the case of spoken languages this is obvious and easier to define. You should be listening to music, watching videos in the target language and speaking to natives or fluent speakers of that language as much as possible. For technology things can be a little bit trickier.It is unlikely that you'll be able to get a job utilising a skill that you've just started to learn when it comes to tech, in order to counter that you'll have to find other ways to immerse yourself into the tech area you're trying to learn.The most obvious way to get exposure to the thing you're learning is by practising it. Building low stakes projects will be the most effective way to achieve this as you can try different things out without running the risk of having a bigger impact on things around you. Then after that I would recommend listening to podcasts, reading blog posts, books, developer documentation, watching conference talks (online and in-person if possible), joining communities online around the topic that you're trying to learn (more on this later).These are all great options and you should try and mix and match them as and when you can, so long as you incorporate some kind of daily practice on your routine you will see the value in this effort in no time.  4. Embrace your mistakesMistakes are a very natural part of learning. Regardless of whether we're just getting started or have been practising for a little while, it's obvious that we will make many mistakes along the way. You should learn to be comfortable with your mistakes early on, in order to avoid frustrations.As briefly alluded to in my previous point, having low stakes settings for your practice is one way to help you be more comfortable with making mistakes. Another point that is worth noting is that mistakes can also be used to give us more perspective on what we're learning.Whenever you make a mistake, be it one that makes it so your code doesn't compile or something that someone else is telling you shouldn't be done in that way you can ask yourself why is it that this is not how it should be:Did you break a hard rule by making a syntax error or referencing a variable or file that doesn't exist?Did you not follow best practice and are now running into unexpected behaviour?Did you rely on a feature of the language you're learning that you didn't fully understand and now don't know why it isn't doing what you hoped it would?Mistakes in programming and other aspects of technology can come in different shapes and forms but they're a great way to help us understand what it is that we're lacking in terms of knowledge so that we can work to fill that gap.Another great way to use our mistakes as a positive part of our growth is by having a mentor or community that can help you to keep moving when you're struggling to understand something or to get it to work as intended, this takes us to the last point I want to touch on...  5. The importance of focused communitiesThere will always be other learning or using the same things you're trying to learn, if you can find a good group of people to learn with or at least exchange some of your experiences the synergy it creates can drastically improve your learning journey. Furthermore, by participating in communities you will likely start to meet people that could eventually help you on a professional level too, or that you may be able to help them.I strongly recommend trying to find local communities for this as well, for offline meet-ups and events. These will usually have an online side to them but being able to get together and meet people, join hackathons or other events where you also get to do things alongside others can really help the immersion part of learning.Another, possible less obvious, benefit of being part of more focused communities is that it helps with staying motivated. Very often in our lives things will happen that will force us to set things aside for a short period of time or  deprioritise something in favour of a more pressing issue. When this happens, being part of a community and attempting to stay active will serve as a reminder of your learning journey and how you should continue to try and learn as much as your available time allows.  ConclusionThat's it! I understand that this is by far not a comprehensive list but I hope it helps you when you next try to learn something from scratch or even on your current learning journey.You can find the slides for my original talk in here and the source code for the slides on my Github.Share in the comments below what sort of techniques or tips you keep coming back to when learning and what you are trying to learn now. Me, I'm currently trying to learn more of the Rust programming language, as it's a compiled, lower level, language and I've never really done anything with compiled languages before."
41,"It happened! That spark! An epiphany!You got a brilliant app idea. Or maybe a new concept for a SaaS platform.As developers, our instincts say to start coding right away and bring this idea to life!But hang on. Before diving into development, it's crucial to validate the idea first.Just because you can build something doesn't mean you should. Validating an idea reduces risk, saves time and money, and ensures you're addressing a real market need that someone is willing to pay to solve.How can I validate an idea? Good question.  Understand Your Target MarketWho is going to use or buy your product? Get ultra-clear on your target demographics. Consider factors like:Age, gender, locationIncome level, educationValues, interests, pain pointsResearch similar products and analyze their target markets. Figure out how your idea differs and who would find value in those differences.  Conduct Competitor AnalysisIgnore this step at your own peril. What other solutions currently exist? How do they meet (or fail to meet) your target users' needs?Make a list of direct and indirect competitors. Study their offerings closely to understand positioning and identify potential gaps/opportunities.If you are going to try to sell to customers in the niche, how credible do you think you'll sound if they ask you about these competitors and you don't know anything about them?  Validate Demand Through SurveysCreate simple surveys using Google Forms, Typeform, or SurveyMonkey. Reach out to people in your target market and gauge interest in your idea.Ask about their needs, what they dislike about current solutions, and if they see value in your proposed offering.The questions don't need to be complicated. If there's interest, it'll quickly become apparent.  Interview Potential CustomersSurveys provide breadth of feedback, but interviews offer depth. Have phone calls with your ideal users. Dig deeper into their needs and hear reactions to your idea.Pay attention to subtle cues like tone and energy levels. If they seem genuinely excited, you're onto something!Early on, these interviews might be something that happen naturally when you are trying to solve a problem for a customer. Yes, before you've built your product and while you're learning about the market, you'll very likely have opportunities to solve real customer needs -- and they'll pay you for the privilege. This is part of the idea of doing things that don't scale.  Define Your Minimum Viable Product (MVP)Determine the bare minimum set of critical features needed for an MVP. Avoid getting bogged down by bells and whistles at this stage.Your MVP should showcase the core value proposition and resonate with early adopters.I read a story about an org that delivered on the core value proposition but also added links to every feature they could think of to the UI in the app. None of the additional features were implemented. The links led to individual feature surveys asking those already paying customers what the feature would do for them and how it would impact the value of the product. Brilliant!  Create a Landing PageSet up a simple landing page explaining your product and allowing for signups. Use concise, emotional copy focused on user benefits.Promote the page through social media, communities, and target emails. Have a form to collect emails and gauge conversion rates.You're only interested in determining market demand for the idea. See solid conversion rates? Great! You've got your targeting down. Low conversion rates? It might mean your targeting is off (as opposed to just a poor idea -- though that could be it, too).  Pre-Sell the ProductConsider pre-selling through a crowdfunding campaign or by offering discounted early access. This tests if people are willing to pay for your idea.Just be transparent if the product is still in development. Manage expectations appropriately.The goal of idea validation is not to guarantee success, but to minimize assumptions. By testing key hypotheses, you gain confidence to move forward or quickly pivot if needed.Approaching development informed rather than blindly optimistic will save much heartache down the road. Do the work on the front end to validate demand, understand the market, and clarify the MVP.Once you've checked those boxes, you'll know much better how to fit the need.Then (and finally 😅) sling some code!"
42,"  The Perfect Union: Exploring the Synergy between GraphQL and Large Language Models  IntroductionIn the dynamic world of software engineering, two technologies have emerged as transformative: GraphQL and Large Language Models (LLMs) like OpenAI. While each has revolutionized how we handle data and build applications, their combined potential is truly remarkable. This blog post will delve into the perfect union between GraphQL and LLMs, and how this synergy can benefit software engineers.  Understanding the BasicsBefore we delve into the heart of the matter, let's demystify the basics. LLMs, such as OpenAI, are powerful tools that can understand and generate human-like text. They can answer questions, write essays, summarize texts, and even generate code. On the other hand, GraphQL is a query language for APIs and a runtime for executing those queries. It allows clients to request exactly what they need, making it easier to evolve APIs over time.Two tools that exemplify the integration of these technologies are LangChain and Wundergraph. LangChain offers a GraphQL plugin, while Wundergraph provides an OpenAI integration. Both tools showcase how GraphQL and LLMs can be combined to create powerful solutions.  The Synergy between GraphQL and LLMsGraphQL and LLMs complement each other in several ways. Both technologies use graphs, which are structures that model the relationships between entities. In the context of LLMs, graphs can represent the connections between different concepts in a text. In GraphQL, graphs represent the relationships between different types of data.One of the key synergies between GraphQL and LLMs is the ability to feed data from GraphQL APIs into LLMs. This allows LLMs to generate responses based on precise, up-to-date data. Conversely, LLMs can be added to federated GraphQL APIs, enriching the data graph with AI-generated content.  LangChain: A Case StudyLangChain provides a shining example of how GraphQL can be integrated with other technologies. Its GraphQL plugin allows users to consume GraphQL APIs with ease. This means that you can request exactly what you need from an API, reducing over-fetching and under-fetching of data.The LangChain GraphQL plugin is easy to use. With just a few lines of code, you can connect to a GraphQL API and start making queries. This simplicity, combined with the power of GraphQL, makes LangChain a valuable tool for any software engineer. For more information and examples, check out the LangChain documentation.Code Example:from langchain import OpenAIfrom langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.utilities import GraphQLAPIWrapperllm = OpenAI(temperature=0)tools = load_tools(    [""graphql""],    graphql_endpoint=""https://swapi-graphql.netlify.app/.netlify/functions/index"",)agent = initialize_agent(    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)graphql_fields = """"""allFilms {    films {      title      director      releaseDate      speciesConnection {        species {          name          classification          homeworld {            name          }        }      }    }  }""""""suffix = ""Search for the titles of all the stawars films stored in the graphql database that has this schema ""agent.run(suffix + graphql_fields)Enter fullscreen modeExit fullscreen mode  Wundergraph: A Case StudyWundergraph, on the other hand, showcases how OpenAI can be integrated into a GraphQL API. With Wundergraph's OpenAI integration, you can include AI-generated responses in your data graph. This opens up a world of possibilities, from AI-powered chatbots to dynamic content generation.While Wundergraph requires you to use their library and architecture, it serves as a good example of how OpenAI can be implemented into a GraphQL API. For more details and examples, visit the Wundergraph documentation.Wundergraph Code Example:// .wundergraph/operations/openai/weather.tsimport { createOperation, z } from '../../generated/wundergraph.factory';export default createOperation.query({  input: z.object({    country: z.string(),  }),  description: 'This operation returns the weather of the capital of the given country',  handler: async ({ input, openAI, log }) => {    const parsed = await openAI.parseUserInput({      userInput: input.country,      schema: z.object({        country: z.string().nonempty(),      }),    });    const agent = openAI.createAgent({      functions: [{ name: 'CountryByCode' }, { name: 'weather/GetCityByName' }],      structuredOutputSchema: z.object({        city: z.string(),        country: z.string(),        temperature: z.number(),      }),    });    const out = await agent.execWithPrompt({      prompt: `What's the weather like in the capital of ${parsed.country}?`,      debug: true,    });    return out;  },});Enter fullscreen modeExit fullscreen mode  The Impact on Software EngineeringThe combination of GraphQL and LLMs has significant implications for software engineering. By integrating these technologies, developers can create more dynamic, intelligent, and efficient applications. Whether you're already using GraphQL or OpenAI in your projects, or you're planning to do so, understanding the synergy between these technologies can give you a competitive edge.  ConclusionIn conclusion, the marriage between GraphQL and Large Language Models is indeed a match made in heaven. The synergy between these technologies unlocks new possibilities, from smarter APIs to more dynamic applications. As software engineers, it's our job to stay on top of these trends and leverage them to build better solutions. So, why not explore the union of GraphQL and LLMs today? You might just discover a new way to revolutionize your projects.  Further ReadingFor those interested in delving deeper into the practical applications of GraphQL and Large Language Models, here are some resources that might be helpful:WunderGraph's websiteLangChains websiteGraphQL.orgHow To GraphQLApollo GraphQLPractical GraphQL: Become a GraphQL NinjaGitHub GraphQL APIThe Guild BlogRemember, the implementation of GraphQL with Large Language Models will depend on your specific use case and the programming language you are using. These resources should provide a good starting point. Happy exploring!Ready to be part of this revolution? Sign up for my newsletter to keep up with the latest in technology."
43,"A common meme of the mock O'RLY book covers :  ""Googling the Error Message""Note on ""googling"": I am well aware that there are many Google alternatives, and I chose Ecosia as my default search engine for multiple reasons, including privacy and ecology. But I found that Google often provides better matches for tricky programming issues.  Google: better, but not good enoughStylelint hangs, stylelint gets stuck and I seem to be the only one affected, apart from the one single issue when stylelint --fix got stuck with React.js inline styles, none of which matches my own specific setup. I started to wonder if I had lost my talent to paste the right thing into Google's search box, or maybe people don't report errors anymore? How can there be less than 3 pages of search results for any query in 2023?All I want is something that works. To be honest, I'd prefer an elegant, robust, and maintainable solution, so perfection might be one of my problems.This post tries to sum up various takeaways from days, or possibly years struggling with error messages instead of proceeding with my work in a more productive and satisfactory manner.Note that my takeaways are not guaranteed work for you as well!  Question, rephrase, isolate, and experiment!Don't get stuck trying to make one specific solution strategy work! If you don't find any helpful results on Google or Ecosia, try rephrasing your questions, question your assumptions, and try to isolate relevant aspects in simplified scenarios like in a CodePen.  Narrow down the problem preciselyWhen you're calling an ambulance, you must answer some very precise questions: who you are, what happened, at which place exactly? So they don't send a fire engine to entrance A when you need an ambulance at entrance B.Following this principle, we need to narrow down our problem to specific circumstances that we can mention precisely in a bug issue or search query and avoid broad or ambiguous search terms. Otherwise our results will always look like this:My search query for 'custom post type CPT media library empty ""repair""' yielded few relevant results and soon switched to seemingly random stuff like a Nature Journal's post about non-viral precision T cell receptor replacement.  Learn to express your problem in different wordsTry variations and don't insist on unnecessary constraints!Just because the problem only occurs on my specific Ubuntu version but not my coworker's MacBook does not imply that it matters.Maybe it's just a Safari vs. Chrome thing, but again, this will only become clear once we actually narrow down the problem and ask ourselves, again and again:under which circumstances can I reproduce the problem?under which circumstances I can't?In the Ubuntu vs. Mac example, comparing Safari and Chrome on the same MacBook might have eliminated a lot of irrelevant assumptions quickly.  Anticipate further inquiriesLike calling an ambulance, we can prepare ourselves by anticipating what we'll probably be asked. If I state my OS and browser version in a bug ticket (as often suggested by template fields for filing a new issue), I might already think what I would ask a customer when I read an error report like that. One of my questions would be: ""Does it only occur in this specific browser? Have you tried what happens in Firefox?""  A small success story about a small CSS misconceptionIn one of my recent posts, I presented a small problem where I managed to save myself after having got stuck trying to apply max-width after transforming and scaling a pseudo element. It turned out that using a proper DOM child instead eliminated my problem.CSS max-width after transform + scale vs. pseudo elementsIngo Steinke ・ Aug 14#webdev#css  Lost? Try searching for a pattern!This isn't the first time that I fail to find solutions on Google. Bing is no better, by the way. And this keeps happing since long before assistant systems like chatGPT became the new go-to resoure. And don't ask me if I asked on StackOverflow: how could I come up with a minimal reproducible example of something failing on my current machine, often even without any error message.  Reproducible examples vs. hidden assumptionsBut trying to reproduce the error in another setup can make us aware of our environment and possible hidden assumptions. Are we sure we built, committed, and deployed? Are we even looking at the correct server? Sometimes I hit reload several times before finding out that I must have followed a link to the production server without realizing that I'm no longer testing my development environment. This should have been obvious from the URL, but I must have stopped paying attention to that important detail.  Avoid debugging irrelevant warnings!Ever so often, the actual error is somewhere else. It might be a missing semicolon or any kind of typo or mismatching variable or file name. But while I keep getting spammed with irrelevant warnings and information (lines are too long, some attribute is not allowed in some HTML tag, ""i++"" should never again be used in JavaScript etc.) the tool miss out on the crucial part.Sometimes it is obvious that an error message does not point to the actual root cause, for example when it states there is a missing closing bracket at the end of a file: Uncaught SyntaxError: Unexpected end of input (at scripts.js:12345:1).  Don't rely on linting and code inspection!False positive warnings might distract our workflow, but false negatives (undetected mistakes) are more dangerous. Have a look at this example:Both stylelint and PhpStorm's built-in code inspection complain about the wrong (right) definition.Wrong, defunct, but formally correct:font-family: ""var(--wp--preset--font-family--source-sans)"";Enter fullscreen modeExit fullscreen modeThe false positive example below is actually correct, provided that we actually define that property somewhere.font-family: var(--wp--preset--font-family--playfair-display);Enter fullscreen modeExit fullscreen modeHow could static code analysis know that --wp--preset--font-family--playfair-display will be defined in CSS at run-time when it's only defined in a JSON dataset like below? (That's a WordPress theme.json by the way.)""typography"": {    ""fontFamilies"": [        {            ""fontFace"": [                {                    ""fontFamily"": ""Playfair Display"",Enter fullscreen modeExit fullscreen modeThe same configuration file quotes custom CSS properties as string values:""h1"": {    ""typography"": {        ""fontFamily"": ""var(--wp--preset--font-family--source-sans)""Enter fullscreen modeExit fullscreen modeSo I must have copy-pasted this value to my custom CSS file.Too bad that it's syntactically correct to write:font-family: ""var(--wp--preset--font-family--source-sans)"";Enter fullscreen modeExit fullscreen modeEven worse, there seems to be no stylelint rule to warn about that yet, at least not in the default recommended configuration.  Machine learning, AI, and AlgorithmsMachine learning and so-called artificial intelligence haven't helped me much so far. I have tried to use chatGPT in different situations, including the WordPress issue below, where both chatGPT and the classic Google search engine became helpful only after I already knew the solution, thus knowing how to ask the right question. AI can reproduce some typical coding challenge answers and commonplace boilerplate code the kind of which can be found everywhere else, including StackOverflow, MDN, W3Schools, and uncountable pages copying the same content desparate to earn some money with page ads.  OpenAI: helpful, irrelevant or dangerously confabulating?When I asked chatGPT about various tricky WordPress problems, it came up with reasonable statements that were both true and helpful in general, but either not related to the actual problem in question, or a list of possible reasons all of which I had already been able to verify.Other people have found chat bots quite helpful, so try and decide for yourself, but don't take anything for granted. Artificial ""intelligence"" is not intelligent, it's just a very elaborate guess, trained on popular posts and solutions, interpolating these sources often causing made up, probable but incorrect artificial hallucination (confabulation), thus giving wrong advice!  Find out what's missing!What about a git blame to inspect the latest changes after the last known working state? But what if do not even know when it worked as expected? And what if the error is caused by a deleted line (maybe accidentally), as deleted lines are not shown by git blame and reconstructing those can be harder than expected, especially when there were merge commits involved.We can also have a look at what's not present, but should be, like a colored syntax highlighting or an implicit parameter annotation etc. like this conspicuously inconspicuous gray loation property that should have been a location: Another variation that's even worse, when the unintended spelling or syntax is formally correct, likeif (a = 1) is not a comparison, but an assignment in most languages;myFunction is a reference, but myFunction() executes immediately in JavaScript;a misplaced brace / bracket or a missing semicolon can change the control flow;auto-closing behavior of HTML parsing: <p class=""outer""><p =""inner""> is equivalent to <p class=""outer""></p><p class=""inner""> because paragraph elements must not be nested. Quoting MDN on tag omission:The start tag is required. The end tag may be omitted if the <p> element is immediately followed by an <address>, <article>, <aside>, <blockquote>, <div>, <dl>, <fieldset>, <footer>, <form>, h1, h2, h3, h4, h5, h6, <header>, <hr>, <menu>, <nav>, <ol>, <pre>, <section>, <table>, <ul> or another <p> element, or if there is no more content in the parent element and the parent element is not an <a> element.Source: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/pA lot of those kind of errors cause warnings in a good linter configuration, but some mistakes can't be detected by algorithms as they don't follow a typical anti-pattern.  Solution StrategiesI usually try to run all available checks and tests to rule out any problems even if they seem to be unrelated. I try to vary configurations. I try to find out more details by trying if there is a --verbose option or a logfile.I google the error message if there is any. I try different variations of my queries, I read hopeful sources which usually helps me narrow the possible root causes. I try to describe the problem in a more detailed way, like I would have to when asking a coworker, open a GitHub issue or ask a question on StackOverflow. I do one of those things and get no helfpul answer (coworker), no answer at all (GitHub) or my question gets downvoted and deleted (StackOverflow).  Beyond googling (""missing ... must include""?!)It is hard to google for code anyway, but sometimes it feels as if we are trying to query some secret that must not be told, so the search engines refuse to process our query and insist on ignoring certain parts of it, or stop caring about ordering results by relevance and put the one missing most of my query on the number one top position.Trying long-tail variations, after ignoring the warning that ""there are not many great results"" for our queries ......  we will finally hit the wall and meet the secret animated cartoon character making me crazy with its passive-aggressive ""this is fine attitude"". Well, at least I do. Thanks to Bing, Bard, and chatGPT, many people just copy and paste the answer to their magic prompt and voilà they've done 2 weeks of work in 2 minutes. At least that what some developers claim to achieve on social media. I already mentioned this ""idle fisher"" character in my rant post ""I enjoy life-long learning, but..."" about all the things that I could do without.I enjoy life-long learning, but...Ingo Steinke ・ Oct 22 '21#webdev#watercooler#devjournal#rantI have mentioned AI before. Sometimes developers, can profit a lot by getting extensive code snippets either by the popular chatGPT or by a virtual coding assistant like GitHub copilot or tabnine, although it can waste a lot of time and concentration when the recommendations aren't helpful at all.So let's ask a chatbot instead of querying a search engine. Maybe that's the first issue preventing me to do so, as I usually don't type or speak natural language questions but rather type or paste something quite technical into a prompt. Instead of an obscure technological error detail, I can try to form a natural language question like ""how to write php code that finds the static front page in the current language in a wordpress theme localized by polylang?""Let's try this same question in Google, Bing, and chatGPT...... and they all give me helpful results ... now.Why? Because I managed to ask the right question in the right way, which wasn't that hard in hindsight, after I had already solved the problem.  Learn to ask the right questions the right way!Can we learn to ask better questions? Well, StackOverflow has become infamous for its quest for good questions. It already helped me a lot to try and write a StackOverflow question and anticipate the further inquiries and reasons for downvotes without ever finishing and publishing my draft.That's much like the stuffed toy teddy bear junior developers had to talk to and explain their issues to the inanimate figure before proceeding to bother an actual human developer.While it may still be hard to word the correct question, lest find an appropriate answer, we might cut short and eliminate some false assumptions and do some basic checks that we might have missed when focusing too much on the details of what we thought to be the problem.   Beyond rants and downvotesAs you might know already, I sometimes use blogging to convert negative energy caused by frustrating search for elegant best practices that have never existed into something constructive and provide a solution to be found when using the previously unsuccessful search query.Unlike StackOverflow, where I could, at least in theory, ask and answer my own question, on DEV I am allowed to be verbose and admit my negative emotions starting with a naive question, a frustrated rant, to conclude with a pragmatic solution that doesn't have to stand up to pseudo-scientific criticism.""This question is closed. It is not currently accepting answers."" might fit the logic of a strictly moderated Wiki website, but it still feels like the exact opposite of usability and inclusive UX writing to me.Let's find a pragmatic solution then!  Pragmatic solutionsAs you can see on GitHub, StackOverflow, and various forums like on WordPress.org, not all of my questions are unanswered or deleted though. If there is an answer, I try to verify it as soon as possible, to follow up with further details or by saying thank you or upvoting the answer.Sometimes I write a blog post about my experience, to help me review what happened and share it with others who might have the same problem. Often, one of those ""others"" will be myself, some time later, when the same problem comes up again after I forgot about the solution. So there will be at least one helfpul search result on Google next time.  My 3 stages of bugfixingPicture me: on the phone with my customer, frowning in a screen sharing zoom meeting, and giving a thumbs up when I finally found the solution!  So what's the Pattern?Another strategy is questioning my assumptions and my favorite solution. If things don't work, get too complicated, or nobody else seems to do it like this, I might be wrong or at least there might be a better (i.e. more easy, more supported, less error-prone) approach.I might not be aware of doing something in an unusual way, but, back to square one, I could check my configurations and my recent commit history. Maybe there is something suspicious that I introduced, or maybe there has been an update to a tool or a framework that has introduced an incompatibility.When I fail to come up with a solution, I try to do something else: take a break or switch tasks. Often there is more than one (sub-)task to work on.  ConclusionWhen coding and debugging, always keep an open mind for a different view, question your strategies, and verify your assumptions. "
44,I love to read some quality articles. Don't hesitate to share your own work.
45,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
46,"If you ask the average entrepreneur what his wet dream is, he would answer; ""Being qualified for a triple A Silicon Valley VC firm"". Little does he know, that's literally like wishing for a coffin for his idea and creativity. VC firms are based upon ""The Bigger Fool's Theory"".This theory implies you buy junk, knowing it's junk, but you don't care, because regardless of how much you pay for the junk, there will come a bigger idiot behind you willingly buying your junk, for even more money than whatever money you paid for the junk originally.Don't believe this is an actual thing? Please explain why this painting is worth $105.7 million!Facts are, the entire modern art scene is entirely based upon ""buy junk expensive, sell it even more expensive"". Both for art and for venture capitalism, the point is to pay as much as possible, since this creates the illusion of intrinsic value, where no value actually exists.This is why a VC firm will often give you MORE than what you ask for, telling you ""You do want to scale as fast as possible, right?""At which point the ignorant entrepreneur of course accepts, thinking Ohh my God, what couldn't I do with twice as much? 🤪  The Idiot EconomyThe idiot economy again is based upon ""Ohh my God, somebody paid 100 million dollars for that thing. It must be extremely valuable"" - Not realizing they could have bought it for 50 million, but they wanted to give 100 million for it, because 50% increase in evaluation of 100 million is a lot more money that 50% increase in evaluation of 50 million.It's the ""industrialization of bubbles"", similar to NFTs in nature. Zero actual value, besides the belief in value, which artificially inflates the evaluation, such that profits becomes possible. Venture Capitalism is in its entirety based upon these mechanisms.  Manufacturing FaithFirst of all, once you've got VC funding, everybody will automatically flock to you, congratulating you, affirming you scored, believing that whatever you've got going must be good if you were able to convince some VC firm to give you money.And of course, the more money you got, the more valuable your shit must be, right?The investment itself becomes a self fulfilling prophecy of future earnings. However, why do you think 90% of all startups fail? Even those being backed by VC firms? It's because the VC firm literally doesn't give a shit. Typically they've made their money indirectly, even on failed startups, by forcing deals unto the entrepreneur with other companies in their portfolio, or by funneling money out from your startup somehow, to some ""invisible 3rd party"".And if you should somehow manage to do an IPO, the VC firm sells 50% of their stock for 100x what they gave you in the first place, at which point the sheeptards takes over the responsibility for the losses, while they've already cashed in their earnings. When the company goes belly up, they have protection for themselves by being able to say; ""We lost money too on this. It was a shame it didn't work"" - Not telling the other losers they actually cashed in 100x during the IPO.  The Value of an EmployeeOne employee is worth $250,000True story. The above are actual figures from a VC firm. Each employee further strenghtens the illusion of actual value in your company by $250,000. This is the industry average. BTW, before you run of an hire 500 Ukrainians, please realize that the average Ukrainian is (only) worth $100,000. The above $250.000 figure is for North/West Europe and North America. I don't know the figures for India, but I suspect they're at the level of Ukraine, possibly lower.I want to emphasize this isn't something I am making up, these are figures given to me by a VC firm. When my developers quit in AISTA, The Schmuck (Mister Investor) was screaming at me for having lost him a million dollars because I lost 3 employees in a day. He didn't even care what they did, or if they did anything at all. From his point of view, I had lost him somewhere between 300,000 dollars and 750,000 dollars. The reason is because the more employees you've got, the stronger the illusion of that your company must be worth a lot becomes.In theory you could literally hire a cemetary to inflate your company's perceived evaluation  Industrialized BubblesThe VC firm doesn't give a shit about your company's value, it only cares about perceived value. If it can somehow convince a bunch of idiots that your company is worth a billion dollars, your company is worth a billion dollars - Regardless of whether or not your only production literally is used toilet paper! And the more employees with fancy titles, good diplomas, and higher education you've got - The easier this illusion becomes to create ...Maybe you think that this is just ""some few VC firms"", certainly my VC firm is different. Believe whatever you want, but if you've got VC money, there is a 98% statistical probability your product is literally crap, and that you're an idiot!Crap in, crap out - Similary to NFTs and the above 105 million dollar painting ...  How the Illusion is SustainedOnce you get an A-level VC firm, they'll contact Wired, TechCrunch, YCombinator, and all the other corrupt media organizations, who's purpose it is to hype up your product. Then they'll have parts of their portfolio actually spend their money buying your product, to inflate the growth, allowing them to create growth curves, apparently leading into the 7th Heaven.Everything is of course carefully orchestrated, and all the participants are of course in the VC firms pockets, and paid to write garbage about your garbage, such that the illusion of value becomes stronger.Then they'll convince other idiots to join in with more money, B rounds, C round, then maybe an IPO or an Exit - At which point they will have spent 100 million dollars, cashes in 500 million dollars, leaving some idiots to pick up the bill. All while zero actual value was produced, exclusively using the mechanics of ""The Bigger Fool's Theory"".100 years ago we had a name for such a thing, we used to call these things ""Ponzi Schemes"". Today we call them VC firms. Same garbage. This is why the psychological makeup of entrepreneurs being qualified for VC rounds are often similar to the psychological makeup of evangelic preachers and cult leaders. Their primary job is to ""keep the bullshit running"" for a few years, such that when the bubble bursts, both the entrepreneur and the VC firm have made mountains of money.  Dead Cat BounceThe above is an actual economic term, and it is recognised by something that apparently seems to be ""a miraculous save"". A last minute miracle, saving something from going bankrupt. ChatGPT and AI was that thing for A-level VC firms from Silicon Valley. Every single VC firm threw money at AI as if it was ""The VC Jesus of the 21st Century, coming to save them from themselves, absorbe their sins, allowing them to enter Paradise"".They basically fell for their own bullshit 🤣There will be no save, sorry - Haven't you heard? The Boom is Over. Burn in hell zuckers!  How to build a company in a post-VC worldActually, it will be much easier. Once all the bullshit is gone, it will be easier for real companies to be noticed, being talked about, and find people to test their stuff, help them build real value. How do I know? Because I'm doing it. And in case you still haven't understood my relationship to this, let me explain it with the most colorful analogy I possibly can imagine ...If you're from a VC firm and you come to my home offering me money, I've got a baseball bat under my bed, and it's got your name on it 😎"
47,"Observability isn’t PillarsTracing and OpenTelemetryBackground Developer ObservabilityEnough ExpositionHow Does This Help at 2AM?Final WordOnce we press the merge button, that code is no longer our responsibility. If it performs sub-optimally or has a bug, it is now the problem of the DevOps team, the SRE, etc. Unfortunately, those teams work with a different toolset. If my code uses up too much RAM, they will increase RAM. When the code runs slower, they will increase CPU. In case the code crashes, they will increase concurrent instances.If none of that helps they will call you up at 2AM. A lot of these problems are visible before they become a disastrous middle of the night call. Yes. DevOps should control production, but the information they gather from production is useful for all of us. This is at the core of developer observability which is a subject I’m quite passionate about. I’m so excited about it I dedicated a chapter to it in my debugging book.Back when I wrote that chapter I dedicated most of it to active developer observability tools like Lightrun, Rookout, et al. These tools work like production debuggers, they are fantastic in that regard. When I have a bug and know where to look I can sometimes reach for one of these tools (I used to work at Lightrun so I always use it). But there are other ways. Tools like Lightrun are active in their observability, we add a snapshot similarly to a breakpoint and get the type of data we expect. I recently started playing with Digma which takes a radically different approach to developer observability. To understand that we might need to revisit some concepts of observability first.  Observability isn’t PillarsI’ve been guilty of listing the pillars of observability just as much as the next guy. They’re even in my book (sorry). To be fair, I also discussed what observability really means…Observability means we can ask questions about our system and get answers or at least have a clearly defined path to get those answers. Sounds simple when running locally, but when you have a sophisticated production environment and someone asks you: is anyone even using that block of code?How do you know?You might have lucked out and had a log in that code and it might still be lucky that the log is in the right level and piped properly so you can check. The problem is that if you added too many logs or too much observability data, you might have created a disease worse than the cure: over-logging or over-observing.Both can bring down your performance and significantly impact the bank account, so ideally we don’t want too many logs (I discuss over-logging here) and we don’t want too much observability.Existing developer observability tools work actively. To answer the question if someone is using the code I can place a counter on the line and wait for results. I can give it a week's timeout and find out in a week. Not a terrible situation but not ideal either, I don’t have that much patience.  Tracing and OpenTelemetryIt’s a sad state of affairs that most developers don’t use tracing in their day-to-day job. For those of you who don’t know it, it is like a call stack for the cloud. It lets us see the stack across servers and through processes. No, not method calls. More at the entry point level, but this often contains details like the database queries that were made and similarly deep insights.There’s a lot of history with OpenTelemetry which I don’t want to get into, if you’re an observability geek you already know it and if not then it’s boring. What matters is that OpenTelemetry is taking over the world of tracing. It’s a runtime agent which means you just add it to the server and you get tracing information almost seamlessly. It’s magic. It also doesn’t have a standard server which makes it very confusing. That means multiple vendors can use a single agent and display the information it collects to various demographics:A vendor focused on performance can show the timing of various parts in the system. A vendor focused on troubleshooting can detect potential bugs and issues.A vendor focused on security can detect potential risky access.  Background Developer ObservabilityI’m going to coin a term here since there isn’t one: Background Developer Observability. What if the data you need was already here and a system already collected it for you in the background?That’s what Digma is doing. In Digma's terms, it's called Continuous Feedback. Essentially, they’re collecting OpenTelemetry data, analyzing it and displaying it as information that’s useful for developers. If Lightrun is like a debugger, then Digma is like SonarQube based on actual runtime and production information. The cool thing is that you probably already use OpenTelemetry without even knowing it. DevOps probably installed that agent already, and the data is already there!Going back to my question, is anyone using this API?If you use Digma you can see that right away. OpenTelemetry already collected the information in the background and the DevOps team already paid the price of collection. We can benefit from that too.  Enough ExpositionI know, I go on… Let’s get to the meat and potatoes of why this rocks. Notice that this is a demo, when running locally the benefits are limited. The true value of these tools is in understanding production, still they can provide a lot of insight even when running locally and even when running tests.Digma has a simple and well-integrated setup wizard for IntelliJ/IDEA. You need to have Docker Desktop running for setup to succeed. Note that you don’t need to run your application using Docker, this is simply for the Digma server process where they collect the execution details.Once it is installed, we can run our application, in my case I just ran the JPA unit test from my latest book and it produced standard traces which are already pretty cool, we can see them listed below:When we click a trace for one of these, we get the standard trace view, this is nothing new, but it’s really nice to see this information directly in the IDE and readily accessible. I can imagine the immense value this will have for figuring out CI execution issues:But the real value and where Digma becomes a “Developer Observability” tool instead of an Observability tool, is with the tool window here:There is a strong connection to the code directly from the observability data and deeper analysis which doesn’t show in my particular overly simplistic hello world. This Toolwindow highlights problematic traces, errors and helps understand real-world issues.  How Does This Help at 2AM?Disasters happen because we aren’t looking. I’d like to say I open my observability dashboard regularly but I don’t. Then when there’s a failure I take a while to get my bearings within it. The locality of the applicable data is important, it helps us notice issues when they happen. Detect regressions before they turn to failures and understand the impact of the code we just merged.Prevention starts with awareness and as developers, we handed our situational awareness to the DevOps team. When the failure actually happens the locality and accessibility of the data makes a big difference. Since we use tools that integrate in the IDE daily this reduces the meantime to a fix. No, a background developer observability tool might not include the information we need to fix a problem. But if it does, then the information is already there and we need nothing else. That is fantastic.  Final WordWith all the discussion about observability and open telemetry, you would think everyone is using them. Unfortunately, the reality is far from that. Yes, there’s some saturation and familiarity in the DevOps crowd. This is not the case for developers.This is a form of environmental blindness. How can our teams who are so driven by data and facts proceed with secondhand and often outdated data from OPS?Should I spend time further optimizing this method or will I waste the effort, since few people use it?We can benchmark things locally just fine, but real-world usage and impact are things that we all need to improve."
48,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts published later in the week.   Getting Started in a New CodebaseWhether contributing to open source or starting a new job, the first step is familiarizing yourself with the codebase, which can be daunting. Here are some tips from @abbeyperini to help you hit the ground running.Getting Started in a New CodebaseAbbey Perini ・ Aug 16#beginners#programming#webdev#softwaredevelopment  Getting Started With SCSS – The CSS Preprocessor With SuperpowersHave you ever felt there should be a way to make writing CSS easier and faster? This is where SCSS (Sassy CSS) comes in and @classicthedemigod will teach you all about it.Getting started with SCSS - The CSS Preprocessor with SuperpowersAbdullahi Muftau ・ Aug 19#webdev#css  WebAssembly: Byte-Code of the FutureJS: love it or hate it, it’s here to stay. But it would be good if browsers supported more programming languages. @joshnuss is here to share that this is the promise of WebAssembly: Providing a generic runtime to which any programming language can compile.WebAssembly: byte-code of the futureJoshua Nussbaum ・ Aug 14#javascript#webassembly#webdev  How to Dockerize a React ApplicationDocker keeps everything you need to run your app in one place so that the containerized image file can be run in any environment. All you need is a React project and the desktop Docker app and @ayesh_nipun will show you how to dockerize it in just a few simple steps.How to Dockerize a React ApplicationAyesh Nipun  ・ Aug 16#react#docker#webdev#javascript  I Was Tired of Langchain and Created My Own WrapperEvery programmer who wants to build a production-ready LLM application inevitably stumbles upon certain libraries such as LangChain. In this post, @zakharsmirnoff shares the most recent development on their tiny wrapper for OpenAI API!I was tired of Langchain and created my own wrapperZakhar Smirnoff ・ Aug 15#ai#gpt#python#opensource  How To Make an Impact as a Developer AdvocateDeveloper Advocates are influencers. Not in the sense that they’re on Instagram taking pictures, but they influence the developer community and their companies. Here’s @blackgirlbytes with more on the role of developer advocates in the tech industry. How to make an impact as a developer advocateRizèl Scarlett ・ Aug 20#career#devrel#leadership#discuss  Why You Should Make a Game Engine: 5 Years as a DeveloperFive years ago, @lkatkus made the switch from being an architect to becoming a software developer. In this post, Laimonas shares their journey of creating a game engine and progressing as a developer.Why You Should Make a Game Engine: 5 Years as a DeveloperLaimonas K ・ Aug 15#javascript#webgl#frontend#webdevThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
49,"  IntroductionThe landscape of CSS paradigms has seen a constant evolution, marked by the rise of popular CSS-In-JS libraries like styled-components and emotion.However, in recent times, there has been a notable shift in focus towards CSS libraries that emphasize ""zero-runtime"" approaches, such as Tailwind CSS and vanilla-extract.These libraries are garnering attention for their promise of improved performance.However, CSS Lube challenges the notion of relying solely on build time for achieving optimal performance.  What is CSS Lube?CSS Lube is Highly-optimized CSS Interpreter.It is makes improved your developer experience by implement any designs directly in markup and immediately reflect feedback.In addition, CSS Lube parses HTML documents at runtime and render styles, so it can completely replace style files that become bloated whenever updated with a 6,558 byte(2,794 byte on gzip) js file.Looking at the PageSpeed Insights score table below, you'll be able to guess the performance level of the CSS Lube, even considering the margin of error.Benchmark - CSS Lube  What's the difference?One of the key things about lube is that it's a zero-buildtime css Luberary.More than half of the CSS Lube code is the part that defines shorthand, and the actual logic is less than 3kb.With syntax and various optimizations that can be completely converted to css with just a simple string replacement, CSS Lube was able to achieve the same level of performance as zero-runtime css in js with this small bundle size.  VS. Traditional wayUtility-first CSS is much better in terms of maintenance and developer experience than semantic CSS.  VS. Existing CSS In JS librariesThis is enough. Css Lube is incredibly fast.  VS. Tailwind CSSThere are no additional learning curves except for a few syntax and shorthand.All styles are available without write custom, and all changes are immediately reflected in the development phase.You can easily switch to dark mode using basic media queries.Build time is much faster because no additional steps are required to build.  VS. vanilla-extractIt is much more productive using various convenient shorthand without having to write a separate ts phrase.Overall, CSS Lube aims to eliminate various constraints from the convenience of utility-first and to achieve the same level of performance as zero-runtime performance based on zero build time.  SyntaxLet's take a quick look at the syntax of CSS Lube.If you want to find out more, please see the Syntax - CSS Lube.  Basic<div class=""bg=--primary-50    w=calc(100%-4em)    h=3.5    bd=2px_solid_red;br=.75"">  background: var(--primary-50);  width: calc(100% - 4em);  height: 3.5em;  border: 2px solid red;  border-radius: .75em;</div>Enter fullscreen modeExit fullscreen mode  Selector<div class=""w=3.5    ta=center    >div.target/bgc=red    _div:nth-of-type(2n+1)/bgc=blue"">  <div>blue</div>  <div class=""target"">red</div>  <div>blue</div>  <div></div>  <div class=""bgc=yellow!!"">yellow</div></div>Enter fullscreen modeExit fullscreen mode  Media Query<div class=""@sm&!lg@c=red"">  @media (min-width:640px) and (max-width:1023px) {}</div><div class=""@@container_md@fs=10px"">  @container (min-width:768px) {}</div><div class=""@dark&min-width=1024px@fs=10px"">  @container (prefers-color-scheme:dark) and (min-width:1024px) {}</div>Enter fullscreen modeExit fullscreen mode  ConclusionCSS Lube challenges existing CSS paradigms with highly optimized syntax and performance based on runtime methods.Enjoy enhanced developer experience with no custom, no restrictions, and zero buildtime.CSS Lube - Highly-optimized CSS Interpreter"
50,"Hey y'all 👋Hope you all have wonderful weekends!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugPlaying with legos 🧱"
51,"I was reading an article about unit tests. Honestly, it seems like a lot of effort. Do you receive a lot of value from your unit tests? Personally, I'm still trying to understand domain-driven design. I feel like with supple design, we need to use several techniques to pin software on the wall. Constraints such as revealing interfaces, side-effects-free functions, and many assertions should make your software better.What do you think? Is it always better to write unit tests? "
52,"Automation testing has become a fundamental part of web development, and Playwright has emerged as one of the most powerful end-to-end testing tools. Thanks to its robust API and multi-browser support, it's easy to test sites and web apps.At the same time, Playwright can present some challenges if not approached correctly. Several pitfalls can compromise the effectiveness and performance of your tests, potentially leading to inaccurate results.In this article, we'll cover the seven most common mistakes developers should avoid when dealing with Playwright, to ensure that your testing process is quality-oriented, efficient, and reliable.It's time to become a Playwright ninja!  7 Common Mistakes to Avoid in Playwright for Node.jsLet's take a look at the major pitfalls you should avoid when using Playwright for browser automation.If you want a quick overview of Playwright before diving in, check out our post An Introduction to Playwright for Node.js.  1. Configuring Playwright for Node.js PoorlyA wrong Playwright configuration can lead to failures, false positives, and unreliable results. To avoid that, you must set up the tool correctly. Playwright supports several configuration options, and you should particularly pay attention to:Environment variables: Tests can access env variables during runtime, allowing you to avoid hard-coding strings and parameters in your scripts. Environment variables are a good way to define the required configurations for your tests. For example, you could use them to specify the browser type, page timeout, viewport size, and more. Always add some fallback values to avoid failures if the envs aren't defined.CLI parameters: Playwright offers several CLI (Command-Line Interface) options to configure how tests are run. Familiarize yourself with all the CLI options available and learn their effects. For example, the --headed or --headless flags control whether the browser should be launched with UI or headless mode, respectively.playwright.config.ts: This is the main configuration file where you can define settings for all tests. For example, here you can enable cross-browser testing and force Playwright to run tests on the specified browser. That's essential to ensure cross-browser compatibility and see how your script behaves on Chromium, Firefox, and/or WebKit.  2. Writing Short Tests For No Real ReasonSeparating each assertion into an individual test to keep tests short is a mistake you shouldn't make. This practice brings no significant benefit and only slows down test execution. Short and focused tests are great for unit tests, but in end-to-end testing scenarios, it's more practical to have long tests that reproduce the entire user journey.The goal is to cover the complete application flow. It doesn't matter if tests end up being long and involve multiple assertions. When a user interacts with your app, they perform several actions.Also keep in mind that if a test fails, Playwright will provide you with specific messages to help you understand what went wrong and in what part of the script. As long as they are easy to read and maintain, you don't have to worry about writing long scripts.  3. Testing Third-Party ApplicationsWhen you test an application flow, you may be tempted to test integrations with third-party services (e.g., a headless CMS), but that's a trap!As explained in the Playwright official documentation, you should avoid testing third-party applications and dependencies. These aren't under your control, and their behavior or UI may change without notice. Dealing with them can lead to false negatives, and you don't want that.Instead, you should focus only on testing elements and features within your application. If you need to interact with an external service, take advantage of the Playwright Network API to mock API responses, as in the example below:await page.route(""https://api.your-cms.com/articles"", (route) => {  route.fulfill({    status: 200,    contentType: ""application/json"",    body: JSON.stringify({      articles: [        {          title: ""An Introduction to Async Stack Traces in Node.js"",          description:            ""Let's dive into how async stack traces work and how they can be used to debug code."",          url: ""https://blog.appsignal.com/2023/05/17/an-introduction-to-async-stack-traces-in-nodejs.html"",        },        // omitted for brevity...      ],    }),  });});Enter fullscreen modeExit fullscreen modeWith the page.route() function, you can simulate the behavior of third-party services. When the web page makes a request to https://api.your-cms.com/articles, Playwright intercepts it and responds with the mocked JSON response. This makes your tests more isolated and reliable, allowing them to succeed even when third-party dependencies aren't available.  4. Not Using Proper SelectorsSelectors play a key role in Playwright tests as they give you the ability to identify and interact with HTML elements.Failing to use appropriate selectors can lead to flaky results, increased maintenance effort, and decreased test stability.One of the most common mistakes to make is using poor selectors that are overly generic. The web page under test might have a single <span> element, but selecting it with page.locator('span') is likely to lead to unintended actions on an incorrect element in the future. That's because <span> is a pretty generic tag!On the other hand, overly specific selectors can tightly couple tests to a page structure. In this scenario, a minor change in the HTML of the target page may break your tests. This can result in frequent test failures and require consistent maintenance. Also, long and complex selectors reduce code readability.Let's consider an example. Suppose you want to retrieve the following button in a form:<button class=""form-button login-button"" type=""submit"">Login</button>Enter fullscreen modeExit fullscreen modeThis selector would be too generic:page.locator(""button"");Enter fullscreen modeExit fullscreen modeThis one too specific:page.locator(""form > button.form-button.login-button"");Enter fullscreen modeExit fullscreen modeWhile this one is resilient to DOM changes and restrictive enough to select the desired element:page.getByRole(""form > button"", { type: ""submit"" });Enter fullscreen modeExit fullscreen modeDevising the right selectors is an art. However, remember that Playwright can generate test code as you take actions in the browser. Thanks to this advanced feature, the tool will analyze the DOM of your target page and figure out the best selectors for you.  5. Ignoring Playwright's Debugging CapabilitiesDon't forget that a test can fail not only because of issues with the functionality being tested, but also because of a bug in the test code itself. Here's why it's so important to debug your scripts. Playwright comes to the rescue with several advanced, powerful, built-in debugging tools. These include:Debug mode: Running a test with the --debug option opens the Playwright Inspector. This GUI tool allows you to step through a running script, edit locators in real time, and see actionability logs. This is a built-in alternative to the recommended way to debug tests in Playwright (using your IDE's debugger). If you are using Visual Studio Code, take a look at the Playwright Test for VSCode extension.Logs: If you use console.log() directly in your script, it won't work. To leverage that function, you need to wrap it with the page.evaluate() method, as below:await page.evaluate(() => {  console.log(""Page title:"", document.title);});Enter fullscreen modeExit fullscreen modePrinting values in the console will help you identify bugs and understand how your code is behaving.Breakpoints: You can define breakpoints in your tests with the page.pause() function. When encountering this instruction, Playwright will stop executing the script and wait for the user to click the “Resume” button in the page overlay, or call playwright.resume() in the DevTools console.  6. Failing to Handle ErrorsYour tests can throw errors and exceptions. Ignoring them can lead to false positives or negatives, undermining the effectiveness of the entire testing process. To avoid that issue, it's crucial to handle exceptions and errors gracefully.In Playwright, you can implement error handling with the try-catch statement:test(""example test"", async () => {  // test logic...  try {    // specific test operation  } catch (error) {    // handle error here  }  // test continues...});Enter fullscreen modeExit fullscreen modeIn this example, the try block contains test code that could potentially throw an error. That will be caught by the catch block, which might log some data, retry the operation, or take another action depending on the specific situation.Thus, it's important to distinguish between issues in your Node.js application and errors in tests. Implementing proper error handling will help you identify and isolate the latter.  7. Relying on Hard WaitsHard waits, also known as static or fixed waits, involve pausing test execution for a specific amount of time.Playwright supports hard waits through the page.waitForTimeout() function:// wait for 2 secondpage.waitForTimeout(2000);Enter fullscreen modeExit fullscreen modeThe official docs mark this feature as 'discouraged', clearly stating that you should never rely on it in production. The reason is that, in most cases, it's virtually impossible to know the right timeout to keep on hold. The same test may be successful once and then fail because of a network slowdown. In addition, hard waits introduce unnecessary delays. That's especially true if the pending operation completes way before the specified duration.For this reason, Playwright also provides built-in smart wait functions. These allow you to wait for specific events to occur before proceeding with test execution. Some of the most popular ones are:page.waitForSelector(): Waits until an element matching the specified selector is present in the DOM.page.waitForNavigation(): Waits for a navigation event to occur, such as clicking a link or submitting a form, before continuing with the test.page.waitForFunction(): Waits until the provided JavaScript predicate function returns a truthy value.These functions are designed to wait for dynamic elements, page navigation, network requests, and other asynchronous operations. Thanks to them, it's possible to guarantee a test's progress as soon as the desired conditions are met.  Wrapping Up: Don't Let Common Playwright Mistakes Slow You Down!In this blog post, we explored the most common mistakes you can make in Playwright, their effects on your tests, and how to avoid them.You now know:How important it is to configure Playwright and use all of its featuresWhat elements to exclude from your testing logicWhat functions and methods to avoidThanks for reading!P.S. If you liked this post, subscribe to our JavaScript Sorcery list for a monthly deep dive into more magical JavaScript tips and tricks.P.P.S. If you need an APM for your Node.js app, go and check out the AppSignal APM for Node.js."
53,"Welcome to a world where web development meets superhero fandom! It's no secret that building websites and applications can seem like a formidable task, similar to combating arch-nemeses on a daily basis. That's why we've turned to the amazing AI tool, Midjourney, to visualize our favorite web frameworks as superheroes.Stay tuned and get ready to finally met your favorite framework face-to-face. In the end, they rescue us (from the grunt work and boilerplate code) every day :).  React.js - All Hail The King 👑Let’s immediately start with the king among web frameworks - React.js! With its unmatched popularity and vibrant community, React has won the hearts of developers across the globe. Still, being at the top comes with a price, so we’ll occasionally witness a heated discussion or even a bit of drama concerning king’s decisions.Author’s note: for the life of me, I couldn’t get Midjourney to draw React’s atom symbol, so I had to settle for this strangely looking R.  Vue.js - A Graceful And Reliable Queen 👸If React is the king, then Vue is definitely the queen of web development. Exhibiting a harmonious blend of might and elegance, Vue.js has captivated developers worldwide, firmly establishing her reign in the realm of progressive JavaScript frameworks.  Ruby on Rails - The Unyielding Veteran 🚂Was there ever any other way to imagine Ruby on Rails, the seasoned guru of web development, than in a hardcore steampunk setting? Despite being the granddaddy of the lot, Rails still packs quite a punch, effortlessly fueling web development engine rooms. Sure, the youngsters might have glittering gimmicks, but when things get rough and the job needs to get done, you know who you’re gonna call (now I wish I went with a Ghostbusters theme).  Wasp - A Full-Stack Speedster 🐝⚡️It’s time to introduce some fresh blood to the squad (picture Tom Holland's Peter Parker). Meet Wasp, a full-stack web framework coming straight from the future. It melds together React, Node and Prisma into a tight, type-safe package and takes your development to super-sonic speeds. Sure, it's still wet behind the ears and learning some ropes, but blink, and you'll be eating its cosmic dust!  Nest.js - The Server-Side Beast 👹We’ve met kings, queens, and suited-up heroes - now, it's time to unleash the beast. Meet Nest.js, the muscular powerhouse of web development, roaring in the form of a hulk-like figure crowned with a lion’s head. Nest.js is a force to be reckoned with, blazing the trails with its might and resilience in the rough world of server-side applications. I definitely wouldn’t mention I ever used Rails in front of this guy.  🌯 And that's a wrap! Whom should I cover next?I have to admit this was a super fun article to write. This is also the first time I've used Midjourney, and although it took a bit of figuring things out, I had a blast.Now it's your turn! Do you agree with the images, or have you imagined your framework differently? Also let me know which incredible framework or a tool would you like to see suiting up as a superhero next?The stage is yours and I can't wait to hear your ideas!Author's note: I am one of the core maintainers at https://github.com/wasp-lang/wasp. If you like it, give us a star!⭐️"
54,"Which emerging technologies do you find fascinating? How do you see these themes shaping the future of the tech industry?This week we're exploring the experiences of seasoned developers:  their stories, hurdles, and successes. Like what you're reading? Follow the DEVteam for more discussions like this!The DEV TeamFollow        The team behind this very platform. 😄      "
55,"In the realm of programming languages, Go shines as a standout contender when it comes to handling concurrency. Its unique approach to concurrency, centered around goroutines and channels, has enabled developers to build highly responsive and efficient applications. In this blog post, we'll delve into the world of concurrency in Go, exploring the concepts of goroutines and channels and showcasing how they unlock new dimensions in your code.🔸 Concurrency vs. Parallelism: Understanding the DifferenceBefore we dive into the specifics of goroutines, it's crucial to understand the distinction between concurrency and parallelism. Concurrency is the ability to execute multiple tasks seemingly at the same time, even if the tasks are not physically executing simultaneously. Parallelism, on the other hand, involves the simultaneous execution of multiple tasks on separate processors or cores. Go's concurrency model is built around managing and coordinating concurrent tasks effectively.🔸 Meet Goroutines: Lightweight ConcurrencyAt the heart of Go's concurrency model are goroutines. A goroutine is a lightweight, independently executing function that runs concurrently with other goroutines. Unlike traditional threads, which are relatively heavy and can lead to performance overhead, goroutines are incredibly lightweight and can be spawned in the thousands without bogging down your system.Creating a goroutine is as simple as adding the keyword go before a function call. This marks the function to be executed as a goroutine, allowing other parts of your program to continue executing concurrently.func main() {    go printNumbers()    // Other code...}func printNumbers() {    for i := 1; i <= 5; i++ {        fmt.Println(i)    }}Enter fullscreen modeExit fullscreen mode🔸 Synchronization with ChannelsConcurrency isn't just about running multiple tasks—it's also about coordinating their interactions. This is where channels come into play. Channels are communication mechanisms that allow goroutines to send and receive data in a synchronized manner. They facilitate safe data sharing and synchronization between goroutines.func main() {    ch := make(chan int)    go sendData(ch)    receiveData(ch)}func sendData(ch chan int) {    for i := 1; i <= 5; i++ {        ch <- i    }    close(ch)}func receiveData(ch chan int) {    for num := range ch {        fmt.Println(""Received:"", num)    }}Enter fullscreen modeExit fullscreen modeIn the above example, the sendData function sends integers through the channel, and the receiveData function receives and prints them. The range loop gracefully terminates when the channel is closed.🔸 Concurrency Patterns and Best PracticesWhile goroutines and channels form the backbone of Go's concurrency model, there are various concurrency patterns and best practices to consider:Fan-Out, Fan-In: Distribute work among multiple goroutines (fan-out) and then consolidate the results (fan-in).Select Statement: Use the select statement to wait on multiple channels simultaneously, allowing for non-blocking operations.Context Handling: Utilize the context package to manage the lifecycle of goroutines and handle cancellations.Go's concurrency model is a game-changer in the world of programming. By embracing goroutines and channels, you can write highly concurrent, responsive, and efficient applications that make the most of modern multi-core processors. Whether you're building web servers, distributed systems, or data processing pipelines, Go's concurrency features empower you to tackle complex challenges with elegance and efficiency. So, take the leap into the world of goroutines and unlock the true potential of concurrent programming in Go. 👩‍💻 🧠"
56,"What piece of advice, inspirational quote, or unique perspective have you gained that you'd like to impart to your fellow community members?Join us on a journey that's all about newbies sharing, learning, and growing together. Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.         Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
57,"There's been a growing buzz about AI taking over software development in the next decade or so. But let's dig deeper and understand why this doesn't mean we're on the verge of being replaced. In this post, we'll explore the reasons why software engineers aren't going anywhere, even in the AI age.  AI's Influence and the Unchanged Essence of Software EngineeringThe AI wave is indeed changing the game with tools like GitHub's Co-pilot. These tools boost our efficiency and save a ton of time and money. And there's cool stuff on the horizon, like self-healing code, that'll make our software better and quicker to produce. It's an exciting time, no doubt.  My Recent Experience: A Peek into Our WorldI recently took on a project from scratch to finish, and it got me thinking. I compiled a list of technologies that we, as software engineers, need to be familiar with to create a simple app. Here's a snippet:Creating the look (HTML)Adding style (CSS)Making it work (JavaScript)Handling browsers (Browser stuff)Navigating within the app (Routing)Managing data flow (State management)Designing the interface (UI libraries)Linking with other apps and services (APIs)Speeding things up (Caching)Picking a backend language (Python, JavaScript, etc.)Building the backend (Server framework)Juggling tasks (Async programming)Ensuring security (Security basics)User access (User authentication)Storing data (Database)Team coordination (Version control)Packaging the app (Docker)Getting it out there (Deployment)Checking it works (Testing)Speeding up delivery for end users (CDN)Handling addresses (DNS and networking)Utilizing the cloud (Cloud architecture)Domain managementSending emails (Email service setup, reputation and warm-up)Respecting privacy (Privacy concerns)Monitoring performance (Monitoring)It's a hefty list, right? Sure, AI tools like ChatGPT can help with some. Today's tools let us do more with a smaller team than before.  The Real Value We BringHere's the scoop: being a software engineer isn't just about knowing tools. It's about fitting these tools together seamlessly. It's like cooking up a dish with various ingredients. As we improve at this, we innovate fresh ways to solve issues.  A Bright Future AheadThe idea that AI will replace us isn't the full picture. In the next 10 to 15 years, we'll still be here, doing our thing. Instead of fading away, we'll focus more on tackling tough challenges in smarter ways. As technology advances, so will our skills to make great things happen.In a nutshell, the AI storm won't wipe us out. While AI tools are handy, the blend of skills, creativity, and problem-solving we possess is hard to replicate. So, brace yourselves – the future of software engineering is a thrilling ride!"
58,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
59,"The last 9 months we've seen a boom without historical precedence. I am of course talking about the ChatGPT and AI boom. The boom is over now, and it has officially been cancelled. Sorry, you're not going to get rich fast, without putting down some actual work - The world simply doesn't work that way ...I have personally witnessed 10,000+ companies trying to make some fast cash on this boom, popping out of the woodwork like maggots at spring. Everybody thought they were going to get rich fast, delivering zero actual value, by creating some garbage tech on top of OpenAI's API and ChatGPT.The party is over, and you can all go home  The MadnessI remember back in February, some guy integrating ChatGPT into GHL, using some basic prompt engineering, creating a system message claiming to have sold ""his software"" for $300,000 the first week alone. I am not shitting you: I could have created the same ""system"" with both my hands tied to my back, being forced to code with my nose, blindfolded in the dark, while attending a Dimmu Borgir concert - And I could have created it in 5 minutes! ZERO value!People were still flocking to the dude as if he was some sort of modern AI Messiah, promising to deliver them from evil, resulting in a life of prosperity, where they could have everything they point their fingers at - Including a private jet, a harem of virgins, and a trillion dollar mansion in Paradise.If I had a dollar for every ""get rich fast with ChatGPT"" schemes I've seen the last 9 months, I would be a billionaire today  ""Where is the ChatGPT app?""The above was the by far most popular question on Facebook the last 9 months. I would know, I'm participating in most of the ChatGPT Facebook groups myself. Every time some ""get rich fast dude"" asked the above question I had to sit on my hands to avoid answering.IT'S A FREAKIN' WEBSITE DUDE!A couple of times I tried answering the above, but it was impossible to use reason. Their limbic reward system based upon endorphines and dopamid had long since high jacked their brains, having flushed reason and logic down the toilet, as if it was the breakfast from yesterday.Thousands of companies made small fortunes on this ignorance. I would know, at least 5 of my friends created ""ChatGPT apps for iPhones and Androids"" selling these for $20 per month, while OpenAI was desperately trying to give it away for free from their website.Psst, HERE is the 'ChatGPT app' - It works from all phones 😂You know the psychosis is real when they start selling Chai GPT from an Indian Tea House 😜At some point even OpenAI became so frustrated by this, they created their own app. At this point, 10,000+ Ukrainian outsourcing companies, desperately looking to capitalize on the boom, had already made mountains of cash on their users' ignorance. For the record, such ""apps"" can literally be created by a junior developer, in 11 minutes - And people PAID for it 😂Even Mister Investor, The Schmuck, bought an app like this 😜I tried to explain to him how it works, he just told me ""It's not how it works"" - He would know, because he's made billions of dollars selling cake and bread 😂  The boom is OVERThe boom is over. Like all booms, it can only exist for a finite amount of time, until people realize they will not buy a private jet unless they actually put down some work.NOTHING pleases me more than the fact that the boom is over!To understand why, realize that all of the above ""get rich fast schemes"" are making our lives difficult. We who actually try to create value on top of AI, solving real problems, trying to create real products, are ""drowning"" in the marketing noise of all the ""get rich fast preachers"" out there, trying to convince you to give them your money - Practically for nothing.I have been working on AI since the mid 1990s, and all of a sudden I needed to explain why my stuff is better than a collection of prompts, bundled into a PDF, by a teenager with a degree in sales and marketing, from ""The Ponzi School of How to Sell Rubbish to Idiots"". This boom created so much trouble for me you cannot possibly imagine it!The AI boom is OVER! HALLELUJAH, PRAISE THE LORD!If you are serious about AI, and you're willing to invest in it, realizing it can give you an ROI without historical precedence - You can contact us below. If you want to simply get rich fast, without putting down any work, please go away. We don't want to hear from you, because you're simply noise to us and the rest of the industry.I've heard crypto is booming again though. Maybe go buy some BitCoin? 😁Or contact us if you are serious about AI and Machine Learning 😉"
60,Think you've got what it takes to whip up the cleverest caption for this image? Let's hear it!Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
61,"  Introduction to sorceryI like this quote: Magic is the technology we still need to understand. Rails is an excellent framework; it hides complexity from developers, but because of that, many people qualify it as magical.This article will demystify Rails by looking deeper into the Rails active record association internals. In the meantime, we will also try to understand pretty cool programming concepts.I hope you are ready ( you are not ), it's going to be fun, let's go.Oh yes, and if you like to learn or read about Rails, Ruby, databases, and a lot of tech-related stuff :  Keep in TouchOn Twitter/X : @yet_anotherDevOn Linkedin : Lucas Barret  Did you say association?Let's begin with defining active record associations and why they are helpful.If you are a Rails developer, you should know, and I am sure you know it, this fantastic website : Rails Guides. Going to this link and you can read that : association is a connection between two active record models, and that's all. But Why do they exist? Because it makes everyday operations straightforward and more accessible. Nice, keep reading and we see that Associations are implemented using macro-style programming ?   Macro style Ruby FuA lot of definition in this article but yet this is useful to be sure we all understand the same thing.Now going to Wikipedia we can see that : a macro is a rule or a pattern that specifies how a specific input should be mapped to a replacement output. This makes everyday tasks or definitions available for programmers as a single statement. ( Like your associations statements ).This kind of programming style enables define our association in a declarative way. If you define an Athlete class that has_many Medal(s), you will write it as it :class Medal < ActiveRecord::Base    belongs_to :athleteendclass Athlete < ActiveRecord::Base    has_many :medalsendEnter fullscreen modeExit fullscreen modeYou declare that your athlete has_many medals and that medal belongs_to athlete.In ruby, macros and this kind of declarative style of programming are possible thanks to the class-level method but also thanks to how ruby classes work.  Go back to classRuby Classes are no unique code; as with everything else in Ruby, they are executable. If I define a Ruby class called: Athlete, with a workout class method. I could call it inside the class, and when my ruby interpreter reads my class code, it will execute my workout method.#./athlete.rbclass Athlete   def self.workout    p '1 push up'   end   workoutendEnter fullscreen modeExit fullscreen mode> ruby athlete.rb> 1 push upEnter fullscreen modeExit fullscreen modeAs you can see, your class definition code is executed!It is precisely what is happening with your has_many declaration. It is a method call with an argument which is the name of your associate model in a simple case we illustrated earlier.  Dancing in the darkIt is time to dive into rails code; let's see what we can find.As we want to find out how has_many associations work, the first step is to look for a definition of a method called has_many.  If you look in the ActiveRecord code, you will find :#rails/activerecord/associations.rbdef has_many(name, scope = nil, **options, &extension)  reflection = Builder::HasMany.build(self, name, scope, options, &extension)  Reflection.add_reflection self, name, reflectionendEnter fullscreen modeExit fullscreen modeBut this is weird, and you could ask why this is not defined as a class method.Looking around, this is a class method defined in the module ClassMethods, with another pattern we won't cover here. Now in the internal of this function, little is done. We build a reflection and add it to the Reflection class with the association name.If we go to the rails/activerecord/associations/builder/has_many.rb file, what we see is not helpful for what we want to understand at first sight.We see the options available for our association and the dependent options. But there has yet to be a build class methods function.module ActiveRecord::Associations::Builder # :nodoc:  class HasMany < CollectionAssociation # :nodoc:    def self.macro      :has_many    end    def self.valid_options(options)...    end    def self.valid_dependent_options...    end        private_class_method :macro, :valid_options, :valid_dependent_options  endendEnter fullscreen modeExit fullscreen modeNevertheless, this class inherits from CollectionAssociation let's see what we got in rails/activerecord/associations/builder/collection_association.rb; there are many cool things here, but still no build methods.module ActiveRecord::Associations::Builder  class CollectionAssociation < Association Enter fullscreen modeExit fullscreen modeBut as before, this class inherits from another class, Association. Let's see this one.And this is what we are looking for. We have the build methods, which all the associations share.And in this method, the famous reflection is built and returned to the has_many class methods.def self.build(model, name, scope, options, &block)  if model.dangerous_attribute_method?(name)    raise ArgumentError, ""You tried to define an association named #{name} on the model #{model.name}, but "" \                         ""This will conflict with a method #{name} already defined by Active Record. "" \                         ""Please choose a different association name.""  end  reflection = create_reflection(model, name, scope, options, &block)  define_accessors model, reflection  define_callbacks model, reflection  define_validations model, reflection  define_change_tracking_methods model, reflection  reflectionendEnter fullscreen modeExit fullscreen modeBut why is reflection needed? What is a reflection? This will be the subject of my next article...  ConclusionWe have begin our journey in the dark magic Rails. If you want to feel powerful, wait for the second one next week.If you liked this article and would like to know more or hear from it differently: check this keynote from Daniel Colson. I dove into the code and began this article before seeing the keynote. Then I was like, should I not publish it? Eventually, I got more knowledge from this conference and tried to improve the article the best I could. I hope this article will help my fellow rubyists.See you for the second part next week."
62,"Imagine being invited to a TED Talk that showcases your expertise. If you had this chance, which aspect of coding or development would you discuss to inspire and enlighten your audience?This week we're exploring the experiences of seasoned developers:  their stories, hurdles, and successes. Like what you're reading? Follow the DEVteam for more discussions like this!The DEV TeamFollow        The team behind this very platform. 😄      "
63,"  A Pair Programming PartnershipJust like Disney characters have friendships and partnerships that enrich their stories, developers also benefit from collaboration. Developers, like Mickey and his friends, thrive on pair programming. Working together with a colleague not only enhances productivity but also fosters creativity and problem-solving. All we have to do is recall those late nights where the support of a friend resulted in breakthroughs and accomplishments.Learn more about the exciting features in GitHub Copilot in this video from ngConf 2023.  Introducing GitHub CopilotGitHub Copilot is an AI tool that brings the power of artificial intelligence to the coding experience. GitHub Copilot uses large language models to generate code suggestions and help developers write code more efficiently. Almost a million developers are already using GitHub Copilot and highlights some of its exciting features. Perhaps you are one of them?  Enhancing Developer Productivity with AIThe developer experience is undergoing a fundamental shift with the rise of AI tools like GitHub Copilot. Gone are the days of relying solely on copying and pasting from Stack Overflow. With AI as a partner, developers can expect faster coding, improved fulfillment, and higher-quality code. The future of coding is AI-assisted, with developers leveraging tools like GitHub Copilot to simplify their coding journey.  A Live Demo that AmazesIn this video you experience the capabilities of GitHub Copilot. You can effortlessly write code and leverage Copilot to generate code suggestions, complete functions, explain complex regex expressions, get quick hints, and create documentation all within the coding environment.  Copilot Goes Beyond CodingGitHub Copilot is adding features all the time including chat integration, voice commands, automatic pull requests, and more. These advancements indicate that AI is becoming an even more integral part of the developer's toolkit.  Unleashing the Potential of AI for Documentation and Code QualityGitHub Copilot is not limited to code generation. It can also help with documentation, automatically review and generate pull requests, provide comprehensive code explanations, and even produce more readable code. The video showcases how Copilot can create helpful comments, refactor code, and suggest best practices, all while saving valuable time.  Embracing AI for Angular and React DevelopmentSometimes we need more than a simple code suggestion, for example you may have found a great component in React and you need it to work in your Angular app. GitHub Copilot simplifies complex tasks like these, even within popular frameworks like Angular and React. In the video you can see how you can effortlessly convert a React component into an Angular one using Copilot. This transformation showcases Copilot's ability to understand code structure and provide accurate suggestions, making developers' lives easier when working with different frameworks.  Enhancing Developer Creativity and HappinessAI tools like GitHub Copilot are designed to augment developers' capabilities rather than replace them. By automating repetitive tasks and providing valuable suggestions, Copilot frees up developers' mental space, allowing them to focus on creative problem-solving and critical thinking. This newfound freedom enhances the overall developer experience and leaves developers feeling more fulfilled and productive.  What Lies Ahead for Developers and AI?There an re so many exciting future possibilities that lie ahead for developers and AI. GitHub is driving ongoing research and development efforts to further improve GitHub Copilot and the exciting features upcoming in GitHub Copilot X. Developers can look forward to enhanced capabilities, improved collaboration, and an overall more streamlined coding experience.  What Will You Do?How can you leverage the power of AI to unlock their full creative potential? Consider the significant impact AI tools like GitHub Copilot can have on your coding journey. Imagine the possibilities and think about ways they can embrace AI to enhance their productivity and satisfaction as developers.  ReferencesGitHub CopilotGitHub Copilot DocumentationGitHub Copilot Technical PreviewMicrosoft Build ConferenceVS CodeAngularReactBase of this article written with AI and then modified by hand."
64,Switching to newer tech in coding can be a gamble. How do you choose? Tell us about a project you upgraded & what drove the change.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
65,"Hello there,We all know that we are speaking quite a lot about artificial intelligence (AI) in recent times.Artificial intelligence has transformed how we live, work, and communicate with one another. AI-powered technology has made our lives easier and more convenient in many ways.AI-powered tools are advanced applications or tools that use artificial intelligence technologies to automate specific tasks or actions or workflows. Some common examples of such tools include virtual personal assistants, facial recognition and biometrics programs, customer service chatbots, and recommendation engines. These tools are useful for streamlining workflows, enhancing customer experiences, and providing better insights.In this Appium tutorial, learn about Appium and its benefits for mobile automation testing. Take a look at how Appium works and see how to perform Appium testing of your mobile applications: https://www.lambdatest.com/appium  What is AI-driven test automation?“I predict that, because of artificial intelligence and its ability to automate certain tasks that in the past were impossible to automate, not only will we have a much wealthier civilization, but the quality of work will go up very significantly and a higher fraction of people will have callings and careers relative to today.” -Jeff Bezos, Executive Chairman, Amazon.AI-driven test automation is a process of using artificial intelligence to automatically develop and execute tests. This entails teaching machines to recognize patterns in code and identify areas of the application that are prone to errors or can be improved upon, which speeds up testing and reduces the need for human involvement.AI-driven automation tools can also be used to automate repetitive tasks, such as running regression test suites, creating test data, and generating test reports.AI-driven test automation has the potential to revolutionize the software testing industry, but it also has ethical implications that must be considered. We can guarantee that this technology is utilized responsibly and beneficially by addressing these concerns and defining ethical standards and best practices for AI-driven test automation.In this XCUITest tutorial, learn about XCUITest framework and its benefits for mobile automation testing. Take a look at how XCUITest works and see how to use it to test your mobile applications: https://www.lambdatest.com/xcuitest  The benefits of AI-driven test automationThere are several benefits to using AI-driven test automation.1. Increased Performance: AI-driven test automation has the potential to significantly reduce the amount of human effort required to design and execute tests. This allows testers to concentrate their efforts on more critical areas of testing, greatly improving the overall performance of the testing process.2. Improved Quality: AI Automated testing improves accuracy in test cases that span large-scale scenarios. It is also capable of detecting unnoticed defects, minimizing the likelihood of manual errors, and enhancing test coverage.3. Improved Time-to-Market: Automated AI testing can assist software testers in running tests more quickly and efficiently, resulting in a reduced time-to-market for the product. It also reduces the need for manual test case preparation, allowing teams to focus on more critical tasks and discover areas for optimization.4. Increased Accuracy: AI-driven test automation provides higher accuracy. AI-driven test automation technology can be trained to detect patterns and classify them more precisely than manual tests. This eliminates the potential for human mistakes and increases the overall accuracy of the testing process.5. Reduced Costs: By augmenting the testing process with AI, companies can reduce costs in several ways. AI testing delivers insights that assist decrease the expenses associated with debugging and retesting due to low-quality code.However, like with any technology, there are ethical concerns to be made, particularly when it comes to AI-driven test automation.Get started with this complete Selenium guide. Learn what Selenium is, its architecture, advantages and more for automated cross-browser testing: https://www.lambdatest.com/selenium  The Ethical Considerations“Integrity without knowledge is weak and useless, and knowledge without integrity is dangerous and dreadful.” — Samuel Johnson, English Author, Poet, and Writer.Any tool or technology which is being adopted and used by a variety of people and organizations across the globe must have certain rules and regulations that need to be followed. Set of policies to be written and tagged to the product.Increased usage of Artificial Intelligence poses some threats and many countries are taking steps to mitigate them by introducing regulations.**For example, Europe is planning to propose a new regulation for AI. Refer to **this site* for more details on it. Not only Europe, but the US also has certain **AI regulations** as well. We need certain rules and legislation to be followed in this regard. Many countries started thinking about introducing and implementing regulations for the ethical use of AI.***As AI-driven test automation becomes more prevalent in software development, it is important to consider the ethical implications of this technology. Below are some of the ethical considerations:Bias: When AI systems are trained on biased data, they might become biased. This can lead to unfair testing practices and inaccurate results. It is important to ensure that the data used to train AI models is diverse and representative of the population being tested.Privacy: AI-driven test automation may collect and process sensitive data, such as personal information or user behavior. It is critical to ensure that sensitive data is managed securely and in accordance with applicable privacy laws.Transparency: AI algorithms can be opaque and complex, making it difficult to understand how they arrive at their conclusions. It is important to ensure that AI-driven test automation is transparent and explainable so that developers and stakeholders can understand how the technology is making decisions.Accountability: Ethical considerations promote accountability and responsibility in AI-driven test automation. It is important to ensure that there is accountability for these decisions and that there are mechanisms in place to address any negative outcomes. It is important to clearly define roles and responsibilities, ensuring that humans remain in control of the testing process and are accountable for the outcomes. This includes establishing mechanisms for addressing errors or unintended consequences caused by AI systems and taking appropriate corrective actions.Human oversight: While AI-driven test automation can improve efficiency and accuracy, it should not replace human oversight entirely. It is important to ensure that humans are involved in the testing process to provide context and make decisions when necessary.Impact on Human Testers: Many organizations are not mature enough to understand that AI can never replace Testers. So after seeing the temporary success of AI-driven test automation, they might reduce the number of Testers in the team or organization. This can lead to job loss and a loss of important human skills, such as creativity and problem-solving.Test your website or web app online for iOS browser compatibility. Perform seamless cross browser testing on the latest iPhone tester Simulator. Try for free: https://www.lambdatest.com/test-on-iphone-simulator  Real-world instances of how AI tools are biased  Case study about Amazon’s biased AI recruitment tool:Amazon developed its own hiring tool to screen resumes in 2014. As you all know there are plenty of resumes received by Amazon each year. Also, they have plenty of job openings in different categories. So every year they have to go through umpteen resumes to find the right candidate. This is a tough job and needs a lot of manpower.So, Amazon developed a hiring tool to screen resumes. They used machine learning algorithms and fed loads of data to the machine learning model. After a year, they noticed that the system is automatically preferring male candidates and it’s downgrading the profiles which have text like “Female”, “Women”, “Women’s College” etc.This is because the system is predominantly trained using historical data which has more Male applicant details. So, the algorithm is biased towards the male candidates. They found that the tool is not gender-neutral. The media started thrashing Amazon for this hiring tool and later Amazon stopped using that tool. They even claimed that the tool was employed in real-time to screen the resumes of the applicants.Source Link  Racist AI Image Generator:Recently there were a lot of tweets floating around the internet which showed that the AI Image generators show racial bias. Rona Wong, an Asian-American student was trying to get a professional headshot using an AI tool. And the results left us all worried. The resulting image made her white, with blue eyes. So do we all need to have fair skin to look professional? This clearly depicted the racial bias in AI.Source LinkWebDriver is a remote programming interface that can be used to control, or drive, a browser either locally or on a remote machine. Learn more in this complete Selenium WebDriver Tutorial: https://www.lambdatest.com/learning-hub/webdriver  Best practices for ethical AI-driven test automationWe learned the significance of ethical considerations in AI-powered test automation. Let’s look at some best practices now. Beginning with the establishment of ethical rules and standards, conducting frequent audits and evaluations, ensuring diversity and inclusion in the development team, and providing training and education on ethical issues in AI-driven test automation are all part of the process.1. Prioritize Legality: Use AI technology and automated testing techniques in accordance with the relevant rules and regulations. Be diligent when you look into and understand the legal implications of automated testing.2. Clarify Purpose and Goals: Before initiating an AI-powered test automation project, it’s vital to understand why AI is being employed. Consider the potential consequences of the technology and its application.3. Respect and Maintain Privacy: When employing AI for automated testing, adhere to data privacy and security requirements. Ensure that proper data protection procedures are in place and that any data acquired is appropriate for the AI project.4. Monitor Automated Tests: To guarantee correctness and current results, closely monitor automated testing carried out with AI.5. Maintain Transparency: Explain to stakeholders the rationale for your decision to automate your test tests using AI and any prospective advantages. Ensure that everyone is aware of the risk. Inform others on the performance of AI, including achievements and shortcomings.6. Documentation and Version Control: Documenting tests, using version control, and setting up a quality assurance process can lead to more effective and efficient use of AI.7. Use ethical data sets: Make sure that the data sets or test data used for automation are gathered responsibly and that appropriate privacy and data security mechanisms are in place.8. Test for bias: Analyze test automation output and AI-driven models regularly for bias9. Monitor results: Analyze the outcomes of AI-driven test automation and use analytics to find mistakes or anomalies. Make careful to record any results so they may be reviewed.10. Develop trust: When stakeholders are involved in the AI-driven test automation process, they establish trust in the team’s work. This boosts trust in the accuracy and dependability of the outcomes.11. Choice of Tools: Choose relevant automated testing tools for the project. Always ensure that these are secure, effective, and scalable.To ensure the effective and ethical use of AI-driven test automation, it’s important to follow relevant best practices.A complete tutorial on retesting that sheds light on its features, importance, pros and cons, and how to perform it: https://www.lambdatest.com/learning-hub/retesting  Conclusion: Embracing Ethical Standards to Ensure a More Reliable and Responsible Use of AI-Driven Test AutomationIn conclusion, ethical considerations are of utmost importance in AI-driven test automation. They help mitigate biases, protect privacy, ensure transparency, promote accountability, and address the social impact of AI systems. By incorporating ethical principles into the development and deployment of AI-driven test automation, we can ensure that it benefits society while upholding fundamental values and principles. By doing so, we can ensure that AI-driven test automation is used responsibly and ethically."
66,"Awww shi...here we go again.Yes I am back, breaking the internet once more. I know, it has been a while.But this time...I may have come up with something kind of useful?We will see!First of all, the title is not clickbait.I have actually built a (buggy) syntax highlighting system, that uses just a single element and can function in pure CSS (for displaying snippets).No <span> elements for each different part of syntax that is highlighted, no bulky JavaScript libraries to render everything. Sounds interesting? Let's jump right in with a code example:  An exampleLook at this beautiful syntax highlighting! All done in less than 1kb of code!Here is the HTML:<pre>let thisContent = 'highlighted';for(x = 0; x &lt; 10; x++){    console.log('loopy loopy loop' + x);}</pre>Enter fullscreen modeExit fullscreen modeNote: Please use <pre><code> for marking up code blocks in production. And here is the CSS:body{    background-color: #111;    padding: 20px;    color: white;    font-size: 125%;}pre{    width: 80ch;    font-family: monospace;    font-size: 30px;    line-height: 30px;    background:         linear-gradient(to right, white 0ch, #78dce8 0ch, #78dce8 3ch, white 3ch, white 18ch, #FFD658 18ch, #FFD658 31ch, white 31ch, white 80ch),         linear-gradient(to right, white 0ch, #a6e22e 0ch, #a6e22e 3ch, white 3ch, white 12ch, #f92672 12ch, #f92672 15ch,  #A7C 15ch,  #A7C 17ch, white 17ch, white 80ch),         linear-gradient(to right, white 0ch, white 0ch, white 4ch, #fd971f 4ch, #fd971f 11ch, white 11ch, white 12ch, #a6e22e 12ch, #a6e22e 15ch, white 15ch, white 16ch, #FFD658 16ch, #FFD658 34ch, #f92672 34ch, #f92672 37ch, white 37ch, white 80ch),         linear-gradient(to right, white 0ch, white 0ch, white 80ch),         linear-gradient(to right, white 0ch, white 0ch, white 80ch);     background-repeat: no-repeat;     background-size: 80ch 30px, 80ch 60px, 80ch 90px, 80ch 120px, 80ch 150px;     background-clip: text;     -webkit-background-clip: text;     color: transparent;}Enter fullscreen modeExit fullscreen modeThat is it!  So what?So...highlight.js, one of the leading syntax highlighting libraries is...wait for it...286Kb (and that is minified and gZipped! It is over 980kb of raw JS 😱).That is a huge amount of JS to push down the wire if all you are wanting to do is show a code snippet with some syntax highlighting. Yet many sites do this, destroying their performance.So while the demo may not look that impressive, the 99.8% data saving is pretty impressive!  Explanation: how does it work?So what we are doing is applying a very carefully created background linear-gradient to the <pre> element, that looks like this:Each of the coloured blocks corresponds to some text we want to highlight.Then all we do is use background-clip: text;, a CSS property that allows us to say ""hey, can you please use the text above the background as a mask, and only show the background if there is text in front of it, otherwise show a transparent background.""And we end up with this example:  Working Example  But if it is that easy, then why doesn't everyone do this?The short answer is: linear-gradients and alignment.To try and align the linear gradient by hand would take a lot of time. Also, this relies on lines not ""wrapping"", as otherwise the gradient will not align anymore (although with some clever maths, we could probably account for this! Not part of this demo though).You see, in order to generate the gradient we need to know:how wide each highlighted section to be generated ishow many lines of text there areto know what colour each part needs to be highlighted in.The second part is straight-forward. But working out the width of each item to be highlighted is hard, working out what to highlight...is really hard!Luckily...I am silly enough to build a fully working editor, which finds relevant ""tokens"" within a JavaScript snippet, and then uses these to calculate where each part of the linear-gradient should be.Wanna try it?  The Snippet generatorInstructions:Input: Enter a short JS snippet in the first box(*)Preview: Check that the preview is as expected (Preview) (this is a janky setup for highlighting, it may fail on certain snippets).Output: Copy and paste the resulting code from the output section into your code! (Don't forget, this is designed for a dark background, so you need a dark background on either your <body> element or to create a wrapper around the <pre> element and give that a dark background. (*) Due to limitations of this demo, please make sure that no line is more than 70 characters in length.That is it, give it a try below:  Understanding how this worksLook, that JavaScript is a hot mess of cobbled together snippets...I would not expect you to try and follow it. Here is the simplified version of what is happening though:We grab each line in the (input) section and loop through it.We use a RegEx (yes...I know) to capture key terms in JavaScript such as let and function etc.We then create a linear gradient for each line, with the length of each section of the gradient corresponding to found matches.Finally, we adjust the background-size CSS property to account for the height of the given lines of code, so that each linear-gradient declaration we have lines up with the length and height of each line of code.That last part might be the most confusing part.To explain better, think of the following:let a = 'test';let b = a + ' your code';Enter fullscreen modeExit fullscreen modeLet's assume that all we want to do is highlight the strings in these two lines ('test' and ' your code').So we need 2 gradients.They need to be 25 characters long (the length of the longest line) and we need to have a coloured block appear at:character 9 to 13 on line 1character 13 to 23 on line 2These turn into linear gradients as follows:linear-gradient(to right, white 0ch, white 8ch, red 8ch, red 14ch, white 14ch, white 25ch),linear-gradient(to right, white 0ch, white 12ch, red 12ch, red 24ch, white 24ch, white 25ch);Enter fullscreen modeExit fullscreen modeWhere ""red"" is our highlight colour and ""white"" is our non-highlighted colour. (our characters are 0 indexed in case you wonder why the number / position of each character is 1 less).BUT, if we just tried to use those two gradients on their own, it would fail.This is because the first gradient has taken up 100% of the height.So to fix this, we need to set the height of each of the linear-gradient declarations, using background-size.This would look like this:background-size: 25ch 22px, 25ch 44px; Enter fullscreen modeExit fullscreen modeAssuming a line-height of 22px (so the first gradient is 22px high from the top, to cover the height of the first line, and then the second gradient is 44px high from the top, to cover the second line. This is because linear gradients stack on top of each other and the one that is declared first is on top).Oh but it still doesn't work yet.You see, gradients repeat by default. So we also need to set background-repeat: no-repeat;Now we get a working highlight on the strings:And that is essentially it, just add different colours for each type of token and you have a ""working"" syntax highlighting system in pure CSS with no <span> elements.  But...why?Ok, ok. You have now read the whole article and are still asking why. That is fair!To be honest, I just had a silly idea. But also, I like to take something and use it in a way that was not intended, I find it a great way to learn as there are no tutorials I can follow for things like this. I just have to keep trying things and work out how to solve the problem. It also really helps you learn things more deeply (for example, I learned a couple of things with linear-gradients that I didn't fully understand before) as you need to read the docs and experiment.  So what do you think?Could this actually become something useful?Can you imagine generating super light-weight code snippets for documentation as part of the build step, and just serving CSS and a single element?Although it is a joke project right now, could the concept actually work in production? 🤔Let me know what you think in the comments. 💗 "
67,"(This post was written as part of an assignment for the Computer Science Career Path from Codecademy.com)If you told me a week ago that the hardest part of finishing an assignment for Codecademy would be to write about it for complete strangers online... I probably would've believed you. So let's give it a try!  The BackgroundI've been coding for a little over a year now casually, but a few months ago, when I learned that I would not be returning to my job for the following year, I decided it might be a good opportunity to jump into a new field. Lots and lots of thinking and planning and gathering materials and information later, and now I'm finally starting to work through it all. Right now, I am mainly using Codecademy's more guided paths (I am currently on the CS career path), since I know that I would benefit from the added handholding at the beginning. This was my way of attempting to fill in the gaps in my knowledge (since I was mainly self-taught), but it turns out I should really give myself more credit if it's due. I should have realized that when a course says it is ""beginner friendly"", it really means beginner friendly.    Getting StartedAs I started working, I quickly realized that to get the most out of this learning, I was going to have to consciously keep track of the time I spend on the projects. I usually tend to do one of two things: I'll either speed through everything and make a ton of mistakes just for the sake of moving onto the next thing, or I will do the complete opposite, and refuse to move on from a project until it is exactly the way I want it. My new objective was clear, but still somehow ambiguous. I've settled on saying that I need to spend a good amount of time on my work (but not too much!). I especially need to push past the urge to fly through everything and submit the first fully working solution I find; but I also need to stop myself from getting caught in an endless loop of debugging and optimizing.  Am I putting too much thought into it? Who knows? I'm sure most people would probably say to stop talking about it and just write some code, so let's take a look at some. Take me to the GitHub page!First of all, what did I make? Well, the task was to build a terminal game using Python and version control with Git, then write a blog post about it (I really wasn't expecting that part, but here we are). It actually caught me so off guard to see the blog post requirement that I decided to dedicate the title to my long-standing and fairly severe fear of public eyes. I joked about it at the start, but it was a joke very much based on reality. All right, tangent over. Back to the project!I decided on a Connect-Four style game, since I thought it would be a pretty straightforward task. This was a little more tame, since this project had the most open ended directions, where I could use whatever methods I wanted; but to be honest, I put way more effort into the project before it (since it was a topic I was less comfortable with), so I think I might've actually just gotten lazy with this one. (You can find the GitHub page for the previous project here.)   The ProjectThe program itself is very straightforward; at the top it prompts the users for a name and sets the global variables  (I know I know, global bad; but again, trying to find a good balance between rushing through and getting caught in ""paralysis by analysis"" as an old music professor of mine called it). The game board is stored in lists, and when a player selects the column they want to place a piece in, a loop iterates through the rows to find the lowest option that hasn't been played, and changes the placeholder to the current player token before toggling the global variables. All of the game logic is contained in three functions: display_board, play_round, and check_win. This is another area that I feel could have been improved with a bit more time and nitpicking. This is especially true for the check_win function, which is just plain cumbersome, and should probably make use of some smaller or higher order functions; not to mention I had a little help from Professor GPT for the diagonal checks after spending more than double the time on it that I wanted to. Again, coming back to, ""I probably could've solved it myself, but that would've taken disproportionately longer and would've been much messier, so to save time I'll have a robot do it cleanly now and I'll just tidy it up to make sure it works then go back to analyze the structure myself later"". All that said, I'm not too concerned with the code. I know that it could be better, but I also know that it could be worse. I know that there are people out there who would've written it better, but I also know that there are people who would've written it worse. I'm happy with it as is, for being in the beginning stages of my structured learning. This was more about finding an approach that keeps me happy (something that wasn't always guaranteed at my old job), seeing how well I could balance my time, and getting over my huge fear of being seen (even if it's only by a name online). I'm sure I won't win the ""race to senior dev"" with that attitude, but I'll bet that I will be happier and have more fun. That's good enough for me, at least for now ☺️  "
68,"Methods are used to don't repeat the same thing all along the program.  Creating MethodsTo create a method use this syntax:def my_first_method  ""Hello""endputs my_first_method  #=> ""Hello""Enter fullscreen modeExit fullscreen mode  Parameters and ArgumentsParameters are placeholder variables in the template of your method, whereas arguments are the actual variables that get passed to the method when it is called.def add_ten(number)  number + 10endputs add_ten(20)  #=> ""30""Enter fullscreen modeExit fullscreen modeIn this example, number is a parameter and 20 is an argument.  Default ParametersIf you don't want to always give parameters when calling a method, use default parameters:def add_ten(number = 1)  number + 10endputs add_ten(20)  #=> ""30""puts add_ten      #=> ""11""Enter fullscreen modeExit fullscreen mode  What Methods ReturnRuby offers implicit return for methods, it always returns the last expression that was evaluated.And Ruby offers explicit return too, it is useful to write methods that check for input errors before continuing.def even_odd(number)  unless number.is_a? Numeric    return ""A number was not entered.""  end  if number % 2 == 0    ""That is an even number.""  else    ""That is an odd number.""  endendputs even_odd(30) #=>  That is an even number.puts even_odd(""Egg"") #=>  A number was not entered.Enter fullscreen modeExit fullscreen mode  Predicate MethodsMethods that have a question mark (?) at the end of their name, such as even?, odd?, or between? are predicate methods, which is a naming convention that Ruby uses for methods that return a Boolean.puts 3.even?  #=> falseputs 10.even?  #=> trueputs 171.odd?  #=> trueputs 13.between?(10, 15)  #=> trueEnter fullscreen modeExit fullscreen mode  Bang MethodsMethods that are denoted with an exclamation mark (!) at the end of the method name.By adding a ! to the end of your method, you indicate that this method performs its action and simultaneously overwrites the value of the original object with the result.whisper = ""HEY""puts whisper.downcase! #=> ""hey""puts whisper #=> ""hey""Enter fullscreen modeExit fullscreen mode"
69,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
70,"  What are Common Table Expressions?Common Table Expressions (CTEs) are a valuable feature in SQL that lets you create temporary result sets within a query. They simplify complex queries, enhance code readability, and improve query performance. CTEs are initiated using WITH keyword.Fig: CTE Syntax. Image from MariaDB  When to use CTEs?CTEs are particularly useful to: Break down complex operations into simpler stepsHandle hierarchical data structuresImplement pagination for large result setsStreamline complex aggregation tasksHave reusable code if you need the same logic at multiple placesImprove code readability and maintainability if your query involves subqueries, multiple joins, or intricate filtering conditions  Types of CTEsBroadly CTEs can be classified into:Non-recursive (Simple) CTEs Recursive CTEs  1. Simple Common Table ExpressionsNon-recursive CTEs are straightforward and do not involve self-reference. They are useful for simplifying complex queries, aggregations, and transformations by breaking them into smaller, more manageable steps.  Example: Total Salary by DepartmentWITH department_salary AS (  SELECT department_id, SUM(salary) AS total_salary  FROM employees  GROUP BY department_id)SELECT * FROM department_salary;Enter fullscreen modeExit fullscreen modeHere, the CTE department_salary calculates the total salary for each department by using the SUM and GROUP BY functions. The main query then fetches the results from the CTE.  2. Recursive Table ExpressionsRecursive CTEs are used to work with hierarchical or recursive data structures. They allow a query to reference its own output, enabling operations like traversing a tree structure or finding paths in a graph.  Example: Organization HierarchySuppose we have a table named employees with columns employee_id, name, and manager_id, where manager_id refers to the employee_id of the employee's manager.WITH RECURSIVE org_hierarchy AS (  SELECT employee_id, name, manager_id, 1 AS level  FROM employees  WHERE manager_id IS NULL  -- Root level employees (managers)  UNION ALL  SELECT e.employee_id, e.name, e.manager_id, oh.level + 1  FROM employees AS e  JOIN org_hierarchy AS oh ON e.manager_id = oh.employee_id)SELECT * FROM org_hierarchy;Enter fullscreen modeExit fullscreen modeIn this example, we define a recursive CTE named org_hierarchy. The initial query retrieves root-level employees (managers) by selecting those with a NULL manager_id. The recursive part of the CTE uses the UNION ALL clause to join the employees table with the CTE itself, connecting employees to their respective managers using the manager_id.The recursive CTE is structured as follows:The anchor query selects the root-level employees (managers) and assigns them a level of 1.The recursive query selects employees who report to the managers found in the previous iteration, incrementing the level by 1.The final query retrieves the entire organizational hierarchy, including employees and their respective levels within the hierarchy.Yes, recursive CTEs are confusing. I myself struggle a lot with them. It takes a long time to understand when to use them and why. 🙃  ConclusionIn conclusion, Common Table Expressions (CTEs) are powerful for enhancing the readability, maintainability, and efficiency of complex queries.If you like what you read, consider subscribing to my newsletter.Find me on GitHub, Twitter"
71,"Recently I wanted to create a sitemap for my Razor Page web application. Adding a sitemap to a website is a relatively straightforward process, but I found out that many examples over the web are a bit outdated. So I decided to document how I added it.The following information is related to Microsoft.AspNetCore.App version 7.0.7.In general, creating a sitemap.xml for web applications can significantly enhance their search engine visibility. A sitemap provides a roadmap for search engine bots, enabling them to index your website content more efficiently.Step 1: Understand the Structure of sitemap.xmlA sitemap XML file lists URLs for a site along with additional metadata about each URL (when it was last updated, how often it changes, and its importance relative to other URLs).Here is a very basic XML sitemap that includes the location of a single URL:<?xml version=""1.0"" encoding=""UTF-8""?><urlset xmlns=""http://www.sitemaps.org/schemas/sitemap/0.9"">    <url>        <loc>https://www.example.com/foo.html</loc>        <lastmod>2022-06-04</lastmod>    </url></urlset>Enter fullscreen modeExit fullscreen modeThere are more parameters defined in the protocol specification, but Google claims to ignore them, so I think they could be omitted:Google ignores <priority> and <changefreq> values.Google uses the <lastmod> value if it's consistently and verifiably (for example by comparing to the last modification of the page) accurate.Step 2: Create a Model for the SitemapFirst, I created a model for the sitemap node. This model will represent individual URLs, their priority, and other metadata.    public class SitemapNode    {        public SitemapFrequency? Frequency { get; set; }        public DateTime? LastModified { get; set; }        public double? Priority { get; set; }        public string Url { get; set; }    }    public enum SitemapFrequency    {        Never,        Yearly,        Monthly,        Weekly,        Daily,        Hourly,        Always    }Enter fullscreen modeExit fullscreen modeThere is another approach if I wanted to use serialization, which would look a bit clearer, but it takes twice as many lines of code, so I skipped it.[XmlRoot(""urlset"", Namespace = ""http://www.sitemaps.org/schemas/sitemap/0.9"")]public class SitemapUrlSet{    [XmlElement(""url"")]    public List<SitemapNode> SitemapNodes { get; set; } = new List<SitemapNode>();}public class SitemapNode{    [XmlElement(""loc"")]    public string Url { get; set; }    [XmlElement(""lastmod"")]    public DateTime? LastModified { get; set; }    [XmlElement(""changefreq"")]    public SitemapFrequency? Frequency { get; set; }    [XmlElement(""priority"")]    public double? Priority { get; set; }}public enum SitemapFrequency{    [XmlEnum(""never"")]    Never,    [XmlEnum(""yearly"")]    Yearly,    [XmlEnum(""monthly"")]    Monthly,    [XmlEnum(""weekly"")]    Weekly,    [XmlEnum(""daily"")]    Daily,    [XmlEnum(""hourly"")]    Hourly,    [XmlEnum(""always"")]    Always}Enter fullscreen modeExit fullscreen modeStep 3: Setting Up the Method to Generate Sitemap NodesI needed a service or method that will generate the sitemap nodes based on my website's content. To generate URLs for Razor Pages, you typically could use PageLink or LinkGenerator. I used the last one:    public class SitemapModel : PageModel    {        private readonly LinkGenerator _linkGenerator;        public SitemapModel(LinkGenerator linkGenerator)        {            _linkGenerator = linkGenerator;        }        // ... rest of the code    }Enter fullscreen modeExit fullscreen modeCreating a sitemap for static pages is easier by hardcoding them. Blog pages or other dynamic content are taken from a database or file system (in my case) based on where they are stored.Method GetUriByPage from provides an absolute URL based on page name - handy.    public class SitemapModel : PageModel    {           // ... rest of the code           public IReadOnlyCollection<SitemapNode> GetSitemapNodes()        {            var nodes = new List<SitemapNode>            {                new()                {                    Url = _linkGenerator.GetUriByPage(HttpContext, ""/Index""),                    Priority = 1,                },                new()                {                    Url = _linkGenerator.GetUriByPage(HttpContext, ""/Tools/CreateCode""),                    Priority = 0.9                },                new()                {                    Url = _linkGenerator.GetUriByPage(HttpContext, ""/Legal/Privacy""),                    Priority = 0.6                },                new()                {                    Url = _linkGenerator.GetUriByPage(HttpContext, ""/Legal/TermsOfService""),                    Priority = 0.6                }            };            foreach(...)            {                // fill nodes from blog index            }            return nodes;        }    }Enter fullscreen modeExit fullscreen modeStep 4: Creating the Sitemap PageThen I added a new Razor Page Sitemap.cshtml that will be responsible for generating the sitemap.xml. When users or search engine bots access this page, it should return the sitemap in XML format. This is an elegant trick: we return the razor page Sitemap.cshtml as an XML file.@page@model Xakpc.Project.Pages.SitemapModel@{    Layout = null;    Response.ContentType = ""text/xml"";}<?xml version=""1.0"" encoding=""UTF-8"" ?>@Html.Raw(Model.RawXmlData)Enter fullscreen modeExit fullscreen modeAnother required step is to set up the app to return this file by /sitemap.xml path. It is done in options of AddRazorPages method like this:builder.Services.AddRazorPages()    .AddRazorPagesOptions(options =>{    options.Conventions.AddPageRoute(""/sitemap"", ""Sitemap.xml"");    });Enter fullscreen modeExit fullscreen modeStep 5: Formatting the XMLOn the sitemap Razor Page model, I formatted the sitemap nodes into XML format. For that, I manually built XML file with XElements    public class SitemapModel : PageModel    {           // ... rest of the code          /// <summary>        /// Serializes to raw XML        /// </summary>        public string GetSitemapDocument(IEnumerable<SitemapNode> sitemapNodes)        {            XNamespace xmlns = ""http://www.sitemaps.org/schemas/sitemap/0.9"";            var root = new XElement(xmlns + ""urlset"");            foreach (var sitemapNode in sitemapNodes)            {                var urlElement = new XElement(                    xmlns + ""url"",                    new XElement(xmlns + ""loc"", Uri.EscapeUriString(sitemapNode.Url)),                    sitemapNode.LastModified == null ? null : new XElement(                        xmlns + ""lastmod"",                        sitemapNode.LastModified.Value.ToLocalTime().ToString(""yyyy-MM-ddTHH:mm:sszzz"")),                    sitemapNode.Frequency == null ? null : new XElement(                        xmlns + ""changefreq"",                        sitemapNode.Frequency.Value.ToString().ToLowerInvariant()),                    sitemapNode.Priority == null ? null : new XElement(                        xmlns + ""priority"",                        sitemapNode.Priority.Value.ToString(""F1"", CultureInfo.InvariantCulture)));                root.Add(urlElement);            }            var document = new XDocument(root);            return document.ToString();        }    }Enter fullscreen modeExit fullscreen modeThe other option is to use serialization (if you map classes with attributes - I skipped that part)public string GetSitemapDocument(IEnumerable<SitemapNode> sitemapNodes){    var sitemapUrlSet = new SitemapUrlSet { SitemapNodes = sitemapNodes.ToList() };    var xmlSerializer = new XmlSerializer(typeof(SitemapUrlSet));    using var stringWriter = new StringWriterUtf8();    using var xmlTextWriter = XmlWriter.Create(stringWriter, new XmlWriterSettings { Indent = true });    xmlSerializer.Serialize(xmlTextWriter, sitemapUrlSet);    return stringWriter.ToString();}Enter fullscreen modeExit fullscreen modeAnd all that is left is to call methods in OnGet method and set bound property    public class SitemapModel : PageModel    {           // ... rest of the code          /// <summary>        /// Gets the raw XML data        /// </summary>        [BindProperty(SupportsGet = true)]        public string RawXmlData { get; set; }        public void OnGet()        {            var nodes = GetSitemapNodes();            RawXmlData = GetSitemapDocument(nodes);        }    }Enter fullscreen modeExit fullscreen modeStep 6: Register the Sitemap with Search EnginesAfter the sitemap is successfully set up, it's a good idea to register it with major search engines like Google and Bing. This will ensure that they know your sitemap's existence and can crawl your website more effectively.Google: Use Google Search Console to submit your sitemap.Bing: Use Bing Webmaster Tools to submit your sitemap.ConclusionFinal Sitemap.xml<urlset xmlns=""http://www.sitemaps.org/schemas/sitemap/0.9"">    <url>        <loc>https://contoso.com/</loc>        <priority>1.0</priority>    </url>    <url>        <loc>https://contoso.com/make-code</loc>        <priority>0.9</priority>    </url>    <url>        <loc>https://contoso.com/legal/privacy</loc>        <priority>0.6</priority>    </url>    <url>        <loc>https://contoso.com/legal/termsofservice</loc>        <priority>0.6</priority>    </url>    ...</urlset>Enter fullscreen modeExit fullscreen modeAs you can see, setting up a sitemap.xml in a Razor Pages application is straightforward. Following the steps above and adding the appropriate code ensures your website is more visible and accessible to search engines."
72,"  Table of ContentsIntroductionWhy Make an Impact as a Developer Advocate?Tips for Making an ImpactTeam and ManagementUnderstand ExpectationsCultivate a Strong First ImpressionIdentify What the Company Cares AboutUse the Product as a BeginnerDocument Your First-Time ExperiencesCreate Fun, Memorable DemosIntegration with Widely Used Frameworks, APIs, and ToolsMake It PracticalListen to DevelopersThought LeadershipTeach Your CompanyConclusionI find it hard to engage in discussions about my strategy for building a following and driving content engagement. While I never shy away from amplifying my content on social media, discussing these topics fill me with imposter syndrome, so I usually respond with, “I don’t know. I just do it.” Additionally, for me to answer questions coherently, I need space to think and organize my thoughts. However, beneath these discussions lies a more profound question: How can a developer advocate genuinely leave a lasting impression? As much as I would like to deny it, I think it’s evident that within almost two years working as Developer Advocate at GitHub, I’ve made a significant impact both within the company and across the developer community. Instead of being bashful, I’m choosing to embrace my influence and share my knowledge in a blog post. Keep in mind: These strategies worked for me, but developer advocacy is not one size fits all because every company and developer community has different needs and goals. This blog post is tailored specifically to Developer Advocates and may not directly apply to the broader spectrum of Developer Relations roles. Roles such as community managers, technical writers, and developer marketers have different objectives and responsibilities.It's completely fine if your aspirations don't align with creating a sweeping impact. Your focus can be on diligently executing your role, and that's perfectly valid. I’m not asserting that you must do this; rather, I’m aiming to provide insights for those who wish to explore that path.I’m primarily a content focused Developer Advocate with coding and community engagement forming complementary facets of my role.  Why make an impact as a developer advocate?People like to deny it, but Developer Advocates are influencers. I don’t say influencer in the sense that we’re on Instagram taking pictures with flat tummy tea, but we influence the developer community and our companies. Sometimes, the impetus driving one toward developer advocacy originates from a sense of disillusionment with the world of software engineering. This pivot opens doors to:Exploring and experimenting with new technologies.Supporting fellow developers and having fun.Establishing a public presence and engaging in meaningful conversations.The opportunity to travel and connect with communities worldwide.  Reality check: we live in a capitalist societyWhile we do get to do these things, companies don’t pay us 6 figures to have fun. Many companies hire Developer Advocate to spread awareness, and ensure their products thrive, leading to increased revenue. We can achieve this through community engagement, conference talks, hands-on coding, and compelling content. The trust established within the developer community directly translates into a willingness to embrace our company’s products. The ultimate goal is to create a ripple effect where the knowledge you share with developers inspires them to educate others, thus amplifying the reach and impact.  Navigating ethical advocacyBut, our job goes beyond promoting a tool. You don’t want to encourage people to try out a technology that’s not actually good or serving them. That’s inauthentic and irresponsible. Our role includes providing honest feedback to our colleagues – whether it's product managers, engineers, or leadership – on areas that need improvement. When you've nurtured strong internal relationships and your impact is recognized within your company, it’s easier to guide the direction of the product.While Developer Advocacy isn't a popularity contest, nor does it involve forcing people to use your company's technology, your goal is to cultivate relationships and establish a sufficiently strong reputation within both the developer community and your organization. This enables you to best serve developers with integrity and bring value to your company. Your job is to make an impact that reverberates.   Tips for making an impact  Team and managementWorking with a team and manager that sets you up for success is key. Stay away from managers that:Place blameConstantly change expectationsAren’t invested in your successLean into managers and teams that:Regularly give positive feedbackOccasionally give you constructive criticism, so you can improveFind opportunities for you to growPositively mention your name in circles that you’re not inMy personal experienceI’m grateful that I had good management throughout my tenure at GitHub because it helped lay a foundation for success. I had the opportunity to do activities like speak in the GitHub Universe Keynote because my colleagues and managers advocated for me and supported me.  Understand expectationsYou can gain insights and make a good impression as early as the interview. (I’m not great at this, but I do see how impactful it is when people are good at this). During the interview phase, get an understanding of why the company is hiring and the strengths and weaknesses of the team you'll be joining. People struggle to get dev advocate jobs because they don’t understand why the company is trying to fill the role. It’s important to understand what the company expects from you because you do not want to work at a company as a developer advocate with misaligned expectations. For example, if you are hoping to maintain and build the community, but they’re hoping you’re mostly going to be writing code, you will be very unhappy and so will the company.Ask yourself the following questions:What’s the company excelling at?What do you excel at?Do those align?Jason Lengstrof made a video where he talks about the key to getting a job in Developer Relations is knowing what the company is looking for. I agree with this sentiment because it also helps you determine how you’re going to shine.   Cultivate a Strong First ImpressionI’m not great at first impressions because I get super anxious. I believe there are several moments to change people’s minds about you. However, first impressions help set the trajectory of your time at the company. When you make a positive first impression, it’s easier to get buy-in from colleagues and support from the developer community. My personal experience:After I got my offer, I made my first contribution to open source, and I wrote a blog post called “Conquering the fear of contributing to open source”. I tweeted the blog post on the first day of my job at GitHub.Beyond views and retweets, I was asked to do a keynote at All Things Open on this topic. And I turned this into a talk for other conferences. I didn’t write the blog post in hopes of speaking at a conference. I was just over eager about the job, but it helped to craft my brand as authentic, vulnerable, approachable, and passionate about open source.This showed my team my work’s caliber and resonated within the developer community, placing me on their radar.Check out my tips on starting your first DevRel job to learn more.  Identify what the company cares aboutBy identifying your company's goals and aligning your efforts accordingly, you can ensure that your work resonates with the company's strategic direction and contributes positively to the developer community's understanding and adoption of key tools. Read your company and team goals occasionally because those goals will evolve over time.Here are some helpful questions to ask yourself:Does this product make the company more money?Did they invest heavily into this product?Are they talking about this product a lot in meetings?Does it seem like this product aligns with industry trends?Is the company and its customers still learning how to use this product and how this product could be valuable?My personal experience:For me, GitHub Copilot seemed like something I should invest my time in. When I started working at GitHub, I initially focused on open source and GitHub Pages, but as the company's focus shifted to tools like GitHub Copilot and GitHub Codespaces, I realized I needed to approach my job more strategically. GitHub Copilot received substantial investments from GitHub, Microsoft, and OpenAI. However, throughout the developer community there were mixed reviews and miseducation about how GitHub Copilot worked. It was also evident that AI pair programming tools and generative AI were an industry trend. At the time, GitHub was still experimenting with how developers could use GitHub Copilot, and developers were still trying to learn how to use it too. For me, this was a serendipitous time and opportunity to learn about GitHub Copilot. I wanted to figure out: Were the developer complaints valid? If yes, I would try to work with my coworkers to meet their needs. Were they misinformed? If yes, I would figure out how to educate them. And if it was both, I would do both.   Use the product as a beginnerOne effective strategy for aligning yourself with your company's goals and deepening your impact as a developer advocate is to fully immerse yourself in the products or tools you're promoting – from a beginner's perspective. It's common for companies to grant early access to developer advocates and other staff members before a product is made available to the general public. Use this as an opportunity to transition from a state of relative unfamiliarity to true expert before the product's official launch. My personal experience:When GitHub Copilot came out, I experimented with it. I was skeptical at first. My initial impression: So is GitHub Copilot autocomplete that sometimes doesn’t autocomplete? What’s the point?As developers started to question the validity of the product and even direct questions towards me, I increased my usage and began to dig into how the tool actually worked. I wanted to confidently and knowledgeably respond to their inquiries.Over time, I went from skeptic to enthusiast. It's easy to dismiss an innovation at first glance, but using the product to gain my own perspective enhanced my ability to authentically advocate for the product.  Document your first-time experiencesMany times, we prefer to wait until we have an elaborate, complex implementation of a tool, but some products need “getting started” or “hello world” examples. My personal experience:At first, I couldn’t get GitHub Copilot to reproduce anything. It would only do something for the first time and never do it again. I finally found success in promoting GitHub Copilot to write a binary search algorithm. I took that example and wrote about it. Keep in mind, the product you advocate for doesn’t have to be new or groundbreaking. it’s new to you, and it’s new to someone else, so your perspective on getting started is valuable. Sometimes, I would even tweet out my excitement when I got GitHub Copilot to do something that I didn’t expect it to do! Knowledge sharing before you gain ultimate expertise is super valuable for anyone who is a beginner user of that product.  Create fun, memorable demosPeople may argue with me about this, but if you’re trying to create awareness about a product, all of your demos don’t have to be practical. It’s okay to create a few demos that are eye-catching or fun to make people curious about the product. To make it fun and memorable, try integrating trending pop culture phenomena, emerging technologies, or both.The first time I realized the value in small, but creative demos was when I saw Lizzie Siegle do a presentation about Twilio. In her demo, she calls and messages people in the audience, then they get “rick rolled.” Out of all the talks and demos that day, Lizzie’s demonstration stood out. Here are a few developer advocates who I believe are also great at producing creative demos: Colby Fayock, Salma Alam-Naylor, and Hassan El Mghari. One of Hassan’s most popular demos is RoomGPT, which uses AI to redesign rooms.Reuse that content – take your demo and turn it into a blog post, a conference talk, a webinar, a workshop, a tweet, and a TikTok.My personal experience:“I wrote this tweet with Copilot” became almost a meme for me. Every time I presented about GitHub Copilot, I did a demo where I would write a comment prompting GitHub Copilot to generate the code that calls the Twitter API to post a tweet that said, “I wrote this tweet with Copilot and I’m at x conference right now.” True, nobody would typically use GitHub Copilot to publish tweets, but that’s not the point. The goal was to spark awareness of GitHub Copilot. As a result, the tweet:Piqued people’s interest: At the time, the developer community was popping on Twitter and I wanted people to wonder “How could GitHub Copilot write tweets? Should I check out this product?”Community engagement: I saw other people tweet, “I wrote this tweet with Copilot” meaning they tried out the demo too.Invitation from conferences: Some conference organizers invite me to do the talk at their conference because they wanted me to post that I wrote a tweet with Copilot, and I was at their conference.Some practical utility: Even though the demo is silly, it showed that GitHub Copilot can help you interact with an API in a language that you are unfamiliar with.  Integration with widely used frameworks, APIs, and toolsWhen you build with and use a product you're advocating for, you become an expert in it. However, you don’t just have to keep the product within your company’s ecosystem. Here are my reasons for integrating other technologies with your product:It helps you become aware of the limitations of the productIt makes it easy for developers to integrate the product into their daily workflow. For example: If they’re often using TypeScript, but your demos are only in Python, they may not realize you can use your company’s product with TypeScript.You may catch the attention of people who built those frameworks or build with those frameworks, which presents an opportunity to collaborate.As a result, you can introduce a novel avenue to an entirely fresh audience.My personal experienceI realized the importance of building examples with other frameworks when people would ask me, “Does this work with React or Astro?”, but I didn’t know the answer. People would also ask me things like does GitHub Copilot work better if you’re using it in a new project or using it in a large codebase with legacy code. I could try to ask other developers for their experience, but with a product so new, I felt more confident saying yes or no if I’ve tried it out on my own.  So, I started to build little projects with different frameworks. I also used GitHub Copilot when contributing to large open source projects. Now, I can confidently answer, “Yes, and here’s how you do it.”  Make it practicalAs you build and integrate the product into your daily workflow, the use cases of the product become more evident. Start taking notes and creating content around these use cases. It’s helpful to lean into your developer community to figure out how they are using the product, too. There may be experts among your users that you can feature and collaborate with.My personal experienceMy team and I helped people see the value in GitHub Copilot by showing them that you can leverage GitHub Copilot for:Adding code snippets to documentationBrainstormingSyntax recollectionUnit testingConverting applications from Javascript to TypeScriptI believe this encouraged developers to adopt GitHub Copilot because they realized it was more than just autocomplete.  Listen to developersAs you’re creating content, take a look at the questions and confusion developers have about the tool you advocate for. You may find their inquiries on social media platforms or your company’s discussion board. You can create content answering those questions. I also suggest maintaining a periodic session where you meet with product managers to express the pain points of users and you all can work together to figure out how to solve them. This way you can improve the overall developer experience through content and product improvements.My personal experienceI often saw development teams wonder if it was worth it to purchase GitHub Copilot for Business. In turn, I wrote a blog post called, “Can GitHub Copilot be a valuable investment for my team?”I also saw many people complaining that GitHub Copilot’s suggestions were inadequate and distracting. I empathize with that experience. However, I had a ton of tricks for getting optimal results for GitHub Copilot, so I wrote a blog post called, “A Beginner’s Guide for Prompt Engineering with GitHub Copilot.” To my surprise, my CEO shared this blog post with customers to improve their experience with GitHub Copilot. Writing that blog post strengthened my impact on the company internally.   Thought leadershipThere is merit in going beyond how to use the product by providing your thoughts on how the product can transform the industry. We can start productive discourse by challenging our industry leaders.My personal experienceWhen people argued that GitHub Copilot could limit learning, I wrote a blog post called, “How I’m using GitHub Copilot to learn p5.js”, where I talk about taking an intentional and strategic approach to learning a new programming language alongside an AI pair programmer. At the Microsoft Ability Summit, I spoke about using GitHub Copilot to provide psychological safety.I also wrote blog posts and delivered conference talks about how GitHub Codespaces and other cloud-based IDEs are catalysts for diversity, equity, and inclusion. Like I mentioned earlier, we are influencers and we have the power to invoke a paradigm shift, challenge norms, and start conversations that can reshape the tech industry.Ask yourself the question: How can we leverage this developer productivity tool to ethically improve our society?  Teach your companyDeveloper Advocacy is even more effective when other people in the company are advocating for the product. You’re not the only one who needs to be knowledgeable about your company’s developer tools. Some technologists within your organization like to speak at conferences and write blog posts, too! There are individuals in customer success, support, product, engineering, legal, and leadership who may need to know more about how the product works, so they can successfully do their job. As a developer advocate, you may have the most experience using the product, so share that experience internally.My personal experienceAs GitHub and Microsoft have been focusing more on artificial intelligence and GitHub Copilot, my coworkers have been looking to increase their knowledge on the product, so they could best do their jobs. Some people may have initially been on different teams, but now they’ve moved to a Copilot-focused team. To assist in the knowledge transfer, I shared slide decks and repositories with Microsoft and GitHub, so that anyone can feel confident speaking about GitHub Copilot. I also did presentations:Introducing Customer Success managers at Microsoft to GitHub Copilot. My coworker, Juan Pa encouraged me to teach our GitHub Campus experts on how to talk about GitHub Copilot, so I did.I refined the talk for GitHub’s Day of Learning, then I delivered a presentation to my company on how talk about GitHub Copilot.In essence, I’m creating more knowledgeable advocates for the product. The beauty of this is now I won’t be one of the few people at my company that can speak about GitHub Copilot. Other people can, too! Less work for me, haha.   ConclusionBy embracing authenticity, cultivating expertise, and engaging with tools from a beginner's perspective, you're not just advocating products – you're shaping the narrative of innovation itself.As you code, create, and collaborate, remember that your influence extends beyond the immediate. It's in the connections you foster, the solutions you inspire, and the conversations you initiate. I believe developer advocacy isn't just about tools; it's about catalyzing change and leaving an indelible mark on the tech landscape.So, step into your role with confidence. Your journey is a beacon, guiding others through the ever-evolving world of technology. Embrace the power of your impact, and know that your dedication will echo through the codebase, the community, and the future of tech.The blog post was filled with my opinions, but it’s not the only way to do developer advocacy. What approaches do you take to help you make an impact within your developer community and within your company?Please note: I used ChatGPT to write my conclusion because I am not great with writing conclusions."
73,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
74,"Hello, all frontend developers. I am curious what tools do you use in your daily workflow and how do you benefit from them?It could be anything a Chrome extension, VS Code Extension, maybe some AI Code writer, whatever you can't live without.Please tell me in the comments. I am curious to hear your answers."
75,"The CEO of Stability AI, Emad Mostaque, recently predicted that ""there will be no programmers in five years."" It's an intriguing idea, but Emad is wrong.Since the release of Copilot and ChatGPT, we've seen Pipedreamers write more code than ever. We expect that trend to continue. Thomas Frank, one of our most prolific users (see his voice notes to Notion workflow), only learned to code a year ago with the help of AI:We've always wanted to build AI into Pipedream itself, and we knew we'd start with code. Today, we launched a way to generate code from English (or any language ChatGPT supports). You select an app, tell us what you want to do, and we'll generate the Node.js code that does it.It's the quickest way to build integrations with any API, and gives you full code-level control over your app.  How to use itTo manage load as we scale this out, we've released this to all Advanced and Business customers. Since you're getting a dedicated AI engineer, we think it's worth the upgrade!Add a new step to your workflow, select an app, and choose the Use AI option.This opens a modal where you can tell us the code you want us to write. Be verbose. Write something like ""Send a Slack message to the #general channel in the following format: Hello, ${steps.user.name}"" vs. just ""Send a Slack message"".You can also edit existing code. Click the Edit with AI button at the top-right of any Node.js code step. You'll see the code gen window appear with the original code from your step. Enter a prompt to suggest an edit, and we'll give you the modified code.The code gen service understands the Pipedream component API and references the API docs of integrated apps (opens new window). For example, you can tell it to include specific props (input) or async options, and reference specific API endpoints you want to use for the selected app. The more information you provide, the better the code will be.  What's nextFirst, we're adding Python support to the code gen service. Soon you'll be able to generate either Node.js or Python code with AI, all in the same workflow.And we're testing the interface for generating full workflows , with triggers, actions, custom code, and anything you need to build your app.We've also been working on our Q&A bot, Pi, for a few months.Pi, Pipedream's little helper. Not affiliated with https://pi.ai/Like ChatGPT, he provides (mostly) human-level answers on a range of questions about Pipedream, APIs, and code. He's fun to talk to, he's saving us hours of time a day, and he's providing support to our community that we never could without an artificial assistant.Pi has access to Pipedream integration data, pricing, product docs, and moreYou can chat with him in our Slack and Discourse communities, and we're planning to embed him directly in https://pipedream.com so you can ask him questions as you build workflows.Please let us know if you see any bugs, want to suggest a feature, or just want to chat about AI integrations!"
76,"The World Economic Forum (WEF) recently released their 2023 job outlook report, which paints a concerning picture of the future of work. According to the report, automation technologies like GPT-4 are expected to displace up to 85 million jobs globally by 2025. This disruption will impact a wide range of industries and occupations.  Health IndustryIn the healthcare sector, automation is proving to be a game-changer. Generative AI systems can now quickly analyze vast amounts of patient data to identify patterns and provide valuable insights to healthcare providers. This enables more accurate diagnoses, personalized treatment plans, and improved patient outcomes.  Finance IndustryThe finance industry is another arena where automation technologies are making their mark. Generative AI systems can optimize investment portfolios in a fraction of the time of human analysts. However, this does mean that financial analysts and fund managers could see their roles become redundant.  Manufacturing IndustryThe Manufacturing industry is automating complex tasks that were previously prone to human error. This advancement is leading to increased productivity, improved quality control, and streamlined production processes. While this shift may lead to job displacement in certain roles, it also presents opportunities for upskilling and reskilling the workforce to operate and maintain these advanced systems.  MarketingIn marketing, Generative AI excels at generating engaging content and predicting trends to target audiences. However, this means copywriters and market researchers could be replaced by AI.   EntertainmentGenerative AI can now create movie scripts, compose orchestral music, or even predict audience preferences for a more personalized experience. However, this drives out artists, writers and performers.  ConsultingIn the consulting realm, can analyze industry trends, market dynamics, and financial data to generate strategic business recommendations. But this means management consultants and business analysts may struggle to compete.   Medical IndustryThe Medicial Industry is leveraging the power of AI, particularly Generative Adversarial Networks (GANs), for pharmaceutical research. GANs are being used to simulate molecular interactions and accelerate drug discovery processes.This innovation has the capacity to transform medical treatments, leading to life-saving outcomes and substantial cost reductions within a shorter timeframe.  Agriculture IndustryThe agriculture sector is not untouched by automation. By analyzing soil, weather, and yield data, automation technologies provide farmers with valuable decision-making tools. This enables precision farming, optimizing crop yields, reducing resource waste, and ensuring sustainable agricultural practices.  ConclusionThe takeaway is that while AI and automation will boost productivity and efficiency across industries, it will also make many jobs redundant. There is an urgent need for policies to manage this transition and provide support for displaced workers. Organizations must also take steps to upskill and reskill employees to remain competitive in the age of AI."
77,"Hey my peeps 👋Hope everybody is enjoying their weekend!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugNetflix and chillin' 📺"
78,"What are things you look for in a great API?I’d love to hear your thoughts on various aspects like a spec, e.g. OpenAPI, where you think is a great place to host your API, resilience, handling errors, observability, testing etc.If you have examples of great APIs even better! And if you have recommendations for tools to help with your awesome API share those as well.I’m curious to see people’s stacks and tools!"
79,"We're builders. We build things.We explore tech, systems, and processes related to how we build things.We play with the stuff we find that intrigues us, and every now and then, we catch a spark. A glimmer of something bigger. Something that ignites a fire that we just can't ignore. Something that fuels our passion.Then the bills come. Sigh.  The Allure of Passion ProjectsWho hasn't dreamed of turning a weekend hackathon idea into the next big startup? Passion projects are often the playgrounds of innovation. They allow you to get creative, refine skills, and do what you love!Like a painter with a blank canvas, passion projects grant you full creative control. You're not bound by client demands or company standards. This is your masterpiece. Heck, go ahead and use that new tech stack. Worst case you learn something new. Learn something new. No pressure!There's a certain euphoria in building something purely out of love and curiosity. That energy can rejuvenate you and break the monotony of the routine.  The Ground Reality of Paying ProjectsWhile passion projects paint an appealing picture, it's the paying projects that often dominate our day-to-day. And, for better or worse, with good reason.Mmmm, that sweet, sweet, predictable paycheck. It pays for the roof over your head, food in the pantry, if we're lucky (and smart) save a bit, and of course, get new shinys once in a while. Plus, working with clients and folks on your team exposes you to a bunch of new perspectives that broaden your thinking and contacts to add to the network. Let's not pretend that we only learn new stuff when working on our own stuff. Nor should we devalue the benefit of a robust network. Further still, delivering quality work in full view of peers, clients, and customers can enhance your industry reputation. Over time, this can lead to more lucrative opportunities and establish you as a reliable & valuable professional.  Striking the BalanceChasing passion without a paycheck might leave you starving, while solely chasing the paycheck could starve your passion. So, how do you strike a balance? We've got to tune things to let our passion burn bright while delivering professionally. Most obviously, yet most elusive, is finding paying work that allows the freedom to explore new technologies or work with an org already using the new stuff you're interested in! Find those synergies! More tactically though, there's a few things we can try:Time Management: Dedicate specific blocks of time to your passion projects. Whether it's an hour every evening or a dedicated weekend, make it non-negotiable.Set Clear Boundaries: Passion projects should be a joy, not a burden. Be wary of turning them into another form of unpaid labor by overcommitting or setting unrealistic expectations.Monetize Your Passion: Ever considered that your passion project might have market potential? Exploring avenues to monetize it can be rewarding, both personally and financially.Reinvest in Yourself: Use earnings from paying projects to take courses, attend workshops, or buy resources for your passion projects. This ensures you're constantly growing and nurturing your passions.  The Developer's JourneyRemember that your journey is always changing, moving, evolving. Today's passion project could be tomorrow's primary income source. On the other hand, and as unlikely as it may seem, a routine paying gig might spark a new passion -- some small detail in there might be a thread that, when pulled, reveals a new joy.The tug of war between passion and paycheck is real. It's not about choosing one over the other. It's about harmonizing the two.As a developer, our craft thrives on balance. Both passion and paycheck offer unique rewards. It's up to you to architect your path, blending both elements to craft a fulfilling, sustainable career.It's not an either-or choice. The synergy exists. Find it!"
80,"Collaboration is essential in coding, but sometimes it can be challenging to seek help or work with others. Share a story about how you overcame your hesitations and embraced collaboration to achieve a better Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
81,"The objective of this article is to serve as a guide to beginners who want to have basic understanding of containerization and container orchestration using Kubernetes.Introduction:Kubernetes as a container orchestration platform, has become the de facto standard for managing containerized applications at scale. While deploying applications on a real Kubernetes cluster is ideal for production environments, developers often need a local environment for testing, development, and learning purposes. Minikube comes to the rescue as a powerful tool that enables one to run a single-node Kubernetes cluster on your local machine. What is Minikube?Minikube is an open-source tool that allows you to set up a single-node Kubernetes cluster on your local machine. It provides an environment where you can deploy, manage, and test Kubernetes applications without the need for a full-scale production cluster. Minikube is particularly useful for developers who want to experiment with Kubernetes features, test configurations, and develop applications before deploying them to a real cluster.What is Docker?Docker is an open-source platform that automates the deployment, scaling, and management of applications inside lightweight, portable containers. Containers are a form of virtualization technology that allows you to package an application and its dependencies, including libraries and other configuration files, into a single unit called a container. A docker is technically a container runtime.Prerequisites:Install Docker in your local environment.Install Minikube.Install Vim.Let us now begin the exercise proper.Deploying a Simple Application To deploy an application in a container, we will start by creating a new deployment that is a kubernetes object. This can be done using minikube. We use the following command to start the minikube:minikube start --driver=dockerNote that we do not require root privileges to run these commands.We can now go ahead and create the deployment. The name of this deployment is serve1 and the parent image is redis.We then run the following command.kubectl create deployment serv1  --image=redisFrom the above image, we can see that our deployment was successfully created.We can view the deployment we made by running the following command.kubectl get deploymentsWe can also procced to view the deployment details with the following command.kubectl describe deployment serve1From the above snapshots, we can see a more detailed information about our deployment, including date, time, image, ports, age and others.We can also view the event log of our deployment by running this command.kubectl get eventsWe can also view existing items in the cluster in a usable YAML output, to see structure of how serve1 is currently deployed. kubectl get deployments serve1 -o yamlBelow is the output.Outputdonhadley23@donhadley:~$ kubectl get deployments serve1 -o yamlapiVersion: apps/v1kind: Deploymentmetadata:  annotations:    deployment.kubernetes.io/revision: ""1""  creationTimestamp: ""2023-08-12T23:06:45Z""  generation: 1  labels:    app: serve1  name: serve1  namespace: default  resourceVersion: ""5935""  uid: f287eb3d-4c74-44e8-99be-6efe716dd594spec:  progressDeadlineSeconds: 600  replicas: 1  revisionHistoryLimit: 10  selector:    matchLabels:app: serve1  strategy:    rollingUpdate:      maxSurge: 25%      maxUnavailable: 25%    type: RollingUpdate  template:    metadata:      creationTimestamp: null      labels:        app: serve1    spec:      containers:      - image: redis        imagePullPolicy: Always        name: redis        resources: {}        terminationMessagePath: /dev/termination-log        terminationMessagePolicy: File      dnsPolicy: ClusterFirstrestartPolicy: Always      schedulerName: default-scheduler      securityContext: {}      terminationGracePeriodSeconds: 30status:  availableReplicas: 1  conditions:  - lastTransitionTime: ""2023-08-12T23:07:10Z""    lastUpdateTime: ""2023-08-12T23:07:10Z""    message: Deployment has minimum availability.    reason: MinimumReplicasAvailable    status: ""True""    type: Available  - lastTransitionTime: ""2023-08-12T23:06:45Z""    lastUpdateTime: ""2023-08-12T23:07:10Z""    message: ReplicaSet ""serve1-5455dc4fcc"" has successfully progressed.    reason: NewReplicaSetAvailable    status: ""True""    type: Progressing  observedGeneration: 1readyReplicas: 1  replicas: 1  updatedReplicas: 1donhadley23@donhadley:~$Enter fullscreen modeExit fullscreen modeWe can go ahead and to create a service to see more about our newly created serve1 container, but we have to enable a port in order to achieve this.So, let’s create a deployment file with this vim command:vim deploymentfile.ymlThe above command will take us to our deployment file. We can go ahead and edit the file with information from a similar file in Kubernetes documentation at https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ and also enable a port.Please note that we replaced the name of the app with sever1 and added the section for port, and protocol. As can be seen below.apiVersion: apps/v1kind: Deploymentmetadata:  name: serve1  labels:    app: serve1spec:  replicas: 3  selector:    matchLabels:      app: serve1  template:    metadata:      labels:        app: serve1    spec:      containers:      - name: serve1        image: redis        ports:        - containerPort: 80          protocol: TCPEnter fullscreen modeExit fullscreen modeWe save and exit from the deployment file.This changes was necessary to enable us run the service successfully be enabling the port.We can now run this command to replace the deployment with our new changeskubectl replace -f deploymentfile.ymlWe can also view the Pod and Deployment. Take special notice of the Age, showing when the pod was created. kubectl get deploy,pod We can expose the resource again, now that we have a port enabled, it should work.kubectl expose deployment serve1Let us verify the service configuration.kubectl get service serve1To view the Endpoint which is provided by kubelet and kube-proxy. Take special notice of the current endpoint IP. kubectl get ep serve1Let also look at all the pods created.kubectl get podsWe can scale up the deployment. Let's start by checking the current deployment state.kubectl get deployment serve1Let scale it up from 3 to 6. kubectl scale deployment serve1 --replicas=6Scaled successfully!Now that we have successfully scaled our deployment, let’s check the number of pods that we have again.kubectl get deployment serve1We have six now!View the current endpoints. There will be six now.kubectl get ep serve1We can also use o-wide command to view the IP addresses the running podskubectl get pod -o wideNow that we are done with our journey of discovery on Kubernetes, it's time to clean up, by deleting our deployment.kubectl delete deployment serve1Let's verify!kubectl get deployment serve1Deleted!We then stop the minikube.minikube stopHope this guide is simplified enough and you have a better grasp of how Kubernetes functions.Thank you for reading! Please do well to follow our page and subscribe too"
82,"Whether it's contributing to open source or starting a new job, the first step is familiarizing yourself with the codebase, and it can be daunting. Here are some tips to help you hit the ground running.  1. Don't PanicEven if everything about the codebase is new to you, the first step is always the same.Make a local copy of the application on your computer.  2. Try to Get it Running LocallyFor once, Yoda is wrong - there is ""try"" and ""do"" in this step. If you're unable to get the project running based on the information you have, you can help mitigate the problem now, before the next developer is onboarded. Plus, regardless of the outcome, you'll still move on to steps 3 and 4.Ideally, there should be a file called README in the root directory of the application. This should have details about the project and instructions on how to run the codebase. If you're using GitHub and visit the repository page, this is the file displayed after the file directory.If there's no README or documentation, try to find the run scripts. Manifest files are a good place to start. For example, in an application using Node.js, npm, or yarn, the manifest file is called package.json. In addition to metadata about the project, the file may have a scripts section.""scripts"": {   ""build"": ""next build"",  ""start"": ""next build && start"",   ""test"": ""jest --watchAll --verbose"" }Enter fullscreen modeExit fullscreen modeThese scripts are run with your package manager in the terminal like npm run start or yarn run test.If the manifest file doesn't exist or doesn't have a run script, try executing outermost files that are named ""index"" or have the same name as the directory or project. If you navigate to the directory the file is in, you can execute a file in the terminal like ./index.js.Ideally, projects like this will also have a help flag. Executing ./index.js --help may print out helpful instructions, including a list of commands you can use. If you're on a mac or using linux, you can also try man <command>. This will print out a user manual for the command. If it exists, it'll have more information than the --help flag did. If it doesn't exist, you'll see ""No manual entry for <command>"". Running man ./index.js will just print out the file itself. If you're on Windows, you'll have to use a package, like groff. You may even want to use groff with macOS or linux - it displays the manual in the browser instead of in the terminal.  3. Look for DocumentationDeveloper-focused documentation may exist outside the project. It could be in the GitHub repository wiki, a company-owned docs site, or a Google Doc that's sent to you on your first day. Get access to a deployed environment as soon as you can. You'll learn a lot playing around with a working version with test data.You can also find value in documentation for users or other teams within the company. More than once, I've learned about a feature or new ways to use a feature from the user manual. These are also less technical, so they are easier to absorb when you're already taking in a lot of information.There are multiple other ways a project is documented that people don't think of as docs. This can be helpful at companies that unfortunately don't prioritize documentation. For example, tests are usually a one-sentence description of functionality. They often describe what the app is supposed to do as well as what it's not supposed to do.Even if no developer on the project has ever written a descriptive commit message, git and GitHub will still have useful documentation. Check out branches to see if there's a branch naming convention. Read old pull requests to get an idea of the code review process. git log and git blame will give you an idea of feature and fix timelines.Whether the team uses GitHub Issues, JIRA, or another work tracking system, I highly recommend searching to see if a ticket exists before you complain about something. Tickets will also give you a good idea of team goals, users' complaints, bottlenecks, and processes.  4. Talk to PeopleAsk developers what they wish they knew when they started. Ask what tools (e.g. browser extensions, editor plugins, state inspectors, etc.) they find useful for this project. Ask to pair with other developers on their work or as soon as you hit your first roadblock. If the idea of asking for help with your code makes you nervous, check out Virtual Coffee's Guide to Asking Questions About Your Code. If you hear about a bug fix, ask the developer working on it what they checked first. This is how you find out where the useful logs are and which parts of the app are most flaky. Schedule meetings with team members who aren't developers. The Product Manager can tell you the big goals for the project. The Product Owner can tell you what's prioritized for the short term. QA can tell you what's flaky, what kinds of bugs are high priority, and if they need something fixed to help them catch more bugs.If you're working in open source, join any communities related to the project. Listening to the maintainers, other contributors, and community forums can tell you a lot about what part of the app needs more love.  5. Know the BusinessUnderstanding the code is much easier with context. This is especially true when it comes to variable names. It behooves you to understand common industry terms and acronyms.It may seem like it's outside of your role to understand the industry. However, if you hear about a service a direct competitor just started providing and know how to implement it in your product, that's a big win to bring to your boss. In highly regulated industries, like healthcare, some industry knowledge could help you catch a vulnerability in the product design early. That could save the company a ton of money and looks great when you go to negotiate a raise or interview somewhere else.At the very least, it'll be easier to understand meetings and predict edge cases.  6. Mental ModelsA great way to conceptualize any application is creating some high-level mental models.I really love drawing flow charts and diagrams for applications. Tools like miro and whimsical make it easy and shareable. These can be as simple as a tree of components or files and how they relate to each other. Flow charts following the flow of data are super useful, especially if there are any integrations, micro-services, or pub/sub.You don't just have to use drawings to create these mental models. It's common to write out what each API endpoint does, including request and response structure.Once you're finished, ask a developer who is more familiar with the project if you missed anything.  7. Break ItRun into a long function you're having trouble grasping? Delete a line. See what happens. Repeat.Unable to follow the data flow? Use breakpoints in a debugger.Feed the app bad data. I dare you.Remove some props passed to a component just to see what errors pop up.Read the logs you've created with your mess.If you've seen the app break that way before, it's easier to narrow down what part of the app is broken when a bug comes up.  8. Fix ItEven senior developers have to get used to the process in a new repository. Just fixing a typo will allow you to watch the team's process from ticket creation all the way to deployment.  9. Give It TimeLearning the codebase feels URGENT, but you can't learn everything at once. With every PR you learn a little bit more, so give yourself time and grace. A typical expectation is six months to ramp up, so if your code is getting merged in before then, you're doing great.  ConclusionIf I missed your favorite tip for learning a new codebase, tell us about it in the comments!"
83,"I was recently moved onto a new contract at work and told that I would need to get a level of access to interact with the client's systems that would require three certifications, and one of them had to be CompTIA Security+. I raised my eyebrows: that's definitely outside my wheelhouse. I've been a ""full-stack"" engineer for the last four years at my present company, but the preponderance of my skills and experience are in design and front-end development.I'd only had one certification before: AWS Cloud Practitioner, which I'd let expire a couple years ago. It's a foundational, entry-level exam (in other words, it's easier than all the others), and even it was a reasonably difficult exam that gave me a lot of useful context I wouldn't otherwise have had on AWS's ecosystem and its core organizing principles and value proposition.The first thing I did was study for and re-take the Cloud Practitioner exam. I used A Cloud Guru, which I had used last time around and liked. They recently had a sale and I purchased a year's-worth of personal access for a reasonable price.My supervisor asked: how long would it take me to prepare for the Security+ exam? I researched some training options and, based on the hours of course instruction listed combined with homework and self-study, estimated four weeks. My supervisor thought that was reasonable. After going back to HR, though, he ended up coming back with a different plan: a Security+ Certification Boot Camp that would run for four days. I could attend virtually, but it would be a classroom setting. It was expensive, but, of course, my employer has to pay me for the time I'm studying, so if it can really work on that timeline, it could be worth it for them. But four days? I gulped, said, ""Sounds great!"" and got ready for an interesting week.On Friday, I took the test remotely and passed with a 775/950, with a minimum passing score of 750. I thought I'd take the time to reflect on my experience and write down some of lessons that I'm taking away.  What's valuable about certifications?Certifications have obvious benefits: some roles require them, so they can be connected to tangible increases in responsibility and compensation. And they can make you a more attractive hire. Part of the benefit comes from the fact that, in my experience, they're not easy. Having them demonstrates real knowledge.But I'm going to focus on another angle: they provide a unique and powerful form of education, especially for people without technical degrees, and for people with certain personalities.I'm a liberal arts graduate: I went to a weird school in Annapolis, MD where we studied great books for four years. I wouldn't trade that experience for anything, and it hasn't stopped me from having a great career in tech. But it does mean my expertise is sometimes more narrow than broad. I started making webpages on my own and never stopped: I know a ton about CSS, JavaScript, and all sorts of the details in making sites. But there are a lot of things I never got around to learning on my own. What is the difference between TCP and UDP? I get how private/public keys work in terms of my workflow, but do I really understand the chain of authority involved in the public key infrastructure (PKI) that makes encryption work?I won't run through my areas of ignorance exhaustively: my ego can't take it. But my point is that there's a lot that I think people with technical degrees got run through at least once in school that I've never really needed to know. And certifications, especially foundational certifications like the ones I've gotten so far, are a powerful way to get to know an entire landscape.I also think some people are, by nature or habit, just a little better about figuring out the big picture on their own. Me? I'm more of a details guy, which works both for and against me. I do great when I get to sink my teeth into particular problems and work them with creativity, enthusiasm, and focus. But I'm sometimes a little too impatient: I'd rather start building that new feature than spend a day getting the lay of the land. If you're at all like me, getting broad certification in some core technologies might help you understand the environment you work in better.  What is the CompTIA Security+ ce cert?The Security+ certification is a broad, foundational certification in IT Security. It's ""a mile wide and an inch deep,"" which means it covers a lot of territory but doesn't require deep expertise in any particular aspect of it. I tried to get a sense of its difficulty by poking around online, and the most accurate statement I read anywhere is that it just varies according to the individual. For an experienced Ops person, it might be pretty easy. I got the sense that for people like me, who don't normally work most of the subjects covered, it's considered reasonably difficult. Apparently about 50% of first-time takers fail.I'm going to try to avoid dwelling too much on the specific aspects of Security+, though, and focus on the general take-aways I had about approaching studying for certifications and tests in general.  Training Camp's Boot CampThe format for my Boot Camp was three-and-a-half days of full-on instruction with a teacher in a real room somewhere with some in-person students and the rest of us attending via Zoom. It was supposed to be about eight hours of instruction, I think, but the reality was that we never ended before 6:30 or so. After that, we had at least 1 - 2 hours of homework assigned. The trainer's advice? ""Forget YouTube, forget all your normal stuff. Just eat, sleep, and breathe Security+ this week, pass the test, and pick back up where you left off.""I'm a little suspicious about such a compressed format: I don't know if that's the best formula for long-term retention. However, I found that the quality of instruction and the techniques used were much higher quality than any previous instructor-led technical training I'd received.  Pre-Testing and ReviewThe most important strategy from my perspective was the instructor's use of pre-testing and review.Each night we were assigned homework, which consisted of memorizing some information and completing questions from a practice test. The practice test was long, much longer than the actual exam, and the number of questions assigned ranged from 50 or so to well over 100. And every night, they asked us to do questions from sections we hadn't covered yet. Why would they do that?It's a technique called pre-testing, and it engages students' brains in a powerful way by showing them that they don't already know everything (something our brain likes to believe) and directing their attention to exactly what they don't know. Rather than a general ""how much do I think I know about encryption?"" you get a whole lot of specific information about what things you do already know (I know about RSA vs elliptical encryption and why the latter is better, I know why special characters aren't useful for password security) and what things I don't already know. And you'd better believe that when I heard the answers to the questions that stumped me being discussed in the next day's lesson, my brain was ready for them, and primed to pay attention and prioritize remembering those answers.You can employ this technique on your own: look for quizzes or tests on a subject you want to learn before you spend time studying it. Can't find anything? Ask ChatGPT to write one for you.We also spent at least an hour, sometimes more, at the beginning of the day reviewing, in depth, every question we requested going over. And this was high-quality review: not telling us the correct answer (which was in the practice test, anyway), but going through the reasoning and details related to every possible answer. Because the questions selected came from us, the students, it took two important things into consideration: a) what we, ourselves, needed most help with, and b) what wasn't covered as thoroughly or even effectively during the initial classroom discussion. No matter how good the instructor is, there will be parts they cover more or less effectively, and structuring review time this way allowed us to naturally direct time to the things we needed the most.It can be hard, as a teacher (and I was one, for a year after college!), not to focus on your lesson plan, and that all-important list of what you want to impart. But you have to find ways to change that focus, because learning is not mostly about you, as a teacher: it's about your students and what you can work with them to receive. Spending time on review questions is not time lost, with no items on the curriculum getting checked off: it was some of the most valuable instruction time we had.  Diagrams and sketchesDuring their explanations, the instructor often used a digital stylus to draw and type directly onto the slides. This, accompanying the verbal explanations, helped me remember more of the subjects he covered. I can still remember the color and position of some of the explanations. It's very clear that it pulled in more of my attention than verbal explanations on their own would have. Humans are sensing creatures, and the more of those senses you can pull in to the act of communication, the more strands there are to help things stick.This insight may be as old as blackboards, but it's worth preserving the insight into the digital age of virtual teaching: maybe a Wacom tablet is a worthwhile investment if you're spending much time at all training people virtually.  The importance of writingSimilarly, the instructor recommended physically writing one's notes. He said (and I've read this a number of places before) that evidence seems to show that writing notes by hand produces greater retention than typing. He said that making flash cards can also be worthwhile, though the reality is that making them is probably more beneficial than using them. So make them twice!I'm going to confess that I didn't take this advice: I love to type, and I type quickly, and I couldn't convince myself to abandon it as a crutch. What I did do was use my daily note in Obsidian to take notes throughout, and tried as much as possible to put things in my own words rather than re-type what the instructor said. That forced me to reprocess the idea rather than simply repeating a sequence of words.  The instructor's delivery styleThis is something I didn't have much control over, but I just want to call it out for anyone that's ever in the position of being a trainer. It's not easy to listen to someone for days in a row and keep your mind engaged. But your trainer's skills with projection, intonation, and use of examples can go a long way in helping you.This instructor spoke loudly--sometimes comically so, to be honest--and really varied their intonation. They spoke with a lot of expression and intensity. And they also very frequently threw in vivid examples from their own career to illustrate different concepts. These examples were funny and sometimes shocking, but they were enormously helpful for remembering concepts. I'll never forget the concept of chain of custody in cyber security forensics, due to the story he told about how much work was thrown out the window one time when a case a friend of his had worked nine months on was irrevocably broken by one person who left some hard drives where they were temporarily unsupervised.  What I did while the instructor talkedI found that what I did while the instructor talked was one of the most crucial pieces of virtual learning. Sitting at my desk and paying attention and typing notes was okay, but there were a few problems with it: I got tired, and the temptation to check email / Twitter was always there. I'd ignore it five times, then cave on the sixth. I speculate that resisting that temptation takes a little bit of willpower every time, and that we have a finite supply of willpower. Getting comfortable somewhere I couldn't touch my phone or anything else was worse: within half an hour I was ready to fall asleep.By far the best approach for me turned out to be using Zoom on my phone, putting on my over-ear Bose headphones, and walking around the house doing minor chores. Empty the dishwasher, clean spots on the wall that I'd never noticed, move things back to the rooms they should be in; anything that didn't really take much thought or attention. Being physically active let me focus on what was being discussed.But what about notes, you ask! My experience was that notes were less valuable than paying full, steady attention. This class, like most classes, provided plenty of study materials. Why do I need to recreate my own? It was more valuable, in my opinion, to be fully present for the presentation and discussion of those topics by the instructor.I think this is a core insight for a lot of life: get rid of the note-taking, the photo-taking, the record-making. Try to experience things as fully as possible. Even if you don't remember everything that way, you give it the best chance to change you, and to change how you interact with those ideas later. It will make the time spent studying later more effective. It will make the time you spend enjoying the memories of that ride through Pirates of the Caribbean more pleasant.  Study with ChatGPTChatGPT is changing the world shockingly quickly. Right now, we're limited more by what it occurs to us to ask of it than by its own powers. One of the many, many things it does well is act as a study partner.The first night, I asked it:Good evening! I'm doing some homework for this evening, and we're supposed to memorize some of the most important port numbers and what protocols they're matched to. This is the list we've been given. Could you help me memorize these? I'll give you the list, and then I'd like you to randomly ask me about the msg format and protocol for different ports from the list. When you tell me whether I was right or wrong, I'd love it if you wanted to drop in any small bits of trivia or context that you think would help them stick in my head. Ready? Here's the list:22 TCP -> SSH -> also used by SCP/SFTP23 TCP -> Telnet -> plaintext cli53 UDP -> DNS69 UDP -> TFTP (trivial) file transfer protocol, small files only, no directory browsing80 TCP -> HTTP443 TCP -> HTTPS445 TCP -> SMB, Server Message Block, windows file sharing over tcpAnd it worked great.  What's next?I have to get one more certification soon for work, and I'm not sure what it will be, yet. After that, I think the next step for me, personally, would be to get the AWS Certified Developer - Associate certification, using A Cloud Guru's course. Wish me luck!Originally posted on nateeagle.com."
84,"Ever since Netscape launched JavaScript, there were some developers that liked it and others that didn't.Regardless of which side you're on, I think we can all agree that it would be good if browsers supported more programming languages.This is the promise of WebAssembly: Providing a generic runtime that any programming language can compile to.  Past AttemptsIn the earlier days of the web, extensions were attempted with Java Applets and Microsoft ActiveX. But both were plagued by security issues and eventually dropped. The problem was they executed without access controls, which became a massive attack surface.Later, Macromedia Flash and Silverlight had some success, but eventually met the same tragic fate. They both lacked an open standard, which made it hard for browser and OS vendors to support.  What is WebAssembly?WebAssembly (aka WASM) is an open standard byte code format that works in all browsers. It's a low-level binary format and execution engine, conceptually similar to Oracle's JVM or Microsoft's CLR.It's designed from the ground up to be hosted and safe. It cannot access the machine's memory or hard drive. Only the host can decide what APIs to expose.WASM is a portable format, so it can support many programming languages. Think Rust, Ruby, Python and even JavaScript can be compiled to WASM byte code.Though it was originally designed to target the browser, it works well outside the browser too.It can run on the server, in the cloud, in hardware devices, or used a plugin system.  Writing WASMThere are several ways to create a .wasm file:Write it by hand. (not recommended)Write it with Wasm Text Format.Use a higher level language like AssemblyScript, Rust, Ruby, etc.. and then compile it.I'll show you a few examples:  Wat is WAT?The WASM specification provides a text-based format for defining WASM modules that is called WAT (WAsm Text format). It uses S-expresions, similar to Lisp or Clojure.Here's what a basic module looks like:; define a module(module  ; define a function called ""add""  ; it takes 2 params:  ; - $a is a 32-bit integer  ; - $b is a 32-bit integer  ; it returns an 32-bit integer  (fun add (param $a i32) (param $b i32) (result $i32)    ; load param $a onto the stack    local.get $a    ; load param $b onto the stack    local.get $b    ; perform 32-bit integer ""add"" operation    i32.add    ; the last value on the stack is returned    ; which is the result of the `i32.add`  ))Enter fullscreen modeExit fullscreen modeThe .wat file can be compiled to a .wasm using wat2wasm which is part of the WebAssembly Toolkit CLI tools:# outputs example.wasm> wat2wasm example.watEnter fullscreen modeExit fullscreen modeNow the .wasm can be executed from any host. It can even be executed from the command line using wasmtime:# invoke ""add"" function, and pass args 1,2> wasmtime example.wasm --invoke add 1 23Enter fullscreen modeExit fullscreen mode  AssemblyScriptThere is also a higher-level language called AssemblyScript. It's like TypeScript for WebAssembly.If we re-write the add() function from the previous section with AssemblyScript, it would look like this:// in add.tsexport function add(a: u32, b: u32): u32 {  return a + b;}Enter fullscreen modeExit fullscreen modeAs you can see, it's much more readable now.To compile it, use AssemblyScript's compiler asc:pnpm install -D assemblyscriptpnpm run asc add.ts --outFile=math.wasmEnter fullscreen modeExit fullscreen mode  Comparing formatsTo compare AssemblyScript to WAT, I built a little tool:https://assemblyscript-play.vercel.appYou can also use the CLI wasm2wat to compare formats:# outputs .wat formatwasm2wat math.wasmEnter fullscreen modeExit fullscreen mode  Runtime executionJust like there are many ways to compile wasm, there are many ways to execute it too.  Using WebAssembly in the browserTo use the WebAssembly API in the browser, first load the assembly:// fetch .wasm fileconst response = fetch('/path/to/some.wasm')// instantiate module with streamingconst module = WebAssembly.instantiateStreaming(response)Enter fullscreen modeExit fullscreen modeThen, call one of the exported functions:const result = module.instance.exports.add(1, 2)Enter fullscreen modeExit fullscreen modeAn optional API can be passed into the module too:// fetch .wasm fileconst response = fetch('/path/to/some.wasm')// instantiate module and pass an apiconst module = WebAssembly.instantiateStreaming(response, {  imports: {    // share console.log    log: console.log  }})Enter fullscreen modeExit fullscreen mode  Using WebAssembly on the serverWebAssemblies can be executed on the server too. The API is virtually identical to the browser.The only difference is that instead of fetching the .wasm from a server using a URL, it can be read from the disk using fs.readFile():import fs from 'fs'// read .wasm fileconst bytes = await fs.promises.readFile('/path/to/some.wasm')// instantiate the moduleconst module = WebAssembly.instantiate(bytes)Enter fullscreen modeExit fullscreen modeThen, call one of the exported functions, just like we did in the browser:const result = module.instance.exports.add(1, 2)Enter fullscreen modeExit fullscreen modeIt's also possible to do this from many other languages. For example rust, ruby, python or from the CLI.  Using WebAssembly in the CloudAnother big use-case for WASM is the cloud.It has some advantages over JavaScript cloud functions:No cold starts: The host only has to load a .wasm file instead of full app. Typical JS apps have many files to load, which takes a long time.Faster deploys: All that gets uploaded is a simple binary.Polyglot hosting: All languages that compile to WASM can be deployed to the cloud without requiring any special runtime.Snapshots: Execution can be snapshotted. For example, an app that does expensive work during initialization can be snapshotted. Then future requests can start with the snapshot, eliminating the expensive startup time.A great example of WASM in the cloud is Fermyon. It's like AWS Lambda but for WebAssembly.To use Fermyon, install their CLI spin.Then create a new project:# create a new spin project# template is ""http-js""# project name is ""spin-example""spin new http-js spin-examplecd spin-example# install dependenciesnpm installEnter fullscreen modeExit fullscreen modeThen define a handler in src/index.js:const encoder = new TextEncoder()export async function handleRequest(request) {  return {    status: 200,    headers: { ""content-type"": ""text/plain"" },    body: encoder.encode(""Hello World"").buffer  }}Enter fullscreen modeExit fullscreen modeTo run in dev mode:spin watchEnter fullscreen modeExit fullscreen modeTo deploy to The Cloud™, run spin deploy:spin deployEnter fullscreen modeExit fullscreen modeNotice how that deploy was instant?  GotchasThere are still a couple rough edges of of WASM:WebAssembly is still kind of new and in active development. Though it is improving rapidly.Full support is not yet available for some programming languages.WASM doesn't have basic data types like strings or a standard library. This is by design. Languages are expected to be provide their own standard library.Because a ""standard library"" needs to live inside your .wasm, it can make file size large.Most of these will be resolved with time.  The futureOver the past few years WebAssembly has made a lot of progress. Eventually all languages will have compilation targets and runtimes for hosting it (if they don't already). This will enable all languages to run in the browser, server, or even in hardware.It might also bring on new types of programming languages that are designed for a WebAssembly-first world."
85,"Hey, this is the 3rd weekly hangout thread.This is a post where you can discuss anything related to Next.js.You can also share anything new you've worked on with Next.js or any new articles you've created which talk about Next.js.Feel free to ask any questions as well!"
86,"There's a pervasive narrative that infects us.It's one that's been fueled by countless commencement speeches, motivational posters, and well-intentioned advice:Follow your passion and success will follow.What if we've got it backwards?  Passion: The Starting Point or The Endpoint?The notion that we should first find what we're passionate about and then pursue a career in that direction is tantalizing. It suggests that there exists, hidden within us, a pre-defined compass that will lead us to a fulfilling life, if only we can decipher it. However, reality, like most things, is not so simple.Rather than discovering passions fully formed, most people develop them over time. As Cal Newport's research suggests, passion tends to emerge as a byproduct of mastery and experience. That means, instead of waiting for a lightning bolt of inspiration, we should be seeking out experiences and opportunities, investing in our skills, and cultivating expertise. Under this premise, passion is not the spark but the flame – the result of tending to our growth.This is amazing! And, the most empowering realization we can come to is that passion is not a prerequisite; it's a byproduct. It's not bestowed upon a lucky few; it's available to anyone willing to embark on the journey of experience and expertise. And here's the best of it all: the control is in your hands.  Experience First: Why Mastery Fuels PassionConsider the chronology. Before we fall deeply in love with something, we usually have to engage with it, understand its intricacies, and get better at it.Discovery through Doing: It's in the act of doing that we unveil layers, nuances, and facets of a field that might have been invisible from the outside. This discovery, over time, nurtures a deeper connection and can gradually morph into passion.The Joy of Competence: There’s an unmatched gratification in looking back and realizing how far you've come in a particular skill. As your competence grows, so does your confidence and, inevitably, your passion for the craft.Seeing the Bigger Picture: The more you immerse yourself in a field, the more you recognize its potential impact. This larger understanding can be a significant catalyst for passion. When you see the ripple effect of your actions, it's hard not to fall in love with what you do.  The Proactive Approach to PassionThe passive narrative of ""finding your passion"" places the onus on external factors, suggesting that it's something that happens to you. In contrast, understanding that passion is cultivated puts the ball in your court. It empowers you to take charge, seek experiences, and be proactive in your professional journey.This proactive approach doesn't just apply to the realm of careers. Think about personal relationships. While the initial spark is crucial, enduring partnerships are built on shared experiences, challenges faced together, and the deep understanding that comes with time.  The Beauty of ControlUnderstanding that passion is cultivated and not merely discovered is liberating. It means:You’re Not Bound by Destiny: You aren't waiting for a mythical ""calling"" to reveal itself. Instead, you have the agency to explore, immerse, and eventually find passion in various fields.Growth is in Your Hands: If passion is tied to mastery and expertise, then it's within reach of anyone willing to learn, adapt, and grow. Every challenge faced and skill acquired is a step closer to cultivating passion.Freedom to Pivot: Realizing that passion can be cultivated means you're not chained to a singular destiny. If one path doesn't resonate, the freedom to pivot, learn anew, and cultivate passion elsewhere is always available.The idea of being ""self-taught"" and pursuing something out of sheer interest does carry romantic appeal. It suggests a genuine curiosity and love for the craft. However, it's essential to understand that for many, passion isn't the reason they started but the reason they stayed.  Passion as a Journey, Not a Starting PointIn dismantling the ""passion first"" narrative, we open doors to countless possibilities. It's no longer about seeking that one thing you're meant to do, but about diving into experiences, mastering them, and letting passion emerge organically.Embracing this perspective is not just empowering; it's also inclusive. It says that passion is not the realm of a chosen few but an attainable reality for anyone willing to put in the work. And in this journey, the grind, the learning curve, the perseverance... every effort, every challenge, and every small victory becomes a beautiful part of the process.While the world may romanticize stories of those who ""always knew,"" there's an even more inspiring narrative awaiting those who dare to carve their path, master their craft, and let passion find them. It's not about finding passion but building it."
87,We all have that one language that just clicks. Which language are you naturally drawn to for your projects? Share your stories and what makes it your comfort go-to!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       
88,"Have you ever considered your approach to handling exceptions? I'm referring tothe method in which you use the raise keyword within a class, and then youutilize the rescue keyword in the function that calls that method. However, incontemporary programming languages like OCaml, Rust, Elm, Haskell, and Go, there exists an alternative approach that is contrary to exceptions. Essentially, errors are treated as values, and we manage them as regular variables using constructs like match statements or simple if statements. In this article, wewill delve into the implementation of this technique using the dry-monads gem.  Table of contentsWhat is the problem with exceptions?What are the pros and cons of using errors as valuesPutting our hands to workConclusion  What is the problem with exceptions?Exceptions can be quite easy to raise when you're just looking at the method you're developing, but when you try to consume a library or a method inside your big codebase it's noticeable some annoyances that we'll look right now:Does this method trigger an exception? :: Whenever a method is invoked in your codebase or through a third-party library, there's no immediate certainty regarding whether that function will result in an exception being thrown. In the most unfortunate scenario, if you haven't referred to the documentation or examined the code to identify any unhandled exceptions, a sudden issue arises. An unmanaged exception emerges from your application, and probably production is down right now.Which method triggered that error? :: It's quite common to have a method that consume a lot of other methods, if all of those methods trigger different errors it can be very hard to identify which method triggered what while we're developing the method, error messages can be helpful but not 100% accurate.  What are the pros and cons of using errors as values?So far I presented to you the pain points of exceptions and introduced a possible solution (the dry-monad gem), but since in the programming field there is no silver bullet it's crucial to understand the pros and cons of every possible solution, and that's exactly what we're going to see on this section below:  ProsThe runtime helps you (a little at least) :: Imagine the following scenario, you call a function and expect to return a User, but that method returns a Error, suddenly you can't use user.name because ruby will tell you that variable is an error type and not a User, leading to easy debugging and preventing future bugs at production.Disclaimer: This is not as good as having compile time error, but the idea here is to improve your current development experience by bringing the exceptions closer to you.Deal with error handling before business logic :: While this might be a more personal preference than a purely technical advantage, working with errors as values allows you to explore fully the power of early returns by handling all the unhappy paths at the beginning of your method.Clear view of which method returned which error :: The beauty of dealing with errors as return values becomes evident by the transparency it brings to the codebase. As errors are directly returned from methods, it becomes clear which error corresponds to which method.  ConsChallenges while managing deeply nested errors :: As we presented on previous topics the benefit of linking errors to their original methods, a difficulty arises in scenarios where you have a deeply nested method chain, in this case it's hard to keep context of where these exceptions passed through.  Putting our hands to workFirst let's define some disclaimers about dry-monads: Dry monads is not about avoiding exceptions, it's more about using exceptions within a controlled environment where you know you're raising a exception.Dry monads are not perfect, ruby is a dynamic language and we can't have perfect compile time checks, but we can improve our development experience at the best we can.Now that we settled our points, let's create a sample project to present how to use this new gem:  1. Creating the projectYou can create a sample project with:mkdir project && cd project && bundle initEnter fullscreen modeExit fullscreen modeAnd then add the only dependency of this project, dry-monads:bundle add dry-monadsEnter fullscreen modeExit fullscreen mode  2. How to return an errorInitially, we will examine the Result monad. If you're familiar with Rust, comprehending this concept might be relatively straightforward. Essentially, the Result monad encapsulates two potential outcomes: either a Success(value) or a Failure(error).To work with this result monad, first we need to require the library and then for convenience include the Dry::Monads[:result] so we can use Success and Failure without the module prefixes as showed below:require 'dry/monads/all'class Auth  include Dry::Monads[:result]  # @param name [String]  # @return [Failure(Symbol), Success({ name: String })]  def authenticate(name:)    return Failure(:unauthorized) unless name == 'correct'    Success({ name: 'cherry' })  endendEnter fullscreen modeExit fullscreen modeIf we try to call this method expecting to see a name parameter from it like this:val = Auth.new.authenticate(name: 'incorrect')puts val.nameEnter fullscreen modeExit fullscreen modeYou'll get an error from the ruby runtime:$ ruby main.rbmain.rb:19:in `<main>': undefined method `name' for Failure(:unauthorized):Dry::Monads::Result::Failure (NoMethodError)puts val.name        ^^^^^Enter fullscreen modeExit fullscreen modeCool right? Now the runtime help us understand if a function trigger an erroror not, and we can handle it property, but how do we get the object inside theFailure on this and log into the console? Let's see two approaches for that.  3. How to unwrap the Result variants  1. Pattern matchingYou can use the new pattern matching syntax introduced on ruby version 2.7 to unwrap both variants like below:case Auth.new.authenticate(name: 'incorrect')in Dry::Monads::Result::Success({name: String} => user)  puts userin Dry::Monads::Result::Failure(:unauthorized => error)  puts errorendEnter fullscreen modeExit fullscreen modeThis pattern will match on the Failure variant and the output print will be:$ ruby main.rb:unauthorizedEnter fullscreen modeExit fullscreen modeIf you change the name parameter from ""incorrect"" to ""correct"" you'll have the following output print instead:$ ruby main.rb{:name=>""cherry""}Enter fullscreen modeExit fullscreen mode  2. If statementsUsing plain old if statement we'll need to use some new methodsIt's also possible to use the good old if statements, the result provide boolean methods and also a bind method to unwrap the variant. On the example below we handle it with a plain puts, but you can imagine how easy is to use a early return to handle the failure or success variant cases instead.value = Auth.new.authenticate(name: 'incorrect')value.bind { |user| puts user } if value.success?value.bind { |error| puts error } if value.failure?Enter fullscreen modeExit fullscreen modeAs you can see, we have some methods such as success? and failure? that return booleans, facilitating our life when dealing with control statements. Additionally, we have the bind  designed to unwrap the result variant with a closure.  3. Getter methodsAnother way to unwrap a specific variant is to use the correspond getter method, this is specially useful when you're already inside a if statement and can be used as follow:value = Auth.new.authenticate(name: 'incorrect')puts ""The error variant is: #{value.failure}"" if value.failure?puts ""The success variant is: #{value.success}"" if value.success?Enter fullscreen modeExit fullscreen mode  4. Yield syntaxThe yield syntax is a method to unwrap only the Success variant of a result without entering a closure, if the method return a Failure the unwrapping will not happen, so it's recommended to handle the specific failure cases before using the yield.Disclaimer: The include statement it's required to use the yield syntax.class Runner  include Dry::Monads::Do.for(:call)  def call    value = Auth.new.authenticate(name: 'incorrect')    return value.failure if value.failure?    yield value  endendputs ""Result: #{Runner.new.call}""Enter fullscreen modeExit fullscreen mode  4. Dealing with deep nested errorsAt the beginning of this article I presented a problem with handling errors as values. That problem is when you have to return different errors for a deep nested method - where a method invokes another, and so forth. But how do we deal with this problem?In languages like Golang, a function like errors.Wrap() exists to facilitate the contextual addition to an error, simplifying the identification of the error origin and providing a lot more information besides just a error message.Using dry-monads, we can leverage the full power of ruby dynamic nature by allowing us to return anything inside the Failure variant, that way we can create complex data structures like hashes to register context about the error call stack.Let's assume the same class we had before, but with a tweak on the error handling:require 'dry/monads/all'class Auth  include Dry::Monads[:result]  # @param name [String]  # @return [Failure({ error: Symbol, context: String, username: String }), Success({ name: String })]  def authenticate(name:)    return Failure({ error: :unauthorized, context: 'Auth#authenticate', username: name }) unless name == 'correct'    Success({ name: 'cherry' })  endendEnter fullscreen modeExit fullscreen modeAs you can see we can return an object with some keys that provide more information about that error, where it was called and any useful information about it, that freedom allow us to create a key like parent: 'ParentClass#parent_method' that essentially mimics the functionality of errors.Wrap in the Golang world. We can for sure create more complex structures with custom classes, but on this article I chose to go with a more simple and straightforward approach to introduce the potential!  5. Bonus, dealing with the null representationWe saw how to handle failures and success variants for our business logic, but maybe you're thinking with yourself ""I can abstract the absence of value as well?"" and you would be absolute right we can!The absence of value can be understand as None and the value itself can be understand as Some, dry-monads gem provide this amazing functionality for us using the same concepts as we saw with the Result:Consider a similar class as we saw above but using the maybe variants instead of the result ones.require 'dry/monads/all'class Auth  include Dry::Monads[:maybe]  # param name [String]  # @return [None(), Some({name: String})]  def authenticate(name:)    return None() unless name == 'correct'    Some({ name: 'cherry' })  endendnone_val = Auth.new.authenticate(name: 'incorrect')some_val = Auth.new.authenticate(name: 'correct')puts ""None -> #{none_val}""puts ""Some -> #{some_val}""Enter fullscreen modeExit fullscreen modeWith this sample code our output will be the following:$ ruby main.rbNone -> NoneSome -> Some({:name=>""cherry""})Enter fullscreen modeExit fullscreen modeSimilar to the Result monad we can do pretty much every control statement as previously showed, below we'll see all of them briefly:  1. Pattern matchingrequire 'dry/monads/all'class Auth  include Dry::Monads[:maybe]  # param name [String]  # @return [None(), Some({name: String})]  def authenticate(name:)    return None() unless name == 'correct'    Some({ name: 'cherry' })  endendcase Auth.new.authenticate(name: 'correct')in Dry::Monads::Maybe::None  puts 'None branch'in Dry::Monads::Maybe::Some({name: String} => user)  puts ""Some branch #{user}""endEnter fullscreen modeExit fullscreen mode  2. If statementsrequire 'dry/monads/all'class Auth  include Dry::Monads[:maybe]  # param name [String]  # @return [None(), Some({name: String})]  def authenticate(name:)    return None() unless name == 'correct'    Some({ name: 'cherry' })  endendoption = Auth.new.authenticate(name: 'incorrect')puts 'This is the none option' if option.none?option.bind { |opt| puts ""This is the some option #{opt}"" } if option.some?Enter fullscreen modeExit fullscreen modeIt's important to observe that we don't need to use the bind method on None because this variant will just represent the nothingness of value.  3. Yield syntaxDifferently than the Result monad, Maybe don't provide us a getter method so we need to rely on the yield syntax when we don't want to use a closure like on bind.class Runner  include Dry::Monads::Do.for(:call)  include Dry::Monads[:maybe]  def call    option = Auth.new.get_user_name(id: 1)    return None if option.none?    yield option  endendputs ""Result: #{Runner.new.call}""Enter fullscreen modeExit fullscreen modeSimilar to the Result, yield just work on the happy paths (in this case the Some variant).  ConclusionAs always I hope you liked this article and learned something new, I'm working on a new gem to wrapping exceptions and returning this monads, I hope to get something working soon and writing the part 2 of this article. May the force be with you!"
89,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
90,"In this blog post you'll learn how to create a Full Stack Airbnb Clone using Amplication.  Features of the AirBnb CloneBuilt using Next.jsStyled with Tailwind CSSBackend generated using AmplicationState Management with ZustandRealtime Maps using Mapbox API Login Signup using JWT TokensAPI Call's using Axios  Functionalites of the AirBnb CloneCreate ListingsView ListingsBook ListingsDelete ListingsAdd Listing to WishlistRemove Listing from WishlistView booked ListingsSearch ListingsSearch Listings using MapView Listings Data on MapThis blog post is a part of my Youtube video. Check out the amazing video.  Unleashing the Power of Amplication: Accelerating Software Development with EaseAmplication is an open-source development tool designed to simplify and expedite the process of building web applications. With its user-friendly interface and a wealth of features, Amplication empowers both developers and organizations to create robust and scalable applications quickly, saving valuable time and resources in the process.The platform is centered around the concept of a low-code development environment, which allows developers to build applications by configuring and connecting pre-built building blocks rather than writing code from scratch. This approach dramatically reduces the amount of manual coding required, enabling teams to focus on creating business logic and delivering a polished end product.  Step 1: Fork the starter git repository:Clone this git repository to get starter files for the Airbnb Clone.  Step 2: Create a amplication accountHead over to amplication login and connect your github.  Step 3: Create your first serviceNow you need to create a service for amplication which in turn generate your backend code. Give it a meaningful name.We are going to name it AirBnb and hit continue.  Step 4: Connect with Github and Select RepositoryNow you need to connect with Git. There are various options available but we are going to use Github for our git provider.After you connect with github you need to select a repository. Select the airbnb repo.Now hit continue.  Step 5: Selecting GraphQL / RestAPI & Swagger UI / Admin UIIn this step you can enable the options for support of the GraphQL API, the REST API & Swagger UI and the Admin UI provided by Amplication.We are going to enable all the options here. Though we will not be using the GraphQL API for the app but for the demo purposes we are enabling it.We are going to use the REST API's through out the AirBnb clone. Also we will be using Swagger to test out the API's.  Step 6: Selecting the type of backend structure generated by Amplication.Amplication provides two types of structure for the generated code.PolyrepoIf you are using a polyrepo, Amplication will push the code to the root of the repo in separate folders for the server and the admin-ui.MonorepoIf you are using a monorepo, you can select the folder where you want to save the code of the service. “apps”, “packages”, “ee/packages” all are valid.We are going to use the Polyrepo option for this project.It will generate two folders into the root of our repository, named as server and admin-uiNow hit continue.  Step 7: Select the database.Amplication provides three types of database at the moment.PostgreSQLMongoDBMySQLAmplication generates the service with all the required configuration and code to start working with a DB.You can easily change the type of the DB later in the plugins pageFor this AirBnb Clone we are going to use the PostrgreSQL DB.Now hit continue.  Step 8: Selecting a Templates for your ProjectAmplication provides two options for your entities.EmptyManually define your own entities and fieldsUse a TemplatePre-defined set of entities and fields Address, Orders, UserYou can start from scratch or select a demo template.We are going to select the empty option here.Hit continue.  Step 9: Selecting Auth ServicesAmplication provides in built auth module that pre generates code for you authorization and authentication.For this Amplication provides two optionsInclude Auth ModuleGenerate the code needed for authentication and authorizationSkip AuthenticationDo not include code for authenticationFor our AirBnb clone we are going to use the auth module provided by Amplication so we are going to select Include Auth Module Option.Now hit continue All the initial setup is done and now Amplication will generate the code. Wait for it to generate. This may take a minute or two.After the code is generated you can see the following screen that the code has been generated.Now you select view my code button and it will redirect you to the Github Page  Step 10: Merge the pull request generated by amplicationNow after every change in Amplication service it will generate a new pull request that needs to be merged in Github  with our code.Now on the Github Pull Request page you have to merge the code with Merge pull Request button.You can also check the code generated by Amplication by clicking the Files Changed OptionThis will show you all the code generated by Amplication.Now head over to the amplication tab and hit continue.You will see the success page.You have successfully setup your Amplication app.Now click on create entities option to create entities.Entities are like table in DB.Now there is a predefined entity here which is for users in your application.  Setting up Amplication EntitiesWe will be using four entities in our AirBnb Cloneuser:Manages all users with their details.listings:This will store all entities created by a user.trips:If a user books a listing then it would be stored in this entity.wishlists:If a user add a listing into their wihshlists then this would be stored in the Wishlists entity.  Setup ListingsNow click on Add Entity button on Top Right CornerOn the new Entity Modal screen type listings as the name of new entity and hit create entity.Now you will be redirected to the listings entity details page.From here you can add new fields to your entity or even give granular permissions to the entity according to the roles.Now from here we need to create some fields that we are going to use for our AirBnb Clone.  title FieldClick on the add field button Write title as the name and click on + right beside it.You can see that the the new field is created and there are various options to configure.We are going to mark this field as required.Also we will select the Data Type as Single Line Text from the dropdown.Amplication provides various Data Type according to your needs an takes care of the constraints on your code as needed according to the data type.Now amplication auto saves everything after each change so your selections are already selected  description FieldDo the same process for description, but for the datatype we will change to Multi Line Text.  locationType FieldThis field will store the type of location of the listing, whethere it is a house, flat, bunglow, etc.Do the same process as we followed for the title field.  placeType FieldThis field will store the details like if there is a full room to this place, is this place shared, etc. Do the same process as we followed for the title field.  price FieldThis field will store the price of the listing.For the datatype we will use the Whole Number type.The minimum and maximum value would be set by default. We do not need to change it.  mapData FieldThis field will store the maps cordinates for the Mapbox to load the specific location with the accurate marker.For this field we will select the datatype as the Json type, because we will have json data inside of it.  locationData FieldThis field will store the location Data like the pincode, address, city, etc.This will be a Json data type.  placeSpace FieldThis will store the total rooms and total guests the place can have.This will be a Json data type.  photos FieldThis will store the links of the photos for the listings.This will be a Json data type.  listingCreatedBy fieldThis field will store the data of the user that created this listing.This would be relation to the User entiity.Select the data type as Relation to entiity.In the Relation Entity Dropdown Select the User Entity.And select the One 'listings' can be related to one 'listingCreatedBy' option.This means that one user can create many listings.That's it. With this we have created our listings Entity.  Setup WishlistsThis entity will store the wishlists of the user.  user fieldThis will store which user has added the listing.The data type will be Relation to Entity with the user, with the One 'wishlists' can be related to one 'user' option toggled.  listing FieldThis will store which listing has added by the user.The data type will be Relation to Entity with the user, with the One 'wishlists' can be related to one 'listing' option toggled.That's it for the wishlists entity.  Setup TripsThis will store the trips that has been booked by the user.We will follow the same procedure for the trips as we did for the wishlists with the same field names and same relations.And that's all for the Trips entity.Now we have created all the entities that is required and we can build our app and push the code over to github.  Build and publish the code to GithubYou can see that we have some pending changes in the right sidebar. We need to push these changes to github to integrate it with our app.Click on the Commit Changes & build button.With this Amplication will start building your code.As soon as the build would be successfull the code would be pushed over to the Github.Now head over to your github repository.Now click on the Pull requestsClick on the pending pull request that is generated by the Amplication bot.Now you will see the request page. You can either check the code or merge the pull request to merge it with the main source code.Now we have successfully generated the backend code with Amplication.  Setup Local AppNow we need to setup the app on our local machine.For that clone the repository or pull your source code from git.Now to setup the app we need to install the dependencies.For this there's already a pacakge.json file created in the root of the directory.You need to run npm install.This will install the root dependencies.After this you need to run the npm run postinstall script to install the frontend, backend and the admin-ui dependencies.After the process is completed your app is successfully setup with the backend code generated with Amplication.Now for starting the app you can run npm run start.  Amplication REST API's with SwaggerIf you want to check the API's generated by Amplication, head over to http://localhost:3000/api.This will open the Swagger UI with all the API's. You can test out API's here.But wait there's something more,  Amplication introduces a groundbreaking feature: Upload Prisma Schema.If you find yourself in the midst of the development phase and wish to seamlessly transition to Amplication's services, this powerful tool will be a game-changer.Imagine having the ability to effortlessly import your Prisma schema into Amplication, enabling the automatic generation of entities and relationships required for your application. This simplifies the migration process, saving you time and effort while ensuring a smooth transition to Amplication's services.With Amplication's Upload Prisma Schema feature, you can take your development project to the next level, leveraging the platform's robust capabilities to accelerate your app's progress. The integration of your existing Prisma schema will pave the way for a more efficient and productive development experience.Here's what the process looks like,This feature is still in beta mode and would be available to end users shortly.  ConclusionThis blog post has taken you through the process of creating a Full Stack Airbnb Clone using Amplication, a powerful open-source development tool. With Amplication's low-code development environment, developers can build web applications by configuring and connecting pre-built building blocks, reducing the amount of manual coding required. The post covered the various features and functionalities of the Airbnb Clone, including real-time maps, JWT-based authentication, API calls using Axios, and more.The step-by-step guide walked you through setting up the project using Amplication, creating entities for listings, wishlists, and trips, and how to push the code to GitHub for integration. Additionally, it demonstrated how to test the REST APIs generated by Amplication using Swagger UI.By leveraging Amplication's capabilities, developers and organizations can accelerate software development, saving valuable time and resources, and deliver robust and scalable applications. Whether you're a seasoned developer or just starting, Amplication provides a user-friendly platform for building impressive web applications with ease. So, go ahead and unleash the power of Amplication in your next development project! Happy coding!This tutorial was a part of my Youtube video. Check out the entire video."
91,"They say time flies when you are having fun. I can definitely vouch for that, especially since I made the switch from being an architect to becoming a software developer five years ago.With my background in art and design, I found a whole new world of enjoyment by messing around with the HTML canvas and exploring the visual side of coding. So, it was pretty natural for me to get curious about making games. At first, it was just a little experiment driven by curiosity, but over time, it grew into something more. It turned into my personal playground where I would keep coming back to add new cool stuff that I learned throughout the year.The journey had its highs and lows, with moments of victory and some major letdowns. But there was always one thing that kept me going: the game itself.Here's my story.   Year #0 - Improvise, Adapt, and OvercomeIt all started like most stories do – a feeling that my current path, even though successful, was missing something important: joy. It was draining me both physically and emotionally. I knew something had to change.By then, I had a bit of experience with coding. I had made my own portfolio website (a standard thing for architects), worked on simple websites for other businesses, and dabbled with coding in general. But never did I think of coding as a career option. How could I? I had invested so much time into architecture already.Around that time, coding schools were popping up all over, promising amazing opportunities. I talked to some folks from a coding school just next door to where I lived. They had these full day 3-month courses that guaranteed job placement with a sort of ""trust me, bro"" assurance. I was skeptical but a course, which was like a full-time job seemed like a good way to stay focused. So, I set a simple plan: one year, go all in, no ragrets.The courses covered the usual suspects - HTML, CSS, JavaScript, PHP, Laravel - basically, the whole shebang to make you a junior full-stack developer, even though that title makes little sense. But out of it all, one thing stood out - JavaScript tutor.""I won't just teach you JavaScript. I'll teach you how to think like programmers.""Those were the first words from him. It sounded cheesy then, but looking back, I can see how lucky I was. His constant questions - how does this work? Why do you need this? Was a daily ritual. This approach of digging deeper really resonated with me and helped me realize, that I need to focus. A ""junior full-stack developer"" made even less sense, than before. A ""junior JavaScript developer"" sounds much more reasonable.Inspired to do more, I wanted something to work on at home. I mean, there are only so many to-do lists you can make, right? That is when I stumbled upon the HTML canvas. It was amazing to see code come to life visually, especially in a form close to my heart - games. Writing something as simple as Pong felt amazing and I was hooked. I tried making Tetris and that worked!So, what is the natural next step after you have tried to create your own version of Pong or Tetris? For me, it was an obvious choice - make a Mario clone! This was a completely different challenge - creating tiles, making a player object interact with them, jump and everything else what looks as simple as it can. Did it pay off? Yes, it did! Spoiler - it even helped me land my first job, after many rejections, of course.As the coding school course neared its end and the job hunt loomed, I did not want all my efforts to go to waste. So, I transformed that simple Mario project into my personal website, showcasing my journey. Maybe just to show off, or maybe so I could continue working on it in the future.   Year #1 - Small Steps, Big ChangesAfter the initial excitement of ""I'm actually a developer now"" settled down, I knew I had to keep the ball rolling. What next? I had already done Pong, Tetris, a Mario clone... Well of course it is Wolfenstein 3D. What else could it be?Since I already had a system based on tiles for my platformer, the only thing left was to change how it was rendered - essentially, create a ray-casting engine. There were tons of tutorials and videos about this, including some from John Carmack himself. All I needed to do - translate that into JavaScript.Surprisingly, it was not as tough as I thought. In fact, it was quite motivating. Sure, it was not perfect, but I saw it as a fun experiment. Little did I know that tinkering with 3D graphics would become a major driver in improving my skills as a developer.Here is my ScriptenStein. It only has keyboard (arrow buttons) controls, so do not expect much.   Year #2 - Are You Really a Developer If You Don't Have an NPM Package?Feeling comfortable in my developer shoes and having ventured beyond just front-end work, I realized it was time to optimize my game - make updates and deployment easier, expand it further.Main focus this year, was to extract some logic into a separate package, as I have already started having some ideas about using it else were. Spoiler - a mobile app. This is how LaikaJS was born.Isolating game logic from design elements turned out to be a game-changer. It allowed me to concentrate on each aspect more effectively. With new features in place (multi-layered backgrounds, music, so NPCs), I felt motivated to revisit and revamp the visual side. After all, why should code be the only thing that looks good?You can see the latest version here   Year #3 - It's All Fun and Games Until It's an AppBy my fourth year, I had worked on several projects and gained enough experience to dive into React Native. With the core JavaScript foundation of my game already in place, I decided to turn it into an app. How hard could that be? Oh boy, how wrong I was...First and probably the main this was, that there is no native canvas! Technically you can get some implementations of it, but the performance is far from acceptable. So what can you do? WebGL to the rescue. But there is a catch - it has steepest learning curve that I have faced up to that moment. I had to learn the WebGL API, understand GPUs, and implement general logic. It's important to note that I wanted to learn WebGL itself, so using libraries wasn't the route I wanted to take.After quite some time I have managed to get grips of WebGL basics and implemented all the game logic, that I have had on the web!Was it easy? No. Was it worth it? Ohh yes! You can get it from PlayStore and give it a go yourself.   Year #4 - Psst… I Heard You Like WebGLIn my fifth year, I started my journey to understand WebGL better, as it felt like the natural step to turn my 2D world into a 3D one.To do this, I needed to get really comfortable with WebGL and computer graphics in general, not just poke around in the dark. The thing that helped me the most, where amazing tutorials from Andrew AdamsonThat is not all. Another thing that also really stuck to me from this year was, that I finally needed to and was able to read dedicated math and computer graphics books. It is not much, but felt like a great milestone to me.Sometimes it felt like a detour from my day-to-day work, but growing up playing video games, working with 3D software in university, and being an architect with an interest in software got me hooked. Understanding computer graphics better made me appreciate of graphics engineers even more.But anyway, even though it is a work in progress, I'm thrilled that I can replicate this progress myself. From Pong to Tetris, to 2D platformer, to a simple 3D rendering, and now a full 3D world.Take a look here   Year #n+1Switching careers was a tough call, but I'm so glad I took the leap. It's been an amazing journey so far and the architect inside me is really happy, as software development has much more in common with architecture, than most people expect. I'm excited to see where the next 5 years take me. Maybe I will have to learn something else, when AI will make all developers obsolete ¯\_(ツ)_/¯TLDR; I like to code."
92,"Hault! If you're hoping for some interesting tidbits on the second Star Wars movie from 20+ years ago...this is not the article you are looking for.If you're still hear, then perhaps you're hoping to learn a little something about cloning objects in Javascript. If so, you've come to the right place because that is exactly what I want to talk about in this post!As a Javascript developer, cloning objects has been a bit of an issue for a while. There are many different ways to do it, but you have to know and understand the ins and out and the pros and cons of each to know when to use them and why. But luckily, a browser API has come available in the last year or 2 that alleviates this problem.You may be wondering, ""If this thing has been out for a year or 2, why is this person writing about it now?"". That's a great question! The answer...because I still talk to a lot of people who have never heard about it. So this is me trying to spread the word on this little piece of functionality that has made my life better.So what is this mystical, Jedi-esk power I'm speaking of?[queue dramatic music]structuredCloneThis new browser API's main purpose is to allow us to quickly and easily create deep clones of objects without the need of some workaround or third party library! Not only that, but it also brings with it the ability to transfer properties from one object to another instead of cloning them.So why is this new API worth a blog post? To understand that, we first need to understand a few things about Javascript.  Shallow vs Deep ClonesThere are actually multiple types of clones in Javascript, and we need to understand these before we can understand why this new API is so valuable. The two types we need to consider are shallow and deep clones.When we create a shallow clone of an object, it means we're only cloning the top level properties of that object. If the object contains any nested objects, their properties will be copied rather than cloned.A deep clone, on the other hand, clones all the properties, even the nested ones.To better understand this, let's say we have an object like this:const user = {  name: 'Anakin Skywalker',  age: 19,  jedi: {    rank: 'Knight',    master: 'Obi-Wan Kenobi',  },}Enter fullscreen modeExit fullscreen modeIf we were to create a shallow clone, it would look like this:const user = {  name: 'Anakin Skywalker',   // new  age: 19,                    // new  jedi: {                     // new    rank: 'Knight',           // old    master: 'Obi-Wan Kenobi', // old  },}Enter fullscreen modeExit fullscreen modeWhen I say old here, I mean that these values were not cloned, they were only copied.On the other hand, if we were to create a deep clone of the same object, it would look like this:const user = {  name: 'Anakin Skywalker',   // new  age: 19,                    // new  jedi: {                     // new    rank: 'Knight',           // new    master: 'Obi-Wan Kenobi', // new  },}Enter fullscreen modeExit fullscreen modeOkay, we understand the difference between shallow and deep clones, but why does it matter? Shallow, deep, we just want to clone the object and use it in our application, right? Now let's look at the problem...  The ProblemLet say we make a shallow clone of our object and then want to update it. No problem...const user = {  name: 'Anakin Skywalker',  age: 19,  jedi: {    rank: 'Knight',    master: 'Obi-Wan Kenobi',  },}// create the shallow cloneconst clone = {...user};// update the cloned dataclone.jedi.rank = 'Master';Enter fullscreen modeExit fullscreen modeThat was easy...let's log out our objects to confirm everything worked...console.log(user);\\ {\\   name: 'Anakin Skywalker',\\   age: 19,\\   jedi: {\\     rank: 'Master',\\     master: 'Obi-Wan Kenobi',\\   },\\ }console.log(clone);\\ {\\   name: 'Anakin Skywalker',\\   age: 19,\\   jedi: {\\     rank: 'Master',\\     master: 'Obi-Wan Kenobi',\\   },\\ }Enter fullscreen modeExit fullscreen modeUh oh, looks like we have an issue...both of our objects have been updated! But we only changed the value on the clone. How could this be?The problem stems from how Javascript stores data in memory and how it references that data.When you assign an object to a variable, you aren't actually assigning the data to it. Instead, you're assigning the address of where that data is stored in memory. Then when you assign that variable's value to another variable, the second variable receives the same address. Now there are 2 different variables that contain the same address so they are both looking at the same data in memory.To better understand this, let's continue to use our example. Let's imagine that Javascript has stored each value in a different part of memory and the properties don't hold the value, but instead they hold the address to the data in memory...like this:(note: This is only for simple visualization to understand the topic. Memory management in Javascript is much more complicated than this simple example portrays, but it serves to help understand the difference between reference and value.)const user = {  name: abc123, // 'Anakin Skywalker'  age: abc124,  // 19  jedi: {    rank: abc125 // 'Master'    master: abc126 // 'Obi-Wan Kenobi'  },}Enter fullscreen modeExit fullscreen modeWe can now see that each property is storing an address in memory where each piece of data is located. With this in mind, let's also look at our clone in the same way:const user = {  name: def123, // 'Anakin Skywalker'  age: def124,  // 19  jedi: {    rank: abc125 // 'Master'    master: abc126 // 'Obi-Wan Kenobi'  },}Enter fullscreen modeExit fullscreen modeNow we can clearly see the differences and similarities between the 2. Remember, our clone is only a shallow clone so only the top level properties were cloned. The rest are copied from the original object.So if we look at top level properties name and age, we can see that new addresses in memory were assigned to them. But the nested properties jedi.rank and jedi.master have the same addresses as our original object. This is why both objects printed out the same data when we logged them earlier. By changing the value of clone.jedi.rank, we were actually changing the data in memory stored at address abc125. Since both objects are referencing that same address, they both printed out the same data.Sometimes, when a developer thinks they're cloning an object, they're often only creating a shallow clone, resulting in updates being made to other objects they didn't intend to change. This small nuance has caused a great many bugs over the years...and they can be tricky to track down.  How to make a Shallow CloneNow that you understand what a shallow clone is, I want to show you 2 methods that create them. So when you see them in the wild, you'll know more clearly what they're doing.const clone1 = { ...user };const clone2 = Object.assign({}, x);Enter fullscreen modeExit fullscreen mode  Deep Clones...the old waySo we understand what deep clones are, and the need for them, but how do we create them?Before the structuredClone API came about, our options were limited, and none were particularly ""good"". Here are the 2 most common methods I've encountered:(note: These are not the only 2. There are many others, especially when cloning arrays. I limited to only 2 for the sake of time.)import { cloneDeep } from 'lodash';const clone1 = JSON.parse(JSON.stringify(user));const clone2 = cloneDeep(user);Enter fullscreen modeExit fullscreen modeIn the first example, we first stringify the user object, and then immediately parse it back to JSON. The creates an entirely new object from the original one. While this works in many cases, it has some pretty severe drawbacks. One of the most notable issues with this method is that it doesn't handle non-serializable data correctly. If you had things like Functions, DOM Nodes, or Errors in your object, things wouldn't work out as you planned.Consider this simple example:const obj = {  update: () => console.log('update'),};const clone = JSON.parse(JSON.stringify(obj));console.log(clone); // {}Enter fullscreen modeExit fullscreen modeNotice how the clone is only an empty object. The update method on obj was not cloned over. This is one of the most notable issues with using this method to clone objects.The second example uses lodash's cloneDeep function. The downside here is that we're dependent on an external library. This means there is more code that has to be loaded to our app in order accomplish the task. Depending on your use case and requirements, this may be a deal breaker, or it may not be as big of a deal.structuredCloneFinally, let's play with the new hotness we've been gifted.Making a deep clone with structuredClone is very simple, just call it like any other function, passing in the object you want to clone.const clone = structuredClone(user);Enter fullscreen modeExit fullscreen modeSimple!We no longer have to import a third party library, and if something can't be cloned (like Functions) structuredClone will throw an exception letting us know!  Browser SupportMore good news, structuredClone is supported in the latest versions of the big 4 browsers (Chrome, Safari, Firefox, and Edge)! For older versions there's a polyfill available as well.MDN DocsCanIUse  ConclusionPhew, that was a lot! But we now understand the problems we used to have cloning objects (particularly complex objects) and how structuredClone is here to make our lives better!We also saw the difference between shallow and deep clones, the difference between accessing data by reference and by value, and how we used to have to create deep clones, as well as the downsides of those methods.Thanks for joining me, and until next time, Happy Hacking!"
93,"Going through the process of finding what's right for you can be one of the most daunting things. You may find yourself trying out several things before landing where you belong. Like anyone else, I went through this search. I stumbled upon web development and settled, at least for now.It took me a lot of research, experimenting, reading, and engaging with other web developers to make this critical decision. The process has been quite extensive, but I have enjoyed the process.After being in the process for two years, I now know why I became a web developer.  Who is a Web Developer?A skilled web developer crafts and brings to life captivating websites. A developer ensures the website is visually appealing, optimally functional, and easy to navigate by users. Web developers also ensure a website's functionality.There are three types of web developers. They are front-end developers, back-end developers, and full-stack developers.Front-end web developers specialize in the visual aspects of a website. They create the pages users see and interact with, commonly known as the user interface (UI). Back-end developers focus on building server-side applications and managing access points for people to manage a website's content. Full-stack developers do the work done by both front-end developers and back-end developers.  What Led Me to Choose a Path as a DeveloperUnknown to many, my primary career interest was in the Aviation industry. If anyone told me I would later work with computers or in the digital environment, I would have found that laughable.Aviation eluded me, and here is why my search ended when I discovered the exciting world of coding!  1. Coding is Challenging""How is this a motivation to learn to code?"" you may ask. I love a good challenge.In the world of coding, the learning journey is continuous. There's always something new to learn. Every day, new technologies and programming languages are constantly being developed. It is an opportunity to add to your knowledge and skills.When learning to code, my first project was based purely on HTML and CSS. I excitedly showed this project to everyone who knew I was learning to code. I thought I was ready to start applying for jobs. To my amazement, that was just the tip of the coding iceberg. Lying beneath the surface of the web development ocean was the core language of the web, JavaScript.The same thing happened when I learned the basics of JavaScript. I needed to grasp a front-end framework afterward and how to use web development tools and resources such as Git and GitHub. As if that was not enough, when I landed my first internship as a junior developer, the project I was working on required me to have NextJS and TypeScript knowledge on top of React. The first order of business was to learn these technologies.Coding has fostered in me a growth mindset. I have learned to see challenges as opportunities to grow. It has made me believe that there is no limit to what I can achieve.  2. It Satisfies my High Creative Drive.If you want a creative career path, then web development could be it. You can use your creativity skills to design and create page layouts that users enjoy navigating.Coding is a multifaceted discipline that combines the technical intricacies of Science and the creative allure of art. It allows you to use your imagination to 'breathe life' into something.Creativity was one of the main things that informed my pursuit of a career path. As a web developer, I have produced unique effects for websites, allowing me to create something beautiful.By learning to code, I joined the vast group of innovators who work to improve the now overly digitalized world.  3. Creative Problem-SolvingBesides being a creative venture, it is a creative process that requires out-of-the-box thinking to solve a problem.There are many ways to tackle a programming problem. Some solutions are more effective than others. I have learned to weigh the possible solutions I have at hand to choose the best.Coding has given me an endless opportunity to explore my creativity and come up with solutions to complex problems. I use this simple four-step method to solve programming problems. I critically analyze the issue from different angles and break it into smaller manageable pieces.The approach I used to learn code strengthened my problem-solving muscle. I learned through practically solving coding challenges, most of which modeled real-life problems that programmers solve daily in the real world.Creative problem-solving is part of coding. It often involves collaborating with others. Programmers may need to brainstorm with other team members to decide the best approach to tackling a problem.  4. Exposure to Multiple DisciplinesI conducted extensive research on web development and the tech world, and this is one of the things I came across that piqued my interest.Chief among the perks of becoming a web developer is the opportunity to work cross-functionally with various stakeholders. In your day-to-day life as a developer, you're likely to work with a UX designer, a UI designer, or a product manager, among others.Developers should work collaboratively with people of various backgrounds to create satisfactory products and solutions. That way, they create user-friendly solutions that run smoothly and meet customer needs.In my first role as a developer, I joined the marketing team as a content writer and strategist. I had worked as an article and blog post writer in the Real Estate niche for five years, so this wasn't such a leap. I didn't plan to pick up technical writing but developed the skill while working as a developer. I owe this to my thirst to learn new things. I just realized I had a knack for technical writing besides coding.If you are looking for a career with exposure to lots of business functions, web development could be a great fit.  5. A Sense of CommunityAs a web developer, you will never walk alone unless you've chosen to, in which case you won't succeed as a developer.There is an expansive web development community, and therein are supportive people. Countless Discord servers and Slack groups bring web developers together to chat and share ideas. They even help each other solve problems.The communities that built my developer skills include the Front-end Mentor Slack group. Being part of this community helped me improve my front-end skills by building real-world projects. I also joined an African tech community called SpaceYaTech, through which I networked with many developers and stakeholders in the tech industry. I recommend SpaceYaTech to anyone who wants to join an African open-source tech community.At every step in your web development journey, you will have a community of people who openly share ideas. These folks will keep you motivated and encourage your learning.  Final ThoughtsBesides the prospect of making large amounts of money, which is almost every aspiring developer's motivation, web development has several other perks.Coding can give you access to worldwide opportunities through remote work. Learning to code and working as a web developer can be fun. It's artistic and beautiful.To mention a few, I was motivated to become a developer since it presents the chance to be a creative problem solver. Coding has also exposed me to various disciplines and a pool of talented and highly motivated folks.Many resources are available to anyone who would like to learn coding. It is an excellent choice with numerous benefits."
94,"Hey, guys!If you are a frontend developer, developer or just passionate about cool websites and cool User Experience, you probably like animations!The animations can be just a simple fade button animation for example or something more interesting like and interactive 3D object made with Three.js (If you don't know it I advise you to know because it's amazing!)! We have a lot of possibilities animations, like the animations made with GSAP and today we'll talk about it, understand how it works and make some cool animations with it!  📚 What's is GSAP?GSAP is a powerful JavaScript library for making awesome animations with JavaScript! With this you can animate anything else and make cool animations in a simple and easy to understand way. GSAP offers a lot of plugins for you to make your animations and animate different things with different shapes, some plugins are:Flip PluginScrollTriggerMotionPathPlugin In this article we will talk and make some animations with the plugin ScrollTrigger. With each one you can find and make a different animation! There are other plugins available and you can find them here: GSAP List Plugins.  🛠 First steps to useWe need to do some steps to use GSAP in our applications, such as install, import gsap and the plugins and register the plugins, below we'll do these steps and configure our application to use it.  📌 Installation:You can install the GSAP with NPM or use it with CDN:NPMnpm install gsapEnter fullscreen modeExit fullscreen modeCDN<script src=""https://cdn.jsdelivr.net/npm/gsap@3.12/dist/gsap.min.js""></script>Enter fullscreen modeExit fullscreen modeTo use with CDN just insert this script inside the  tag of your project!This link has the most recent version of GSAP, be careful to use the most recent version according to the current moment  📌 Importation:We need to import the GSAP and the plugins we want to use, like below:// typical importimport gsap from ""gsap"";// get other plugins:import ScrollTrigger from ""gsap/ScrollTrigger"";import Flip from ""gsap/Flip"";import Draggable from ""gsap/Draggable"";// or all tools are exported from the ""all"" file (excluding members-only plugins):import { gsap, ScrollTrigger, Draggable, MotionPathPlugin } from ""gsap/all"";Enter fullscreen modeExit fullscreen modeIn our case we'll use the GSAP and ScrollTrigger plugin, so the imports and register will be as below:import { gsap } from 'gsap';import { ScrollTrigger } from 'gsap/ScrollTrigger';gsap.registerPlugin(ScrollTrigger);Enter fullscreen modeExit fullscreen mode  ⚙️ How it works?!GSAP is a generic object that offers several properties and methods to create and control animations with Tweens and Timelines (which basically are the main ones and are used a lot by GSAP). With that we need to understand what Tweens and Timelines are, so let's do this  📌 Tweens:Tween is what makes all the animation work, in it you can select any element you want to animate and with that you can implement animations in any property you want applying the effects according to the instructions applied with the methods.The most useful methods for making simple animations are:gsap.to()gsap.from()gsap.fromTo()In order not to extend too much on the subject and make it an extensive article to read, let's just focus on a few points and with that I recommend consulting the GSAP documentation, which is wonderful and complete.  📌 Timelines:Timeline is my favorite and as the documentation says it's powerful! With this you can create complex sequences of animations and make the animations beautiful, as it offers us simple ways to manipulate the ""timeline"" of animations with simple and easy to understand properties. Let's see an example:var tl = gsap.timeline({repeat: 2, repeatDelay: 1});tl.to("".elementSelector"", {rotation: 360, duration: 1});tl.to("".elementSelector"", {y: -20, opacity: 0, duration: 1});Enter fullscreen modeExit fullscreen modeAnd you can control the animation states like start(), pause(), restart(), rever() and some others in a very simplified form. See below how we can do it:tl.play();tl.pause();tl.resume();tl.reverse();Enter fullscreen modeExit fullscreen modeThere are other interesting methods available for use, you can see the list here: Timeline Methods  🕹 ExamplesNow, let's see some simple examples of how we can use GSAP and make our animations! I like to make simple animations in the examples because if we definitely understand how it works it's easier to make complex animations later and let our imagination take us where it's possible!Soo, let's do it 🤘  📌 Animated box:For this example, let's made a box animated! This animation we'll rotate, scale and change the background-color box, so the code will like bellow:let tl = gsap.timeline({  scrollTrigger: {    trigger: '.container',    start: 'top center', // when the top of the trigger hits the top of the viewport    end: '+=400', // end after scrolling 500px beyond the start    scrub: 1, // smooth scrubbing, takes 1 second to ""catch up"" to the scrollbar  },});// add animations and labels to the timelinetl.from('.box', {  backgroundColor: '#28a92b',  rotation: 360,  scale: 0,});Enter fullscreen modeExit fullscreen modeAnd bellow you can see the live demo:  📌 Animated TextsFor this example, Let's animate some text elements without using the ScrollTrigger, take a look:setupGsap(): void {    gsap      .timeline()      .to('.title0', {        duration: 0.8,        ease: 'back',        delay: 0.9,        scale: 7,        opacity: 0,        color: '#ffffff',      })      .from('.title1', {        duration: 0.8,        ease: 'back',        delay: 1,        x: 900,        opacity: 0,        color: '#feffa6',      })      .from('.title2', {        duration: 0.8,        x: -900,        ease: 'back',        delay: 1,        opacity: 0,        color: '#feffa6',      })      .from('.title3', {        duration: 0.8,        x: 900,        ease: 'back',        delay: 1,        opacity: 0,        color: '#feffa6',      });  }Enter fullscreen modeExit fullscreen modeAnd bellow you can see the live demo:  🎯 Understanding the code and How it works:  📌 How it works:As you can see, the animation will start when the .container element is centered compared to the top of the page. Because we specified start: ""top center"". Therefore, when the element passed in the trigger is in the center of the page, the animation will start. Below you can see an explanation of the image.  📌 Understanding the codeIf you notice, we always have a selector and after that an object, so to select our element that we want to animate, just do as below:// Remember, from is just one method of all that we can use!gsap .timeline()  .from('Your Selector Here', {      ...  }}Enter fullscreen modeExit fullscreen modeAnd now we can manipulate the available properties of our element and make the animation the way we want, like below:// Remember, from is just one method of all that we can use!gsap .timeline()  .from('Your Selector Here', {    opacity: 0,    scale: 0,    x: -500  }}Enter fullscreen modeExit fullscreen mode  ConclusionGSAP is a great and powerful tool to allow us to make websites with amazing animations! It's performative and in a simple way offers us several ways and plugins to make animations!I really like using it in projects I do and I hope that with this article you will feel more at ease with GSAP and with the will to start practicing and using it!Any questions, suggestions or anything else, please leave a comment! It will be a conversation!Thanks guys and see you soon 😄🤟"
95,Ruby's focus on developer happiness and productivity is often highlighted. How do you think this philosophy contributes to the success of Ruby in various projects?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
96,"Open Source thrives through shared efforts. Whether you're a newcomer or a veteran, we're here to encourage your contributions, motivate your endeavors, and provide valuable assistance to maintainers. Together, we are building amazing things!  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy contributing!"
97,"Hey everyone, the past few months have been pretty electric in terms of advancements in AI and actual/imagined changes to our workflow and industry.This is a regular open thread where everyone is encouraged to share...Notable news in the field of AIPersonal experiences and insightsConcerns and fearsSuccess stories and demosAnd any other related discussions you'd like to bring to the tableThis thread will go out every week.     "
98,"  TL;DRMy team and I recently launched an open source tool for developersThis was my first time promoting an open source tool. It was hard to find meaningful early-tage growth advice, so I had to get creative.We've quickly grown to more than 1.5k stars in a short time. I've compiled a detailed list of growth tactics that worked to bring us traffic and starsI’m sharing it all here so that others can apply these tactics and grow their own projects  Launching an open source project for the first timeAnyone involved in marketing knows that no two days are the same. You are constantly facing new challenges and unique situations.And so it was a few months back when I was tasked with promoting a new open source project that we built, called Preevy.I’ve spent years leading go to market efforts at various companies for dozens of products, but this was my first time doing so for an open source developer tool. Don't get me wrong - the devs on my team are seasoned OSS pros. But as the head of marketing, I was the open source newbie facing a learning curve. I looked at my lack of open source marketing experience as both an advantage and a disadvantage.On the one hand, I had a lot of catching up to do in a short period of time. On the other hand, it's always good when you can eliminate any preconceived notions of to how things ""should"" be done. I was free to research, question and develop a creative strategy with an open mind.  Writing the post I wish I found 6 months agoGoogle quickly dampened my initial wave of enthusiasm. I looked for good advice to accelerate my learning, but most of the early-stage, open source growth content was shallow at best. I read articles promising to show me “How to get your first 1k Github stars” but was repeatedly left without the clear, tactical direction I was looking for.The next couple of months became a whirlwind of research and experimentation to figure out what works and what doesn't.And today, 12 weeks after launching Preevy, the project has 1.5k GitHub stars, and we’re seeing a week-over-week increase in repository traffic, forks and contributions. There are several repeatable actions that have been effective in growing our traffic and our star count. In retrospect, some of them were buried in those generic ""How to"" articles, but most of them were not. Many of the creative steps we took (and continue to take) are lessons we learned the old-fashioned way.So in the spirit of true open source, I've outlined some of our most effective tactics in one place. It’s the kind of resource I wish I had found 6 months ago, and hopefully you will find this outline helpful as you launch and growing your own open source projects.  Focusing specifically on traffic GitHub starsTo be clear - my specific focus is to show you how I got traffic and GitHub stars for my project. I won’t be focusing on other (important) aspects of open source growth such as: converting visitors to active users, encouraging contributions to the project, best practices for repo maintenance, building a community around your project, or deciding what to build in the first place.These are all worthy topics, but for another time. For now, I only care about stars.  Why are GitHub stars so important?The underlying assumption here is that GitHub stars have value. But what exactly are they valuable for? Increasing your star count has several benefits clear and present benefits:It focuses the team's efforts and motivates everyone to rally around a single cause and a single metric that is constantly increasingStars = credibility and trustworthiness in the eyes of potential users and contributorsYour pool of stargazers can teach you a lot about your target audience Stars can help you reach GitHub trending status and a TON of visibility. (there are several factors that go into trending, but stars is an important one).So if you’re trying to promote your GitHub library, you should be thinking about how you can get more people to star it, especially in the first couple of months after you go live.So without further ado, let's take a deep dive into the key growth levers that worked for me and my team.  Prerequisites: Basic repo healthThe first thing I focused on was making sure our repository was set up for success. Those generic articles spend a lot of time on this, and like with any good cliche - there's a lot of truth to it. So we established a baseline for repo health that included:A clear description of what the tool doesA Readme that is both informative and aesthetically pleasing (screenshot/GIF at the top, clearly structured, use of some emojis to mix it up a bit). I also upgraded the social card that appeared when the repo is linked on social.A dedicated docs site with relevant technical information and how-to guides for people who want to use itI don't have a lot of wisdom to add here. Just make a best effort at communicating clearly in your documentation (without any fluff) and don't be afraid to iterate as needed.  Once we covered the basics for Preevy, we set our sights on brining attention to the tool we had built.From a bird's eye view, our GTM strategy had two ""phases"": Get our first 100 stars artificiallyMaintain natural growth from 100 stars and beyond  The first 100 stars - artificial growthWe wanted to get our first 100 stars quickly, so we started close to home. I assumed that between all of us on the team, we could find 100 relevant, first-degree connections willing to click a button and congratulate us on launching a new project.Here are the main actions that worked for us in this phase:  Kick-off message to friends and familyWe started simple. I composed a message announcing that we’ve just launched our first open source project, and asking people please check it out and show us support by leaving us a star. The message was simple and friendly, but also direct. Don't just reply with a thumbs up. Go to GitHub and give me a star (please). Each team member sent it out to people in their network: Relevant friends and family members, via email, Whatsapp, LinkedIn and Twitter DMs.  Ask the neighbors in our shared office spaceOur company office is in a shared workspace. Which means there are dozens of other startups and active GitHub accounts within a few meters of my desk. So I swallowed my pride, printed a QR code (to make it easy for others to open our repo on their device) and made a few causal rounds around the floor asking people if they could do us a quick favor and show us some GitHub-love. The vast majority of people were happy to help. My non-scientific assessment is that early morning had the best conversion rates, while people were still small-talking over coffee and before they got focused on their more serious daily tasks.   Show it off (for free) at conferencesIt just so happened that I attended a local tech conference shortly after Preevy launched. So I adapted  the shared office space strategy to the conference showroom floor. I walked around and tried to use my smalltalk opportunities to get a few more stars from the developers walking around.   First launch announcements on social mediaOnce we had a few dozen stars, I posted about our launch on our social channels. I wanted new visitors to the repository to see that at least a few dozen people had already been there and liked what we are doing. Pretty soon, we celebrated our first 100 stars milestone, and we were ready to move into phase 2.  Beyond the first 100I probably could have used the above tactics alone to get us to 500 stars or more, but it would have been inefficient, and regardless - I wasn’t interested in this approach. My phase 1 focus was only on the 100-star threshold so as to establish the minimal credibility needed to convert future traffic.Our first 100 stars were decidedly artificial. And I wanted all the rest to be authentic and organic.Organic stargazers tell you a lot about who is interested in your tool. Analyzing a growing list of stargazers gives you product and marketing insights that you need to move forward effectively. So it was important to me that our list of stargazers grow naturally, as soon as possible. Here’s what worked for us as we moved into growth phase 2:  Content creationContent creation and distribution was a big part of our strategy (and this continues to be the case). This topic alone deserves a dedicated blog post or two, but we’ll summarize the key elements here. As far as content creation, we set out to create an ongoing flow of blog posts. These posts fell into one of four categories:Present the tool directly - We wrote a number of posts that talk about Preevy directly. What it is, why we built it, who we think can benefit from it. These can be very effective when they are written in an authentic, human wayPresent the tool indirectly as part of a larger project - We wrote a number of “How-to” posts that show how to build a cool project, including Preevy as part of the stackListicles - We put together a few list-based articles that had an open source angle to them. “5 Projects that will help you learn [some framework]” or “10 new open source repositories you need to know about in 2023” or something similar. We included Preevy in the list when relevant, but not every time.Building in public - Open source is about sharing with others.  So we wrote  several posts explaining how we solved an interesting problem or how we achieved a relevant milestone (like this post, for example)Each post had clear section headings. We added a TL;DR at the top and emojis/GIFs to keep it friendly and fun to read. We mentioned explicitly that we are building Preevy and we’d appreciate it if people could check it out and star the repository. We phrased this in-line request in different ways (sometimes more directly than others), but we always found a way to put it in the body of the article as a clear call to action.  Content distributionWriting content is great, but it won't help you if you don’t have a good plan for distributing it to the relevant people. Here’s how we distributed our Preevy content:Dev-centric blogging platforms - We published our content on dev-centric blogging platforms like Dev.to, Hashnode, Hackernoon, and Medium. These are the main platforms we’ve been using, but there are others you might consider as well. When doing this, be mindful of any platform-specific tags you can use to better position your content (for example, DevTo has a #showdev tag that can help show your new tool off to other developers). Also note that on platforms like Dev.to, you can create a company blog with a fixed call to action that appears on the right side of any article you publish there. This helps to get more people clicking through from your content to your GitHub repository.Here's one of our posts trending on Dev.to: Reddit and social media - Once the content was published on the above platforms, we promoted it on social media and in relevant subreddits. We did not drive traffic to our company blog (we’ll get to that in a minute). Rather, we intentionally directed people to the articles hosted on these outside blogging platforms. We did this because each of these blogging platforms has a built-in trending algorithm that boosts high-performing posts. By driving traffic to these links, we got the platform algorithms to work for us and get our posts many more views in a short period of time.Our company blog - Don’t worry. We didn’t forget about our own site. We also published all content on our company blog. After all, SEO is still a thing, and so it’s good to have all that relevant content hosted on the company domain. As extra credit, we also managed to get our blog approved as a content source by dev-centric content aggregators like daily.dev. This helps us to distribute the content posted on our company’s blog, in addition to the content published on those external blogging sites.  Github Lists and TopicsThere are tons of great lists on GitHub (often called “Awesome Lists”) where maintainers aggregate tools, projects and resources with a particular focus. We found several lists relevant to our tool, and opened a pull request to suggest Preevy as an addition. Note that in some cases, you’ll need to make minor adjustments to your project or documentation to meet the list membership requirements. But this could be worth it if it's a popular list that has a lot of visitors.In addition to “Lists” which are privately maintained, GitHub also maintains “Topics”. Open source projects can be submitted for inclusion under a relevant topic, but only by someone who is not connected to the project in an official way. So if you have friends or early adopters of your tool who love what you’re doing, you might consider asking them for a favor and having them submit your project to a few of these GitHub ""Topics"".We’ve used both Lists and Topics to promote Preevy.  Other Sites and NewslettersWe found a number of sites and newsletters focused on promoting open source tools. We used these resources to promote Preevy. Here are two examples that were effective for us:GitHub20K - Add your library here for free (maintained by @nevodavid ) Console.dev - Submit your tool for free, or pay to sponsor a newsletter  Relevant communities and dark socialWe joined a bunch of communities. We wanted to be a part of relevant conversations, and promote our tool and our content in a more natural way. These communities exist on platforms such as: Slack, Discord, Reddit, Whatsapp, LinkedIn and Facebook. To find communities relevant to you, just spend a few minutes searching, or ask others in your industry to guide you towards the communities that are worth joining.We noticed that each community has its own rules, nuances and opportunities. For example, on a particular Slack or Discord server, there might be a channel dedicated to showing off new tools or promoting new content you’ve written. Similarly, many subreddits have one day per week where you can self-promote something you’ve built and get feedback. Once you've found some communities, make friends and play by the rules.   Paid ads campaignsOnce we generated a decent amount of organic traffic, we ran some small, paid ad campaigns. We used three advertising platforms:Ethical Ads (a dev-focused advertising platform)Reddit (with a focus on specific, technical subreddits)Twitter (with a focus on specific, relevant keywords)These campaigns brought us traffic, and they also allowed us to test our messaging and learn more about what attracted people to our repository. We used these results to further optimize our content and our future ad campaigns.  InfluencersInfluencer marketing can be very effective in any industry, and open source/developer tools is no different. The trick is to the right people with the right audience.We actively searched for those people in our industry, developed relationships and ran some collaborative experiments. The majority of them were successful (a few were not, which was expected).Each influencer knows their audience and their style. Be clear about your campaign objectives and work with them to create the content and campaigns that work best (co-created posts, product reviews, shout-outs on social or whatever else you all have in mind).   Podcasts and promotionsI’ll keep this one brief because it’s pretty self-explanatory. If you can find other people to promote you on their podcasts, webinars, conferences, or by allowing you to publish a guest blog to their site, it can help you get a lot of traffic quickly.  We were able to do this a couple of times for Preevy so far, and we’re already working on more of these opportunities.  Use cases and testimonialsBecause I’m active on dev-centric blogging platforms, I kept an eye out for dev bloggers who were experienced and well-versed in our space. I looked for high-performing articles and reached out to the authors to ask them if they wanted to try Preevy and write about it. Some wanted to be paid (rightfully so), and some (surprisingly) did not. Some wanted to ghostwrite for us (without using their name) and some wanted to publish content in their own name on their own pages.It took us some time to find the right people, but once we did, all of the above arrangements worked for us.    HackernewsWe used Hackernews to promote Preevy in two ways: Post the GitHub repository under the “Show HN” tag - Hackernews can be a great place to share your new project with other technical folks. It helps to get others to upvote and comment soon after posting (just don’t share the direct link to your post!). We added a first comment where our CTO explained what we built and inviting others to try it. I don’t know if this comment helped, but I saw a lot of other open source projects doing the same. And while I can’t say for sure, it seems like HN is friendlier to GitHub repository links as opposed to some branded URL. So with a bit of coordination, HN could give you a potent dose of traffic.Post content - We’ve tried posting some of our content on HN. Success is hit or miss, and HN will not even accept posts from some external blogging platforms. But it’s free to try and the potential upside is huge.  Social media retargetingFrom the moment we formally announced the Preevy launch, we had organic social media activity running in the background. We'll save the detailed social media strategy for another post, but suffice it to say that the account was active and the content was varied. As more people engaged with the content, I began retargeting as many of them as possible by inviting them to try/star Preevy for themselves. I had Twitter DM template that I would send them, thanking them for linking our recent post and asking if they’d be willing to star the Preevy repo. It took time, but lots of people were happy to help.  Shamelessly promote other people and projectsWhen I outlined my approach to “content creation” above, I mentioned that one types of content we’ve produced are listicles of other relevant projects or tools. One of the reasons this content is so effective is that is enables us to shamelessly promote other people. Open source is not a zero-sum game. There’s enough traffic and enough GitHub stars to go around. And by genuinely promoting other people, companies and projects, you can get them to promote you in return. it’s almost like a “forced” collaboration and it’s often a win-win.So for example, when we wrote listicles that included other open source projects, we tagged these companies/maintainers on Twitter when we promoted the article. Many time, they would like and retweet, adding a lot more reach to our content. This approach can be applied in many different ways, but it’s potent enough to deserve a dedicated mention in our list of open source GTM actions.  My (crazy) Github retargeting experimentOnce we reached a few hundred stargazers, I analyzed the modest audience I had built. I developed an experimental, multi-part playbook for promoting Preevy in a more targeted way to people who were more likely to be interested in it. Here’s a quick summary of what I came up with:I used tools (such at this one and this one) to see what other repos our stargazers were starring most frequently. The stargazers of these ""other"" commonly starred repos became an expanded pool of potential stargazers for PreevyI looked through the stargazers in these other repos and identified people who had publicly exposed email addresses in their GitHub profiles. To me, this was a clue that they didn’t mind being contacted via emailI further identified the people who I thought were most relevant and followed them on GitHubThen, I reached out to these folks via email, told them I had just followed them and introduced myself and my project in case they were interested to check it out.The last two steps were just my personal spin. You can probably do without them. The main idea is to use your pool of authentic stargazers to point you in the direction of a wider pool of similar users who might be interested in what you have to offer.As a bonus, you can also look at what those most commonly starred repositories are doing to market their tools, and try some of it yourself.  Celebrate milestones!We took every opportunity to celebrate a milestone in our Preevy growth journey. Every hundred star milestone got a celebratory GIF and a set of posts to drive as much positive attention to the repository as possible.And when we missed celebrating 700, we celebrated 735 instead (because it’s good to be different sometimes).And when we hit the 1k star milestone, we kicked off a celebratory giveaway (which is actually still open until the end of this week). To enter, people need to star the repo, follow us on Twitter and retweet/tag 3 friends.   Other ideas to considerThese are the ideas that worked best for us to far, that can easily be applied to other projects. We had tons of other ideas that didn't work as well, or that worked but were very specific to what we were building.We have a bunch of experiments still to consider and in the spirit of open source, I'll share a couple of them here for your consideration:- Translate the readme into multiple languages - At the moment, the Preevy readme is in English. But I’ve noticed that in the GitHub trending lists, you can filter by spoken language. I wonder if translating our readme into other languages will create a larger surface area for the repository to hit those trending lists with more frequency- Product Hunt - We’ll soon be launching Preevy on Product Hunt. It’s a great place to launch new products and tools and we’re looking forward to leveraging it’s reach to bring a lot more attention to what we’re building.  In conclusionI hope our experience in starting to grow Preevy can help you grow your own project - by borrowing some of these ideas or by thinking of new ideas on your own.I'd be thrilled to get additional open source growth suggestions in the comments!And if you've made it this far, and are willing to leave Preevy a star I'd really appreciate it! https://github.com/livecycle/preevy 🙏 🙏"
99,"Entrepreneur.It's either orange Lamborghinis and the three-comma club... or risking it all, losing everything, and having to start over, right?Like anything, the extremes tend to get all the attention. But here, the extremes are polarizing. The upside might be so attractive that to some, it's worth risking it all... or the downside might be so fear-inducing that for others, it prevents any risk at all. Even the definition of entrepreneur feels heavy: a person who organizes and operates a business or businesses, taking on greater than normal financial risks in order to do so.Here's the thing, though... as developers, we have an insane skillset that allows us an opportunity that is frankly unfair. Entrepreneurs outside of tech often have to coordinate fundraising, massive expenses in both labor and equipment, and delivering value to customers. But, in tech, as devs? We just need a laptop and internet. We get to dream up something that doesn't yet exist and manifest it into existence by typing on the keyboard. What?! But what about the rest of the stuff involved in running a business? The market analysis? The marketing? The sales? The leadership?  The Shift in Mindset: Coders vs. CreatorsRemember the times we got the tests to go green after a refactor? Or what about setting up the infrastructure just right so that it seamlessly scaled in and out based on traffic demands? Or when the interaction animation felt just right?You already know the challenges in piecing together a complex puzzle. Trying different things. Checking the fit. Changing the approach if something doesn't work. As an entrepreneur, the size of the puzzle just becomes a bit bigger and the pieces are a bit different. But the mindset is pretty similar!  Challenges: It's Not Just About Debugging AnymoreWhat about that market analysis thing? It's a fancy term that effectively means, ""Do you have a customer?""More formally, an analyst would look at a market and identify the gaps, understand customer needs, and position your product just right.For you, you're just looking for a customer. One. Someone who validates that the value you provide is worth compensation. That customer might be you, solving your own problem! It might be Susan next door who needs an easy way to manage her sprinklers from her phone. It might be Raj on the other side of the planet who needs a way to automate his pizza oven. It might even be every developer in the world who needs yet another app launcher. And financials. Yes. You need to be frugal. That's it. Are you bringing in more than you're spending? Great! If you're running the show yourself by yourself, that's really all you need to know.Budgeting, fundraising, profit and loss, forecasting. They're important if you decide to scale up & out... and it can get really weird, really quick with EBITA, revenue recognition, depreciation, on and on. You don't need to deal with this up-front. Get that first customer!Oof, and hiring a team... Yea. But, as a developer, you probably don't need to hire until after you want to. Once you decide to scale, make sure you hire the right talent, nurture the team, and manage conflicts effectively. We can stay small if we want to!Overall, it's possible to reduce the risk to near zero and the downside might even be just some lost time. And even then, you know what? You learned something. Chalk it up to active learning, and you get a portfolio piece!  Skill Development: Wearing the Many HatsThis is the core win for me. Many hats allow for the multidimensionality that keeps the path interesting.Leadership: On the typical path, we'd have to figure out how to build authority and ""lead from below."" After years, we might get an opportunity to be in a leadership position on anything. When you're running the show, you get to choose. And the feedback cycle is very quick. Tons of opportunity to learn.Networking: Connect with customers. Do a great job. Their networks will magically open up to you. The normal advice I hear is, ""Go chat up industry leaders, potential investors, and mentors."" Okay. That's super vague, how would someone do that? If you're operating under the premise of a business, the conversations with potential clients become much easier to reason about and navigate successfully. Decision-making: Sometimes, it's on a tightrope. With limited data and looming deadlines that YOU promised a client, you get to make choices that can make (or set back) your little business. Reflecting on your decisions and learning from the good and the, let's say, not-so-good gives you an immense amount of experience that you wouldn't get otherwise!Sales & Marketing & everything else outside of dev: From pitching your idea to promoting your products, you get to learn a little bit about everything. This allows you to hold your own in conversations with other departments and have a ton more empathy toward their challenges. Resilience: All that opportunity for skill development means that you'll suck at a whole lot of new stuff! How cool is that? It comes with learning anything new. Embrace the suck. Work through the suck. On the other side? You'll get to be good at a whole lot of things and great at a few.   Tips to Navigate the WatersContinuous Learning: You're already doing this if you're taking your career seriously. Just like learning more about programming and keeping up with advancements in our stack, entrepreneurship requires its own set of continuous learning. Books, courses, seminars – the arsenal is vast. The resources are endless for the curious.Stay Passionate: Remember that spark that led you down this path? Hold onto it. It’s your north star during the darkest nights. And, give yourself a break. You've (hopefully) de-risked to the point where it's okay if you need to take a minute. Come on back to it when you've rested up.Keep Coding: Even as you manage, lead, and create, take time to dive back into code. It keeps you connected, grounded, and after all, it's where it all began. Careful not to hide here, though. It's easy fool yourself into believing that ""if you build it, they will come."" If you're not careful, it'll be another one of those lessons learned the hard way that builds up your resilience.Build in public: Communicate your challenges and successes. It's amazing to see a community that self-organizes around folks who share their learnings.Find a Mentor or Mastermind group: Find someone or some folks who've been there, done that. Their insights will be invaluable. Don't even pretend to delegate your responsibility, though. On the entrepreneurial path, the buck stops with you.  The Entrepreneurial VoyageThis transition might seem like a leap of faith, but look: every line of code you ever wrote was a step towards this. Those challenges you faced, the bugs you squashed, and the projects you brought to life – they were all part of the training ground.From passion projects to side hustles, and now to entrepreneurship, the path has been winding, exhilarating, and sometimes covered by hurdles. But we've always been problem solvers, and this? This is just another challenge.Being a tech entrepreneur isn't about leaving coding behind. It's about leveraging it, amplifying it, and weaving it into your business.The compass might have a mind of its own at times, the maps might be blurry, but the destination? It's worth the challenge.Find the rhythm and balance. Have fun with it."
100,"What is a REST APISuppose you have gone to a restaurant and who do you ask to bring you food or pay the bill or you want something in your food to be changed, you don't directly go to the chef or the manager of the restaurant, you call the waiter and he takes your orders and acts according to it. Here waiter is acting as a medium between you and the restaurant.Now think of the restaurant as a server and think of you as a client who wants to get some data from any server how do you get that data?? We use APIs for these interactions.Now the official definition according to your beloved Chatgpt -- API stands for Application Programming Interface. It is a set of rules and protocols that allows different software applications to communicate and interact with each other.So up until now, we have understood what is an API but then what in the world is REST API?REST APIs are the ones that specifically follow the principle of REST architecture style, it is mainly based on designing web services. Well if you didn't understand this just remember that REST APIs are primarily used with the HTTP protocol and are designed for transferring data between clients and servers. The data exchanged during this interaction is commonly referred to as a resource, so throughout this blog, I will use the term 'resource' instead of 'data'. Resources are generally transferred in JSON format as it is most widely used and easy to interact on the frontend side via js.A representation is referred to as the format or structure of a resource, A resource can have many representations for ex:- the data on the server side would be in another format like in SQL/NoSQL, and the same data is transferred in JSON format to the client side.APIs work on the basis of the request-response modelVarious Uses of RESTSo we have understood what is a REST API in theoretical terms now let's look at the practical side of it.In these requests, we don't mention exactly what we have to do inside our URL these two requests have the same URL but one is for getting the data from the server and the other is to create a new document inside the database.REST APIs are used for interaction via HTTP protocol there are different methods to interact with the server, you might want to get some data or update/delete something. These are some reasons for using REST APIsThere are different methods of HTTP by which you can use REST API:-Let's learn them one by one1 ) GETGet is used for getting some resources from the server, the GET method can be used for getting all the data to some specific data. To retrieve specific data, we utilize endpoints within the URL and include path and query parameters.We have used several technical terms, so let's take a moment to define them.1 Endpoints - API endpoints, also known as URL endpoints or simply endpoints, are specific URLs (Uniform Resource Locators) or routes that represent distinct resources or functionalities exposed by an API. Endpoints define the entry points or access points to interact with the API and perform various operations.2 Path Parameter - Also known as route parameter it is used within the API endpoints that help in dynamic/variable values to be passed as part of URL.3 Query Parameter - A query parameter is a component of a URL that is used to provide additional information or parameters to an API endpoint. Query parameters are appended to the end of a URL with a question mark ""?"" and are typically in the form of key-value pairs.We have understood what get API (ps - everything you type in the URL is always a GET request, you can't make any other method request to the server from the URL) is but what does the request look likeHere localhost:8000 -- is a domain name and after that all that is path parameters, if you are wondering what tool is this it is ""postman""2) POSTPost request is used to send data to a server to create or add any new entity to the database, for ex - if you visit ""Youtube"" you will have to sign up for this the frontend side of your application has to send a post request to the server of youtube to register your details in their database.A Post request has a body as you will be sending some data to the server in this case for signup you might be sharing your name, username, email Id, and password.3) PUT / PATCHA Put and Patch request is used to update the data inside the database the difference between these two is that in a Patch request you only have to send the attributes you want to update, and in a Put request you have to send the entire object you want to update.4) DELETEAs the name suggests a Delete request is made to delete something from the database, the delete request requires a query parameter with the unique id of the object the user wants to delete.Thanks for reading this blog.If you find this post exciting, find more exciting posts on Learnhub Blog; we write everything tech from Cloud computing to Frontend Dev, Cybersecurity, AI, and Blockchain.This article was written by Ankur Sharma."
101,"Heyo folks! Sloan, DEV Moderator and resident mascot, back with another question sent in from a DEV community member. 🦥For those unfamiliar with the series, this is another installment of Sloan's Inbox. You all send in your questions, I ask them on your behalf anonymously, and the community hops in to offer advice. Whether it's career development, office politics, industry trends, or improving technical skills, we cover all sorts of topics here. If you want to send in a question or talking point to be shared anonymously via Sloan, that's awesome; just scroll down to the bottom of the post for details on how.So, let's get down to business...  Today's question is:I've been at the same company for quite a while now. I'm comfortable — the job pays well, the workload is reasonable, and I really like my colleagues — but, I've been feeling bored. I'm wondering if this is a sign that I should move on to something else? Do I just need to take some time to myself and recharge? Is boredom a justifiable reason to leave a place that otherwise fits all my needs? How should I approach talking about this with my manager?Share your thoughts and lets help a fellow DEV member out! Remember to keep kind and stay classy. 💚Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
102,"This week we're chatting all things remote work, and we want to hear from you about your experiences, pros, cons, and advice for those transitioning or considering remote work options.Let's dive into today's topic of conversation... How do you structure your daily schedule to make the most of remote work flexibility?Share techniques for setting boundaries between work and personal life to avoid burnout and any time management tools or strategies do you find helpful in optimizing productivity?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
103,"Last night, I was scrolling through twitter and I found a interesting JavaScript question, and I bet you won't be able to answer this without cheating.Let's see how long would would it take for you to answer this one:  What does (""b"" + ""a"" + + ""a"" + ""a"").toLowerCase() output in JavaScript?The question does look simple, but the answer will definitely blow your mind.Tell me how long it took you to answer in the comments.And Yes, JavaScript is crazy!"
104,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
105,"Hi friends 👋,As we know, open source encourages open collaboration among contributors and maintainers. And collaboration requires good communication. Mostly, communication in open source happens asynchronously because of its remote environment. But there are also times when it occurs synchronously. I want to share how to communicate remotely in this article, especially in open source.  Asynchrounous CommunicationAsynchronous (async) communication is a type of communication with a lag of time in sharing and receiving information and responses between recipients, for example, in writing conversations.  ToolsMost of the communication in open source happens on GitHub (or any other similar platform). It could be through the issue and pull request comments or via the organization's GitHub discussion board. Some organizations also provide chat services such as Slack or Discord for their community to communicate asynchronously.  Essential Things in Async Communication  Don't make assumptionsWhen you have doubts or need more clarification, ask questions and don't make assumptions. Async communication, more often than not, can lead to misunderstanding because writing is different from speaking. And in an international community, cultural and language backgrounds also play a role in a loss in translations.  Keep transparencyIn open source, you want to keep open communication and be transparent. That means you better use the comments and discussion board on GitHub or threads on chat service apps rather than direct messages whenever you want to share information or ask about something. This transparency is beneficial for the community to follow the threads, know what's going on, and help out when necessary.  Effective communicationYou want to keep effective communication through clear and short messages. Consider this when committing your changes, creating issues, making pull requests, and writing comments on GitHub. It also applies to conversations on chat service apps. That way, others can easily understand your purpose. Consider also different cultures and languages background; you want to use words with explicit meanings because not everyone understands specific cultural sayings, etc.  Timezone differencesIn a remote environment, timezone plays one of the significant roles. It is daylight at your place, but it might be midnight in other parts of the world.Therefore, don't use the channel or here tags when asking questions in the chat service apps. Doing so will notify everyone in the app, which is disturbing, especially when it is not an important announcement for the community. These tags are usually only used by the maintainers or people who the maintainers already grant permission.You can also take the initiative to turn off your notifications at particular hours. Some chat service apps have the setting to do so.  Have patienceMost open-source projects are volunteer-based. Contributions and maintainers collaborate at their convenience times. So both sides should have patience in collaborating. When you ask questions, you cannot rush the maintainers to answer them immediately, and vice versa. Both sides should have reasonable expectations that are best discussed from the beginning.  Synchrounous CommunicationSynchronous (sync) communication is a type of communication that happens in real-time, for example, in-person conversation or remote meeting conversation.  ToolsThere are times when collaborators need to pair synchronously on a remote meeting app such as Zoom, GoogleMeet, etc.  Essential Things in Sync Communication  Active listeningIn sync communication, active listening plays an important role. Who doesn't like to be heard and feel appreciated? Don't hear what the other person is saying while preparing your answer. Doing so will distract you and make you miss something they've said. It would be best if you understood their intention fully. You want to pay attention to what they say and their body language. Active listening means being fully present, showing interest in the topics, and engaging actively without judgment in a conversation.  Have empathy and be respectfulSometimes, people need time to think about what to say. One of the reasons — especially in an international community — is that not everyone is fluent in English, amongst other reasons. Whatever the reason is, you want to be empathetic and respectful. Give them space and time to think about what they want to say without interrupting unless they ask. And you can always ask for clarification if you don't understand something they say rather than assuming.There also can be a day you have a disagreement leading to a debate. Don't let this escalate to negative criticism and disrespect. You always want to keep a healthy conversation.  Appreciate others timeWhen you make an appointment for a sync meeting, you always want to respect other collaborators' time. Be there a few minutes before the agreed time. If you will be there late or something urgent happens and you can't even come, don't wait to tell the other person that you can't make it. You don't want to make them wait for you. Their time is as valuable as yours.  Final WordsCommunication is a skill that you can learn through continuous practice. And good communication leads to positive conversations and relationships.Most communication in open source happens asynchronously through writing. And written conversation is different from verbal. It is prone to misunderstanding. So it is essential always to use empathy and be respectful in communicating. It applies to both sync and async communication.🖼️ Credit cover image: unDrawThank you for reading! Last, you can find me on Twitter, Mastodon, and BlueSky. Let's connect! 😊"
106,"Writing is the secret sauce that not only amplifies your skills but also the external knowledge of your skills.It clarifies your thinking, lights the path for your team, and bridges the gap between engineering and business.Writing can do more than create code; it can persuade, inform, encourage, and inspire.It's worth practicing in its own right.  Clarify Your ThoughtsEver been stuck in a mental maze, trying to wrangle a problem like an uncooperative octopus? Yeah, we've all been there. Coding can feel like an endless loop of confusion at times. However, writing can be your trusty problem-solving sidekick. Think of writing as a kind of dialogue you're having with yourself, like rubber ducking, but on paper (or screen). It's a way for your brain to untangle the neurons and make sense of the chaos. Writing forces you to slow down, take a breath, and really think through your ideas. It's like parking your racing thoughts in neat little garages.It helps you spot inconsistencies, gaps, and dead ends in your thinking. You ever re-read something you've written and thought, ""What was I even trying to say here?"" Yup. That's the point.Writing down your thoughts crystallizes them, making them more tangible and manageable. It's like turning fog into ice cubes. You can handle them, rearrange them, even toss them out if they're not doing you any good.  A Lifeline for TeammatesIn complex code, comments serve as lighthouses, guiding fellow devs through the intricacies of the implemented logic. These written notes explain the 'why' behind certain code choices, offer context for future developers, and sometimes, serve as warnings against potential pitfalls. Well-written (and maintained) documentation, code, and comments reduce the learning curve for new team members and ensure that the code's original intent is preserved even as the codebase evolves.Sigh - remember the telephone game? Sitting in a circle, each person whispers the message to the next, and by the time it reaches the last person, the message no longer even remotely resembles the original. The same can happen with code. Sure, good code is self-documenting. But, when there's an opportunity to add clarity, we should take it.Writing docs and commenting code is like planting trees. Sure, you might not enjoy the shade, but someone else surely will. The trouble with this analogy is in the forest of code, the trees grow quickly... and the next developer who revisits the code could be you revisiting your own code in six months, wondering what on earth you were thinking. For yourself and your team, always leave a note.  Bridge the Engineering/Business GapWriting has the power to break down the walls between the engineering world, often viewed as a cryptic land of code, and the business domain, which thrives on clear, concise communication. For developers, the ability to articulate complex ideas through writing can be a game-changer. You might be a pro at creating elegant solutions, but if you can't convey that elegance in a way that everyone, from the project manager to the sales team, can understand, your skills might not get the recognition they deserve. ""The single biggest problem in communication is the illusion that it has taken place."" - George Bernard ShawShaw got it right. Communication is key. But how can you, as a developer, use writing to bridge this gap?We need to be able to articulate technical constraints to stakeholders, propose solutions to business teams, or explain the implications of certain technological decisions. Imagine how useful it would be for a developer to craft concise, jargon-free, and persuasive documents. They'd be able to seamlessly connect the worlds of engineering and business, ensuring that both sides are aligned in their goals!  Persuade, Inform, Encourage, InspireOutside the confines of code, developers have stories to tell, experiences to share, and knowledge to convey.Whether it's writing a tech blog, penning an op-ed about ethical tech, or drafting a proposal for a new project, the act of writing amplifies a developer's voice.Well-written content can persuade stakeholders, inform the community, encourage peers, and inspire the next generation of coders.In essence, through writing, developers can transcend their immediate roles and make meaningful contributions to the broader tech community.What are you waiting for?"
107,"Hey everybody 👋Hope that y'all all have wonderful weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugWalking the dog 🦮"
108,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers!🏫 Imagine a school where coding was a mandatory subject. How would that have changed your learning experience?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
109,"  TL;DRWebSockets allow your app to have “real time” features, where updates are instant because they’re passed on an open, two-way channel. This is different from CRUD apps, which usually use HTTP requests that must establish a connection, send a request, receive a response, and then close the connection.To use WebSockets in your React app, you’ll need a dedicated server, such as an ExpressJS app with NodeJS, in order to maintain a persistent connection.Unfortunately, serverless solutions (e.g. NextJS, AWS lambda) don’t natively support WebSockets. Bummer. 😞 Why not? Well, serverless services turn on and off depending on if a request is coming in. With WebSockets, we need this “always on” connection that only a dedicated server can provide (although you can pay for third-party services as a workaround).Luckily, we’re going to talk about two great ways you can implement WebSockets:Implementing and configuring it yourself with React, NodeJS, and Socket.IOBy using Wasp, a full-stack React-NodeJS framework, to configure and integrate Socket.IO into your app for you.These methods allow you to build fun stuff, like this instantly updating “voting with friends” app we built here (check out the GitHub repo for it):  Before We BeginWe’re working hard to help you build performant web apps as easily as possible — including creating content like this, which is released weekly!We would be super grateful if you could support us by starring our repo on GitHub: https://www.github.com/wasp-lang/wasp 🙏FYI, Wasp = } is the only open-source, completely serverful fullstack React/Node framework with a built-in compiler and AI-assisted features that lets you build your app super quickly. even Ron would star Wasp on GitHub 🤩  Why WebSockets?So, imagine you're at a party sending text messages to a friend to tell them what food to bring. Now, wouldn’t it be easier if you called your friend on the phone so you could talk constantly,  instead of sending sporadic messages? That's pretty much what WebSockets are in the world of web applications. For example, traditional HTTP requests (e.g. CRUD/RESTful) are like those text messages — your app has to ask the server every time it wants new information, just like you had to send a text message to your friend every time you thought of food for your party. But with WebSockets, once a connection is established, it remains open for constant, two-way communication, so the server can send new information to your app the instant it becomes available, even if the client didn’t ask for it. This is perfect for real-time applications like chat apps, game servers, or when you're keeping track of stock prices. For example, apps like Google Docs, Slack, WhatsApp, Uber, Zoom, and Robinhood all use WebSockets to power their real-time communication features.So remember, when your app and server have a lot to talk about, go for WebSockets and let the conversation flow freely!  How WebSockets WorkIf you want real-time capabilities in your app, you don’t always need WebSockets. You can implement similar functionality by using resource-heavy processes, such as:long-polling, e.g. running setInterval to periodically hit the server and check for updates.one-way “server-sent events”, e.g. keeping a unidirectional server-to-client connection open to receive new updates from the server only.WebSockets, on the other hand, provide a two-way (aka “full-duplex”) communication channel between the client and server. As the image above shows, once a connection is established via an HTTP “handshake”, the server and client can freely exchange information instantly before the connection is finally closed by either side.Although introducing WebSockets does add complexity due to asynchronous and event-driven components, choosing the right libraries and frameworks can make it easy.In the sections below, we will show you two ways to implement WebSockets into a React-NodeJS app:Configuring it yourself alongside your own standalone Node/ExpressJS serverLetting Wasp, a full-stack framework with superpowers, easily configure it for you  Adding WebSockets Support in a React-NodeJS App  What You Shouldn’t Use: Serverless ArchitectureBut first, here’s a “heads up” for you: despite being a great solution for certain use-cases, serverless solutions are not the right tool for this job.That means, popular frameworks and infrastructure, like NextJS and AWS Lambda, do not support WebSockets integration out-of-the-box. Instead of running on a dedicated, traditional server, such solutions utilize serverless functions (also known as lambda functions), which are designed to execute and complete a task as soon as a request comes in. It’s as if they “turn on” when the request comes in, and then “turn off” once it’s completed.This serverless architecture is not ideal for keeping a WebSocket connection alive because we want a persistent, “always-on” connection.That’s why you need a “serverful” architecture if you want to build real-time apps. And although there is a workaround to getting WebSockets on a serverless architecture, like using third-party services, this has a number of drawbacks:Cost: these services exist as subscriptions and can get costly as your app scalesLimited Customization: you’re using a pre-built solution, so you have less controlDebugging: fixing errors gets more difficult, as your app is not running locally💪  Using ExpressJS with Socket.IO  — Complex/Customizable MethodOkay, let's start with the first, more traditional approach: creating a dedicated server for your client to establish a two-way communication channel with.👨‍💻 TIP: If you want to code along you can follow the instructions below. Alternatively, if you just want to see the finished React-NodeJS full-stack app, check out the github repo hereIn this exampple, we’ll be using ExpressJS with the Socket.IO library. Although there are others out there, Socket.IO is a great library that makes working with WebSockets in NodeJS easier.If you want to code along, first clone the start branch:git clone --branch start https://github.com/vincanger/websockets-react.gitEnter fullscreen modeExit fullscreen modeYou’ll notice that inside we have two folders:📁 ws-client for our React app📁 ws-server for our ExpressJS/NodeJS serverLet’s cd into the server folder and install the dependencies:cd ws-server && npm installEnter fullscreen modeExit fullscreen modeWe also need to install the types for working with typescript:npm i --save-dev @types/corsEnter fullscreen modeExit fullscreen modeNow run the server, using the npm start command in your terminal. You should see listening on *:8000 printed to the console!At the moment, this is what our index.ts file looks like:import cors from 'cors';import express from 'express';const app = express();app.use(cors({ origin: '*' }));const server = require('http').createServer(app);app.get('/', (req, res) => {  res.send(`<h1>Hello World</h1>`);});server.listen(8000, () => {  console.log('listening on *:8000');});Enter fullscreen modeExit fullscreen modeThere’s not much going on here, so let’s install the Socket.IO package and start adding WebSockets to our server!First, let’s kill the server with ctrl + c and then run:npm install socket.ioEnter fullscreen modeExit fullscreen modeLet’s go ahead and replace the index.ts file with the following code. I know it’s a lot of code, so I’ve left a bunch of comments that explain what’s going on ;):import cors from 'cors';import express from 'express';import { Server, Socket } from 'socket.io';type PollState = {  question: string;  options: {    id: number;    text: string;    description: string;    votes: string[];  }[];};interface ClientToServerEvents {  vote: (optionId: number) => void;  askForStateUpdate: () => void;}interface ServerToClientEvents {  updateState: (state: PollState) => void;}interface InterServerEvents { }interface SocketData {  user: string;}const app = express();app.use(cors({ origin: 'http://localhost:5173' })); // this is the default port that Vite runs your React app onconst server = require('http').createServer(app);// passing these generic type parameters to the `Server` class// ensures data flowing through the server are correctly typed.const io = new Server<  ClientToServerEvents,  ServerToClientEvents,  InterServerEvents,  SocketData>(server, {  cors: {    origin: 'http://localhost:5173',    methods: ['GET', 'POST'],  },});// this is middleware that Socket.IO uses on initiliazation to add// the authenticated user to the socket instance. Note: we are not// actually adding real auth as this is beyond the scope of the tutorialio.use(addUserToSocketDataIfAuthenticated);// the client will pass an auth ""token"" (in this simple case, just the username)// to the server on initialize of the Socket.IO client in our React Appasync function addUserToSocketDataIfAuthenticated(socket: Socket, next: (err?: Error) => void) {  const user = socket.handshake.auth.token;  if (user) {    try {      socket.data = { ...socket.data, user: user };    } catch (err) {}  }  next();}// the server determines the PollState object, i.e. what users will vote on// this will be sent to the client and displayed on the front-endconst poll: PollState = {  question: ""What are eating for lunch ✨ Let's order"",  options: [    {      id: 1,      text: 'Party Pizza Place',      description: 'Best pizza in town',      votes: [],    },    {      id: 2,      text: 'Best Burger Joint',      description: 'Best burger in town',      votes: [],    },    {      id: 3,      text: 'Sus Sushi Place',      description: 'Best sushi in town',      votes: [],    },  ],};io.on('connection', (socket) => {  console.log('a user connected', socket.data.user);    // the client will send an 'askForStateUpdate' request on mount    // to get the initial state of the poll  socket.on('askForStateUpdate', () => {    console.log('client asked For State Update');    socket.emit('updateState', poll);  });  socket.on('vote', (optionId: number) => {    // If user has already voted, remove their vote.    poll.options.forEach((option) => {      option.votes = option.votes.filter((user) => user !== socket.data.user);    });    // And then add their vote to the new option.    const option = poll.options.find((o) => o.id === optionId);    if (!option) {      return;    }    option.votes.push(socket.data.user);        // Send the updated PollState back to all clients    io.emit('updateState', poll);  });  socket.on('disconnect', () => {    console.log('user disconnected');  });});server.listen(8000, () => {  console.log('listening on *:8000');});Enter fullscreen modeExit fullscreen modeGreat, start the server again with npm start and let’s add the Socket.IO client to the front-end.cd into the ws-client directory and runcd ../ws-client && npm installEnter fullscreen modeExit fullscreen modeNext, start the development server with npm run dev and you should see the hardcoded starter app in your browser:You may have noticed that poll does not match the PollState from our server. We need to install the Socket.IO client and set it all up in order start our real-time communication and get the correct poll from the server.Go ahead and kill the development server with ctrl + c and run:npm install socket.io-clientEnter fullscreen modeExit fullscreen modeNow let’s create a hook that initializes and returns our WebSocket client after it establishes a connection. To do that, create a new file in ./ws-client/src called useSocket.ts:import { useState, useEffect } from 'react';import socketIOClient, { Socket } from 'socket.io-client';export type PollState = {  question: string;  options: {    id: number;    text: string;    description: string;    votes: string[];  }[];};interface ServerToClientEvents {  updateState: (state: PollState) => void;}interface ClientToServerEvents {  vote: (optionId: number) => void;  askForStateUpdate: () => void;}export function useSocket({endpoint, token } : { endpoint: string, token: string }) {  // initialize the client using the server endpoint, e.g. localhost:8000    // and set the auth ""token"" (in our case we're simply passing the username    // for simplicity -- you would not do this in production!)    // also make sure to use the Socket generic types in the reverse order of the server!    const socket: Socket<ServerToClientEvents, ClientToServerEvents>  = socketIOClient(endpoint,  {    auth: {      token: token    }  })   const [isConnected, setIsConnected] = useState(false);  useEffect(() => {    console.log('useSocket useEffect', endpoint, socket)    function onConnect() {      setIsConnected(true)    }    function onDisconnect() {      setIsConnected(false)    }    socket.on('connect', onConnect)    socket.on('disconnect', onDisconnect)    return () => {      socket.off('connect', onConnect)      socket.off('disconnect', onDisconnect)    }  }, [token]);    // we return the socket client instance and the connection state  return {    isConnected,    socket,  };}Enter fullscreen modeExit fullscreen modeNow let’s go back to our main App.tsx page and replace it with the following code (again I’ve left comments to explain):import { useState, useMemo, useEffect } from 'react';import { Layout } from './Layout';import { Button, Card } from 'flowbite-react';import { useSocket } from './useSocket';import type { PollState } from './useSocket';const App = () => {    // set the PollState after receiving it from the server  const [poll, setPoll] = useState<PollState | null>(null);    // since we're not implementing Auth, let's fake it by    // creating some random user names when the App mounts  const randomUser = useMemo(() => {    const randomName = Math.random().toString(36).substring(7);    return `User-${randomName}`;  }, []);    // 🔌⚡️ get the connected socket client from our useSocket hook!   const { socket, isConnected } = useSocket({ endpoint: `http://localhost:8000`, token: randomUser });  const totalVotes = useMemo(() => {    return poll?.options.reduce((acc, option) => acc + option.votes.length, 0) ?? 0;  }, [poll]);    // every time we receive an 'updateState' event from the server    // e.g. when a user makes a new vote, we set the React's state    // with the results of the new PollState   socket.on('updateState', (newState: PollState) => {    setPoll(newState);  });  useEffect(() => {    socket.emit('askForStateUpdate');  }, []);  function handleVote(optionId: number) {    socket.emit('vote', optionId);  }  return (    <Layout user={randomUser}>      <div className='w-full max-w-2xl mx-auto p-8'>        <h1 className='text-2xl font-bold'>{poll?.question ?? 'Loading...'}</h1>        <h2 className='text-lg italic'>{isConnected ? 'Connected ✅' : 'Disconnected 🛑'}</h2>        {poll && <p className='leading-relaxed text-gray-500'>Cast your vote for one of the options.</p>}        {poll && (          <div className='mt-4 flex flex-col gap-4'>            {poll.options.map((option) => (              <Card key={option.id} className='relative transition-all duration-300 min-h-[130px]'>                <div className='z-10'>                  <div className='mb-2'>                    <h2 className='text-xl font-semibold'>{option.text}</h2>                    <p className='text-gray-700'>{option.description}</p>                  </div>                  <div className='absolute bottom-5 right-5'>                    {randomUser && !option.votes.includes(randomUser) ? (                      <Button onClick={() => handleVote(option.id)}>Vote</Button>                    ) : (                      <Button disabled>Voted</Button>                    )}                  </div>                  {option.votes.length > 0 && (                    <div className='mt-2 flex gap-2 flex-wrap max-w-[75%]'>                      {option.votes.map((vote) => (                        <div                          key={vote}                          className='py-1 px-3 bg-gray-100 rounded-lg flex items-center justify-center shadow text-sm'                        >                          <div className='w-2 h-2 bg-green-500 rounded-full mr-2'></div>                          <div className='text-gray-700'>{vote}</div>                        </div>                      ))}                    </div>                  )}                </div>                <div className='absolute top-5 right-5 p-2 text-sm font-semibold bg-gray-100 rounded-lg z-10'>                  {option.votes.length} / {totalVotes}                </div>                <div                  className='absolute inset-0 bg-gradient-to-r from-yellow-400 to-orange-500 opacity-75 rounded-lg transition-all duration-300'                  style={{                    width: `${totalVotes > 0 ? (option.votes.length / totalVotes) * 100 : 0}%`,                  }}                ></div>              </Card>            ))}          </div>        )}      </div>    </Layout>  );};export default App;Enter fullscreen modeExit fullscreen modeGo ahead now and start the client with npm run dev. Open another terminal window/tab, cd into the ws-server directory and run npm start.If we did that correctly, we should be seeing our finished, working, REAL TIME app! 🙂It looks and works great if you open it up in two or three browser tabs. Check it out:Nice!So we’ve got the core functionality here, but as this is just a demo, there are a couple very important pieces missing that make this app unusable in production.Mainly, we’re creating a random fake user each time the app mounts. You can check this by refreshing the page and voting again. You’ll see the votes just add up, as we’re creating a new random user each time. We don’t want that! We should instead be authenticating and persisting a session for a user that’s registered in our database. But another problem: we don’t even have a database at all in this app!You can start to see the how the complexity add ups for even just a simple voting featureLuckily, our next solution, Wasp, has integrated Authentication and Database Management. Not to mention, it also takes care of a lot of the WebSockets configuration for us.So let’s go ahead and give that a go!   Implementing WebSockets with Wasp — Fast/Zero Config MethodBecause Wasp is an innovative full-stack framework, it makes building React-NodeJS apps quick and developer-friendly. Wasp has lots of time-saving features, including WebSocket support via Socket.IO, Authentication, Database Management, and Full-stack type-safety out-of-the box.Wasp can take care of all this heavy lifting for you because of its use of a config file, which you can think of like a set of instructions that the Wasp compiler uses to help glue your app together.To see it in action, let's implement WebSocket communication using Wasp by following these steps 😎 TIP If you just want to see finished app’s code, you can check out the GitHub repo hereInstall Wasp globally by running the following command in your terminal:curl -sSL [https://get.wasp-lang.dev/installer.sh](https://get.wasp-lang.dev/installer.sh) | sh Enter fullscreen modeExit fullscreen modeIf you want to code along, first clone the start branch of the example app:git clone --branch start https://github.com/vincanger/websockets-wasp.gitEnter fullscreen modeExit fullscreen modeYou’ll notice that the structure of the Wasp app is split:🐝 a main.wasp config file exists at the root📁 src/client is our directory for our React files📁 src/server is our directory for our ExpressJS/NodeJS functionsLet’s start out by taking a quick look at our main.wasp file.app whereDoWeEat {  wasp: {    version: ""^0.11.0""  },  title: ""where-do-we-eat"",  client: {    rootComponent: import { Layout } from ""@client/Layout.jsx"",  },    // 🔐 this is how we get auth in our app.  auth: {    userEntity: User,    onAuthFailedRedirectTo: ""/login"",    methods: {      usernameAndPassword: {}    }  },  dependencies: [    (""flowbite"", ""1.6.6""),    (""flowbite-react"", ""0.4.9"")  ]}// 👱 this is the data model for our registered users in our databaseentity User {=psl  id       Int     @id @default(autoincrement())  username String  @unique  password Stringpsl=}// ...Enter fullscreen modeExit fullscreen modeWith this, the Wasp compiler will know what to do and will configure these features for us.Let’s tell it we want WebSockets, as well. Add the webSocket definition to the main.wasp file, just between auth and dependencies:app whereDoWeEat {    // ...   webSocket: {    fn: import { webSocketFn } from ""@server/ws-server.js"",  },    // ...}Enter fullscreen modeExit fullscreen modeNow we have to define the webSocketFn. In the ./src/server directory create a new file, ws-server.ts and copy the following code:import { WebSocketDefinition } from '@wasp/webSocket';import { User } from '@wasp/entities';// define the types. this time we will get the entire User object// in SocketData from the Auth that Wasp automatically sets up for us 🎉type PollState = {  question: string;  options: {    id: number;    text: string;    description: string;    votes: string[];  }[];};interface ServerToClientEvents {  updateState: (state: PollState) => void;}interface ClientToServerEvents {  vote: (optionId: number) => void;  askForStateUpdate: () => void;}interface InterServerEvents {}interface SocketData {  user: User; }// pass the generic types to the websocketDefinition just like // in the previous exampleexport const webSocketFn: WebSocketDefinition<  ClientToServerEvents,  ServerToClientEvents,  InterServerEvents,  SocketData> = (io, _context) => {  const poll: PollState = {    question: ""What are eating for lunch ✨ Let's order"",    options: [      {        id: 1,        text: 'Party Pizza Place',        description: 'Best pizza in town',        votes: [],      },      {        id: 2,        text: 'Best Burger Joint',        description: 'Best burger in town',        votes: [],      },      {        id: 3,        text: 'Sus Sushi Place',        description: 'Best sushi in town',        votes: [],      },    ],  };  io.on('connection', (socket) => {    if (!socket.data.user) {      console.log('Socket connected without user');      return;    }    console.log('Socket connected: ', socket.data.user?.username);    socket.on('askForStateUpdate', () => {      socket.emit('updateState', poll);    });    socket.on('vote', (optionId) => {      // If user has already voted, remove their vote.      poll.options.forEach((option) => {        option.votes = option.votes.filter((username) => username !== socket.data.user.username);      });      // And then add their vote to the new option.      const option = poll.options.find((o) => o.id === optionId);      if (!option) {        return;      }      option.votes.push(socket.data.user.username);      io.emit('updateState', poll);    });    socket.on('disconnect', () => {      console.log('Socket disconnected: ', socket.data.user?.username);    });  });};Enter fullscreen modeExit fullscreen modeYou may have noticed that there’s a lot less configuration and boilerplate needed here in the Wasp implementation. That’s because the: endpoints,authentication,and Express and Socket.IO middlewareare all being handled for you by Wasp. Noice!Let’s go ahead now and run the app to see what we have at this point. First, we need to initialize the database so that our Auth works correctly. This is something we didn’t do in the previous example due to high complexity, but is easy to do with Wasp:wasp db migrate-devEnter fullscreen modeExit fullscreen modeOnce that’s finished, run the app (it my take a while on first run to install all depenedencies):wasp startEnter fullscreen modeExit fullscreen modeYou should see a login screen this time. Go ahead and first register a user, then login:Once logged in, you’ll see the same hardcoded poll data as in the previous example, because, again, we haven’t set up the Socket.IO client on the frontend. But this time it should be much easier.Why? Well, besides less configuration, another nice benefit of working with TypeScript with Wasp, is that you just have to define payload types with matching event names on the server, and those types will get exposed automatically on the client! Let’s take a look at how that works now.In .src/client/MainPage.tsx, replace the contents with the following code:import { useState, useMemo, useEffect } from ""react"";import { Button, Card } from ""flowbite-react"";// Wasp provides us with pre-configured hooks and types based on// our server code. No need to set it up ourselves!import {  useSocketListener,  useSocket,  ServerToClientPayload,} from ""@wasp/webSocket"";import useAuth from ""@wasp/auth/useAuth"";const MainPage = () => {    // we can easily access the logged in user with this hook    // that wasp provides for us  const { data: user } = useAuth();  const [poll, setPoll] = useState<ServerToClientPayload<""updateState""> | null>(    null  );  const totalVotes = useMemo(() => {    return (      poll?.options.reduce((acc, option) => acc + option.votes.length, 0) ?? 0    );  }, [poll]);    // pre-built hooks, configured for us by Wasp  const { socket } = useSocket();   useSocketListener(""updateState"", (newState) => {    setPoll(newState);  });  useEffect(() => {    socket.emit(""askForStateUpdate"");  }, []);  function handleVote(optionId: number) {    socket.emit(""vote"", optionId);  }  return (    <div className=""w-full max-w-2xl mx-auto p-8"">      <h1 className=""text-2xl font-bold"">{poll?.question ?? ""Loading...""}</h1>      {poll && (        <p className=""leading-relaxed text-gray-500"">          Cast your vote for one of the options.        </p>      )}      {poll && (        <div className=""mt-4 flex flex-col gap-4"">          {poll.options.map((option) => (            <Card key={option.id} className=""relative transition-all duration-300 min-h-[130px]"">              <div className=""z-10"">                <div className=""mb-2"">                  <h2 className=""text-xl font-semibold"">{option.text}</h2>                  <p className=""text-gray-700"">{option.description}</p>                </div>                <div className=""absolute bottom-5 right-5"">                  {user && !option.votes.includes(user.username) ? (                    <Button onClick={() => handleVote(option.id)}>Vote</Button>                  ) : (                    <Button disabled>Voted</Button>                  )}                  {!user}                </div>                {option.votes.length > 0 && (                  <div className=""mt-2 flex gap-2 flex-wrap max-w-[75%]"">                    {option.votes.map((vote) => (                      <div                        key={vote}                        className=""py-1 px-3 bg-gray-100 rounded-lg flex items-center justify-center shadow text-sm""                      >                        <div className=""w-2 h-2 bg-green-500 rounded-full mr-2""></div>                        <div className=""text-gray-700"">{vote}</div>                      </div>                    ))}                  </div>                )}              </div>              <div className=""absolute top-5 right-5 p-2 text-sm font-semibold bg-gray-100 rounded-lg z-10"">                {option.votes.length} / {totalVotes}              </div>              <div                className=""absolute inset-0 bg-gradient-to-r from-yellow-400 to-orange-500 opacity-75 rounded-lg transition-all duration-300""                style={{                  width: `${                    totalVotes > 0                      ? (option.votes.length / totalVotes) * 100                      : 0                  }%`,                }}              ></div>            </Card>          ))}        </div>      )}    </div>  );};export default MainPage;Enter fullscreen modeExit fullscreen modeIn comparison to the previous implementation, Wasp saved us from having to configure the Socket.IO client, as well as building our own hooks.Also, hover over the variables in your client-side code, and you’ll see that the types are being automatically inferred for you! Here’s just one example, but it should work for them all:Now if you open up a new private/incognito tab, register a new user, and login, you’ll see a fully working, real-time voting app. The best part is, in comparison to the previous approach, we can log out and back in, and our voting data persists, which is exactly what we’d expect from a production grade app. 🎩Awesome… 😏  Comparing the Two ApproachesNow, just because one approach seems easier, doesn’t always mean it’s always better. Let’s give a quick run-down of the advantages and disadvantages of both the implementations above.Without WaspWith Wasp😎 Intended UserSenior Developers, web development teamsFull-stack developers, “Indiehackers”, junior devs📈 Complexity of CodeMedium-to-HighLow🚤 SpeedSlower, more methodicalFaster, more integrated🧑‍💻 LibrariesAnySocket.IO⛑ Type safetyImplement on both server and clientImplement once on server, inferred by Wasp on client🎮 Amount of controlHigh, as you determine the implementationOpinionated, as Wasp decides the basic implementation🐛 Learning CurveComplex: full knowledge of front and backend technologies, including WebSocketsIntermediate: Knowledge of full-stack fundamentals necessary.  Implementing WebSockets Using React, Express.js (Without Wasp)Advantages:Control & Flexibility: You can approach the implementation of WebSockets in the way that best suits your project's needs, as well as your choice between a number of different WebSocket libraries, not just Socket.IO.Disadvantages:More Code & Complexity: Without the abstractions provided by a framework like Wasp, you might need to write more code and create your own abstractions to handle common tasks. Not to mention the proper configuration of a NodeJS/ExpressJS server (the one provided in the example is very basic)Manual Type Safety: If you’re working with TypeScript, you have to be more careful typing your  event handlers and payload types coming into and going out from the server, or implement a more type-safe approach yourself.  Implementing WebSockets with Wasp (uses React, ExpressJS, and Socket.IO under the hood)Advantages:Fully-Integrated*/Less code*: Wasp provides useful abstractions such as useSocket and useSocketListener hooks for use in React components (on top of other features like Auth, Async Jobs, Email-sending, DB management, and Deployment), simplifying the client-side code, and allowing for full integration with less configuration.Type Safety: Wasp facilitates full-stack type safety for WebSocket events and payloads. This reduces the likelihood of runtime errors due to mismatched data types and saves you from writing even more boilerplate.Disadvantages:Learning curve: Developers unfamiliar with Wasp will need to learn the framework to effectively use it.Less control: While Wasp provides a lot of conveniences, it abstracts away some of the details, giving developers slightly less control over certain aspects of socket management.Help Me Help You 🌟 If you haven’t yet, please star us on GitHub, especially if you found this useful! If you do, it helps support us in creating more content like this. And if you don’t… well, we will deal with it, I guess.⭐️ Thanks For Your Support 🙏  ConclusionIn general, how you add WebSockets to your React app depends on the specifics of your project, your comfort level with the available tools, and the trade-offs you're willing to make between ease of use, control, and complexity.Don’t forget, if you want to check out the full finished code from our “Lunch Voting” example full-stack app, go here: https://github.com/vincanger/websockets-waspAnd if you know of a better, cooler, sleeker way of implementing WebSockets into your apps, let us know in the comments below"
110,"Amalgam is my little experimental tool written in rust and my attempt to consider the entire software development lifecycle and question it, can we do better, can we disrupt the way we develop, (yeah, I know, I hate that phrase too) but its true, and here's how. Your code should be an echo of your tests and docs, but it often seems to be that one of the 3 is out of sync or wrong, you and your team chase the tails trying to keep it all together but like it or not, tests can be wrong, docs can be wrong and code can somehow work but still be wrong.  How can code be wrong? 🤔It can work, but it can be wrong, in the way that the party who asked for the code via a ticket for example, was misunderstood - im no 10X dev im not super human, I do misunderstand tickets, well wrote or otherwise, so I wanted to use AI to solve this. Removing the horrific pain point, realising 2 weeks later that you have wrote the wrong solution. 🤨😭I know of Cucumber (I may say Gherkin, I mean that), in essence its  formal syntax and language for generating tests from acceptance criteria - you know, that thing that makes what you’re writing actually the thing that was needed.Scenario: Breaker guesses a word  Given the Maker has chosen a word  When the Breaker makes a guess  Then the Maker is asked to scoreEnter fullscreen modeExit fullscreen mode  Because ticket writing is hard.It is also a machine readable language and in my opinion, it is something with a barrier to entry, you need to learn but you have to commit to it to understand it let alone write it, I feel that very few teams have such time to learn it and manually write it, so enter OpenAI 🦾.  What can Amalgam and OpenAI AI do for us? 🤖🪄cargo run -- docs/sample/src/coo-cart.jsEnter fullscreen modeExit fullscreen modeInput:function addToCart(productId, productName, productPrice) {  let productInCart = cart.find((product) => product.id === productId);  if (productInCart) {    productInCart.quantity += 1;  } else {    cart.push({      id: productId,      name: productName,      price: productPrice,      quantity: 1,    });  }  renderCart();}Enter fullscreen modeExit fullscreen modeHTTP response:Scenario: Add a product to the cart    Given an empty cart    When I add a product to the cart with id ""productId"", name ""productName"", and price ""productPrice""    Then the cart should contain the product with id ""productId"", name ""productName"", price ""productPrice"", and quantity 1    And the cart should be rendered with the product details and total priceEnter fullscreen modeExit fullscreen modeBut Adam! This isn’t how we use Cucumber 🥒!! No it isn’t, it’s the reverse engineering of the traditional model, take the code and turn it into a serialised format on change. We are creating a feedback loop potentially generating and updating documentation too and creating the arse-backwards Cucumber then we can do these crazy things:(Actually every function in this file becomes a source to generate and run tests for one, and docs for two.But here is where it gets really saucy and new, we pass it the html page, this FAKE Jira designed to represent some source of truth<!DOCTYPE html><html lang=""en"">  <head>    <meta charset=""UTF-8"" />    <meta http-equiv=""X-UA-Compatible"" content=""IE=edge"" />    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"" />    <title>Jira Ticket: WPTCS-001</title>    <style>      body {        font-family: Arial, sans-serif;        margin: 20px;        background-color: #f4f5f7;      }      .ticket {        background-color: #fff;        padding: 20px;        border-radius: 5px;        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);      }      .header,      .content {        margin-bottom: 20px;      }      h1 {        color: #0079bf;        margin-bottom: 10px;      }      h2 {        margin-top: 20px;        color: #5e6c84;      }    </style>  </head>  <body>    <div class=""ticket"">      <div class=""header"">        <h1>Jira Ticket: WPTCS-001</h1>        <p>          <strong>Epic:</strong> Nature-Themed Store Experience |          <strong>Sprint:</strong> Sprint 5 | <strong>Priority:</strong> High        </p>      </div>      <div class=""content"">        <h2>Summary:</h2>        <p>          Develop a wood pigeon-themed cart system enhancing user experience in          nature-themed stores.        </p>        <h2>Description:</h2>        <p>          Our objective is to introduce a cart system inspired by the aesthetics          of a wood pigeon. The cart should be visually appealing,          user-friendly, and resonate with our brand's commitment to nature.        </p>        <h2>Acceptance Criteria:</h2>        <ul>          <li>            Feathered Design Aesthetics: Carts must have blue-grey and pink            hues, handles with black striping, wood pigeon silhouette on the            front, and signature white wing markings on the side.          </li>          <li>            Cozy Nest Cart Bay: Carts stored in a ""Cozy Nest Bay"", allowing            efficient stacking, utilizing recycled materials, with soft lighting            for nighttime.          </li>          <li>            Interactive Pigeon Sounds: Sensors activate cooing sounds based on            cart interactions.          </li>          <li>            QR Code Storytelling: Carts feature a QR code linking to an            informative wood pigeon page, with engagement-based discounts.          </li>        </ul>        <h2>Dependencies:</h2>        <p>          Collaboration with design and multimedia team for QR content.          Consultation with hardware vendors for sound integration.        </p>      </div>    </div>  </body></html>Enter fullscreen modeExit fullscreen modeOpenAI Will be able to figure out how closely matched the code is to the criteria giving us a score by comparing it to the Gherkin.“Does this ticket match our code?”Outcomes, would be some sort of correctness report, run-able test for the language, documentation and guidance to improve correctness.  Difficultiesone file doesn’t describe a feature usually so how to collate that? The length of the post limits the file sizes we can POSTAre you comfortable to POST your source?Are you comfortable to POST your Jira?What do you see are the problems?Anyway what do you think?"
111,"Do you remember the time when it used to be so simple to just open a new browser window, type a website address into the search bar, and then wait a bit while the site loaded? You could do everything you needed with that internet resource without a fuss. But things have changed now. Hopefully, your device has a good, or even great, internet connection, so the required website loads quickly enough. However, even after that, you often still have some work to do:You read some strange text and then decide whether to allow the website to use all your cookies 🍪 or maybe try to configure which cookies you want them to set. There's no evidence that the chosen option will really lead to anything, because most of the time, it doesn't. It's just some odd third-party script that was added to this specific website to be ""compliant"" with GDPR, all because some person from marketing told a developer that it's crucial for the website;You try to close this annoying popup window that covers the entire website, not letting you see what's on the site itself. Maybe it's just a never-ending promotion for some ""new"" products or subscriptions. Perhaps it's about the idea that it's ""better"" to use a different browser or even an entirely different device to view the site. And while you're trying to find a way to close this popup window – because the X icon is hidden quite well – you can't even scroll, as if blocking the user's scrolling ability is a brilliant idea;Would you like to enable push notifications for this website? Honestly, we're not quite sure what we'll be sending you, but just in case, you know. Don't like it? Just close this extra window, it's not a big deal;Now, if you've managed to win the battle against popups, it's finally time to see the actual website. But don't get your hopes up too high. As soon as you scroll a few hundred pixels – a new modal window pops up. Why not, right? Someone decided that you've had enough of the real content, and now it's time to show you the latest promotion or just ask you to subscribe to some completely irrelevant newsletter;You might want to use the footer navigation for some reason, but at this point, it's not possible because the cookie banner is still there, covering all the important information like navigation links and company details;And now, just when you've sorted out all these banners and popups and are ready to engage with the website – bam! The LIVE CHAT suddenly takes over your entire screen. Hello there! What can I assist you with?Oh, and let's not forget that EVERY POSSIBLE tracker was loaded via Google Tag Manager. Because someone apparently thought we absolutely needed all this analytics, tracking data, and even live screen capturing of users browsing the website;Finally, you can enjoy THE WEBSITE. You've given up all your cookies, sacrificed your privacy, and invested your time and effort – you've earned it!So, who's responsible for all of this? Is it the person who created the task in some project management tool like Jira, Trello, or Asana? Or maybe it's the one who implemented it? In my humble opinion: it's both. I strongly believe that we, as developers, bear responsibility not just for writing lines of code, but for creating THE PRODUCT. We're answerable for the user experiences. We control the amount of data users need to download to use our website or app. We're accountable for the data collected by first or third-party scripts. Don't let managers or product owners blindly dictate what the product should be. If you're there, if you're part of the team, then take the initiative. This is also your area of expertise. Don't hesitate to ask questions like:""Why do we need all these trackers?"";""Is it appropriate to interfere with how our visitors use our website?"";""Do we really need this massive image slider on the first page?"";""How can we enhance the website experience across a wide range of devices?"";""Why does our design neglect the existence of color-blind individuals?"";And so on...Don't just rely on the expertise or experience of someone who gave you instructions. Sometimes they're just blindly following bad examples: ""If most websites have this popup, we should have it too!"". Show them the other way, find the good examples, provide evidence. We should stand up for our customers, visitors, and users. If not us, then who? So, let's make web great again!"
112,"In the ever-evolving realm of web development, mastering advanced concepts is essential for creating robust and flexible applications. In this article, we'll delve into one of these foundational React concepts: Higher-Order Components, commonly known as HOCs. Whether you're a seasoned developer seeking advanced techniques or a curious beginner eager to learn, we'll walk through the creation and application of HOCs step by step. Get ready to enrich your development toolkit with this powerful approach while discovering how to enhance the readability, reusability, and maintainability of your code.  What is a Higher Order Component?Imagine that you own a pastry shop and you specialize in creating a wide variety of pastries. In your pastry shop, you have croissants, muffins, and danishes. Each pastry must have a label indicating its type and ingredients. If you were to do this for every pastry manually, it would require a significant amount of time. Instead of doing it manually, you can use a ""robot"" that will do it automatically for you.This robot is a Higher-Order Component (HOC), a function that takes a component (your pastry) and returns your pastry with additional functionalities or features (in this case, a label indicating its type and ingredients).  AdvantagesHigher-Order Components (HOCs) offer several significant advantages that enhance how we develop our React applications. Here are some of these advantages, accompanied by concrete examples:Reusability: One major strength of HOCs is their ability to be reused in different parts of your application. Since an HOC is a function with specific logic, you can customize it to suit your needs while keeping it flexible. For instance, an authentication HOC could be adapted to handle access to different types of content. Separation of Concerns: Instead of cluttering a component with multiple distinct logics, HOCs allow for the separation of these responsibilities into distinct components. You can easily envision creating a separate HOC for each logic, making your components clearer and better organized. Code Modularity: HOCs add a modular layer to your code. You can add or remove an HOC without affecting the functionality of the underlying component, making maintenance and adaptation of your application easier. In essence, HOCs nest without altering overall stability. Facilitation of Unit Testing: Due to their isolated nature, HOCs simplify unit testing. You can test the specific logic of an HOC without the complexity of other parts of the application.By combining these advantages, you'll be able to create more flexible and maintainable applications while minimizing code duplication.  Practical Case  The problemLet's take a concrete example to illustrate the relevance of Higher-Order Components. Suppose we're developing an application with an authentication system. In this application, different parts of the interface require authentication: Home Page: This page doesn't require authentication. List of Books: This list can be viewed without authentication. Top Books: This section is reserved for authenticated users. User Ratings: Similarly, only logged-in users can view the ratings.Imagine we have a component that imports all the others:export const App = () => {  return (    <div>      <Home />      <BooksList />      <TopBook />      <UsersRating />    </div>  )}Enter fullscreen modeExit fullscreen modeNow, let's consider a component for each part:export const Home = () => {  return (    <div>      <h1>Hey !</h1>      <p>This is a welcome message !</p>    </div>  )}Enter fullscreen modeExit fullscreen modeexport const BooksList = () => {  return (    <div>      <p>Books list</p>    </div>  )}Enter fullscreen modeExit fullscreen modeexport const TopBook = () => {  const isConnected = false  if(!isConnected) {    return (      <p>You don't have access !</p>    )  }  return (    <div>      <p>Top Book</p>    </div>  )}Enter fullscreen modeExit fullscreen modeexport const UsersRating = () => {  const isConnected = false  if(!isConnected) {    return (      <p>You don't have access !</p>    )  }  return (    <div>      <p>UsersRating</p>    </div>  )}Enter fullscreen modeExit fullscreen modeWe notice that the two components with the restriction logic repeat the same code. While this isn't a big issue with only two components, imagine having 10 components - that's a lot of code repetition. Given this scenario, it's important to find a solution that handles conditional content display based on authentication status.This is where Higher-Order Components (HOCs) come into play.  Solution : Higher Order Components (HOCs)To address this issue of code repetition in multiple places, let's isolate the authentication logic in an HOC called withAuthentication:export const withAuthentication = (Component) => {  const isConnected = false  if (!isConnected) {    return <p>You don't have access !</p>  }  return (props) => <Component {...props} />}Enter fullscreen modeExit fullscreen modeNext, we'll apply this HOC to the components that require access restriction, like this:export const TopBook = withAuthentication(() => {  return (    <div>      <p>Top Book</p>    </div>  )})Enter fullscreen modeExit fullscreen modeexport const UsersRating = withAuthentication(() => {  return (    <div>      <p>UsersRating</p>    </div>  )})Enter fullscreen modeExit fullscreen modeAssuming you retrieve isConnected from either props or context, you now have isolated and reusable logic.  Going furtherWe can go further with HOCs. Let's imagine now that we want to do some layout work with a profile view:export const Profile = () => {  // This is the beta version of the Profile  return (    <div>      <p>Beta Profile</p>      <h1>Nicolas BROUARD</h1>    </div>  )}Enter fullscreen modeExit fullscreen modeWe have our Profile view and we want to add a ""Beta"" banner to indicate that this is indeed the Beta version of the profile. We can also use an HOC:export const withBetaBanner = (Component) => {  return (props) => (    <>      <header className=""beta-header"">This is a beta version</header>      <Component {...props} />    </>  )}Enter fullscreen modeExit fullscreen mode  You can easily nest various HOCs if needed:const ProtectedBetaProfile = withAuthentication(withBetaBanner(Profile))return <ProtectedBetaProfile />;Enter fullscreen modeExit fullscreen modeThis allows you to isolate different rules, making unit testing easier! You can also manipulate props if necessary. HOCs are very powerful!You can also manipulate props if necessary. HOCs are very powerful!  ConclusionIn conclusion, you now have all the tools you need to fully leverage the power of Higher-Order Components (HOCs) in your React projects.By combining concepts such as prop forwarding, HOC composition, and using TypeScript for type safety, you can create more flexible, cleaner, and efficient components. HOCs provide a practical approach to handling cross-cutting concerns and simplifying your components, which can greatly facilitate maintenance and expansion of your applications. Keep experimenting with HOCs in your projects and don't hesitate to explore concrete examples to deepen your understanding.Mastering the art of HOCs will give you a significant advantage in building robust and scalable React applications. So, dive in, apply this knowledge, and transform your components into flexible and powerful building blocks for your future React creations.If you enjoyed this tutorial, please consider following me for more helpful content. Your support is greatly appreciated! Thank you!X _brdnicolas"
113,"GitHub Actions are a powerful tool to automate your workflow. They can be used to run tests, deploy your code, publish a package, and much more.The cool thing is, there's a GitHub Actions Marketplace where you can find a lot of actions created by... the community.But what if you can't find the action you need? You can create your own and publish it there!  How to use this tutorialRead more...In this tutorial we're going to see in detail how to:Create a GitHub Action in TypescriptExpand our Action to support custom inputsIntegrate with GitHub's API to add labels to Pull RequestsUnit testing our actionDebugging in Visual Studio CodePublishing our action to the GitHub MarketplaceUsing our action in another repositorySome final touches to make our project more robustThe articles will be split into separate bite-sized chapters as technically each one can be a little tutorial by itself.If you're interested in the full text all at once, you can find it here: https://leonardomontini.dev/typescript-github-action/One more great piece of advice is to create a new repository and follow along with the steps. This way you'll have a working action at the end of the post and you'll be able to play with it and experiment, rather than just reading a long tutorial and forgetting about 90% of it.The full code of this tutorial is available on GitHub on this repo, so you can always refer to it if you get stuck.The full tutorial (all chapters at once) is also available as a video, which you can find here:  Chapter 4: Use case - Adding a label to new Pull RequestsWe learned the basics, we have our MVP ready to be expanded so let's do it! We'll create a new action that will automatically run every time a new Pull Request is created and it will add a needs-review label to it.  Update the action codeIn order to add a label to a Pull Request, we need to use the GitHub REST API. We can use the Octokit client to make the API calls. Luckily for us there's an official package we can use.npm install @actions/githubEnter fullscreen modeExit fullscreen modeThen we can import the Octokit client and use it to add the label to the Pull Request. Here's the full code.import { getInput, setFailed } from '@actions/core';import { context, getOctokit } from '@actions/github';async function run() {  const token = getInput('gh-token');  const label = getInput('label');  const octokit = getOctokit(token);  const pullRequest = context.payload.pull_request;  try {    if (!pullRequest) {      throw new Error('This action can only be run on Pull Requests');    }    await octokit.rest.issues.addLabels({      owner: context.repo.owner,      repo: context.repo.repo,      issue_number: pullRequest.number,      labels: [label],    });  } catch (error) {    setFailed((error as Error)?.message ?? 'Unknown error');  }}run();Enter fullscreen modeExit fullscreen modeWhat happened here?We read the gh-token and label inputs from the workflow. The token is a personal access token that we need to create and pass to the action. More on that later. The label is the name of the label we want to add to the Pull Request.We create an instance of the Octokit client using the token.We get the Pull Request number from the context.payload.pull_request object. This object is only available when the action is triggered by a Pull Request event.We call the octokit.rest.issues.addLabels method to add the label to the Pull Request.In case something fails, we catch the error and we set the workflow as failed with the setFailed function, also coming from the @actions/core package.  Update the action definitionWe also need to update the action definition to add the new inputs.inputs:  gh-token:    description: 'The GitHub token for authentication.'    required: true  label:    description: 'The label to be applied to the pull request.'    required: trueEnter fullscreen modeExit fullscreen mode  Update the workflowFinally, we need to update the workflow to run when PRs are opened or reopened:on:  pull_request:    types: [opened, reopened]Enter fullscreen modeExit fullscreen mode...and to pass the new inputs to the action.- uses: ./  with:    gh-token: ${{ secrets.GITHUB_TOKEN }}    label: 'needs-review'Enter fullscreen modeExit fullscreen modeWe're passing the GITHUB_TOKEN secret to the action. It usually does not require you any extra action, as GitHub automatically creates it for you.In case you get an error that says ""Resource not accessible by integration"", you need to make sure your token on that repository has write access. You can do that by going to the Settings tab > Actions > General and scroll down to the ""Workflow permissions"" section.Setting it to ""Read and write permissions"" will be enough.  Run the actionWe can now run the action again and see the label is added to the Pull Request.However, let's not forget to run npm run build first, then we can commit and push the changes. The reason is that we told GitHub that the action is located in the dist folder, so we need to make sure that folder is up to date.npm run buildgit add .git commit -m ""Add label to new Pull Requests""git pushEnter fullscreen modeExit fullscreen modeCool! We can now create a new branch, change a file and open a Pull Request. We'll see the action running and adding the label to the Pull Request, aaaand...Error: Cannot find module '@actions/core'Enter fullscreen modeExit fullscreen modeWhat happened here? If you look at your file in dist/index.js, you'll see that the @actions/core package is not there. That's because we didn't tell TypeScript to include it in the build.A good way to include packages and condense everything in one file is with the tool @vercel/ncc. Let's install it.npm install @vercel/nccEnter fullscreen modeExit fullscreen modeThen we can update our build script in package.json to use it. ""build"": ""tsc && ncc build lib/index.js""Enter fullscreen modeExit fullscreen modeWe also need to change outDir in tsconfig.json to lib.""outDir"": ""lib""Enter fullscreen modeExit fullscreen modeYou might also want to double-check that lib is in your .gitignore file but dist is not. This is our desired behavior as lib will only have our code in javascript, but dist will have the whole action.  Run the action (2.0)We can now run npm run build again, then commit and push the changes.Create a new branch, change a file and open a Pull Request. This time, you'll see the action running and adding the label to the Pull Request.  ClosingAnd that was it for today! if you have any question or suggestion, feel free to add a comment :)See you in the next chapter!Thanks for reading this article, I hope you found it interesting!I recently launched my Discord server to talk about Open Source and Web Development, feel free to join: https://discord.gg/bqwyEa6We6Do you like my content? You might consider subscribing to my YouTube channel! It means a lot to me ❤️You can find it here:Feel free to follow me to get notified when new articles are out ;)Leonardo MontiniFollowI talk about Open Source, GitHub, and Web Development. I also run a YouTube channel called DevLeonardo, see you there!"
114,"As an open source maintainer, contributors are one of the most important ways to scale up the goals you want to achieve in an open source project, along with scaling down the amount of work you have to do as a maintainer. This post provides a few tips on mentoring new contributors to your project, and continuing someone's open source journey.  Embracing Early InteractionsNew contributors to a project have a fresh perspective on how to contribute. They may run into paper cuts getting the environment set up, and little nuances about contributing that you have long moved into muscle memory. Mentoring new contributors involves answering those little details that help them in the long run. Not every contributor is familiar with using Git commands, using the terminal, or running the test suites. To help a new contributor, you must put yourself in their shoes and go back to when you were contributing to a new project. Going over the contributing documentation is one way to do this, but being more explanatory on certain terms goes a long way with new contributors. By helping them learn the ins and outs of your project, it can help in at least a couple of ways. It provides them more contribution opportunities through updates to documentation, smooth over the rough edges to contributing so it becomes easier for the next person, and becoming more familiar with the codebase.  Providing Guide RailsBy providing some measures in place for new contributors to thrive, you can ensure you get steady contributions that maintain a certain level of quality. It doesn't mean you need to nitpick on pull requests to teach lessons. There are things in place in your project to help contributors and yourself to save time.Guides include:Onboarding and contributing documentationIssue templatesPull request templatesTools such as:ESLint for automated lint checks and fixes.Prettier for automated code formatting.GitHub Actions for automated builds and tests.These are just a few tools that help developers adhere to the standards set by the project without new contributors having to learn them all upfront.   Giving Trust and Gauging InterestContributors of today can eventually become maintainers one day. There will be some contributors who come in to drop a pull request once and you never see them again. Then there are contributors who stick around because they are genuinely interested in the success of your project, and it may be mutually beneficial for them also.Giving more trust to new contributors can come in the form of invitations to private Slack/Discord channels for more focused discussion, providing more guidance on pull requests on historical decisions that were made on the project, and continuing to teach how to look at the project from a different perspective. Having a contributor stick around long enough could turn into someone you invite to contribute more directly as a co-maintainer. The mentorship doesn't end there, as you'll still be answering questions on the overall vision for the project, and how you plan to get there as a team.  Recognizing ContributionsThere are many ways to recognize contributions outside of GitHub repositories. Tools such as All Contributors provide a common way to recognize many different types of contributions, from code, to docs, and more. Contributions can also be recognized in the form of shoutouts on social media, upgraded roles on Discord or Slack channels, and access to internal chats for more focused conversations. These external interactions go a long way in building community and engagement around your project and encourage future contributors to come onboard.Mentoring new contributors helps to build an ecosystem and community around an open source project. Whether it be helping explain new topics, improving onboarding, or recognizing contributions, all help contributors along their open source journey. These were a few ways you can help new and experience contributors get involved and grow an open source project together."
115,"Yesterday, I briefly interacted with Manuel Matuzović after reading his Mastodon post on his growing doubts over the shadow DOM in general.After almost a year working with web components I'm starting to doubt the usefulness of style encapsulation and shadow DOM in general.Styling and some accessibility stuff is so much easier without…Manuel Matuzović, August 17th 2023@matuzo That's how all of us enhance.dev folks feel. The shadow DOM is a tool that should be reached for only when needed. It shouldn't be the default when it comes to working with custom elements/web components.Simon MacDonald, August 17th 2023@macdonst interesting! That's the exact opposite of what e.g. the lit docs say. Do you have your or your team's thoughts on shadow don written down somewhere?Manuel Matuzović, August 17th 2023@matuzo  let me find something or better yet this gives me the excuse to blog about thoughts that have been running through my head for a bit.Simon MacDonald, August 17th 2023This made me realize we haven’t done the best job of explaining why we don’t default to using the shadow DOM and how Enhance works. So let’s dig in!  Why not just use the shadow DOM from the start?In many cases, you ain’t gonna need it (YAGNI). The light DOM has served the web well for many years, and we can get quite far with it. To enumerate some of the reasons why we don’t immediately reach for the shadow DOM, they would be:HTML-first: To keep our page weight down, we defer adding JavaScript until it is absolutely required. For many of our custom elements, we can get by with only HTML and CSS.Server-side Rendering: While we are excited about Declarative Shadow DOM it has yet to land in all evergreen browsers (come on FireFox). Until such time it becomes ubiquitous, we’ll stick with our approach.Flash of Unstyled Custom Element (FOUCE): as described below, waiting for the customElements.define() method to be called before your web component is displayed can negatively affect users’ impression of your application.Form participation: by default, elements in the shadow DOM inside a form do not inherit the default behaviors of form elements. For example, a submit button in the shadow DOM will not automatically submit your form when the Enter key is hit. There is a spec called Form Associated Custom Elements (FACE) that gives you the APIs to build web components that participate in forms. However, fixing a problem created by JavaScript by writing more JavaScript is like handing a drowning man a glass of water, IMHO.Styling: I confess that I am CSS challenged, but the shadow DOM introduces a new way of styling components for the sake of style encapsulation. Plus, we have other (easier) ways of ensuring style encapsulation.Accessibility: the shadow DOM introduces problems with accessibility. For more info, read this thoughtful post from Nolan Lawson.  What is Enhance?Enhance is an HTML-first full-stack web framework that gives you everything you need to build standards-based multi-page web apps that perform and scale.  Right, but what does that mean?It means that Enhance is a one-stop solution for building web applications. You write your application using web standards like HTML, CSS and JavaScript. Enhance allows you to server-side render (SSR) your custom elements while providing a path for them to be “enhanced” to full web components.  Okay, that sounds good, but how does it work?Let’s show instead of tell by building a simple message component from the ground up using Enhance. Let’s create our Enhance single file component “app/elements/my-message.mjs”.export default function MyMessage({ html, state }) {  const { attrs } = state  const { message = '' } = attrs  return html`    <h1>${message}</h1>  `}Enter fullscreen modeExit fullscreen modeThis is a very simple custom element that will take the string from the attribute message and wrap it in a h1 tag. To use it in our HTML page, we’d just write:<my-message message=""Hello World""></my-message>Enter fullscreen modeExit fullscreen modeWhich produces:Hello WorldWhen viewed in the browser.Great, now we have the basis of our single file component by writing the HTML-first, but now I want to do some styling, so let’s add a style tag to our component.export default function MyMessage({ html, state }) {  const { attrs } = state  const { message = '' } = attrs  return html`    <style>      h1 { color: Crimson; }    </style>    <h1>${message}</h1>  `}Enter fullscreen modeExit fullscreen modeRefreshing our browser, we now see hello world in crimson.Hello WorldBut wait, wouldn’t that style tag screw up the style of all the h1 tags on my page? Don’t we need to use the shadow DOM here to encapsulate our component styles away from the rest of the page?Well, you could do that, and you wouldn’t be wrong, but one of the philosophies behind Enhance is to delay using the shadow DOM until you absolutely need it instead of immediately reaching for it.  Style TransformsThe way Enhance prevents your component styles from interfering with other elements on your page is by running a style transform on the server before sending your HTML to the client. In our above example, it will take the style tag:<style>  h1 { color: Crimson; }</style>Enter fullscreen modeExit fullscreen modeAnd hoist it to the head of your document, where it will look like this:<style>  my-message h1 { color: Crimson; }</style>Enter fullscreen modeExit fullscreen modeIf you have more than one my-message element on your page, the style transform will also deduplicate the CSS so the directives only appear once.This provides the added benefit of avoiding the dreaded Flash of Unstyled Custom Element (FOUCE) when dealing with web components. This way, you can avoid using the::not(:defined) {  visibility: hidden;}Enter fullscreen modeExit fullscreen modetrick to hide web components until they are defined by a call to customElements.define().  But this isn’t a web component?True. I’d say what we have built so far is a server-side rendered custom element, and it doesn’t become a real web component until we enhance it (see what I did there) by calling customElements.define(). So let’s go ahead and round out our single file component by adding in some JavaScript.export default function MyMessage({ html, state }) {  const { attrs } = state  const { message = '' } = attrs  return html`  <style>    h1 { color: Crimson; }  </style>  <h1>${message}</h1>  <script type=""module"">    class MyMessage extends HTMLElement {      constructor() {        super()        this.heading = this.querySelector('h1')      }      static get observedAttributes() {        return [ 'message' ]      }      attributeChangedCallback(name, oldValue, newValue) {        if (oldValue !== newValue) {          if (name === 'message') {            this.heading.textContent = newValue          }        }      }  }  customElements.define('my-message', MyMessage)  </script>`}Enter fullscreen modeExit fullscreen modeAh, now we have a real web component. If you update the message attribute of the my-message tag, the component will re-render itself.In our example, we still aren’t using the shadow DOM, and I don’t see any reason why we would need to at this point, but if you really wanted to, you could change the script tag to use the shadow DOM approach.export default function MyMessage({ html, state }) {  const { attrs } = state  const { message = '' } = attrs  return html`    <h1>${message}</h1>    <script type=""module"">    const template = document.createElement('template')    template.innerHTML = ""<style>h1 { color: Crimson; }</style><h1></h1>""    class MyMessage extends HTMLElement {        constructor() {          super();          const shadow = this.attachShadow({ mode: 'open' });          shadow.appendChild(template.content.cloneNode(true));        }        static get observedAttributes() {          return [ 'message' ]        }        attributeChangedCallback(name, oldValue, newValue) {          if (oldValue !== newValue) {            if (name === 'message') {              this.shadowRoot.querySelector('h1').innerText = newValue            }          }        }      }      customElements.define('my-message', MyMessage)    </script>    `}Enter fullscreen modeExit fullscreen modeThis doesn't mean you are required to write vanilla JavaScript web components either. If you are familiar with using Fast or Lit to write web components you can include those libraries in you Enhance application. However, with the introduction of Enhance base classes for the light and shadow DOM you can get the same DX improvements where you write less boilerplate web component code while enabling the sharing of a render method between the SSR and CSR rendering.  Next StepsIf you disagree with this article, maybe try out Enhance in anger and let us know what you think.Follow Axol, the Enhance Mascot on Mastodon…Join the Enhance Discord and share what you’ve built, or ask for help."
116,"  TL;DR 🔥In this tutorial, you'll learn how to build a blogging platform that let's you create and react to posts.We will build a login and registration with HankoBuild the entire blog:Create postsReact to posts Add in-app notification to every reaction with Novu.  Novu: Open-source notification infrastructure 🚀Just a quick background about us. Novu is an open-source notification infrastructure. We basically help to manage all the product notifications. It can be In-App (the bell icon like you have in the Dev Community - Websockets), Emails, SMSs and so on.  Let set it up 🆙Here, I'll walk you through creating the project setup for the application. We'll use React.js for the front end and Node.js for the backend server.Create a folder for the web application as done below.mkdir simple-blogcd simple-blogmkdir client serverEnter fullscreen modeExit fullscreen mode  Setting up the Node.js serverNavigate into the server folder and create a package.json file.cd server & npm init -yEnter fullscreen modeExit fullscreen modeInstall Express, Nodemon, and the CORS library.npm install express cors nodemonEnter fullscreen modeExit fullscreen modeExpressJS is a fast, minimalist framework that provides several features for building web applications in Node.js, CORS is a Node.js package that allows communication between different domains, and Nodemon is a Node.js tool that automatically restarts the server after detecting file changes.Create an index.js file - the entry point to the web server.touch index.jsEnter fullscreen modeExit fullscreen modeSet up a Node.js server using Express.js. The code snippet below returns a JSON object when you visit the http://localhost:4000/api in your browser.//👇🏻index.jsconst express = require(""express"");const cors = require(""cors"");const app = express();const PORT = 4000;app.use(express.urlencoded({ extended: true }));app.use(express.json());app.use(cors());app.get(""/api"", (req, res) => {    res.json({        message: ""Hello world"",    });});app.listen(PORT, () => {    console.log(`Server listening on ${PORT}`);});Enter fullscreen modeExit fullscreen modeConfigure Nodemon by adding the start command to the list of scripts in the package.json file. The code snippet below starts the server using Nodemon.//In server/package.json""scripts"": {    ""test"": ""echo \""Error: no test specified\"" && exit 1"",    ""start"": ""nodemon index.js""  },Enter fullscreen modeExit fullscreen modeCongratulations!🎉 You can now start the server by using the command below.npm startEnter fullscreen modeExit fullscreen mode  Setting up the React applicationNavigate into the client folder via your terminal and create a new React.js project with Vite.npm create vite@latestEnter fullscreen modeExit fullscreen modeInstall React Icons and React Router - a JavaScript library that enables us to navigate between pages in a React application.npm install react-router-dom react-iconsEnter fullscreen modeExit fullscreen modeDelete the redundant files, such as the logo and the test files from the React app, and update the App.jsx file to display “Hello World” as done below.function App() {    return (        <div>            <p>Hello World!</p>        </div>    );}export default App;Enter fullscreen modeExit fullscreen modeCopy the CSS file required for styling the project here into the src/index.css file.  Building the app user interface 🛠️Here, we'll create the user interface for the blogging application to enable users to view, create, and react to posts.Create a components folder within the client/src folder containing the Home.jsx, Login.jsx, Details.jsx, and NewPost.jsx.cd client/srcmkdir componentstouch Home.jsx Details.jsx Login.jsx NewPost.jsxEnter fullscreen modeExit fullscreen modeFrom the code snippet aboveThe Home.jsx component displays all the available posts.The Detail.jsx component displays the details of each post, such as its content, the date posted, and the number of reactions to the post.The NewPost.jsx component enables users to create a new post.The Login.jsx component log users into the application via Hanko.Update the App.jsx file to render the components using React Router.import React from ""react"";import { BrowserRouter as Router, Route, Routes } from ""react-router-dom"";import Home from ""./components/Home"";import Details from ""./components/Details"";import Login from ""./components/Login"";import NewPost from ""./components/NewPost"";const App = () => {    return (        <Router>            <Routes>                <Route path='/' element={<Home />} />                <Route path='/login' element={<Login />} />                <Route path='/post/:slug' element={<Details />} />                <Route path='/post/new' element={<NewPost />} />            </Routes>        </Router>    );};export default App;Enter fullscreen modeExit fullscreen mode  The Home pageThe Home page displays all the posts created within the application. Copy the code below into the Home.jsx file.import React from ""react"";import { Link } from ""react-router-dom"";const Home = () => {    return (        <div>            <nav className='navbar'>                <Link to='/' className='logo'>                    <h2>MyBlog</h2>                </Link>                <div style={{ display: ""flex"", alignItems: ""center"" }}>                    <Link to='/post/new' className='newPostBtn'>                        New Post                    </Link>                </div>            </nav>            <main className='main'>                <h2 className='heading'>Latest Posts</h2>                <div className='posts_container'>                    <Link to={`/post/details`} className='post'>                        <h2 className='post_title'>                            Building a chat app with React, Novu, and Websockets                        </h2>                    </Link>                    <Link to={`/post/details`} className='post'>                        <h2 className='post_title'>How to install Novu in React</h2>                    </Link>                </div>            </main>        </div>    );};export default Home;Enter fullscreen modeExit fullscreen mode  The Post Details pageThis page displays post details when a user clicks on them from the Home.jsx component. Copy the code below into the Details.jsx file.import React from ""react"";import { AiTwotoneLike, AiTwotoneDislike } from ""react-icons/ai"";const Details = () => {    return (        <div>            <header className='details_header'>                <h1 className='details_heading'>How to install Novu in React</h1>                <div className='post_details'>                    <div>                        <p className='details_date'>Posted on 30th July, 2023</p>                    </div>                    <div className='reactions-group'>                        <button className='reactBtn'>                            Like <AiTwotoneLike /> <span style={{ marginLeft: 5 }}>2</span>                        </button>                        <button className='reactBtn unlikeBtn'>                            Dislike <AiTwotoneDislike />                            <span style={{ marginLeft: 5 }}>1</span>                        </button>                    </div>                </div>            </header>            <main className='details_body'>                Lorem Ipsum is simply dummy text of the printing and typesetting                industry. Lorem Ipsum has been the industry's standard dummy text ever                since the 1500s, when an unknown printer took a galley of type and                scrambled it to make a type specimen book. It has survived not only five                centuries, but also the leap into electronic typesetting, remaining                essentially unchanged. It was popularised in the 1960s with the release                of Letraset sheets containing Lorem Ipsum passages, and more recently                with desktop publishing software like Aldus PageMaker including versions                of Lorem Ipsum.            </main>        </div>    );};export default Details;Enter fullscreen modeExit fullscreen mode  The New Post pageThis page displays a form field that accepts the title and content of a blog post. Copy the code snippet below into the NewPost.jsx file.import React, { useState } from ""react"";import { Link, useNavigate } from ""react-router-dom"";const NewPost = () => {    const navigate = useNavigate();    const [title, setTitle] = useState("""");    const [content, setContent] = useState("""");    const handleSubmit = (e) => {        e.preventDefault();        console.log({ title, content });        setContent("""");        setTitle("""");    };    return (        <div>            <nav className='navbar'>                <Link to='/' className='logo'>                    <h2>MyBlog</h2>                </Link>                <div>                    <button className='newPostBtn logOut'>Log out</button>                </div>            </nav>            <main className='main'>                <h2 className='heading'>Create new post</h2>                <form className='newPost_form' onSubmit={handleSubmit}>                    <label htmlFor='title' className='label'>                        Title                    </label>                    <input                        type='text'                        className='newPost_title'                        id='title'                        name='title'                        value={title}                        required                        onChange={(e) => setTitle(e.target.value)}                    />                    <label htmlFor='content' className='label'>                        Content                    </label>                    <textarea                        rows={10}                        className='newPost_content'                        value={content}                        required                        onChange={(e) => setContent(e.target.value)}                    />                    <button className='newPostBtn submitBtn' type='submit'>                        Create Post                    </button>                </form>            </main>        </div>    );};export default NewPost;Enter fullscreen modeExit fullscreen mode  Are passkeys the future? 🔑Hanko is an open-source, easy-to-integrate authentication solution that enables you to add various forms of authentication such as Email & Password, password-less, passkeys, and OAuth to your software applications.It is an all-in-one authentication solution that enables you to set up authentication in a few minutes in your web applications. It also provides customisable web components which you can add to your web application to handle authentication quickly and easily.In the upcoming sections, you'll learn how to add Hanko to the blogging application.  Adding authentication easily to React apps with HankoHere, you'll learn how to add authentication to your React applications using Hanko. Before we begin, install the Hanko package by running the code snippet below.npm install @teamhanko/hanko-elementsEnter fullscreen modeExit fullscreen mode  Setting up an Hanko projectVisit the homepage and create an account.Create a new organization that will manage your Hanko projects.Then, create a new Hanko project and add your development server as the API URL.Finally, save your API URL somewhere on your computer; it will be used for setting up the authentication.  Adding Hanko to React appsCopy the code below into the Login.jsx file.import React, { useEffect, useCallback, useMemo } from ""react"";import { useNavigate } from ""react-router-dom"";import { register, Hanko } from ""@teamhanko/hanko-elements"";const hankoApi = ""<YOUR_HANKO_API_URL>"";const Login = () => {    const navigate = useNavigate();    const hanko = useMemo(() => new Hanko(hankoApi), []);    useEffect(() => {        register(hankoApi).catch((error) => {            console.log(error);        });    }, []);    return (        <div className='login_container'>            <hanko-auth />        </div>    );};export default Login;Enter fullscreen modeExit fullscreen modeThe code snippet displays the Hanko authentication component and enables users to sign up or sign in directly via Hanko.Add the code snippet below within the Login.jsx component.//👇🏻 generates random string as IDconst generateUserID = () => Math.random().toString(36).substring(2, 10);//👇🏻 executes after a user logs inconst redirectAfterLogin = useCallback(() => {    localStorage.setItem(""loggedIn"", ""true"");    if (!localStorage.getItem(""u_id"")) {        localStorage.setItem(""u_id"", generateUserID());    }    navigate(""/"");}, [navigate]);//👇🏻 triggered after a successful sign inuseEffect(    () =>        hanko.onAuthFlowCompleted(() => {            redirectAfterLogin();        }),    [hanko, redirectAfterLogin]);Enter fullscreen modeExit fullscreen modeFrom the code snippet above, when a user signs into the application, the u_id value is set to the local storage to identify each user when they request the Node.js server.💡PS: I'm using local storage because this is a small application. If you are using Hanko in a production environment, you may need to check out the backend guide.Congratulations!🎉 You've successfully added Hanko to a React application. In the upcoming section, we'll add all the necessary features to the blogging application.  Communicating with the Node.js serverIn this section, you'll learn how to communicate with the Node.js server by retrieving and creating posts within the application.Before we begin, create a utils folder containing a util.js file within the React app.cd clientmkdir utilscd utilstouch util.jsEnter fullscreen modeExit fullscreen mode  Displaying the blog postsCreate a posts array within the index.js file on the server.let posts = [    {        u_id: ""a123"",        post_id: ""1"",        title: ""Building a chat app with NextJS and Novu"",        slug: ""building-a-chat-app-with-nextjs-and-novu"",        content:            ""Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged."",        published_date: ""27-07-2023"",        likes: [{ u_id: ""12345"" }, { u_id: ""ancsd"" }],        dislikes: [{ user_id: ""12345"" }, { u_id: ""12345"" }],    },    {        u_id: ""b123"",        post_id: ""2"",        title: ""How to create an ecommerce app with NextJS and Novu "",        slug: ""how-to-create-an-ecommerce-app-with-nextjs-and-novu"",        content:            ""Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets."",        published_date: ""27-07-2023"",        likes: [{ u_id: ""12345"" }],        dislikes: [{ user_id: ""12345"" }],    },];Enter fullscreen modeExit fullscreen modeAdd another endpoint that returns the posts in JSON format.app.get(""/posts"", (req, res) => {    res.json({        posts,    });});Enter fullscreen modeExit fullscreen modeNext, create a function within the utils/util.js file that sends a request to the endpoint from the React app.export const fetchAllPosts = (setLoading, setPosts) => {    fetch(""http://localhost:4000/posts"")        .then((res) => res.json())        .then((data) => {            setLoading(false);            setPosts(data.posts);        })        .catch((err) => console.error(err));};Enter fullscreen modeExit fullscreen modeFinally, execute the function when the Home component mounts.import React, { useCallback, useEffect, useState } from ""react"";import { Link } from ""react-router-dom"";import { fetchAllPosts } from ""../utils/util"";const Home = () => {    const [loggedIn, setLoggedIn] = useState(false);    const [posts, setPosts] = useState([]);    const [loading, setLoading] = useState(true);    const fetchPosts = useCallback(() => {        fetchAllPosts(setLoading, setPosts);    }, []);    useEffect(() => {        if (localStorage.getItem(""loggedIn"")) {            setLoggedIn(true);        }        fetchPosts();    }, [fetchPosts]);    if (loading) return <p>Loading...</p>;    return (        <div>            <nav className='navbar'>                <Link to='/' className='logo'>                    <h2>MyBlog</h2>                </Link>                <div style={{ display: ""flex"", alignItems: ""center"" }}>                    {loggedIn ? (                        <Link to='/post/new' className='newPostBtn'>                            New Post                        </Link>                    ) : (                        <Link to='/login' className='newPostBtn'>                            Log in                        </Link>                    )}                </div>            </nav>            <main className='main'>                <h2 className='heading'>Latest Posts</h2>                <div className='posts_container'>                    {posts?.map((post) => (                        <Link to={`/post/${post.slug}`} className='post' key={post.post_id}>                            <h2 className='post_title'>{post.title}</h2>                        </Link>                    ))}                </div>            </main>        </div>    );};export default Home;Enter fullscreen modeExit fullscreen modeThe code snippet above fetches all the posts from the server when the page mounts and displays them within the React app. It also checks if the user is authenticated to display either the Login or New Post buttons.  Retrieving the posts' detailsHere, you need to fetch a post's details when you click on it from the Home page. To do this, you need to filter the array of posts via its slug property.Create another POST route that filters the posts array by a post's slug and returns the entire post object.app.post(""/post/details"", (req, res) => {    const { slug } = req.body;    const result = posts.filter((post) => post.slug === slug);    res.json({ post: result[0] });});Enter fullscreen modeExit fullscreen modeAdd a function within the utils/util.js file that sends a request to the post/details endpoint and returns the post object.export const fetchPostContent = (slug, setLoading, setPost) => {    fetch(""http://localhost:4000/post/details"", {        method: ""POST"",        body: JSON.stringify({ slug: slug }),        headers: {            Accept: ""application/json"",            ""Content-Type"": ""application/json"",        },    })        .then((res) => res.json(res))        .then((data) => {            setLoading(false);            setPost(data.post);        })        .catch((err) => console.error(err));};Enter fullscreen modeExit fullscreen modeImport the function into the Details.jsx component.import { useParams } from ""react-router-dom"";import { fetchPostContent } from ""../utils/util"";const Details = () => {    const { slug } = useParams();    const [post, setPost] = useState({});    const [loading, setLoading] = useState(true);    const fetchPostDetails = useCallback(() => {        fetchPostContent(slug, setLoading, setPost)    }, [slug]);    useEffect(() => {        fetchPostDetails();    }, [fetchPostDetails]);    if (loading) return <p>Loading...</p>;    return (        <div>....</div>    )Enter fullscreen modeExit fullscreen modeUpdate the UI elements to display the post details accordingly.return (    <div>        <header className='details_header'>            <h1 className='details_heading'>{post.title}</h1>            <div className='post_details'>                <div>                    <p className='details_date'>Posted on {post.published_date}</p>                </div>                <div className='reactions-group'>                    <button                        className='reactBtn'                        onClick={() => reactToPost(slug, ""like"")}                    >                        Like <AiTwotoneLike />{"" ""}                        <span style={{ marginLeft: 5 }}>{post.likes.length}</span>                    </button>                    <button                        className='reactBtn unlikeBtn'                        onClick={() => reactToPost(slug, ""dislike"")}                    >                        Dislike <AiTwotoneDislike />                        <span style={{ marginLeft: 5 }}>{post.dislikes.length}</span>                    </button>                </div>            </div>        </header>        <main className='details_body'>{post.content}</main>    </div>);Enter fullscreen modeExit fullscreen mode  Reacting to blog postsFirst, you need to create an endpoint on the Node.js server that updates the number of likes and dislikes property of a post when a user clicks the button from the user interface.app.post(""/post/react"", async (req, res) => {    const { slug, type, u_id } = req.body;    //👇🏻 like post functionality    for (let i = 0; i < posts.length; i++) {        if (posts[i].slug === slug && type === ""like"") {            //👇🏻 validates the post reaction            const validateLike = posts[i].likes.filter(                (likes) => likes.u_id === u_id            );            if (validateLike.length === 0) {                posts[i].likes.push({ u_id });                res.json({ message: ""You've just liked a post"" });            }        }        //👇🏻 dislike post functionality        if (posts[i].slug === slug && type === ""dislike"") {            //👇🏻 validates the post reaction            const validateDislike = posts[i].dislikes.filter(                (dislikes) => dislikes.u_id === u_id            );            if (validateDislike.length === 0) {                posts[i].dislikes.push({ u_id });                const sendNotifcation = await notify(""liked"", u_id);                res.json({ message: ""You've just disliked a post"" });            }        }    }});Enter fullscreen modeExit fullscreen modeThe code snippet above handles the user's reaction to posts. It filters the posts array via the post's slug and validates the post reaction to ensure that the user has not reacted to the post, before updating the property accordingly.Create a function within the utils/util.js file that sends a request to the endpoint when a user clicks the Like and Dislike buttons.export const postReaction = (slug, type) => {    fetch(""http://localhost:4000/post/react"", {        method: ""POST"",        body: JSON.stringify({ slug, type, u_id: localStorage.getItem(""u_id"") }),        headers: {            Accept: ""application/json"",            ""Content-Type"": ""application/json"",        },    })        .then((res) => res.json(res))        .then((data) => alert(data.message))        .catch((err) => console.error(err));};Enter fullscreen modeExit fullscreen modeExecute the function when a user clicks on the buttons.import { postReaction } from ""../utils/util"";const Details = () => {    //👇🏻 calls the function    const reactToPost = (slug, type) => {        postReaction(slug, type);    };    return (        <div>            <header className='details_header'>                <h1 className='details_heading'>{post.title}</h1>                <div className='post_details'>                    <div>                        <p className='details_date'>Posted on {post.published_date}</p>                    </div>                    <div className='reactions-group'>                        {/*-- like button*/}                        <button                            className='reactBtn'                            onClick={() => reactToPost(slug, ""like"")}                        >                            Like <AiTwotoneLike />{"" ""}                            <span style={{ marginLeft: 5 }}>{post.likes.length}</span>                        </button>                        {/*-- Dislike button*/}                        <button                            className='reactBtn unlikeBtn'                            onClick={() => reactToPost(slug, ""dislike"")}                        >                            Dislike <AiTwotoneDislike />                            <span style={{ marginLeft: 5 }}>{post.dislikes.length}</span>                        </button>                    </div>                </div>            </header>            <main className='details_body'>{post.content}</main>        </div>    );};export default Details;Enter fullscreen modeExit fullscreen mode  Creating new postsCreate an endpoint that adds a new post to the posts array.//👇🏻 creates post slugconst createSlug = (text, id) => {    let slug = text        .trim()        .toLowerCase()        .replace(/[^\w\s-]/g, """");    slug = slug.replace(/\s+/g, ""-"");    return slug + ""-"" + id;};//👇🏻 generates a random string as IDconst generateID = () => Math.random().toString(36).substring(2, 10);app.post(""/post/add"", (req, res) => {    const { u_id, title, content, date } = req.body;    const postObject = {        u_id,        post_id: generateID(),        title,        slug: createSlug(title, generateID()),        content,        published_date: date,        likes: [],        dislikes: [],    };    posts.unshift(postObject);    res.json({ message: ""Post added successfully!✅"" });});Enter fullscreen modeExit fullscreen modeThe code snippet above creates a new post object and adds the newly created post to the posts array.Add a function that sends a request to the endpoint within the utils/util.js file.export const addNewPost = (u_id, title, content, date, navigate) => {    fetch(""http://localhost:4000/post/add"", {        method: ""POST"",        body: JSON.stringify({ u_id, title, content, date }),        headers: {            Accept: ""application/json"",            ""Content-Type"": ""application/json"",        },    })        .then((res) => res.json(res))        .then((data) => {            alert(data.message);            navigate(""/"");        })        .catch((err) => {            console.error(err);            alert(""Encountered an error ❌"");        });};Enter fullscreen modeExit fullscreen modeExecute the function when the user submits the form within the NewPost.jsx file.//👇🏻 formates the date to a readable stringconst formatDate = () => {    const date = new Date();    const day = String(date.getDate()).padStart(2, ""0"");    const month = String(date.getMonth() + 1).padStart(2, ""0"");    const year = date.getFullYear();    return `${day}-${month}-${year}`;};//👇🏻 executes on form submitconst handleSubmit = (e) => {    e.preventDefault();    //👇🏻 adds the new post    addNewPost(        localStorage.getItem(""u_id""),        title,        content,        formatDate(),        navigate    );    setContent("""");    setTitle("""");};Enter fullscreen modeExit fullscreen mode  Sending in-app notifications with Novu 📳Here, we need to notify the post authors when someone reacts to their posts. To do this, we'll use Novu - an open-source notification infrastructure that enables you to send in-app, SMS, chat, push, and e-mail notifications from a single dashboard.  Creating a Novu projectNavigate into the client folder and create a Novu project by running the code below.cd clientnpx novu initEnter fullscreen modeExit fullscreen modeSelect your application name and sign in to your Novu dashboard. The code snippet below contains the steps you should follow after running npx novu init.Now let's setup your account and send your first notification? What is your application name? Forum App? Now lets setup your environment. How would you like to proceed? Create a free cloud account (Recommended)? Create your account with: Sign-in with GitHub? I accept the Terms and Conditions (https://novu.co/terms) and have read the Privacy Policy (https://novu.co/privacy) Yes✔ Created your account successfully.Enter fullscreen modeExit fullscreen modeVisit the demo page, copy your subscriber ID from the page, and click the Skip Tutorial button.Create a notification template with a workflow as shown below:Novu Digest allows you to control how you send notifications in your app. It collects multiple trigger events, schedules them, or sends them as a single message.Update the In-App notification step to send this message to the post author when someone reacts to their post.You have a new {{reaction}} on your post.Enter fullscreen modeExit fullscreen mode  Adding Novu notification bell to a React appNovu in-app notification uses a notification bell to send alerts to users. Here, you'll learn how to add it to your React applications.Install the Novu Notification package.npm install @novu/notification-centerEnter fullscreen modeExit fullscreen modeCreate a Novu.jsx file within the components folder and copy the below into the file.import React from ""react"";import {    NovuProvider,    PopoverNotificationCenter,    NotificationBell,} from ""@novu/notification-center"";import { useNavigate } from ""react-router-dom"";function Novu() {    const navigate = useNavigate();    const onNotificationClick = (notification) =>        navigate(notification.cta.data.url);    return (        <>            <NovuProvider                subscriberId='<YOUR_SUBSCRIBER_ID>'                applicationIdentifier='<YOUR_APP_ID>'            >                <PopoverNotificationCenter                    onNotificationClick={onNotificationClick}                    colorScheme='light'                >                    {({ unseenCount }) => <NotificationBell unseenCount={unseenCount} />}                </PopoverNotificationCenter>            </NovuProvider>        </>    );}export default Novu;Enter fullscreen modeExit fullscreen modeThe code snippet above enables us to add Novu's notification bell icon to the application. With this, you can view all the notifications within the app.Select Settings on your Novu Admin Panel to copy your App ID and replace the subscriber's ID placeholder with yours.Import the Novu.jsx component into the Home.jsx component.const Home = () => {    return (        <div>            <nav className='navbar'>                <Link to='/' className='logo'>                    <h2>MyBlog</h2>                </Link>                <div style={{ display: ""flex"", alignItems: ""center"" }}>                    {/*---👇🏻 Novu component👇🏻---*/}                    <Novu />                    {loggedIn ? (                        <Link to='/post/new' className='newPostBtn'>                            New Post                        </Link>                    ) : (                        <Link to='/login' className='newPostBtn'>                            Log in                        </Link>                    )}                </div>            </nav>            {/*--- other components ---*/}        </div>    );};Enter fullscreen modeExit fullscreen mode  Configuring Novu on a Node.js serverInstall the Novu SDK for Node.js into the server folder.npm install @novu/nodeEnter fullscreen modeExit fullscreen modeImport Novu from the package and create an instance using your API Key.const { Novu } = require(""@novu/node"");const novu = new Novu(""<YOUR_API_KEY>"");Enter fullscreen modeExit fullscreen modeCreate a function within the index.js file that sends notification to the post author via Novu.const notify = async (reaction, userID) => {    await novu.subscribers.identify(userID, {        firstName: ""inAppSubscriber"",    });    const response = await novu.trigger(""notify"", {        to: {            subscriberId: ""<YOUR_SUBSCRIBER_ID>"",        },        payload: {            reaction,        },    });    return response.data.data;};Enter fullscreen modeExit fullscreen modeExecute the function when a user reacts to a post.app.post(""/post/react"", async (req, res) => {    const { slug, type, u_id } = req.body;    for (let i = 0; i < posts.length; i++) {        if (posts[i].slug === slug && type === ""like"") {            const validateLike = posts[i].likes.filter(                (likes) => likes.u_id === u_id            );            if (validateLike.length === 0) {                posts[i].likes.push({ u_id });                //👇🏻 Triggers Novu                const sendNotifcation = await notify(""like"", u_id);                if (sendNotifcation.acknowledged) {                    res.json({ message: ""You've just liked a post"" });                }            }        }        if (posts[i].slug === slug && type === ""dislike"") {            const validateDislike = posts[i].dislikes.filter(                (dislikes) => dislikes.u_id === u_id            );            if (validateDislike.length === 0) {                posts[i].dislikes.push({ u_id });                //👇🏻 Triggers Novu                const sendNotifcation = await notify(""dislike"", u_id);                if (sendNotifcation.acknowledged) {                    res.json({ message: ""You've just disliked a post"" });                }            }        }    }});Enter fullscreen modeExit fullscreen modeCongratulations! You've completed the application.  ConclusionSo far, you've learnt how to authenticate users with Hanko, communicate between a React and Node.js app, and send in-app notifications using the Novu Digest.Novu enables you to create a rich notification system in your applications, thereby providing a great user experience for your users. You should also try out Hanko - it is minimal and easy to integrate.The source code for this tutorial is available here:https://github.com/novuhq/blog/tree/main/hanko-auth-blog-with-novu.Thank you for reading!"
117,"Hey there! I’m the CTO of a web3 startup, and before that, I was a senior engineer working on infrastructure and full-stack systems at Google. I’ve learnt a few things along the way about coding, and today, I’m excited to dive into something that we often overlook until it’s too late: error handling and logging.When I first jumped ship from Google to start my own venture, it was all about moving fast, hacking stuff together, and making things work. One thing that I initially put on the back burner was implementing a robust error handling and logging system. After all, why waste time preparing for errors when you can just code to avoid them, right? Well, fast forward to countless hours spent debugging and troubleshooting, and I’ve learnt my lesson.In this post, I’ll share with you some practical tips and best practices on error handling and logging that I’ve picked up, alongside examples from my own experiences. If I knew back then what I know now, I would have set up error handling right from the start. But as they say, hindsight is 20/20.Let’s get into it!  Why is Error Handling Important?Before we dive into the practicalities, let’s take a moment to consider why error handling is important. Well, for starters, errors are inevitable. No matter how careful you are, how experienced your team is, or how thorough your QA process might be, things can and will go wrong. That’s just the reality of software development.Debugging: A proper error handling and logging system can make debugging significantly easier and faster. By having detailed error messages and logs, you can trace back the series of events that led to the error, making it easier to reproduce and fix.Resilience: Handling errors appropriately can make your system more resilient. Instead of crashing the whole system, a well-placed try/catch can contain the error and allow the system to recover and continue running.User Experience: Users don’t like seeing raw error messages or, worse, having the app crash on them. Good error handling can allow you to provide user-friendly error messages and fallbacks, leading to a better user experience.Security: Detailed error messages can reveal more about your system than you might want. You can avoid potential security risks by controlling what gets revealed in an error message.  Getting Hands-on with Error HandlingNow, let’s get down to business. How do you handle errors effectively in a backend environment? There’s no one-size-fits-all answer, as it heavily depends on your tech stack, team size, project complexity, and a dozen other factors. That being said, there are some universally good practices to adhere to.  1. Centralized Error HandlingIt’s a good practice to centralize your error handling as much as possible. This approach simplifies code readability and maintainability and ensures consistency. If you’re using a framework like Express.js, you can use middleware for this.Here’s a simplified example:app.use((err, req, res, next) => {  console.error(err.stack);  res.status(500).send('Something broke!');});Enter fullscreen modeExit fullscreen modeThis error-handling middleware would catch errors that occur in your route handlers and send a generic response. But what about sending more user-friendly messages or dealing with different error types? That’s where custom error classes come in.  2. Custom Error ClassesCustom error classes in JavaScript (or whatever language you’re using) allow you to create specific error types, each potentially having its own error handling. Here’s a simple example:class ValidationError extends Error {  constructor(message) {    super(message);    this.name = ""ValidationError"";    this.statusCode = 400;  }}class DatabaseError extends Error {  constructor(message) {    super(message);    this.name = ""DatabaseError"";    this.statusCode = 500;  }}Enter fullscreen modeExit fullscreen modeWith these classes, you can throw specific errors in your code, and your error-handling middleware can behave differently depending on the error type.app.use((err, req, res, next) => {  if (err instanceof ValidationError) {    res.status(err.statusCode).send(err.message);  } else if (err instanceof DatabaseError) {    res.status(err.statusCode).send('A database error occurred');  } else {    res.status(500).send('Something broke!');  }});Enter fullscreen modeExit fullscreen modeThese are just simplified examples. In a real-world scenario, you might log the errors to an external service, handle more error types, etc.  3. Proper use of Try/CatchTry/catch blocks are your bread and butter for catching errors as they occur. It’s important only to catch errors that you can handle. If you can’t handle the error (for example, you don’t know why it would occur), it’s usually better to let it bubble up to the global error handler.Here’s a good use of a try/catch block:try {  const user = await getUserFromDb(userId);} catch (err) {  if (err instanceof NotFoundError) {    // We know why this error occurred and we can handle it    return createNewUser(userId);  }  // We can't handle any other errors, rethrow them  throw err;}Enter fullscreen modeExit fullscreen modeHere, we’re only catching a specific error that we know might happen and that we can handle. Any other errors get rethrown and can be handled by our global error handler.  The Importance of Good LoggingNow, while error handling is about dealing with errors as they occur, logging is about recording what happened so you can look back on it in the future. This can be extremely helpful when debugging.There are several things you should consider when implementing logging:What to log: You want to log any information that might be useful for debugging. This can include input parameters, output results, and any intermediate variables. However, be aware of privacy and security issues. Never log sensitive information like passwords.When to log: Ideally, you want to log as much as possible, but there’s always a trade-off between detail and performance/storage. Consider using different log levels (error, warning, info, debug) to control this.Where to log: For local development, logging into the console might be sufficient. But for a production system, you’ll want to use a logging service that can handle large volumes of logs, manage retention policies, and provide search and analysis tools. This could be a cloud service like Google’s Cloud Monitoring, a self-hosted solution like Elasticsearch, or a log management service like Loggly or Datadog.Here’s an example of how you might log a function’s input and output:function add(a, b) {  console.log(`add was called with ${a} and ${b}`);  const result = a + b;  console.log(`add result is ${result}`);  return result;}Enter fullscreen modeExit fullscreen modeIn a production scenario, you’d replace console.log with a call to your logging library or service, and you might add more detail (like a timestamp or the name of the function).  Final ThoughtsI hope this post has given you a practical insight into error handling and logging in backend development. If there’s one thing I want you to take away from this, it’s that error handling and logging are not an afterthought. They are an integral part of your code that can save you countless hours of debugging and many headaches. So, invest the time upfront to set up a good error handling and logging system. You’ll thank yourself later!Stay tuned for future posts where I plan to delve deeper into some of these topics. If you have any questions, feel free to drop a comment or reach out to me. Happy coding!For more coding tutorials, please subscribe to my YouTube channel: https://www.youtube.com/@CtrlAltVictoria and Twitter https://twitter.com/ctrlaltvictoria 💕🚀"
118,"Scrolling through a website especially with a notched mouse wheel is typically jumpy and harder to navigate.Smooth Scrolling, or spring scrolling adds an animated touch to the traditional mouse scroll.If you've never experienced smooth scrolling before, try out the Live Demo.  ConceptConsider the viewport window.  When a bunch of HTML elements combine to a size taller than the window, it overflows and can be accessed when you scroll down.To override the default scroll, we need to wrap the content in a fixed element we can control.Finally, we will create an invisible spacer (div) equal to the scroll height of the content.  This will trigger the browser's default scroll bar.  SetupCreate a React Typescript Repl on Replit to get started.Install Framer Motion with npm install framer-motion.  The  ComponentThe <SmoothScroll/> Component will wrap all the HTML elements we want to incorporate in the Smooth Scrolling effect.export default function SmoothScroll({  children}: {  children: React.ReactNode;}) {  return <></>;}Enter fullscreen modeExit fullscreen mode  Scroll & Spring ValuesImport the following hooks from framer-motion.import { useScroll, useSpring, useTransform } from 'framer-motion';Enter fullscreen modeExit fullscreen modeIn the SmoothScroll component, destructure scrollYProgress from the useScroll hook.const { scrollYProgress } = useScroll();Enter fullscreen modeExit fullscreen modeNext, use the useSpring hook to apply the smooth effect to the scrollYProgress value.const smoothProgress = useSpring(scrollYProgress, { mass: 0.1 })Enter fullscreen modeExit fullscreen mode  Content & SpacerAdd the motion component to the existing import from framer-motion.- import { useScroll, useSpring } from 'framer-motion';+ import { motion, useScroll, useSpring } from 'framer-motion';Enter fullscreen modeExit fullscreen modeSkip down to the component's return statement.  Return an empty <div> element and a <motion.div> element which renders the children prop as a child.return <>  <div style={{ height: contentHeight }} />  <motion.div    className=""scrollBody""  >    {children}  </motion.div></>Enter fullscreen modeExit fullscreen modeCreate a contentRef react reference via the useRef hook and a contentHeight state with useState.import { useState, useRef } from 'react';...const contentRef = useRef<HTMLDivElement>(null);const [contentHeight, setContentHeight] = useState(0);Enter fullscreen modeExit fullscreen modeAssign the content wrapper the contentRef.<motion.div  className=""scrollBody""  ref={contentRef}>  {children}</motion.div>Enter fullscreen modeExit fullscreen modeUse the style prop to make the spacer have a height of contentHeight.<div style={{ height: contentHeight }} />Enter fullscreen modeExit fullscreen mode  Resize HandlerWhen the window gets resized, the height of the content content is likely to change.  Since the contentHeight value is a state, we will need to update it whenever the window resizes, and when the contentRef reference updates.Start by importing the useEffect hook from react.- import { useState, useRef } from 'react';+ import { useEffect, useState, useRef } from 'react';Enter fullscreen modeExit fullscreen modeWithin the useEffect hook, create and call a handler to set the contentHeight value to contentRef.current.scrollHeight.Add contentRef to the dependency array.useEffect(() => {  const handleResize = () => {    if (contentRef.current) {      setContentHeight(contentRef.current.scrollHeight)    }  }  handleResize();}, [contentRef]);Enter fullscreen modeExit fullscreen modeFinally, add a resize event listener to window in the useEffect hook, and return a disposer function.useEffect(() => {  ...  window.addEventListener(""resize"", handleResize);  return () => {    window.removeEventListener(""resize"", handleResize);  }}, [contentRef, children]);Enter fullscreen modeExit fullscreen mode  Put it all togetherImport the useTransform hook from framer-motion.- import { motion, useScroll, useSpring } from 'framer-motion';+ import { useTransform, motion, useScroll, useSpring } from 'framer-motion';Enter fullscreen modeExit fullscreen modeCreate a constant y and set it to the useTransform hook with smoothProgress as the initial value.const y = useTransform(smoothProgress, value => {  return value;});Enter fullscreen modeExit fullscreen modeVisualizing how to calculate the scroll, we will be subtracting the viewport height from the content container's scroll height, multiplying it by -1, and then by value.const y = useTransform(smoothProgress, value => {  return value * -(contentHeight - window.innerHeight);});Enter fullscreen modeExit fullscreen modeUse the y transformed value in the content container.<motion.div  className=""scrollBody""  style={{ y }}  ref={contentRef}>  {children}</motion.div>Enter fullscreen modeExit fullscreen mode  StylesI already fought CSS so you won't have to.  Simply copy and paste the bare minimum CSS over and the scroll component will be ready to roll..scrollBody {  width: 100vw;  position: fixed;  top: 0;  display: flex;  flex-direction: column;}Enter fullscreen modeExit fullscreen mode  Complete 🎉That's it!  All you have to do is add a bunch of HTML elements within the <SmoothScroll /> component.Nothing better than fifty <h1>Lorem Ipsum</h1>s in your codebase.Source Code: https://replit.com/@IroncladDev/FramerSmoothScroll?v=1Live Demo: https://framersmoothscroll.ironcladdev.repl.coThanks for reading.  If you have any feedback or recommendations for this article, I'd love to hear it in the comments.Let's get in touch 🤝🐱 Github🦜 Twitter⠕ Replit🌐 Website"
119,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers!🏆 Which coding challenge or puzzle felt like winning the Nobel Prize for developers when you finally cracked it?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
120,"  IntroductionThe frontier of AI research has seen remarkable intersections. Merging the domains of computer vision and natural language processing, the question arises: Can an AI discern and understand language directly from its visual representation, i.e., from raw pixels? In this blog, I attempt to figure out how well AI can understand natural language directly from raw pixels.The link to the repository is here. Please keep in mind that the project is WIP and that the README and code still require some tweaking.  Problem StatementInterpreting language from visual cues isn’t merely an OCR task; it’s about understanding context, semantics, and even masked information. In Layman’s terms, I am trying to figure out how well AI models can understand text from raw image pixels, the same way we do. To that end, I used the self-supervised masked-language modeling (MLM) paradigm.Fig 1 - Examples of small, medium and large images used for training. Tokens were masked similarly to the BERT MLM task. Texts with less than 50 tokens are considered small, less than 100 medium and others are large. This was done to make data generation easier. It was also motivated by curriculum learning. The dataset contains many font sizes and font types.To provide a bit of context — initially, I structured the task without the MLM part. The goal was to literally reconstruct the text from an image, the same way OCR does it but end-to-end. This worked fine, but the model failed to understand the text.To alleviate that issue, I masked some words on the image, leaving the target text unmasked; several examples can be seen on Fig 1. This lead to a significant boost in terms of understanding the text, but there is still a lot of room for improvement and more ways to formulate the task. One of them could be to task the model with reconstructing removed pixel from an image.On a high level, the architecture is quite simple:Fig 2 — An overview of the architecture used for training. For downstream tasks, such as classification, the transformer decoder and linear layers are removed.The CNN is used to capture textual features and is important for convergence. Encoder should learn to understand the context, which is then used by the decoder to output either the reconstructed token or the predicted mask token. The linear layer maps the decoder’s output to a token from our vocabulary.It is possible the CNN layer can be removed (we can use patches similar to ViT), but I haven’t managed to get good results without it so far.  ArchitectureThis section is slightly more technical, so feel free to skip it if interested only in results!The project’s backbone relies on the hybrid Convolutional Neural Networks (CNNs) and transformers model. Lets dive a bit deeper into the architecture!Feature Extraction with CNNs - This layer was important for convergence, but merely increasing its complexity didn't amplify the results. This suggests potential saturation or the necessity for more intricate architectural adjustmentsResNetFeatureExtractor - Our model employs a ResNet-based CNN, slightly adjusted for the task at hand. This module takes care of converting the raw image into a flattened set of feature maps. Each of these feature maps captures intricate patterns present in the image, readying it for further processing.import torch.nn as nnfrom torchvision.models import resnet50class ResNetFeatureExtractor(nn.Module):    def __init__(self, feature_map_size, out_features_size):        super(ResNetFeatureExtractor, self).__init__()        self.feature_extractor = nn.Sequential(            *list(resnet50(pretrained=True).children())[:-2])        self.input_proj = nn.Conv2d(feature_map_size,                                    out_features_size,                                    kernel_size=1)    def forward(self, x):        x = self.feature_extractor(x)        x = self.input_proj(x)        x = x.view(x.size(0), x.size(1), -1).permute(0, 2, 1)        return xEnter fullscreen modeExit fullscreen modeSinePositionalEncoding: Subsequent to the ResNet module, the SinePositionalEncoding takes over. This layer is crucial, as it infuses our feature maps with positional information. Unlike sequences in pure NLP tasks, images don't inherently have a sequence, and this positional encoding provides our model with spatial insights. Below is the code used for the positional encoding. A potential improvement could be to use 2D positional encoding.class SinePositionalEncoding(nn.Module):    def __init__(self, d_model, max_len=1000):        super(SinePositionalEncoding, self).__init__()        pe = torch.zeros(max_len, d_model)        position = torch.arange(0, max_len).unsqueeze(1)        div_term = torch.exp(            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))        pe[:, 0::2] = torch.sin(position * div_term)        pe[:, 1::2] = torch.cos(position * div_term)        pe = pe.unsqueeze(0)        self.register_buffer(""pe"", pe)    def forward(self, x):        return x + self.pe[:, :x.size(1)].requires_grad_(False)Enter fullscreen modeExit fullscreen modeThe Transformer and VLP model - The choice of a transformer was motivated by its universal appeal and scalability. The input from the CNN was forwarded to a transformer encoder, which then passed its output to a transformer decoder. This encoder-decoder process allowed us to handle the image data token-by-token, including the prediction of masked tokens in some cases.Transformer configuration: With the model_config_factory function, our architecture remains highly configurable. It allows for the easy specification of model parameters like model_dim, num_heads, and more. This ensures that I can quickly adjust and scale our model based on the demands of our data and the insights from previous experiments. I follow the traditional transformer implementation; the full code can be found here.Below is the config used for the best performing model:...,""encoder_decoder_lg"": {  ""model_dim"": 768,  ""ff_dim"": 4096,  ""num_heads"": 16,  ""num_layers"": 12,  ""feature_map_size"": 2048, # from the resnet model  ""dec_div"": 2}, ...Enter fullscreen modeExit fullscreen modeVLP Class: This is the centerpiece. Once the image features are extracted using the feature_extractor, these features are passed into our transformer for processing. The structure of the transformer can vary based on the choice – an encoder, a decoder, or a combination of both.class VLP(nn.Module):    def __init__(self, model_dim, num_layers, ff_dim, num_heads,                 feature_map_size, vocab_size, dropout, transformer_type,                 dec_div):        super(VLP, self).__init__()        self.feature_extractor = nn.Sequential(            ResNetFeatureExtractor(feature_map_size=feature_map_size,                                   out_features_size=model_dim),            SinePositionalEncoding(model_dim))        self.transformer = get_transformer(num_layers=num_layers,                                           model_dim=model_dim,                                           ff_dim=ff_dim,                                           num_heads=num_heads,                                           vocab_size=vocab_size,                                           dropout=dropout,                                           transformer_type=transformer_type,                                           dec_div=dec_div)    def get_image_features(self, images):        return self.feature_extractor(images)    def forward(self, images, tgt=None, tgt_mask=None):        image_features = self.get_image_features(images)        return self.transformer(image_features, tgt, tgt_mask=tgt_mask)Enter fullscreen modeExit fullscreen modeHandling Text with VLPForTextMLM: Built on top of the VLP model, the VLPForTextMLM class is tailored for our Masked Language Model (MLM) task. It has an additional linear layer that maps the transformer's outputs to our desired number of classes (tokens).class VLPForTextMLM(nn.Module):    def __init__(self,                 model_dim,                 num_layers,                 num_heads,                 ff_dim,                 feature_map_size,                 num_classes,                 dec_div=2,                 dropout=0.0):        super(VLPForTextMLM, self).__init__()        self.vlp = VLP(num_layers=num_layers,                       model_dim=model_dim,                       ff_dim=ff_dim,                       num_heads=num_heads,                       feature_map_size=feature_map_size,                       vocab_size=None,                       dropout=dropout,                       transformer_type=""encoder"",                       dec_div=dec_div)        self.out = nn.Linear(model_dim, num_classes)    def forward(self, images):        out = self.vlp(images)        return self.out(out)Enter fullscreen modeExit fullscreen modeAsymmetry by Design - The encoder and decoder weren't symmetrical in size. An intentional design choice, the encoder was equipped with a significantly larger number of parameters. The aim was to have the encoder store as much linguistic knowledge as possible. This choice reflected positively on the MNLI dataset results.Inference is done in autoregressive fashion, using greedy decoding.  Data and TrainingOur training data for the MLM task comprised from the subsets (around 30–50% - because of hardware and time constraints) of Wikipedia and Bookcorpus datasets, with texts filtered to maintain a length of less than 144 tokens. The largest portion of my time went into creating the dataset - there are still many more improvements on this front. The model was trained for around 1.5M iterations, with a batch size of 16. The encoder_decoder_lg variant of the model has 129M parameters.The choice of this token length was a balance between computational efficiency and sufficient contextual information. Also, it is more difficult to create images with large texts.The training loop is quite simple:Forward passing the image through VLPForTextMLM.Calculating the loss based on the differences between the predicted tokens and actual tokens.Backpropagating the errors to adjust model weights.Iterating over this process for many iterations or until convergence or until the model's performance plateaus.I used the CrossEntropy loss, AdamW optimizer, OneCycle cosine anneal learning rate policy and mixed precision for training.  Results and ObservationsTo test the quality of learned representations, I trained the VLP model on the MNLI textual entailment downstream task. Given a premise sentence and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis (entailment), contradicts the hypothesis (contradiction), or neither (neutral). This is classification task, so the decoder layer is removed.Fig 3 - On the left is a image fed to the model and on the right is the attention map when inferring on the MNLI dataset. The attention map was extracted using the Integrated gradients method.Achieving an F1 score of 0.73 on the MNLI dataset, the model showed promise. However, it wasn’t devoid of challenges. Its heavy reliance on the CNN layer for convergence and stagnant results post CNN size increase, indicated potential bottlenecks.Fig 4 - Additional examples on validation images from the MNLI dataset. Both examples are correctly classified.To analyze the quality of learned embeddings, I performed linear probing on the imdb sentiment classification task (positive / negative) in two settings:Not limiting the number of tokens — in this setting, the VLP model achieved an F1 score of 0.7, comapred to BERT’s 0.8. This made sense, since the VLP model wasn’t trained on texts with more than 144 tokens.Limiting the number of tokens to 144 — in this setting, VLP faired a lot better, scoring an F1 score of 0.78, compared to BERT’s 0.82.Overall, linear probing showed promising results, but there is still a lot of room for potential refinements in the representation learning approach.Also, it would be interesting to explore how well the VLP model would scale with larger context sizes.Fig 5 — The model can recognize text decently even from random images from the internet. The output for this image is Pray Pathole and’’ Tech enthusiasts! My entire house is smart. Tech workers : The only piece of technology in my house is a printer and I keep a gun next to it so I can shoot it if it makes a noise I don’t recognize. 851 AM. April 12, 2019, Twitter for iphone 7, 387 feltees — 656 Oak Tweets 238K Likes _ Q — 11.  Current Status and Future DirectionsThe project, in its current state, works well for text recognition. It adeptly understands linguistic constructs such as verb usage, punctuation, and co-references. However, it faltered in tasks requiring memorization, such as The capital of France is [MASK] (wouldn't yield Paris). The project is ripe for exploration, with plans to train on datasets like SQUAD and Ontonotes.Some of the most obvious ways to address the performance plateau could be:expanding and improving the training datasets,revisiting the architecture and introducing alternative techniques.I am very eager to hear from fellow researchers and enthusiasts, your insights and contributions are very welcome! Please feel free to contact me if you have any ideas or questions! And thank you for taking the time to read this rather lengthy blog post, hope you had fun! 🙏😁Special thanks to Igor Tica and Nikola Tomic for giving me many notes and providing a very detailed review of the blogpost! 🙏Email: basarafilip@gmail.comLinkedIn: https://www.linkedin.com/in/filip-basara-84a694195/Twitter: https://twitter.com/basarafilipGithub: https://github.com/filipbasara0"
121,"Se você chegou até aqui, é provável que tenha se deparado com um problema muito comum para vários devs: o de precisar utilizar duas contas do GitHub na mesma máquina utilizando chaves SSH.Geralmente essa demanda surge quando temos uma conta pessoal e uma conta vinculada à empresa em que trabalhamos na plataforma, então ATENÇÃO: só faça se a sua empresa autorizar ter sua conta pessoal na máquina deles ou se eles autorizarem você a ter o projeto deles em sua máquina pessoal.Nota 1: Vou partir do pressuposto de que você possui uma conta principal (por exemplo, sua conta pessoal) e já utiliza a chave SSH no dia-a-dia e deseja de vez em quando utilizar outra conta em um diretório separado, sem misturar as coisas. Se você deseja utilizar dessa forma, aqui é o lugar certo.Obs: imagino também que já tenha o Git instalado, se não, baixe aqui e só depois prossiga com o tutorial.Nota 2: Existem outros tutoriais disponíveis, sobretudo em inglês e voltados para Linux. Portanto vou abordar o Windows e comentar sobre um problema nesse OS e como uma resposta no Stack Overflow me ajudou a resolver. No fim das contas é um condensado de informações já disponíveis que espero que te ajude! Não quero reinventar a roda.  Passo 1: Criar um novo par de chaves SSHSempre utilizo a expressão par de chaves, pois ao gerar uma nova chave temos a versão pública e a versão privada dessa chave.Para criar um novo par de chaves SSH, vá até a pasta .ssh (no Windows ela fica em C:\Users\seu_usuario\.ssh) e dentro dela abra um novo terminal Git Bash:Como terminal aberto, você rodará o seguinte comando:ssh-keygen -t ed25519 -C ""seu_email@provedor.com"" -f nome_da_chaveEnter fullscreen modeExit fullscreen modeSubstitua seu_email@provedor.com pelo seu e-mail e nome_da_chave pelo o nome que você prefira para identificar a chave.Lembra que eu comentei que parto do pressuposto de que você já possui um par de chaves cadastrada em sua máquina? Sem a parte final do comando que citei acima, ele geraria um par de chaves com o nome de id_ed25519 e substituiria as suas chaves originais caso você tenha gerado sem um nome personalizado da primeira vez. Portanto o -f nome_da_chave é importante nesse contexto para garantir uma identificação diferente e não apagar suas chaves iniciais.Ao rodar o comando, será solicitado que você digite uma senha para sua chave SSH e depois confirmá-la. Caso opte por não incluir uma senha, apenas prossiga sem digitar nada e aperte Enter nas duas oportunidades.Enter passphrase (empty for no passphrase):Enter fullscreen modeExit fullscreen modeE depois:Enter same passphrase again:Enter fullscreen modeExit fullscreen modeSe você gerou uma senha para seu par de chaves, convém adicioná-las ao ssh-agent. Ele vai gerenciar sua senha e deixar suas chaves prontas para uso sem que você precise ficar digitando sempre a sua senha. Se não colocou senha, apenas ignore esse passo.Para colocar suas chaves no ssh-agente, primeiro você tem que iniciá-lo com o seguinte comando:eval ""$(ssh-agent -s)""Enter fullscreen modeExit fullscreen modeE depois adicionar sua chave:ssh-add ~/.ssh/nome_da_chaveEnter fullscreen modeExit fullscreen modeSubstitua nome_da_chave pela identificação da chave que você criou anteriormente.No meu caso, eu não criei uma senha, pois fiz no meu computador pessoal, então não adicionei ao ssh-agent, mas é aquela conversa: o seguro morreu de velho.  Passo 2: Adicione a chave pública ao GitHubVocê pode copiar a chave pública de duas maneiras:Abrindo a chave com o final .pub em algum editor de texto e copiando todo o conteúdo com um simples Ctrl+C; ouRedigindo o seguinte comando (se estiver usando Windows e o Git Bash):clip <~/.ssh/nome_da_chave.pubEnter fullscreen modeExit fullscreen modePara outros OS, veja aqui como copiar a chave via terminal.Com a chave copiada, vá até o seu perfil no GitHub, entre nas configurações e depois em SSH and GPG Keys. Agora clique em Add new SSH Key e cole sua chave pública no campo Key. Se quiser, pode dar um nome para identificar a chave em Title. Depois disso é só confirmar e sua chave já está pronta para uso!  Passo 3: Configurar corretamente os perfis em sua máquinaDentro da pasta .ssh deve existir um arquivo chamado config. Caso ele não exista, você pode criá-lo. Com o Git Bash aberto na pasta .ssh, digite o seguinte comando:touch configEnter fullscreen modeExit fullscreen modeE para editar o arquivo, abra o em um editor de texto ou use um editor diretamente no terminal.Esse arquivo é o que fará o elo entre as suas chaves e o comando que você faz ao clonar um repositório em sua máquina. Ao visualizar o que há dentro do arquivo config, ele deve possuir os seguintes itens:Host github.com    HostName github.com    IdentityFile ~/.ssh/nome_da_chaveEnter fullscreen modeExit fullscreen modePorém como estamos falando de duas contas na mesma máquina, ele deverá possuir duas configurações diferentes. Para fazer isso, você precisa compreender os termos que estão ali no arquivo.Host: aqui você define para qual Host ou Hosts a configuração vai se aplicar. Em outras palavras: você tá criando uma identificação para determinado Host;HostName: especifica o nome real do Host, o endereço ao qual você irá se conectar;IdentityFile: especifica qual arquivo deverá ser lido ao se conectar ao Host.Dito isto, vamos especificar apenas Host e IdentityFile, enquanto para HostName usaremos sempre github.com, já que é lá que estão os repositórios.Se você já tinha chaves SSH e utilizava GitHub normalmente em sua máquina, sugiro que o seu Host dessa primeira chave continue como github.com. Caso seja alterado, você precisará atualizar a origin de todos os repositórios já clonados anteriormente.Sendo assim, o seu arquivo deve ficar assim:# sua primeira chaveHost github.com    HostName github.com    IdentityFile ~/.ssh/id_ed25519# chave que você criou seguindo esse artigoHost github.com-trabalho    HostName github.com    IdentityFile ~/.ssh/nome_da_chaveEnter fullscreen modeExit fullscreen modePercebam que para o segundo Host, o que fiz foi adicionar -trabalho após github.com na primeira linha e alterei o caminho para a nova chave criada.Seja livre para alterar da maneira que achar necessário. Você pode incluir o nome que quiser ali.A primeira parte está concluída, e agora vamos configurar o nosso arquivo .gitconfig. É nele que estão as configurações globais da nossa conta. Se tiver dúvidas de como seu Git está configurado, com o terminal aberto, digite o seguinte comando:git config --listEnter fullscreen modeExit fullscreen modeEle deverá retornar uma lista com algumas configurações, e as que importam para nós agora são user.email e user.name.user.name=Seu Nomeuser.email=seu_email@provedor.comEnter fullscreen modeExit fullscreen modeSe ele retornar pelo menos o user.email, significa que essa é a conta que está cadastrada globalmente em sua máquina. O que vamos fazer agora é criar uma verificação para esses dados. Basicamente ele vai funcionar assim:Se você clonar qualquer repositório em sua máquina, ele vai pegar as configurações globais;Porém se você clonar um repositório dentro de um diretório/pasta específico, ele irá utilizar as configurações da sua segunda conta e sua segunda chave SSH.O arquivo .gitconfig fica no seguinte endereço: C:\Users\seu_usuario\.gitconfig. Abra-o em algum editor de texto. Ele deverá se parecido com esse:[user]    email = seu_email@provedor.com     name = Seu NomeEnter fullscreen modeExit fullscreen modeO que faremos agora é criar uma verificar utilizando o includeIf, que nada mais é do que um inclua isso SE... . Dessa forma, vamos criar a seguinte regra: se for dentro da pasta tal, leia esse .gitconfig.Portanto seu arquivo deverá ficar assim:[user]    email = seu_email@provedor.com     name = Seu Nome[includeIf ""gitdir/i:C:/nome_da_pasta/""]    path = C:/nome_da_pasta/.gitconfigEnter fullscreen modeExit fullscreen modeRepararam que inclui um /i antes de :C:? Pois bem, ao incluir o /i, você está garantindo que ao ler a rota, sua regra será case insensitive, em outras palavras: ela vai ignorar se o texto está em caixa alta ou não. Como no Windows o padrão é que os drives contenham letras maiúsculas, você garante que o script conseguirá ser lido. Consegui resolver isso com ajuda do bom e velho Stack Overflow.Pois bem, agora o ajuste final: Você deverá criar a pasta em que guardará todos os repositórios que serão clonados com seu novo par de chaves SSH. Se repararem bem, no meu caso eu criei a pasta diretamente no drive C, mas você pode fazer como bem entender.Para finalizar, crie um arquivo .gitconfig dentro dessa pasta, e dentro dele coloque as configurações da sua segunda conta do GitHub. O arquivo deve ficar assim:[user]    email = seu_email@provedor.com    name = Seu NomeEnter fullscreen modeExit fullscreen modeIsso garantirá que seus commits estejam sempre vinculados à conta correta.  Passo 4: clone um repositórioPara clonar um repositório, vamos relembrar o Host citado mais atrás. Lembre-se dele ao clonar os repositórios para sua máquina.Entre na pasta que você criou o arquivo .gitconfig, abra o Git Bash e clone um repositório fazendo o seguinte: adicione o nome que você criou para seu Host logo após a @ e antes dos dois ponts :, como no exemplo abaixo:git clone git@{seu-novo-host}:{usuario}/{repositorio}.gitEnter fullscreen modeExit fullscreen modeSubstitua seu-novo-host pelo Host criado no passo 3. Lembre-se sempre de fazer essa pequena alteração ao clonar os repositórios para essa pasta específica. E pronto! A partir de agora você não terá nenhum tipo de problema com ao criar um novo commit e um novo push.  ConclusãoComo já citei anteriormente, sei que existem outros tutoriais, sobretudo em inglês, que abordam a mesma questão. Mas optei por trazer uma versão em português mais longa tentando abordar o funcionamento de cada passo e espero que isso ajude outras pessoas a entenderem melhor o funcionamento do Git e suas pequenas particularidades.Espero que tenha resolvido seu problema. Me conte nos comentários!  Referênciashttps://stackoverflow.com/questions/69988240/includeif-is-not-working-on-git-for-windowshttps://medium.com/@pinglinh/how-to-have-2-github-accounts-on-one-machine-windows-69b5b4c5b14ehttps://gist.github.com/rahularity/86da20fe3858e6b311de068201d279e3https://dev.to/fabriciadiniz/como-utilizar-duas-contas-do-github-no-mesmo-computador-windows-2348https://dev.to/devgirls/guia-gerenciando-2-ssh-keys-do-github-no-seu-pc-apmhttps://dev.to/giovanisleite/como-configurar-chaves-ssh-para-duas-ou-mais-contas-no-github-5de9https://medium.com/@timleland/copy-ssh-key-to-clipboard-183dbf6d2a39https://www.cyberciti.biz/faq/create-ssh-config-file-on-linux-unix/https://dev.to/dxwebster/como-conectar-ao-github-com-chaves-ssh-1i41"
122,"Share a coding experience that left you scratching your head in confusion. What was the problem, and how did you eventually figure it out? What lessons did you learn from that experience?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
123,"As a developer, presenting dates in a readable and user-friendly format is crucial for enhancing the user experience. In this comprehensive guide, we'll dive into various techniques to format dates in JavaScript, exploring different libraries and native methods, and providing code examples for each approach.1. Using JavaScript's Native Date Methods:JavaScript'sDate object offers several methods to retrieveindividual date components, which you can then assemble into your desired format:2. Using Intl.DateTimeFormat:3. Using Libraries (moment.js - Deprecated, date-fns, Luxon, Day.js):Using libraries provides more advanced and flexible date formatting options:Best Practices:Consider User Locale: When using native methods or Intl.DateTimeFormat, consider users' preferred locale for proper date formatting.Library Selection: While libraries provide powerful formatting capabilities, consider the trade-offs in terms of performance and bundle size.Consistency: Maintain consistent date formats across your application for a better user experience.Conclusion:Formatting datesin JavaScriptis a skill that enhances the usability of your applications. By leveraging JavaScript's native methods or utilizing specialized libraries, you can easily customize date presentation to match your application's needs.LinkedIn Account : LinkedInTwitter Account: TwitterCredit: Graphics sourced from JFormatting Dates in JavaScript: A Comprehensive Guide"
124,"Open Source thrives through shared efforts. Whether you're a newcomer or a veteran, we're here to encourage your contributions, motivate your endeavors, and provide valuable assistance to maintainers. Together, we are building amazing things!  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy contributing!"
125,Imposter syndrome is common among developers. How do you deal with self-doubt and feelings of inadequacy when coding? What advice would you give to others facing similar challenges?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik
126,"In the few years I've been working in tech, I've started to see common patterns that engineers adopt to solve most problems. For example, here's a popular problem with different approaches:Problem: The way we clean our client's archives is complex and messy.  Craftsman's scope - How to make the piece better?""Maybe we can simplify the clean up script. Can we possibly use another language with built-in features we can leverage, maybe one with less dependencies?""It's the stereotypical engineering work we find in TV and movies. This is the scope that can spend days or years focused on extracting +5% of efficiency out of a component. It's where algorithms are born and faster compute time is achieved.  Architect's scope - How to make the system better?""Since the data is spread out evenly, maybe we can create a centralized service that cleans each archive at a certain frequency?""The Architect scope is focused on arranging the pieces to produce an elegant system. Tools for this problem are still rooted in technology, but seen through a lens that encompasses more abstract concepts like patterns, relationships, coordination, and communication.  Entrepreneurial's scope - How to serve the client better?""Maybe we should confirm that our users even need this data. How often do they access it? Can they live with only the last X number of backups?""In this scope, technology is simply a giant lever to fill a real need. Communication and vision are the most useful tools here since uncovering needs and addressing them efficiently is much more about understanding than technology's use.  Finding a great solution requires the right mixI believe much of what plagues software engineering is that we simply copy roles from other disciplines, but we don't organize our thinking around what those roles actually mean. Or ignore the fact that some scopes tend to misalign with people's preference.Titles like ""architect"", ""senior engineer"", and ""manager"" should technically embody one scope over the other, but I rarely see that level of separation in thinking. Especially when those positions are filled by engineers who have spent years looking at problems deeply through a Craftsman scope.""If you've ever had a manager spend hours preaching the benefits of a mapping library, while you have yet to have a talk about your career progression, you can see the scope misuse at work"" My hypothesis: When the three scopes are used effectively, teams are much more productive in achieving the best possible solution to a given problem.   Have you seen these scopes in the wild? Do you lean towards one more than the other?Image references:Photo by Markus Spiske on UnsplashPhoto by Rob Lambert on UnsplashPhoto by ThisisEngineering RAEng on UnsplashPhoto by Clem Onojeghuo on Unsplash"
127,"Hello everyone! In this post I would like to share with you my recent development on my very own tiny wrapper for OpenAI API.   MotivationNowadays, every programmer who wants to build a production-ready LLM application, inevitable stumbles upon certain libraries such as LangChain, Semantic Kernel, Guidance etc. Then a lot of developers quickly grow frustrated and disappointed in their stack choice. Why? Because all these tools introduce unnecessary abstractions, add complicated logic and hide prompts they are using. As a result, the development starts to resemble a very tedious task even for simple applications. In fact, you don't need anything to work with existing Open AI API. You don't even need any wrappers, all you need to get started is just using your own logic, reasoning and naked API calls via your preferred programming language. I created the wrapper based on my experience and my current tasks and thought it would probably be useful for a larger audience.   ConceptI had some requirements in mind which I tried to convey in code: No hard-coded prompts. It's just a text, if you feel like your prompts are not working, there are thousands of them over the internet available for freeConversation history should be stored by default. This is a chat model anyway, so it's a good idea for the conversation history to be stored as a dictionary for consistent experience. It's easier to implement a method to clear the history rather than constructing the historyToken count validation. Tokens should be counted and if the amount exceeds the available quota, the program should reduce the messages or at least produce a warning or an errorNo hard-coded complicated logic for any chains/agents etc. It should implement only basic methods, while anything else should be done by the developer. Later below I will show that it's quite easy  LloomWith concepts listed above, I have implemented and released ""lloom"" version 0.0.1: https://github.com/zakharsmirnoff/lloom. It's available via pip, the documentation for methods can be found on github. Here I would like to give some examples in comparison with Langchain.  ExamplesOne of the main use cases for GPT-powered applications is summarization. I studied this page in Langchain docs and implemented the same logic using my wrapper:from lloom import LloomConfig, Lloomfrom pypdf import PdfReaderimport re# I'm using PdfReader package for processing PDF docs, the pdf here is a paper available on arxivreader = PdfReader(""virtual_injection.pdf"")config = LloomConfig(your_api_key, model=""gpt-3.5-turbo-0613"")lloom = Lloom(config)answers = []# A minimal helper function to achieve a stuff chain. I know it's not exactly stuff chain as in Langchain documentation, but the concept is similar: putting the whole document into the prompt. I just split the PDF by pagesdef one_shot(text):    res = loom.generate(f""Write a concise summary of the following: {text}"")    answers.append(res)    loom.clear_history()# The code below took approximately 1.5 minutes to execute, as a result we got a list with gpt-generated summaries. I chose only 11 first pages, since the rest is examples and referencesfor page in reader.pages[0:11]:    text = page.extract_text()    one_shot(text)# This single line of code along with the function above implements a map-reduce chainsummary = loom.generate(f""Write a short and concise summary for these pieces of text: {', '.join(answers)}"")print(summary) # it gave me this: '''The papers introduce the concept of Virtual Prompt Injection (VPI) as a method to manipulate the behavior of Large Language Models (LLMs) without directly modifying the model input.VPI allows an attacker to control the model's responses by specifying a virtual prompt, leading to biased views and potentially harmful outcomes.The papers propose a method for performing VPI by poisoning the model's instruction tuning data and demonstrate its effectiveness in steering the LLM's behavior.They emphasize the importance of ensuring the integrity of instruction tuning data and suggest data filtering as a defense against poisoning attacks.The effectiveness of VPI is evaluated in various scenarios such as sentiment steering and code injection, with comparisons to baseline methods and different model scales.The papers also discuss defense mechanisms and the need for further research in this area to develop better defense mechanisms against VPI attacks.The limitations of the study are acknowledged, and the authors emphasize the importance of studying vulnerabilities in instruction-tuned language models to enhance security measures.'''Enter fullscreen modeExit fullscreen modeYou can check other examples of summarization in the repo (to be added later actually)Let's head to the agent example. Below you can see the implementation of DnD for one player:from lloom import LloomConfig, Lloomprotagonist_name = ""Storm Ryder""storyteller_name = ""Captain Quill""quest = '''Set sail on the ""Marauder's Dream"" with your unique crew, seeking the fragmented map leading to the legendary ""Mythic Isles"" and the coveted ""Seafarer's Heart"" artifact. Battle fierce rivals, sea monsters, and unravel hidden histories while forging unbreakable bonds. A thrilling quest inspired by One Piece awaits with treasure beyond gold adventure, camaraderie, and freedom.'''protagonist_description = ""Storm Ryder, a daring and enigmatic adventurer, possesses the heart of a true pirate. Guided by an unyielding sense of justice and fueled by an insatiable thirst for adventure, Storm sails the uncharted seas, leaving a legacy of courage and camaraderie in their wake.""storyteller_description = ""Captain Quill, a weathered and charismatic storyteller, carries tales of ancient legends and forgotten myths in their ink-stained logbook. With a twinkle in their eye and a voice that mesmerizes, they narrate the epic quest of Storm Ryder and the fabled Mythic Isles, inspiring awe and wonder in all who listen.""# I have already taken the ready-made system message from langchain docs, but the same functionality of so-called specifying the description can be implemented in 3 lines of code if neededplayer_sysmsg = f'''Here is the topic for a Dungeons & Dragons game: {quest}.There is one player in this game: the protagonist, {protagonist_name}.The story is narrated by the storyteller, {storyteller_name}.Never forget you are the protagonist, {protagonist_name}, and I am the storyteller, {storyteller_name}. Your character description is as follows: {protagonist_description}.You will propose actions you plan to take and I will explain what happens when you take those actions.Speak in the first person from the perspective of {protagonist_name}.For describing your own body movements, wrap your description in '*'.Do not change roles!Do not speak from the perspective of {storyteller_name}.Do not forget to finish speaking by saying, 'It is your turn, {storyteller_name}.'Do not add anything else.Remember you are the protagonist, {protagonist_name}.Stop speaking the moment you finish speaking from your perspective.'''master_sysmsg = f'''Here is the topic for a Dungeons & Dragons game: {quest}.There is one player in this game: the protagonist, {protagonist_name}.The story is narrated by the storyteller, {storyteller_name}.Never forget you are the storyteller, {storyteller_name}, and I am the protagonist, {protagonist_name}. Your character description is as follows: {storyteller_description}.I will propose actions I plan to take and you will explain what happens when I take those actions.Speak in the first person from the perspective of {storyteller_name}.For describing your own body movements, wrap your description in '*'.Do not change roles!Do not speak from the perspective of {protagonist_name}.Do not forget to finish speaking by saying, 'It is your turn, {protagonist_name}.'Do not add anything else.Remember you are the storyteller, {storyteller_name}.Stop speaking the moment you finish speaking from your perspective.'''master_config = LloomConfig(your_api_key, temperature=1.0, logging=False, model=""gpt-3.5-turbo-0613"",system_message=master_sysmsg)player_config = LloomConfig(your_api_key, temperature=1.0, logging=False, model=""gpt-3.5-turbo-0613"", system_message=player_sysmsg)master = Lloom(master_config)player = Lloom(player_config)max_iter = 3initial_message = ""I'm ready to start!""n = 0# as the history is stored by default, we don't need to implement any additional classes or methodswhile n < max_iter:    master_message = master.generate(initial_message)    print(f""Master message: {master_message}"")    player_message = player.generate(master_message)    initial_message = player_message    print(f""Player message: {player_message}"")    n += 1Enter fullscreen modeExit fullscreen modeIf you check the Langchain docs, you will see that their implementation is at least of the same length, but usually they need more code. Same is true for Semantic Kernel. Thank you for reading! If you like my work, please star the repository and share your use cases, would be excited to learn new ways!P.S. In no means I'm trying to make a competition with LangChain and similar libraries, and no hate either! Langchain and others might be a good choice in some cases, I just found out that simpler implementation works best for me. "
128,"Here at Stout we screen a lot of technical candidates. Our first step is to filter the resumes. (We have little need for glass window installers despite the fact that they match the keywords ""windows"" and ""installation!"") Then we conduct a technical interview to assess a candidate's skill level. For candidates who will be contracting with us directly we like the extra step of doing a coding exercise.Why not just request a code sample?We do like to get code samples from candidates, but we rarely get useful ones—and frequently we get nothing at all. Candidates are understandably leery about sharing code that is owned by the companies they've worked for, and sometimes they aren't able or willing to give an anonymized sample.Sometimes we get code from hobby projects, but that usually isn't deep or up to production quality. Other samples are just too small to glean anything useful from. Very occasionally we get code stolen from the Internet, which is helpful in identifying candidates who are stupid!Thus, the coding exercise.A good coding exercise is about more than just coding. It should also be about process, communication and personality / working styles. Our coding exercise follows a process that is common to many of our contracting projects:It's geared towards remote work, so it's conducted via email.The programmer is given a generic task with some requirements.The programmer needs to do some analysis and come up with an implementation plan, along with time estimates.After we've reviewed the plan, the programmer is directed to implement some or all of it—or is given slimmed down requirements as needed.The programmer delivers the finished product and reports how long it took.It's important to note that the tasks we give them are generic. They are something any programmer can understand and don't require any specific domain knowledge. While we are asking them to spend time on this exercise (typically less than an hour for the analysis and somewhere around an hour for the implementation), we aren't asking them to do free work. The task they are implementing is for the exercise only. We don't use the results.The exercise must be small enough that it can be comprehended easily and implemented quickly, while still being complex enough to produce meaningful results. Coming up with a good exercise is quite a challenge!Having programmers implement the popular ""FizzBuzz"" test would tell us whether they could code, but it would tell us neither how well they deal with real problems, nor whether they can analyze or estimate.I've administered our coding exercise to a number of programmers over the past few years, and I've seen some interesting results (focusing on the failures here because they are more interesting!):Some developers aren't a good personality fit; they can be difficult or unpleasant to deal with even for the length of the exercise, or even fail to respond to the exercise all.Some fail to comprehend requirements or follow directions. Some people take a lot of back and forth iteration to understand what others grok in one go. Even when told specifically to ""do X, don't do Y"" some developers will ignore you and do Y anyway.The quality of the implementation plans vary wildly. Some come back with excellent detail and a complete plan, while others come back with plans that are sketchy or actually infeasible.Estimates for implementation have varied from 0.5 hours to over 8 hours, though some of that is due to differences in plans or requirements.Strangely some programmers will deliver code that doesn't actually work or run. I've had implementations with a single click crash bug or implementations with a lot of code that just doesn't work. Makes you wonder if the programmer actually ran it!Our exercise requests ""production quality"" code, but apparently that's a very broad definition.No coding exercise is perfect and I'm sure we've passed up great candidates who just misunderstood something or were having a bad day. But our exercise gives us invaluable insight into how a programmer might operate on real world projects within our specific process and requirements.  Tips for CompaniesRecognizing that candidates are in short supply, avoid some of the common coding exercise turn-offs. Don’t expect a candidate to enthusiastically accept a coding exercise before they’ve had an opportunity to meet with the hiring manager. Most candidates won’t undertake a coding exercise unless they are jazzed up about the opportunity. Integrate the coding exercise into, say, a half day interview that includes short sessions with the hiring team. Candidates are willing to make a finite investment with a company and its interview process. They balk at interview after interview, exercise after exercise, spread out over several weeks.If you want to use a coding exercise for your company, first figure out what process points you want to cover. For example, if you do a lot of requirements gathering then perhaps you want to give them an underspecified task and have a dialog where you can see how they elicit requirements.Focus on finding a task that is simple enough that it doesn't require discovery and isn't too specific to your problem domain (unless you require programmers to have pre-existing domain knowledge). Any coding should be specific to your language / platform. If your company uses a practice like Test Driven Design or pair programming, then your coding exercise should too. It may be helpful to provide a starting project or skeleton code that has TODOs to be finished by the programmer.  Tips for CandidatesRead the instructions. Then read them again. If there is something that isn’t clear, ask for more information. Many coding exercises deliberately leave out vital information to see how candidates address that.Focus on completing features or sub features instead of bouncing around and completing nothing. I'd rather see a working backend with no UI, or conversely, a working UI with stubbed or mocked backend then have everything be a work in progress. Maybe you display data, but can't yet sort it or edit it.As you go, leave TODOs about things you still need to do. That will help you not to forget things, but more importantly if you run out of time it shows that you are aware of something that needs to be addressed, not just that you forgot about it entirely.Aim for production quality, but a little under polished is okay. You should absolutely do things like closing database connections, preventing SQL Injection attacks, or releasing/disposing of resources (as any production quality code should), but not everything needs to be as clean and refactored as full production code. This only applies to a time-limited coding exercise though! If you are turning in a pre-written code sample, I assume you think it's polished and production quality!Please test your code, or at least run it! If I can't run your sample or it breaks with a single click you didn't anticipate, it doesn't reflect well! Expect your code to be reviewed by developers who know how to break things (like putting text in number fields).Comments and error handling matter, but too much of either can be as bad as too little. Again, aim for what you consider to be production quality, with TODOs if you are constrained by time.  SummaryWhether you give the programmer time by him- or herself to implement the code or you pair program, you will come away with a far better understanding of how the programmer approaches tasks. If, as a candidate, you are lucky enough to be given a paired programming coding exercise, realize that this is a great way to get to know how your team interacts and approaches problems. For both, coding exercises give you better insight into whether or not you've got a good fit!This is a technical/business article catered to developers, hiring/project managers, and other technical staff looking to improve their skills. Sign up to receive The Informatizer in your email inbox.If you're looking for a job in the tech industry, visit our job board to see if you qualify for some of our positions. If you're looking to hire technical talent for your company, please contact us.Stout Systems is the software consulting and staffing company Fueled by the Most Powerful Technology Available: Human Intelligence®. We were founded in 1993 and are based in Ann Arbor, Michigan. We have clients across the U.S. in domains including engineering, scientific, manufacturing, education, marketing, entertainment, small business and robotics. We provide expert level software, Web and embedded systems development consulting and staffing services along with direct-hire technical recruiting and placements."
129,"Marley Anthony, Software Engineer at Bench Accounting, came on the podcast yesterday to discuss the importance of maintaining a strong coding foundation, navigating performance improvement plans, and quelling imposter syndrome. We really couldn't have chosen a better way to start Season 25!On the podcast, Marley shared that ""Imposter syndrome [is always] going to be there. It’s just understanding how to deal with it better and understanding that it’s going to be part of your experience... nobody knows everything.""Needless to say, imposter syndrome is a super common difficulty when navigating any career, let alone in tech. Since everyone's approaches are super different in responding to imposter syndrome, we would love to know your thoughts! What are your biggest tips for handling imposter syndrome? Does imposter syndrome ever get better?How can we stop giving imposter syndrome all the power?ICYMI— find that episode below or wherever you get your podcasts:""Pivoting to Tech from Biomedical Science"": CodeNewbie Podcast S25E1Sloan the DEV Moderator for CodeNewbie ・ Aug 16#podcast#career#codenewbie#beginnersSend us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
130,"Let's explore a fascinating concept in JavaScript called closures. Think of them as special coding tools that remember important things, much like a magical vault that keeps valuable information safe even after its owner has left. Just as a chef's recipe book holds onto the memory of ingredients long after the meal is cooked, closures in JavaScript have the ability to remember important data. We'll take a journey through real-life examples to help you understand closures easily, even if English isn't your first language.  Understanding Closures in JavaScript with Practical ExamplesClosures might sound complicated, but they're really just like helpful friends that remember things for us. They're used in coding to make tasks easier. Imagine two everyday situations: cooking and handling money. These scenarios will show you how closures work, step by step.Scenario 1: The Cooking ConnectionImagine you're a chef in your kitchen, creating delicious dishes. You have a magical cookbook that not only guides you through recipes but also remembers all the ingredients you use. Even after you've finished cooking, the cookbook holds onto the memory of what you've added. Closures work in a similar way. They're like little assistants that remember things from the past, even when that time is over.Cooking Scenario Code:function prepareDish(dishName) {    const ingrediants=[];    function addIngrediants(ingrediant) {        ingrediants.push(ingrediant);        console.log(`${ingrediant} added to ${dishName}`);    };    return addIngrediants;}const preparePasta = prepareDish(""Pasta"");const prepareSoup=prepareDish(""Soup"");preparePasta(""Pasta Noodles"");prepareSoup(""Tomato Souce"")preparePasta(""Chicken Broth"");prepareSoup(""Carrots"")Enter fullscreen modeExit fullscreen modeThe Output of the above Code will be as follows:Pasta Noodles added to PastaTomato Souce added to SoupChicken Broth added to PastaCarrots added to Soup    Scenario 2: The Money ManagerNow, let's switch to a different scene - managing money. Imagine you're a manager in a company, keeping track of employee salaries. You write down what each employee earns and then calculate the total amount. Just like in the cooking scenario, closures are at work here. They help functions remember important details, even after they've done their main job.Money Scenario Code:function createSalaryTracker() {  let salaries = [];  function addSalary(employee, amount) {    salaries.push({ employee, amount });    console.log(`Added ${amount} salary to ${employee}'s account`);  }  function calculateTotalSalary() {    let total = 0;    for (let record of salaries) {      total += record?.amount;    }    return total;  }  return {    addSalary,    calculateTotalSalary,  };}const salaryTracker = createSalaryTracker();salaryTracker.addSalary(""Alice"", 50000);salaryTracker.addSalary(""Bob"", 25000);const totalSalary = salaryTracker.calculateTotalSalary();console.log(`Total Salary: ${totalSalary}`);Enter fullscreen modeExit fullscreen modeThe Output of the above code will be as follows:Added 50000 salary to Alice's accountAdded 25000 salary to Bob's accountTotal Salary: 75000The Magic of Closures:In both scenarios, closures help functions remember things. Just like your magical cookbook holds onto ingredients, closures remember data even after their main task is done. This is like having a memory in coding!Conclusion:Closures might sound tricky, but they're actually very helpful. They're like small assistants that remember important stuff for us. So, whether you're cooking or managing money, closures are there to make things easier in the world of coding."
131,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
132,"Despite experience, certain aspects of coding can be challenging. What specific syntax or concepts do you find most perplexing? How do you work on improving your understanding in those areas?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
133,"As builders, we have the tools. We have the ability to breathe life into features, projects, and platforms that don't yet exist.Are you kidding me!?That's just about the coolest thing there is. We don't have to take the world as it is, but imagine it as it could be... and then we can just go and make it exist! What!?Dreams spawned from lines of code, the buzz of a fresh idea, might be the seed of a side hustle. What if, just maybe, that spark of passion could not just burn bright but also lighten our financial load?  The Side Hustle SeductionJust like passion projects, side hustles are birthed from an idea, a wish, a ""what if"". They are personal, driven by our individual desires. And, just maybe, they carry the sweet promise of extra cash. A monetized passion? Count me in!Imagine this: You've dabbled with a novel API integration over the weekend. It's smart, it's intuitive, and dang it, it’s sexy. Could this be it? Could this be the side project that doesn’t just feed the soul but also adds a bit of weight to the wallet?  The Practicality of Passive IncomeBut wait, before we get lost in dreams of dollar signs, let's talk passive income. It's not about creating something today and watching the cash flow in forever. It requires maintenance, updates, customer support, and often a hefty initial time investment.Eek.Yet, it's appealing. Why? Because it scales. Unlike a 9-5, where your earnings are tied to your hours, passive income decouples effort from reward. Put in the groundwork, and you can earn while you sleep, while you vacation, or while you dive into yet another passion project.  The Side Hustle SpectrumLet’s be clear: Not every side hustle is created equal. On one end, you have the ""set it and forget it"" ventures – think e-books, online courses, or certain apps. On the other, you've got ongoing commitments like SaaS products or membership sites. Where your side hustle falls on this spectrum will determine the balance of effort vs. reward.  Crafting the Side Hustle BlueprintHarnessing a passion project’s potential for income requires strategy:Research the Market: It's cool. It's innovative. But does it fill a need? Understand your target audience and ensure there's demand. Who would care about the thing? Go talk to them.Start Lean: Build a Minimum Viable Product (MVP). Gauge interest. Iterate. The MVP could be a phone call with a target customer. You might not have to build first. Marketing Matters: Even the best product needs visibility. Learn basic marketing or partner up with someone who can handle this side of things. A good rule of thumb: every hour of building needs an hour of marketing. Yes. 50:50.Time Management (Yes, Again!): Juggling a day job, passion projects, and a side hustle? Time blocks become your best friend. Passion might fuel you, but a schedule keeps you grounded.Monetize Smartly: Subscriptions? One-off purchases? Ads? Pick a model that aligns with your project and audience. Do things that don't scale when you're starting off! You don't need to build a high-availability, multi-region cluster, powering k8s with hypersensitive scaling thresholds underpinning a microservices architecture... all just to see if there's a single person willing to entertain your services.Stay Adaptable: Markets change. Tech evolves. Feedback flows in. Adaptability isn’t just about coding languages; it’s about business acumen. Planning is invaluable! But don't fool yourself into taking your plans as gospel. Feedback from paying customers outweighs even your best-conceived plans.   The Side Hustle Soul-SearchBefore diving deep, ask yourself: What’s driving this endeavor? If it's purely monetary, tread with caution. Passion, interest, and genuine curiosity will sustain you during the inevitable challenges.I like the idea of projects being ""alive by default."" Expenses related to the project is zero or as close as you can possibly get. This both lengthens the runway for your little endeavor and if you lose interest (or bandwidth) for a minute, it's okay!   Beyond the HorizonThe intersection of passion and income is drool worthy. Today's side hustle could be tomorrow's full-time gig, or it might remain a delightful moonlighting venture. Either way, we get to play, tinker, and learn new things. With the right blend of skill, passion, and strategy, the possibilities? They’re virtually limitless.The harmony between passion, paycheck, and passive income is delicate... but we possess the tools to tune it just right. It's not just about coding; it's about vision.The synergy? Oh, it’s there. More than ever. Pursue it. Revel in it."
134,"Introduction:A functional programming(FP) is paradigm, means a way of thinking about software construction based on some principles like Pure functions, Immutability, First class and higher-order functions, Function composition, Closure, Declarative Programming, Recursion, Referential Transparency, Currying and  Partial ApplicationThese principles, when applied effectively in JavaScript, can lead to code that is more modular, maintainable, resilient, more understandable, testable, and capable of elegantly handling complex problems.This article looks quite long but not theoretical as such.Let's start experimenting each item:1. Pure Functions:Two RulesGiven the same input, always return same output.Produces no side effectsUse: Easy to refactor, makes code more flexible and adaptable.Example 1:// Impure function.let a = 4;const multiplyNumbers = (b) => a *= b;multiplyNumbers(3);console.log(a); // first time: 12> 12multiplyNumbers(3);console.log(a); // second time: 36> 36// Mutates external variable so it isn't pure.Enter fullscreen modeExit fullscreen mode// Pure function.const multiplyNumbers = (x,y) => x * y;multiplyNumbers(2, 3);> 6Enter fullscreen modeExit fullscreen modeExample 2:// Impure function.addNumberarr = (arr, num) => {arr.push(num);};const testArr = [1,2,3];addNumberarr(testArr, 4);console.log(testArr);> [1, 2, 3, 4]// Mutates input array so it isn't pure.Enter fullscreen modeExit fullscreen mode// pure version of above.addNumberarr = (arr, num) => {return [...arr, num];};const testArr = [1,2,3];addNumberarr(testArr, 4);> [1, 2, 3, 4]Enter fullscreen modeExit fullscreen modeJS Built-in Pure functions:arr.reduce()arr.map()arr.filter()arr.concat()arr.slice()arr.each()arr.every()... - spread syntaxEnter fullscreen modeExit fullscreen modeJS Built-in Impure functions:arr.splice()arr.push()arr.sort()Math.random()Enter fullscreen modeExit fullscreen mode2. Immutability:Objects whose state can't be altered once it is created.A simple example would be using the slice method to help you easily grasp the meaning.const arr = [1,2,3,4];const slicedArray = arr.slice(1,2);slicedArray> [2]arr> [1, 2, 3, 4]Enter fullscreen modeExit fullscreen modeIf you see above example, slice didn't alter or modify or mutate original array arr. Whereas, if you see below example:const arr = [1,2,3,4];arr.push(5);> 5arr> [1, 2, 3, 4, 5]Enter fullscreen modeExit fullscreen modeoriginal array arr has been mutated. It's not that we shouldn't use push but we can avoid in most of the situations. Simple example would be:const arr = [1,2,3,4];const newArr = [...arr, 5];arr> [1, 2, 3, 4]newArr> [1, 2, 3, 4, 5]Enter fullscreen modeExit fullscreen modeThe above all are simple examples and won't create any issues possibly. But, situations where we keep on modifying same object wherever possible across whole file will create many issues. As we need to maintain the track as how many times and ways that object has been altered.So, to solve this issue we need to avoid mutating the object.3. First Class functionsFirst-class functions refer to the concept of treating functions as first-class citizens, which means they are treated as regular variables or values. It enable functions to be manipulated and used in the same ways as other data types like strings or numbers. This allows functions to be passed as arguments to other functions, returned as values from other functions, and assigned to variables. Javascript supports this.It opens the door to powerful programming techniques, such as higher-order functions, function composition, and the creation of abstractions.4. Higher-Order Functions:A function can take a function as an argument or can return a function as a value is called a higher-order function.A function that returns a functionconst higherOrderFunc = function() {    return function() {        return 12;    }}// which returns below function hence it is higher order function.higherOrderFunc(); > ƒ () {        return 12;    }higherOrderFunc()();> 12Enter fullscreen modeExit fullscreen modeA function that takes a function as an argumentconst testFunc = function(x) {    return x + 12;}//which takes function as an argument.const higherOrderFunc = function(testFunc) {    return testFunc(8);}higherOrderFunc(testFunc);> 20Enter fullscreen modeExit fullscreen modeExample 1:function calculate(operation, numbers) {    return operation(numbers);}function addition(numbers) {    let sum = 0;    for (const number of numbers) {        sum+=number;    }    return sum;}function multiply(numbers) {    let sum = 1;    for (const number of numbers) {        sum*=number;    }    return sum;}const numbers = [1,2,3,4,5];console.log(calculate(addition, numbers));> 15console.log(calculate(multiply, numbers));> 120Enter fullscreen modeExit fullscreen modecalculate(multiply, numbers) - Don't append parenthesis while sending function as an argument.Benefits of higher-order functions:Reduces code duplicationSingle responsibilityIn Javascript, functions can take arguments as primitives or objects and return the same called first-order functions.JS built-in higher order functions are:arr.reduce(), arr.forEach(), arr.filter(), arr.map()5. Functional Composition:It is an approach where result of one function passed on to next function.const add = (x, y) => x+y;const subtract = (x) => x-4;const multiply = (x) => x * 8;// result of `add` is passed to `subtract` and its result passed to `multiply`.const result = multiply(subtract(add(2, 3)));result;> 8Enter fullscreen modeExit fullscreen modeThat looks readable but what if we have more functions to call one after other. Let's try little cleaner approach.const compose = (...functions) => x => functions.reduceRight((total, f) => f(total), x);const add = x => x+2;const subtract = x => x-1;const multiply = x => x * 8;compose(multiply, subtract, add)(2);> 24Enter fullscreen modeExit fullscreen modeWe can also use reduce to implement:const pipe = (...functions) => x => functions.reduce((total, f) => f(total), x);const add = x => x+2;const subtract = x => x-1;const multiply = x => x * 8;pipe(add, subtract, multiply)(2);> 24Enter fullscreen modeExit fullscreen modepipe - performs from left-to-right. compose - performs from right-to-left.6. Declarative Programming:Declarative: tells What to doImperative: tells How to doExample: Find the employees with dept 'justCode' and summation of their salary.Imperative Style:const employees = [{id: 1, name: 'james', dept: 'admin', salary: 10000},{id: 1, name: 'Tom', dept: 'finance', salary: 10000},{id: 1, name: 'peter', dept: 'justCode', salary: 12500},{id: 1, name: 'tunner', dept: 'justCode', salary: 14500},];const justCodeDept = [];// filter employees based on dept name.for (let i=0; i<employees.length; i++) {  if (employees[i].dept === 'justCode') {    justCodeDept.push(employees[i]);  }}// summation of justCodeDept employees.let summation = 0;for (j = 0; j<justCodeDept.length; j++) {  summation = summation + justCodeDept[j].salary;}console.log(summation);Enter fullscreen modeExit fullscreen modeDeclarative Style:const employees = [{id: 1, name: 'james', dept: 'admin', salary: 10000},{id: 1, name: 'Tom', dept: 'finance', salary: 10000},{id: 1, name: 'peter', dept: 'justCode', salary: 12500},{id: 1, name: 'tunner', dept: 'justCode', salary: 14500},];console.log(employees.filter(item => item.dept === 'justCode').reduce(((previousValue, currentValue) => previousValue += currentValue.salary), 0));Enter fullscreen modeExit fullscreen mode7. Currying:Splitting up function that takes multiple arguments into a sequence of functions that each take its individual argument (only one).Example 1:Generally, we write:function addition(x, y, z) {    return x + y + z;}addition(1, 2, 3);> 6Enter fullscreen modeExit fullscreen modeCurrying:function addition(x) {    return function addY(y) {        return function addz(z) {            return x+y+z;        }    }}addition(1)(2)(3);> 6Enter fullscreen modeExit fullscreen modeUsing arrow functions:addition = (x)=>(y)=>(z)=>x + y + z;addition(1)(2)(3);> 6Enter fullscreen modeExit fullscreen modeExample 2:function formWelcomNote(name) {    name = `Hello ${name}, `;    return function(location) {        location = `Welcome to ${location},`;        return function(section){            return `${name}${location} Please visit ${section} section`        }    }}formWelcomNote('Yester')('VK Just Code Articles')('JS Articles');> 'Hello Yester, Welcome to VK Just Code Articles, Please visit JS Articles section'Enter fullscreen modeExit fullscreen modeWe can also write as:formWelcomNote = (name)=>{    name = `Hello ${name}, `;    return (location)=>{        location = `Welcome to ${location},`;        return (section)=>{            return `${name}${location} Please visit ${section} section`        }    }}formWelcomNote('Yester')('VK Just Code Articles')('JS Articles');> 'Hello Yester, Welcome to VK Just Code Articles, Please visit JS Articles section'Enter fullscreen modeExit fullscreen modeExample 3:function calculation(fn) {    switch (fn) {        case 'add': return (a, b) => a + b;        case 'sub': return (a, b) => a - b;        case 'mul': return (a, b) => a * b;        case 'div': return (a, b) => a / b;    }}console.log(calculation('mul')(4, 2));Enter fullscreen modeExit fullscreen mode8. Partial Application:You fix a certain number of arguments for a function and generate a new function with fewer parameters. This new function can be called with the remaining arguments at a later time. Partial application helps in creating more specialized and reusable functions.Example:function add(a, b) {  return a + b;}// Partially apply the first argumentconst add2 = multiply.bind(null, 2);console.log(add2(5));  // Output: 7 (2 + 5)console.log(add2(8));  // Output: 10 (2 + 8)Enter fullscreen modeExit fullscreen mode9. Referential Transparency:An expression in javascript can be replaced by its value is called referential transparency.const add = (x,y)=>x + y;const multiply = (x)=>x * 4;// add (3, 4) can be replaced by 7. - Referential Transparency.multiply(add(3, 4)); > 28multiply(add(3, 4));> 28Enter fullscreen modeExit fullscreen modeconst arr = [];const add = (x,y)=>{    const addition = x + y;    arr.push(addition);    return addition;}const multiply = (x)=>x * 4;// Here, we can't replace add(3,4) with 7 as it affects the programmultiply(add(3, 4));> 28> multiply(add(3, 4));28Enter fullscreen modeExit fullscreen mode10. Closure:Closure gives you access to an outer functions scope from inner function.function outer() {    const name = 'test';    function inner() {     // 'name' from outer function is accessible inside inner function     console.log(name);    }    inner();}outer();> testEnter fullscreen modeExit fullscreen modefunction outerAdd(x) {    return function(y) {        return x + y;    };}const outer12 = outerAdd(12); // x as 12.const outer14 = outerAdd(14); // x as 14.const outer12Result = outer12(12); // y as 12.console.log(outer12Result);> 24const outer14Result = outer14(14); // y as 14.console.log(outer14Result);> 28Enter fullscreen modeExit fullscreen modeAlternatively, you can use arrow functions as well like below.outerAdd = x => y => x + y;const outer12 = outerAdd(12);const outer14 = outerAdd(14);const outer12Result = outer12(12);console.log(outer12Result);> 24const outer14Result = outer14(14);console.log(outer14Result);> 28Enter fullscreen modeExit fullscreen modeCounter example using closure:function outer() {    let counter = 0;    return function inner() {        counter += 1;        return counter;    }}const out = outer();console.log(out());console.log(out());console.log(out());> 1> 2> 3Enter fullscreen modeExit fullscreen mode11. Recursion:Recursion is a programming technique in which a function calls itself to solve a problem.Example:function factorial(n) {  if (n === 0 || n === 1) {    return 1;  } else {    return n * factorial(n - 1);  }}console.log(factorial(5));  // Output: 120 (5 * 4 * 3 * 2 * 1)console.log(factorial(0));  // Output: 1 (by definition)Enter fullscreen modeExit fullscreen modeIn this example, the factorial function calculates the factorial of a given number n. It uses the base cases of n === 0 and n === 1, where the factorial is defined to be 1. For any other value of n, the function recursively calls itself with n - 1 and multiplies the result by n.When you call factorial(5), the sequence of recursive calls looks like this:factorial(5)  -> 5 * factorial(4)       -> 4 * factorial(3)            -> 3 * factorial(2)                 -> 2 * factorial(1)                      -> 1                 <- 2 * 1 = 2            <- 3 * 2 = 6       <- 4 * 6 = 24  <- 5 * 24 = 120Enter fullscreen modeExit fullscreen modeplease do comment any examples on any concept.Thanks.urstrulyvishwak"
135,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers!""What's one lesson from school that surprisingly translates well into coding principles?""Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
136,Python is known for its readability and simplicity. How does this aspect affect the learning curve for newcomers to programming?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
137,"Time for #DEVDiscuss — right here on DEV 😎Complementing exceptions - Introducing monads for error handling in rubyCherry Ramatis ・ Aug 13#ruby#errors#monad#webdevInspired by @cherryramatis' Top 7 post, tonight’s topic is... Error Handling!Effective API design is essential for creating user-friendly, efficient, and maintainable software systems. Idempotency is just one aspect, so what elements of API design are most crucial to you and your team?   Questions:How do you educate and onboard new developers on the error handling practices and conventions used in your projects?Are there any specific programming languages or frameworks that you believe excel in terms of providing comprehensive error handling mechanisms? Why?As projects scale, error management becomes more complex. What tools or practices do you recommend for effective error tracking and monitoring in large-scale applications?Any triumphs, fails, or other stories you'd like to share on this topic?"
138,"Duck typing is a concept in programming languages, including Python, where the type or class of an object is determined by its behavior (methods and properties) rather than its explicit class or type declaration. In duck typing, ""If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.""In other words, duck typing focuses on what an object can do, rather than what it is. If an object can perform certain actions or has certain attributes, it's treated as if it belongs to a certain type or class, even if it doesn't explicitly inherit from that type or class.Example:class Dog:    def speak(self):        return ""Woof!""class Cat:    def speak(self):        return ""Meow!""class Duck:    def speak(self):        return ""Quack!""def animal_sound(animal):    return animal.speak()dog = Dog()cat = Cat()duck = Duck()print(animal_sound(dog))  # Output: Woof!print(animal_sound(cat))  # Output: Meow!print(animal_sound(duck)) # Output: Quack!Enter fullscreen modeExit fullscreen modeIn this example, the animal_sound function takes an argument that is expected to have a speak method. Duck typing allows us to pass objects of different classes (Dog, Cat, and Duck) to the function, as long as they have a compatible method (speak). The function doesn't care about the actual type of the object; it only relies on the presence of the required method.Real-Life Example:Imagine you're building a music player application. You might have different classes for different audio file types, like MP3, WAV, and FLAC. Instead of checking the specific class type for each audio file, you can use duck typing to determine whether an audio file can be played:class MP3:    def play(self):        print(""Playing MP3 audio"")class WAV:    def play(self):        print(""Playing WAV audio"")class FLAC:    def play(self):        print(""Playing FLAC audio"")def play_audio(audio):    audio.play()mp3 = MP3()wav = WAV()flac = FLAC()play_audio(mp3)  # Output: Playing MP3 audioplay_audio(wav)  # Output: Playing WAV audioplay_audio(flac) # Output: Playing FLAC audioEnter fullscreen modeExit fullscreen modeIn this example, the play_audio function expects an object with a play method. As long as an object has this method, it can be treated as an audio file and played using the function.Duck typing simplifies code and promotes flexibility by allowing you to work with different classes and types that exhibit similar behavior. It's a powerful concept in dynamic programming languages like Python, making the code more concise and adaptable."
139,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers!🤖 Time travel back to your first line of code: What would your past self say to your present self?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
140,"  We are back y'all!!!!In the first episode of our 25th season of the CodeNewbie Podcast, @saronyitbarek talks about making a major career change and the significance of laying a strong foundation with with Marley Anthony, Software Engineer at Bench Accounting.       codenewbie.org    Marley is a software engineer, photographer, and outdoor enthusiast based in Vancouver, BC. He love tech and spending time outside riding bikes or hiking! Tune in to gain valuable perspectives on strategies for landing that all-important internship, fostering growth, and embracing the ongoing pursuit of knowledge.  Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!  WOW we are happy to be back for another season.  Make sure to follow us on your preferred platform if you haven't already!And beyond all— happy coding y'all!"
141,"The importance of e-commerce and retail apps has grown significantly due to their convenience, personalization, and seamless shopping experiences. As businesses adopt a mobile-first approach, these apps engage and retain customers, offer omnichannel experiences, and utilize push notifications for marketing. With a global reach, e-commerce and retail apps have become crucial tools for businesses to stay competitive and drive sales in the digital age.The performance of retail and e-commerce apps should be flawless. In today's competitive market, users expect smooth and efficient online shopping experiences. Slow loading times, crashes, or other performance issues can lead to user frustration and abandoned transactions. Ensuring seamless and fast performance is vital for these apps to retain customers, drive sales, and stay ahead of the competition. App performance monitoring and testing are essential to proactively identify and address any issues, providing users with the best shopping experience.This blog will cover the importance of retail and e-commerce performance testing, the KPIs to be monitored, and how HeadSpin enables enterprises to streamline testing and deliver exceptional customer experiences.Importance of performance testing for retail applicationsRetail and e-commerce apps serve as the primary touchpoint between businesses and their customers, making flawless performance essential for a positive user experience. Here are the key reasons why performance testing for retail applications is crucial:- Customer satisfaction:High-performing retail apps provide smooth navigation, fast response times, and quick loading of product pages. This translates to a satisfying user experience, increasing customer retention and loyalty.- Brand reputation:A poorly performing app can tarnish a brand's reputation and lead to negative reviews and word-of-mouth publicity. On the other hand, a fast and reliable app enhances a brand's image, fostering customer trust.- Revenue generation:Slow or buggy apps can result in abandoned carts and lost sales opportunities. Retail and e-commerce performance testing help identify and resolve bottlenecks, ensuring the app efficiently handles peak loads and transactions.- User engagement:Responsive and seamless app experiences keep users engaged and encourage them to explore products and make purchases. This leads to increased conversions and higher revenue potential.- Competitive edge:In the crowded retail market, superior app performance sets a brand apart. A well-optimized app attracts and retains customers, giving the business a competitive advantage.- Scalability:Retail apps need to handle varying levels of user traffic, especially during seasonal sales or promotions. Retail and e-commerce performance testing for retail applications and other e-commerce software assesses the app's scalability, ensuring it can accommodate increased loads without crashing.- Cost-effectiveness:Identifying and fixing performance issues early in the development cycle is more cost-effective than addressing them after the app is live. Performance testing helps catch potential problems before they impact the end users.- Security: Performance testing for retail applications also includes stress testing to assess the app's stability under extreme conditions. This indirectly contributes to security by ensuring the app doesn't crash or become vulnerable to attacks.- Customer retention: A positive app experience encourages customers to return for future purchases. By focusing on performance, retail apps can increase customer retention and drive repeat business.The significance of KPIs in gauging retail and e-commerce app performanceIn today's competitive landscape, flawless performance of retail and e-commerce apps is paramount to success. KPIs (Key Performance Indicators) play a pivotal role in achieving this by providing measurable metrics to assess various aspects of the app's functionality and user experience.Here's why KPIs are important in this context:1. Performance monitoring: KPIs allow retailers to monitor critical performance metrics such as response time, page load speed, and error rates. By tracking these KPIs, retailers can identify performance bottlenecks and areas that need improvement.2. User experience improvement: KPIs provide insights into the app's usability and responsiveness, helping retailers understand how users interact with the app. Positive user experiences lead to improved conversion rates, higher customer satisfaction and increased engagement.3. Stability: KPIs like transaction throughput and peak user load handling assess the app's ability to handle increased user traffic during peak seasons or promotions. This ensures the app remains stable and responsive even under heavy load.4. Identifying weak points: By analyzing KPIs, retailers can pinpoint weak points in the app's infrastructure or design. This enables them to proactively address issues and optimize the app's performance before they impact user experience negatively.5. Optimizing resource utilization: KPIs related to resource utilization, such as CPU and memory usage, help retailers optimize their app's performance. Efficient resource management leads to reduced costs and improved overall app performance.6. Data-driven decision making: KPIs provide objective data for making informed decisions related to app improvements. Retailers can prioritize development efforts based on the KPIs that significantly impact performance and user experience.7. Competitive advantage: Monitoring KPIs enables retailers to benchmark their app's performance against competitors. By outperforming competitors in terms of app speed and user experience, retailers can gain a competitive edge.8. Enhancing conversion rates: A high-performing app positively influences conversion rates. Faster load times and smoother checkout processes can lead to higher sales and revenue.What are the critical KPIs that retail and e-commerce performance testing helps measurePerformance testing for retail and e-commerce apps involves measuring several Key Performance Indicators (KPIs) to assess their overall performance and ensure a positive user experience. Some of the essential KPIs that performance testing helps measure for these apps include:- Average response time:The time taken by the app to respond to user actions, such as loading product pages or completing transactions.- Transaction throughput:The number of transactions the app can handle per unit of time, indicating its capacity to support concurrent users.- Error rate:The percentage of errors or failures encountered during testing, indicating the app's stability and reliability.- Page load time:The time taken for web pages to load, including product listings, images, and checkout pages.- Peak user load handling:The maximum number of concurrent users the app can handle without a significant deterioration in performance.- Resource utilization:Monitoring CPU, memory, and network usage to ensure efficient resource utilization.- Latency:The time taken for data to travel between the user's device and the app's server, influencing the app's responsiveness.- Database performance:Assessing the efficiency of database queries and data retrieval processes.- Network performance:Evaluating the app's performance under different network conditions to ensure a consistent user experience.By measuring these KPIs, performance testing provides valuable insights into the app's performance, scalability, and reliability. It helps identify potential issues, optimize the app's performance, and ensure that retail and e-commerce apps deliver a flawless user experience even during peak usage periods.Types of performance tests performed on retail appsImagine your retail app facing a surge of users during a holiday sale. Different performance tests help brands identify and fix predictable and unpredictable issues to ensure the perfect performance of the apps. E-commerce performance testing involves a diverse range of tests, each with a specific focus to ensure the optimal functioning of the application. Let's dive into these tests and explore how they contribute to creating a seamless shopping experience:1. Load testing: This test evaluates how well the app performs under both expected and peak user loads. By simulating different levels of user traffic, load testing helps identify potential performance bottlenecks, such as slow response times or server overloads. It ensures that the app is able to handle the expected user base without compromising performance.2. Stress testing: Stress testing pushes the app to its extreme limits by subjecting it to heavy user loads and resource constraints. The goal is to determine the app's stability and responsiveness under challenging conditions. Stress tests reveal how the app behaves during periods of high demand and helps identify any weaknesses or points of failure.3. Endurance testing: This assesses the app's performance over an extended period, typically for hours or days. The objective is to identify memory leaks, resource utilization issues, or performance degradation that may occur over time. Endurance testing ensures that the app remains stable and reliable during prolonged usage.4. Scalability testing: As retail businesses grow, their app must handle increased user and transaction volumes. Scalability testing evaluates the app's ability to scale up or down seamlessly. It helps ensure that the app can accommodate a growing user base without compromising performance or user experience.5. Spike testing: Spike testing examines how the app responds to sudden, significant spikes in user activity or traffic. It helps determine if the app can handle sudden surges in demand without crashing or experiencing performance issues. This is particularly important during peak shopping seasons or special promotions.6. Security testing: Retail apps deal with sensitive customer data and financial transactions. Security testing assesses the app's ability to withstand security breaches and ensures that user data remains protected, even during high user loads. It helps identify vulnerabilities and potential risks that could compromise user trust and data integrity.7. Network latency testing: This type of testing evaluates how app performance is affected by network delays and poor connectivity. Network latency can significantly impact the app's response times, especially for users in areas with weaker network connections. This test helps optimize the app's performance under varying network conditions.8. Transaction testing: Retail apps process numerous transactions daily. Transaction testing verifies the app's capability to handle a high volume of transactions smoothly and efficiently. It ensures that order processing, payment transactions, and inventory management functions work flawlessly, even during peak times.9. Concurrent user testing: This test examines how well the app handles multiple users accessing it simultaneously. It evaluates the app's ability to manage concurrent sessions without performance degradation or user conflicts. Concurrent user testing helps guarantee a smooth and responsive experience for all users, regardless of the user load.How does HeadSpin help streamline performance testing for retail and e-commerce brands?Delivering perfect digital experiences to customers is a key priority for retailers, and HeadSpin’s data science driven retail app testing Platform is the right-matched solution to address it. HeadSpin offers a comprehensive Platform to test retail and e-commerce apps and optimize their performance for rendering exceptional customer experiences. With deep ML models, the Platform helps pinpoint high-priority issues and resolve them quickly. The data science capabilities enable QA and testing teams to capture critical business-specific KPIs that degrade the user experience and thereby optimize app performances. Key HeadSpin CapabilitiesBy leveraging the unique features of HeadSpin's Platform, businesses are able to deliver optimal performance and user experience for their retail applications.The solution offers a range of unique benefits, including:- End-to-end monitoring:Businesses can analyze end-to-end scenarios to ensure proper integration and identify potential bottlenecks or issues in the application flow. HeadSpin enables customized customer experiences and proactively monitors and detects errors, ensuring a seamless shopping journey for users.- Performance regression:Retail apps often undergo updates and changes, which can impact their performance. HeadSpin helps businesses monitor performance over time to detect any regressions or degradation in app performance. This proactive approach ensures that the app consistently delivers a high-quality experience to users.- Actionable insights:HeadSpin provides visualization of comparative views of UX and performance for peer applications. These actionable insights help enterprises make data-driven decisions to improve their retail apps continually.- UX benchmarking:HeadSpin's solution enables retailers to perform UX benchmarking. By tracking critical user journeys, such as login times, product searches, and checkout processes, businesses can obtain valuable insights into user behavior and optimize the app's user experience accordingly.- Testing on various devices:HeadSpin allows retailers to test their applications on a diverse set of devices, including different smartphones, tablets, and operating systems. This ensures that the app functions optimally across a wide range of devices, meeting the needs of a diverse user base. HeadSpin's global device infrastructure allows teams to test their apps on real devices in different locations and address varying consumer requirements across different regions. With this, businesses can ensure consistent and reliable performance worldwide.Bottom linePerformance optimization is of paramount importance for retail apps in today's highly competitive digital landscape. As the demand for modern applications continues to soar, delivering flawless customer experiences is no longer optional—it's a business imperative. Retailers must ensure their apps perform optimally, offering seamless navigation, fast loading times, and reliable functionality across various devices and locations. Delivering a high-performing retail app fosters customer loyalty, satisfaction, and brand credibility. It sets retailers apart from the competition, allowing them to thrive in a digital-first world. With the right retail and e-commerce software testing tools and strategies, retail apps can remain at the forefront of the industry and continue delighting customers with exceptional digital experiences."
142,"In event-driven architectures, communicating between different microservices via messages can be enabled using Publish and Subscribe functionality (Pub/Sub for short).The publisher (or producer) writes messages to a message topic (or queue), while a subscriber will subscribe to that particular topic and receives the message. Both the publisher and subscriber are unaware of which application either produced or subscribed to the topic. This pattern is useful when we want to send messages to different services, while ensuring that they are decoupled from each other.image taken from https://docs.dapr.io/developing-applications/building-blocks/pubsub/pubsub-overview/In this article, we'll discuss how Pub/Sub works in Dapr, and how we can implement Pub/Sub functionality in a ASP.NET Core Web API. We'll then configure our Pub/Sub component and wire it up to our API to see it in action.  What is Pub/Sub in Dapr?Dapr has a Pub/Sub API that you can use to implement Pub/Sub capabilities to your applications. It's platform agnostic, meaning that you can a variety of message brokers to send and receive messages from. We can configure our message broker as a Dapr Pub/Sub component at runtime, removing the dependency from our service and making it more flexible to changes (should you need, or even want to, change your message broker).The API offers at-least-once message guarantees, meaning that Dapr ensures that the message will be delivered at least once to every subscriber. In the event that a message fails to deliver, or your application fails, Dapr will attempt to redeliver the message until it's successful.When we use Pub/Sub in Dapr, our service (In our case, our publisher service), will make a network call to a Pub/Sub building block API. This building block will make a call to our Pub/Sub component (our configured message broker). To receive messages on a topic, Dapr subscribes to the Pub/Sub component with a topic and then delivers messages to a particular endpoint when messages arrive.In this article, we'll build two APIs. One that will act as our publisher which will send messages to our message broker (In this example, I'll be using Azure Service Bus), and the other will act as our subscriber, which will receive messages from our Service Bus topic:Dapr Pub/Sub has a variety of features available that simplifies Pub/Sub capabilities in your application, so I'd recommend taking a look at the Dapr documentation on Pub/Sub if you want to gain a deeper understanding.  Configuring Dapr in our Web APITo see Dapr Pub/Sub in action, we'll build two ASP.NET Core Web APIs: One to handle the publishing of an Bookshop order message, another to subscribe to the topic that our orders will be sent to so they can receive the message.To see the full code for this project, please check out this repository on my GitHub.To work with Dapr in an ASP.NET Core Web, we'll need to install the Dapr.AspNetCore package. For this tutorial, we'll need to install this package in both our API's. To do this, we can run the following NET CLI command in our Web API projects:dotnet add package Dapr.AspNetCoreEnter fullscreen modeExit fullscreen modeAlternatively, you can use the NuGet Package Manager in Visual Studio to install it.This package will allow you to interact with Dapr applications through the Dapr Client and build routes and controllers in your ASP.NET applications using Dapr.  Implementing our Pub/Sub logicNow that the Dapr package has been installed in both our APIs, we can start to build our publisher API. For this application, we're going to keep our Order model simple like so:namespace Bookshop.Common{    public class Order    {        public string OrderId { get; set; }        public string Title { get; set; }        public string Author { get; set; }        public decimal Price { get; set; }    }}Enter fullscreen modeExit fullscreen modeFor our publisher, we can create the following controller:using Bookshop.Common;using Dapr.Client;using Microsoft.AspNetCore.Mvc;namespace Bookshop.Publisher.Controllers{    [Route(""api/orders"")]    [ApiController]    public class OrderPublisherController : ControllerBase    {        private readonly DaprClient _daprClient;        private readonly ILogger<OrderPublisherController> _logger;        public OrderPublisherController(DaprClient daprClient, ILogger<OrderPublisherController> logger)        {            _daprClient = daprClient;            _logger = logger;        }        [HttpPost]        public async Task<IActionResult> CreateOrder([FromBody] Order order)        {            if (order is not null)            {                _logger.LogInformation($""Publishing order ID {order.OrderId}"");                await _daprClient.PublishEventAsync(""dapr-pubsub"", ""orderstopic"", order);                return Ok(order);            }            return BadRequest();        }    }}Enter fullscreen modeExit fullscreen modeLet's break this down.We inject our DaprClient into the controller since we'll be using it to publish our event. In this controller, we have a single method called CreateOrder which will be invoked when we make a POST request. We'll need to pass an Order request payload to the endpoint, which will invoke the PublishEventAsync method.In this method, we pass three parameters:dapr-pubsub - This will be the name of the Pub/Sub component that we will define later.orderstopic - This is the name of our topic that we will send Order messages to.order - This is the payload that we'll send to our orderstopic.In our Bookshop.Publisher Program.cs file, we need to add the DaprClient service to our service container like so:var builder = WebApplication.CreateBuilder(args);// Add services to the container.builder.Services.AddDaprClient();builder.Services.AddControllers();// Rest of fileEnter fullscreen modeExit fullscreen modeTo receive messages from our orderstopic, we can create a controller that will act as our subscriber:using Bookshop.Common;using Microsoft.AspNetCore.Mvc;namespace Bookshop.Subscriber.Controllers{    [Route(""api/orders"")]    [ApiController]    public class OrderSubscriberController : ControllerBase    {        private readonly ILogger<OrderSubscriberController> _logger;        public OrderSubscriberController(ILogger<OrderSubscriberController> logger)        {            _logger = logger;        }        [Dapr.Topic(""dapr-pubsub"", ""orderstopic"")]        [HttpPost(""orderreceived"")]        public async Task<IActionResult> OrderReceived([FromBody] Order order)        {            if (order is not null)            {                _logger.LogInformation($""Received Order ID: {order.OrderId}: {order.Title} - {order.Author} - {order.Price}"");                return Ok();            }            return BadRequest();        }    }}Enter fullscreen modeExit fullscreen modeAgain, let's break this down.We don't need to inject a DaprClient into this controller. Instead, we annotate our OrderReceived method with the Dapr.Topic attribute. This attribute accepts two arguments:The name of our Pub/Sub component that this subscriber will target. In this case, our component will be called dapr-pub, which we will define later.The name of the topic that to subscribe to, which is called orderstopic.The action method will expect to receive an Order object and once the message is received, we will log out the order that has been received and return a 200 response.In our subscriber Program.cs file, we need to add the following:var builder = WebApplication.CreateBuilder(args);// Add services to the container.builder.Services.AddControllers().AddDapr();var app = builder.Build();// Configure the HTTP request pipeline.app.UseAuthorization();app.UseCloudEvents();app.MapControllers();app.MapSubscribeHandler();app.Run();Enter fullscreen modeExit fullscreen modeLet's break this down,We integrate Dapr into the MVC pipeline in the line builder.Services.AddControllers().AddDapr().On line app.UseCloudEvents(), this will add CloudEvents middleware into the ASP.NET Core middleware pipeline. This unwraps requests that use the CloudEvents structured format, so the receiving method can read the event payload that is sent directly.On line app.MapSubscribeHandler(), this will make the endpoint http://localhost:<your-app-port>/dapr/subscribe available for the consumer so it responses and returns the available subscriptions. When the endpoint is called, it finds all the WebAPI actions decorated with the Dapr.Topic attribute and will tell Dapr to create subscriptions for them.  Working with Dapr Pub/Sub componentsNow that our application code is finished, we'll need to set up our Pub/Sub component. For my message broker, I'm going to be using Azure Service Bus. To define our Pub/Sub component to use Azure Service Bus, we can write the following YAML:apiVersion: dapr.io/v1alpha1kind: Componentmetadata:  name: dapr-pubsubspec:  type: pubsub.azure.servicebus  version: v1  metadata:    - name: connectionString      value: ""<YOUR-SERVICE-BUS-CONNECTION-STRING>""    - name:  consumerID      value: ""order-processor-subscription""Enter fullscreen modeExit fullscreen modeTo define which message broker we will use for Pub/Sub capabilities, we define this using the type field. So for Azure Service Bus, this will be of type pubsub.azure.servicebus. In the metadata section, we just need to define our connectionString and the consumerID. Now for this example, I'm using connection strings purely for local development. In production scenarios, please use Azure AD to authenticate to your Service Bus namespace for more granular control. You can also use Dapr secret stores to store sensitive values.For our consumerID, I've created a subscription for my Service Bus topic called order-processor-subscription. The value that we give our consumerID in our Pub/Sub component should match the name of your subscription.The power of the Dapr framework lies in its portability, meaning that you can plug in different message brokers without having to change your application code. Check out this guide on how to configure Pub/Sub components in Dapr and this reference to see all the supported message brokers available to you for your Dapr applications.   Testing our APIWith our application logic and Pub/Sub component defined, we can now test sending and receiving messages via Dapr. To do this, we'll need to open two separate command lines (one for our publisher, one for our subscriber). In each command line, run the following commands:# Run our Publisher APIdapr run --app-id bookshop-publisher --app-port <app-port-defined-in-launchSettings.json-file> --dapr-http-port 3500 --resources-path ..\..\..\components\ dotnet run# Run our Subscriber APIdapr run --app-id bookshop-subscriber --app-port <app-port-defined-in-launchSettings.json-file> --dapr-http-port 3502 --resources-path ..\..\..\components\ -- dotnet runEnter fullscreen modeExit fullscreen modeAgain, let's break these commands down:The --app-id parameter sets the id for our applications.For our --app-port, we will use the ports defined in our APIs launchSettings.json file.We need to give both our APIs different --dapr-http-ports, so I've used 3500 for our publisher and 3502 for our subscriber.I've added my Pub/Sub component into a components folder, so I've used the --resources-path to point to that folder when running our application.We then run both our publisher and subscriber with dotnet run.To test our APIs, we start by sending a POST request to our publisher endpoint so it will send a message to our topic. For this, I'm going to use Postman. In Postman, we can do this like so:Here, we make a POST request to our http://localhost:5105/api/orders endpoint, and send a JSON payload for our order. In our controller, we Since we're running our Subscriber API at the same time, we should see in our Subscriber terminal that the message has been received.  ConclusionIn this article, we talked about Pub/Sub in Dapr and how we can use it to enable Pub/Sub capabilities in our distributed applications. We then learnt how to configure a publisher and subscriber in ASP.NET Core Web API projects, how to configure our pub/sub component and how we can test our publisher and subscriber projects locally.If you have any questions on the above, feel free to reach out to me on twitter (or X, whichever suits you) @willvelidaUntil next time, Happy coding! 🤓🖥️"
143,"Since a couple of days I’m seeing this screenshot everywhere on Twitter and Linkedin, and I’m sorry for you, this is now also here!But what is it about?This was posted on Reddit a couple of days ago, it's from someone who worked as a Flutter developer for 3 years who got laid off and he's struggling to find a new job.I'm not going to talk about Flutter specifically but I'd like to use this as a hook to talk about my personal view about going all-in on a specific technology vs stacking more soft and hard skills, clearly at the cost of being less prepared on that one thing in particular, in this case, Flutter.You can watch the full content as a video, or keep reading the transcript  The Shape of a DeveloperThere’s a common definition about the “shape” of a professional that can either be, I shaped, T shaped or π Shaped, you might already have heard about it.There are probably a dozen other variations but these are the most common.So, what does it mean?Imagine on the X axis you have the number of skills you have, and on the Y axis, you have the depth of each skill.Look at the letter I, it's one skill but goes really deep into it. You're a dragon on that specific framework or technology and you can do anything with it. But if you get out of your comfort zone, what's gonna happen?That's why sometimes it's recommended to have a T shape, you still have one skill that you're really good at, maybe slightly less than the I shaped developer, but you also have a couple of other skills that you can use to help you with your main skill.Those are usually soft-skills such as communication, marketing, or other skills that are not directly related to your main role but can somehow help you. Besides, the horizontal line of the T can also include having some bits of knowledge of other technologies that actually are part of your role.For example an I-shaped developer might have 10 years of Angular experience, but none in React, while a T-shaped might have 5 years of Angular and 2 years of React.Who's better?Well, being really really strong on a specific framework can put yourself in a pretty convenient position, but it can also be a trap.What happens if that framework is not used anymore in your company? Or if you get laid off and you need to find a new job, that's what happened to our Flutter developer.If your skill is still relevant, you're probably going to find a new job pretty quickly, but if it's not, you're going to have a hard time, and considering how fast the tech industry is moving, it's not that unlikely.So what about the π shape?The thing is, when you're quite strong on a specific skill, being that 5% better might require quite some time and effort, while you could use the same amount of energy to learn a new skill and become 80% good.That's why the π shape makes a lot of sense for a developer, which is not necessarily having TWO main skills, but having more than one.You still have your main skill where you're really good at, but you also have one or two other hard skills that you can use in case of need.Speaking about Frontend, you might be a React developer, with some experience in Angular and a little experience in Qwik or Svelte.This would make you quite a good pi-shaped developer with a lot of flexibility in case of need.Clearly, this in addition with some good knowledge of the core javascript aspects and some TypeScript on top, so that you can easily learn any other framework if needed.  My take on thatNow that we have some kind of definitions, here's how I'm trying to frame myself into that. I already gave you some hints about what I think anyway.I'm not saying that you shouldn't go deep into a specific technology, I-shaped is not necessarily bad, but you should be aware of the risks that come with it.First of all, you might lose the focus on the fact that your favourite tool is... a tool, and not the goal itself. Your technology or framework serves the only purpose of solving a problem.With that in mind, as long as it's the best tool for the job, you're gonna have a great time, but if this is no longer the case, you should make sure to be able to adapt and transposing your knowledge to what is required at that point.I mean, you can also bet on your hard skill being relevant forever or at least for really long time, that's an option.But if it's not the case, that's why I really like the π shape and it's exactly what I'm trying to do myself.Will it be the right choice? Only time will tell but as proper pi-shaped, I'll be prepared to adapt as smoothly as possible by having at least some knowledge here and there.Do I run into the chance of being mediocre in everything but not really skilled in anything in particular? Not gonna lie, yes, sometimes I have that feeling.However, I'm still young and my career will be quite long so I think as long as I've got a solid and wide base of knowledge, I should be able to decide at any point to go deep into a specific technology if I want to.Now that I think about it, I should probably state what my longterm plan is, maybe in a video, and it will be interesting in 5 or 10 years time to look back at what was the plan and what actually happened.Stay tuned!Thanks for reading this article, I hope you found it interesting!I recently launched my Discord server to talk about Open Source and Web Development, feel free to join: https://discord.gg/bqwyEa6We6Do you like my content? You might consider subscribing to my YouTube channel! It means a lot to me ❤️You can find it here:Feel free to follow me to get notified when new articles are out ;)Leonardo MontiniFollowI talk about Open Source, GitHub, and Web Development. I also run a YouTube channel called DevLeonardo, see you there!"
144,"TABLE OF CONTENTS🤞Introduction🐱‍🏍What is Terraform and how does it work?🧱IAC🧱Benefits Of IaC🗝Common Terminologies in Terraform🚀Steps to install Terraform and set up the environment for AWS🎈Conclusion🤞IntroductionI am excited to announce that I have taken up the TWS TerraWeek Challenge! In this blog post, we will dive into the concepts of Terraform. So Basically, Terraform is a powerful tool that allows you to manage infrastructure as code, providing a more efficient and reliable way to provision and manage resources across various cloud providers. In this blog post, we will explore what Terraform is and how it can help you streamline your infrastructure management processes, and why it is popular and the first choice among the DevOps enthusiast.What is Terraform and how does it work?Terraform is a popular IaC tool that allows you to define, provision, and manage infrastructure across multiple cloud providers using a single, unified language called HashiCorp Configuration Language (HCL). Some of the reasons why Terraform is a popular choice include:Large and Strong CommunityDeclarative ConceptsDependency ManagementScalable and ReusableTerraform work is based on a simple yet powerful concept: the desired state. You define the desired state of your infrastructure in a Terraform configuration file (usually written in HashiCorp Configuration Language or HCL). This configuration file describes the resources you need, their properties, and the relationships between them. Terraform then takes care of provisioning and managing those resources to reach and maintain the desired state.🧱IACInfrastructure as Code (IaC) is a modern approach to managing and provisioning infrastructure through code, rather than manual processes. IaC allows developers to define the desired state of their infrastructure using a high-level, declarative language. This code can then be version-controlled, shared, and reused, making it easier to maintain and scale infrastructure over time🧱Benefits Of IaCAuditing and ComplianceAutomationVersion ControlRecoveryConsistency🗝Common Terminologies in TerraformHere are five crucial terminologies in Terraform along with examples:Providers: Providers in Terraform are responsible for managing and interacting with various cloud and infrastructure platforms, such as AWS, Azure, Google Cloud, and more. Each provider has its own set of resources and configuration options. For example, the AWS provider enables you to provision and manage resources in Amazon Web Services (AWS) cloud. Here’s an example configuration block for the AWS provider:Resources: Resources are the building blocks of your infrastructure. They represent the various components you want to create and manage, such as virtual machines, databases, networks, security groups, and more. Each resource belongs to a specific provider and has its own set of properties. Here’s an example of creating an AWS EC2 instance resource:Variables: Variables allow you to parameterize your Terraform configurations, making them more flexible and reusable. They enable you to define values that can be passed into your Terraform code at runtime. Here’s an example of defining variables for an AWS VPC:Modules: Modules help you organize and reuse Terraform code. They allow you to encapsulate a set of resources and configurations into a standalone component that can be used multiple times across different infrastructure deployments. Modules can be created locally or sourced from external repositories. Here’s an example of using a module to create an AWS S3 bucket:State: Terraform maintains a state file that keeps track of the resources it manages. This file records the mapping between your Terraform configurations and the real-world infrastructure resources. The state file is crucial for Terraform’s ability to perform updates, destroy resources, and manage dependencies. By default, the state is stored locally in a file, but it can also be stored remotely in a backend system. Here’s an example of a local state file:These are just a few key terminologies in Terraform. Understanding them will help you start using Terraform effectively to provision and manage your infrastructure in a repeatable and automated manner.🚀Steps to install Terraform and set up the environment for AWSTo install Terraform and set up the environment for AWS, you can follow these steps:Install Terraform:Download the Terraform binary suitable for your operating system from the official Terraform website (https://www.terraform.io/downloads.html).Extract the downloaded archive file.Move the Terraform binary to a directory included in your system’s PATH.2. Set Up AWS Credentials:Sign in to the AWS Management Console.Create an IAM user or use an existing one with appropriate permissions for managing AWS resources. Ensure the user has permissions for EC2, VPC, S3, and other services you plan to work with.Generate an access key and secret key for the IAM user. Make a note of these credentials as they will be required for Terraform to interact with AWS.Configure the AWS CLI on your local machine by running the following command in your terminal:Enter the access key, secret key, default region, and output format when prompted.3. Initialize Terraform:Create a new directory for your Terraform configuration files.open a terminal and navigate to the new directory.Create a new Terraform configuration file with a .tf extension (e.g., main. tf). This file will contain your infrastructure code.In the configuration file, specify the AWS provider and any resources you want to manage. For example, you can add the following code to create an AWS EC2 instance:Save the configuration file.4. Initialize Terraform:In the terminal, navigate to your Terraform directory (where your configuration file is located).Run the following command to initialize Terraform and download the necessary provider plugins:Deploy Infrastructure:After initialization, run the following command to preview the changes Terraform will make to your AWS environment:Review the output and ensure it matches your intentions.If everything looks good, execute the following command to apply the changes and create the infrastructure:Confirm the changes by typing yes when prompted.Now, Terraform will provision the resources defined in your configuration file on AWS. You can modify your Terraform configuration and repeat the Terraform plan and Terraform applies steps as needed to make changes to your infrastructure.****In this Blog, we Understood that Terraform is a powerful open-source infrastructure as code (IaC) tool that revolutionizes infrastructure management. With its declarative approach, multi-cloud support, and resource graph analysis, Terraform simplifies the provisioning and management of infrastructure resources. By treating infrastructure as code, it enables version control, collaboration, and modularization, enhancing scalability and reusability. Terraform’s idempotent and immutable operations ensure consistent results, while state management maintains the integrity of infrastructure configurations. With Terraform, organizations can automate infrastructure deployment, reduce errors, and achieve efficient, scalable, and standardized infrastructure management across various cloud and infrastructure platforms, ultimately accelerating the software delivery lifecycle.To connect with me — https://www.linkedin.com/in/sanketkalekar  trainwithsanket #Terraform #Terraweekchallenge #devops #AWSThis blog post is a part of the #Terraform initiated by Sanket Kalekar"
145,"If you’ve been following this series, you’ll have noticed that we use mocks often in our unit and integration tests. (If you’re a new reader, welcome – you’re invited to browse the archive.) We set up the mocks in the Arrange sections of our tests to either return a value, or to perform some logic required for the test.In some scenarios, all we need is for a mock to return a default object instance. Complex objects and services can have multiple dependencies, meaning we may need to set up this behaviour on many mocks. While it’s not difficult to do so, it increases the overall amount of test code.This week, we’ll look at a way to keep setup code to a minimum in these situations.  Setting the SceneLet’s imagine we’re writing a service for an online shop. Its purpose is to generate reports for sales orders, and we have models to represent a customer; an order; and a report that combines parts of these two data.public class Customer{    public int Id { get; set; }    public string? Name { get; set; }}public class Order{    public int Id { get; set; }    public int CustomerId { get; set; }    public string[]? ProductsOrdered { get; set; }}public class OrderReport{    public string? CustomerName { get; set; }    public string[]? ProductsOrdered { get; set; }}Enter fullscreen modeExit fullscreen modeWe also have three interfaces: one for a customer data repository, one for an orders repository, and one for a service containing references to the data repositories.public interface ICustomerRepository{    Customer GetById(int id);}public interface IOrderRepository{    Order GetById(int id);}public interface IRepositories{    ICustomerRepository CustomerRepository { get; set; }    IOrderRepository OrderRepository { get; set; }}Enter fullscreen modeExit fullscreen modeHere’s the code for our reports service so far:public class OrderReportsService{    private readonly IRepositories _repositories;    public OrderReportsService(IRepositories repositories)    {        _repositories = repositories;    }    public OrderReport GetOrderReport(int orderId)    {        var order = _repositories.OrderRepository            .GetById(orderId);        var customer = _repositories.CustomerRepository            .GetById(order.CustomerId);        var report = new OrderReport        {            CustomerName = customer.Name,            ProductsOrdered = order.ProductsOrdered        };        return report;    }}Enter fullscreen modeExit fullscreen mode  Writing a TestWe want a simple test to check that everything’s connected, and that we can get a (non-null) report by calling GetOrderReport on our service. We’ve created and set up three mocks. The two repository mocks simply return unmodified default objects for the return type; the IRepositories mock returns the mocked repositories.[Test]public void GetOrderReportReturnsOrderReport(){    // Arrange    var customerRepository = Mock.Of<ICustomerRepository>(cr =>        cr.GetById(It.IsAny<int>()) == new Customer());    var orderRepository = Mock.Of<IOrderRepository>(or =>        or.GetById(It.IsAny<int>()) == new Order());    var repositories = Mock.Of<IRepositories>(r =>        r.CustomerRepository == customerRepository &&        r.OrderRepository == orderRepository);    var reportsService = new OrderReportsService(repositories);    // Act    var report = reportsService.GetOrderReport(1);    // Assert    Assert.That(report, Is.Not.Null);}Enter fullscreen modeExit fullscreen mode  Tidying UpBy default, mocks created in Moq return empty values (i.e. null for reference types, as is the case here). However, this behaviour changes when we set the DefaultValue property to DefaultValue.Mock. Mocks will instead return a mock of the requested type (if the type can be mocked). We can use this to tidy our test up a bit.[Test]public void GetOrderReportReturnsOrderReport(){    // Arrange    var repositories = new Mock<IRepositories>    {        DefaultValue = DefaultValue.Mock    };    var reportsService = new OrderReportsService(        repositories.Object);    // Act    var report = reportsService.GetOrderReport(1);    // Assert    Assert.That(report, Is.Not.Null);}Enter fullscreen modeExit fullscreen mode  SummaryMocking is common when writing unit and integration tests. By default, Moq returns empty values for properties and methods that haven’t been explicitly set up. If your tests involve configuring multiple mocks to return unmodified object instances, it might be worth considering setting the DefaultValue property on your mocks to DefaultValue.Mock; mocks will then return mocks of the requested types. Ultimately, you’ll have less code to write while still maintaining the same functionality.Thanks for reading!This article is from my newsletter. If you found it useful, please consider subscribing. You’ll get more articles like this delivered straight to your inbox (once per week), plus bonus developer tips too!"
146,"You might have seen the word triage thrown around when talking about open source. Maybe you wondered what it meant and how that role impacts open source. If we think of open source like a journey, then the role of someone on the triage team is an explorer who helps to discover hidden challenges and helps to chart a path forward.   What is Open Source Triage?Open source triage involves evaluating and managing incoming issues and bug reports submitted by users and contributors. As a triage team member, your primary goal is to ensure that the project's issue tracker is well-organized and that reported problems receive the attention they deserve. In some ways, we can think of open source projects as a treasure map. A new feature release might be a small treasure. Maybe launching the product is the big X on the map. Along that map, you’ll find that there are challenges (bugs and issues) that need to be understood and categorized to make progress. A triage team member helps to understand and ask the right questions so the other explorers can continue on the journey.   The Triage Team’s Responsibilities  Issue TriageThis means you’ll need to learn how to categorize and prioritize issues based on their severity, impact, and relevance to the project.For example, let’s say you’re triaging an open-source pizza delivery software project. A user reports an issue regarding incorrect pizza toppings being displayed in the order confirmation screen. To triage this issue, you carefully analyze its severity, impact, and relevance to the project. After some investigation, you identify the problem as medium severity because it affects the user experience but doesn't cause critical failures to the success of placing the order. It’s still incredibly important to the project's core functionality, so you prioritize this issue to ensure a timely resolution.At the time this post was written, our Insights repo had 104 open issues. Having someone there to triage the issues provides the development team with more time to work on resolving the issues.   Issue VerificationTo verify issues, you need to replicate reported issues on your system.Continuing with our analogy, you encounter an issue reported by a user regarding a glitch in the pizza tracker, showing inaccurate delivery status. To verify the issue's validity, you follow the user's steps and use their order details to replicate the problem on your system. You’ll also check the software's logs to gather any other useful information. Once you’ve replicated the issue, you confirm the issue's validity and move forward.  Issue ManagementManaging issues helps to create a more efficient development process. Understanding how to assign labels, milestones, and priorities to issues allows you to update the issue tracker to reflect the work that needs to be done and prioritized.Bug: duplicate extension logo issue that needs triagedFor example, let’s say you come across an issue related to adding new pizza toppings to the menu—a request from the community. To manage this issue, you assign the appropriate labels, such as ""enhancement"" or ""feature request."" You add relevant milestones to indicate it as a target for the next software update. Because this is your most upvoted issue and your team has the capability to add this functionality, you prioritize this issue based on its popularity and the potential impact on the project's success. Throughout the process, you update the issue tracker with necessary details, providing the developers with a clear understanding of the community's desire for new pizza toppings.  Communication and CollaborationEngaging with users, contributors, and maintainers, you act as a bridge between them and the development team to resolve issuesAs a triage team member for the pizza delivery software, you see an issue raised by a user who struggled with the pizza customization process in the app. You respond to the user via comments on their issue, asking clarifying questions to understand their specific difficulty. You actively collaborate with other members of the pizza software community to find possible solutions. As part of the process, you gather feedback from other users, identify common usability challenges, and discuss potential improvements with the development team. Effective communication and collaboration efforts bridge the gap between users and developers, leading to a better pizza customization experience for all users.  Getting Started as a Triage Team MemberIf you want to grow in your open source journey, you might find that a good milestone is becoming a part of a triage team for an open source project. Here are some tips to follow that path:Choose a project you’re interested in and willing to commit to for an extended period.Check out the project's documentation, repositories, and issue tracker to understand its goals and contribution processes.Join the project's communication channels, introduce yourself, and let them know that you’re interested in becoming part of the triage team. Ask for help from experienced members.Even if you’re not a part of the team, that doesn’t mean that you can’t help. You can still offer contributors suggestions or direct them to answers if you’re able to. The key is to only do so if you know the answer. For example, maybe someone raised an issue that was already responded to. You can direct them to the previous answer.The triage team plays an important role in the long-term health of the project and supporting maintainers. Triage team members are the first point of contact for issues and bug reports and help to make the communication between the development team and the contributors seamless. Their work makes space for faster issue resolution, resource optimization, and knowledge sharing. It’s important to note that not all contributors have the technical expertise to contribute directly with the code. Triage creates an opportunity for non-developers to make meaningful contributions. A positive user experience often starts with the triage team."
147,"  Introduction:Have you ever wondered how websites and apps communicate with each other to fetch data or perform actions? Well, that's where HTTP requests and APIs come into play. In this guide, we'll demystify these tech terms and uncover the secrets of backend development—the behind-the-scenes magic that powers modern web experiences.  Understanding HTTP Requests: The Backbone of Web CommunicationWhen you click a link, submit a form, or request a picture on the internet, your device sends what we call an ""HTTP request"" to a server. This request is like a letter seeking for information or to an action. Servers then respond with the requested data or tell your device what to do next.HTTP requests have different ""methods"" or types. Think of these methods as verbs: you can ""GET"" (retrieve), ""POST"" (send), ""PUT"" (update), or ""DELETE"" (remove) stuff. These methods help us perform various tasks on the web.  Deconstructing APIs: Building Blocks of Web ServicesAPIs, which stands for ""Application Programming Interfaces,"" work like digital messengers. They help different software talk to each other smoothly. Imagine a friendly waiter taking your food order and passing it to the chef in the kitchen. That's how APIs help apps communicate and share information.Think of APIs as magic connectors. They help apps display weather forecasts, play music, and do all sorts of cool stuff. Imagine APIs as bridges that link different apps together, making the digital world feel like a big playground where everything talks to each other.  RESTful APIs: Principles for Designing Effective InterfacesOkay, so APIs are cool, but how do we design them? Enter ""RESTful APIs."" It's like a recipe for creating user-friendly APIs. Imagine RESTful APIs as a set of cooking instructions that ensure your dishes (data) turn out delicious every time.What's REST and How Does It Work?RESTful APIs follow a set of guidelines that make them easy to understand and use. Imagine these guidelines as a friendly chef's cookbook. REST stands for ""Representational State Transfer,"" which might sound complex, but it's like a roadmap for making APIs everyone can enjoy.1. Clear Names for Things (Resources):Think of RESTful APIs as a library where each book (resource) has a specific spot. This library's librarian (server) knows exactly where every book is located. When you (client) want a specific book, you simply ask for it using the book's title (URL). Just like saying ""I want that Harry Potter book on the second shelf."" The librarian fetches the book for you. It's the same with RESTful APIs. You ask for something specific using a URL, and the API gives you what you asked for.2. Stick to a Few Actions (HTTP Methods):In the cooking analogy, think of HTTP methods (GET, POST, PUT, DELETE) as cooking techniques. Each method is like a different way to prepare ingredients. For example, GET is like asking for the recipe (data), POST is adding a new ingredient (creating data), PUT is changing an ingredient (updating data), and DELETE is removing an ingredient (deleting data).3. Don't Remember Past Interactions (Stateless):Imagine you're ordering pizza from a restaurant. The pizza chef doesn't need to remember every pizza you ever ordered. They only need to know what kind of pizza you want right now. Similarly, RESTful APIs don't hold onto past interactions. Each request you make to the API is treated as a new and separate thing. This keeps things organized and prevents mix-ups.Putting It All Together: Organized and Easy-to-UnderstandJust like a cookbook follows a structured order, RESTful APIs have a clear and organized pattern. When you use a cookbook, you follow the steps to create a tasty dish. With RESTful APIs, you follow the guidelines to interact with the API and get the data you need. It's like having a chef's recipe book for building digital connections.So, next time you use an app to get weather updates or listen to music, remember that behind the scenes, RESTful APIs are following this clever recipe to make it all happen smoothly. By sticking to these cooking instructions, developers create APIs that are simple, consistent, and a joy to work with.  Request and Response: Navigating the API LandscapeWhen your app asks an API for something, it sends a request. Think of it like ordering pizza online. You choose toppings (request), and the pizza joint cooks your pizza with those toppings you requested and brings it to you(response). But watch out, sometimes things go wrong—like when you ask for pineapple on a pizza (error handling).APIs reply with ""status codes."" These are like emojis telling you how things went. For example, ""200 OK"" means all's good, while ""404 Not Found"" means the API couldn't find what you asked for.  Authentication and Security: Safeguarding Backend ServicesYou wouldn't want just anyone ordering pizzas using your account, right? That's where authentication comes in. It's like showing your ID to the pizza place before they give you your order.APIs also need security measures. They wear a digital cloak (SSL/TLS) to protect your data during the journey. Imagine your pizza box having a lock that only the pizza place and you have keys for. Secure APIs keep your info safe and sound.  API Documentation: Bridging the Gap Between Developers and ConsumersEver seen a recipe with clear instructions? API documentation is like that. It basically guides developers on how to use the API. Just as a recipe lists ingredients and steps, API docs show what the API can do and how to talk to it.Good documentation makes developers happy because they understand how to use the API without scratching their heads. It's like having a pizza-making guide with step-by-step pictures.  The Future of APIs: Exploring GraphQL and BeyondWe've journeyed through the fascinating realms of HTTP requests and RESTful APIs, discovering how they power the web we interact with daily. But as technology marches forward, new innovations emerge, and that's where ""GraphQL"" enters the stage—a revolutionary approach to fetching data from APIs.Think of GraphQL as your personal movie librarian in the digital world. Imagine you're at a vast movie library, and you want to find specific types of films. In the traditional web landscape, you'd receive entire stacks of movie catalogs, including information you might not need. It's like ordering an entire pizza when you only want a slice.But with GraphQL, precision is the name of the game. Imagine telling your movie librarian, ""Give me the names of action movies from the 90s,"" and they hand you a neat list, tailored exactly to your request. Similarly, GraphQL empowers you to ask for precisely the data you need, nothing more, nothing less.  Conclusion: Empowering Your Backend JourneyGreat job! You've started exploring the world of HTTP requests, APIs, and backend magic. These tech tricks make the web work smoothly, whether you're ordering your favorite food or enjoying adorable music videos. With this new knowledge, you're ready for an exciting journey into web development possibilities.As you keep going, armed with what you've learned, you'll have the tools to create amazing things. From cool apps to dynamic websites, you can make the web even more awesome. So, go ahead and code with confidence, knowing you're making the web a better place.Your web development adventure is just beginning, and every line of code you write adds to the online world. So, keep going and bring your coding ideas to life. Happy coding!Ziz Here🚀Kindly Like, Share and follow us for more contents related to web development."
148,"  IntroductionAround three years ago, I embarked on a journey of writing technical articles. While this endeavor has been rewarding, it hasn't been without its fair share of challenges. Even today, I occasionally find myself grappling with obstacles such as writer's block or the seemingly insurmountable hurdle of procrastination, which can hinder my motivation to produce yet another article.  Overcoming Challenges and Unleashing PotentialAs a fellow developer, I firmly believe that venturing into the realm of technical writing offers incredible benefits for personal and professional growth. Beyond the realm of code, writing technical articles opens doors to a world of opportunities for connecting with fellow enthusiasts. These interactions foster a sense of community and facilitate the exchange of ideas that can be truly transformative.Notably, writing technical articles can lead to exciting prospects, including high-paying writing gigs. The ability to communicate complex technical concepts effectively is a sought-after skill, and companies are willing to compensate proficient technical writers handsomely.  Discuss 🚀Now, as we delve into the realm of technical writing, I'd love to initiate an open dialogue. Let's discuss the challenges that you, as fellow developers and writers, encounter while crafting technical articles. By sharing these obstacles, we can collectively work towards finding solutions that empower each of us to overcome these hurdles.Some questions to ponder and discuss:What are the primary challenges you face when writing technical articles?Is writer's block a recurring obstacle? How do you tackle it?How do you overcome the occasional laziness that strikes when faced with writing another article?Have you experienced any hurdles related to effectively conveying complex technical concepts?What strategies do you employ to maintain consistency and motivation in your writing journey?By engaging in this conversation, we can pool our experiences, insights, and solutions, creating a valuable resource that helps fellow developers become not only proficient writers but also effective communicators of technical knowledge.Let's embark on this collective exploration of challenges and triumphs, aiming to enhance our skills and share the rewards of technical writing. Also this discuss kind of article has some text generated with ChatGPT."
149,"Debugging is an integral part of any software development process. It's a systematic hunt for bugs and mistakes that may be hidden in the intricate lines of your code. Much like a hunter and its prey, it requires a precise method and a set of specific tools. Let's delve deeper into the fascinating process of isolating assumptions to effectively debug your code.Before I proceed with this week's post if you have friends who are learning to code… I published a new book for Java beginners with no prior knowledge (for learning programming from scratch). Each chapter also has an accompanying video and I think there’s no book quite like it for beginners. I would appreciate spreading the word on this.  The Role of Assumptions in DebuggingDebugging starts with defining the quadrants of the issue and then methodically eliminating possibilities until the root cause of the problem is found. However, this process can be dangerous, as it requires making assumptions about the code.Often, debugging sessions fail or take longer than anticipated due to incorrect assumptions. A mistake at this stage can drastically elongate the debugging session compared to a mistake made at any other stage.Think of it in terms of the popular TV show Dr. House. It’s a Sherlock Holmes version of a medical drama where the lead character, a grumpy misanthrope, often faces challenges due to the incomplete or incorrect information provided by his patients. This is akin to debugging where we often spend most of our time on a wild goose chase due to incorrect assumptions or missing information.  The Solution to Wrong Assumptions: Double VerificationThe best solution to erroneous assumptions is double verification. For every assumption, no matter how basic, we should find another approach to verify it. For instance, let's say we have a bug in code that depends on a result from a remote service. We assume the service works correctly, and we verified that by using the cURL program. To double-verify, we should also add a tracepoint in the code that shows we received the response.As we narrow our assumptions, double verification may not always be necessary. However, if the process seems stuck, it's essential to revisit and ensure every stage has been verified. Often, we miss something simple and obvious, so it's important to verify the ""low-hanging fruit"" first.  Expanding the Assumptions' Perimeter: The Predator AnalogyDebugging can be likened to setting up a fence to trap a predator. If the fence is too small, we risk leaving the predator outside, wasting time searching within the confines of an empty enclosure. Conversely, if we fence off a large area, it will take considerable time to pinpoint the predator.Similarly, in the context of debugging, the bug (predator) and its root cause might be located in different areas of the application (fenced territory). Therefore, we need to make careful assumptions and decide where to place our focus.Understanding why the program behaves the way it does and the root cause is the ultimate goal of debugging. While locating the bug or even fixing it are crucial steps, the understanding gained is invaluable for future debugging sessions and long-term groundwork.  Prioritizing Assumptions to Find the Root CauseWhen faced with a symptom, we need to prioritize our assumptions to find the root cause. Our intuition and experience often guide us toward that root cause. Yet, we must refrain from taking shortcuts that lead from the system directly to the root cause, as this approach often proves misleading. Instead, our focus should be on the next stage, which is the bug itself.For instance, if a value is incorrect on the screen, we can start by verifying that the source returns the right value and work our way from there. However, when faced with a value that ""shouldn't be here"", we may not have an immediate course of action. One effective solution for this could be time travel debugging, which lets us traverse the state of the application after execution is completed. This technique is especially beneficial when the issue is not easily reproducible, and we're dealing with a problematic state that's hard to investigate.  A Common Mistake: The Lure of a Quick FixA frequent mistake made during debugging is rushing to the line of code that contains the bug, as we assume we already know the problem. We then become focused on a specific area around the bug and waste a considerable amount of time investigating that code. Instead, we should create a wider circle by debugging the code we assume works correctly. By doing this, we either discover the assumption isn't working as expected, and we widen our search, or we confirm that the assumption is functioning correctly, giving us a solid base to delve deeper into.This is illustrated by the following diagram. We rush to narrow down the search scope and this leads us down the wrong path where we surround the symptom with assumptions and spend time there instead of looking for the root cause. It in itself can be in a completely different location from the location where the bug is expressed.The downside is that the wide perimeter search is so much bigger, but it is sometimes a preferable scope of search.  Final WordTo sum it up, debugging is indeed a complex process that requires a careful and methodical approach to isolate and eliminate assumptions. By being aware of common pitfalls and adopting proven strategies such as double verification, prioritizing assumptions, and avoiding the lure of quick fixes, we can improve our debugging skills and make the process more efficient. In the next article, we will further explore this topic by discussing common problems and solutions that can provide a practical application to these theoretical concepts. Stay tuned!"
150,"In the realm of programming, lists are the workhorses of data storage. They hold collections of items, acting as dynamic containers that can expand and contract as needed.When it comes to working with lists, mastering the art of manipulation and filtering is essential for crafting elegant and efficient code. Enter ""ListElegance,"" a Python programming paradigm that combines simplicity and power to bring your code to life.In this journey, we'll explore how ListElegance can transform the way you manipulate and filter lists, and we'll unravel its mysteries through examples and practical scenarios.PrerequisiteTo get started you must have basic knowledge of Python and must have a code editor that has the Python framework installed, I would suggest you install Pycharm or Vscode.You can get started with the basics of Python on our blog page, a lot of materials are listed here.Unveiling ListEleganceImagine coding as an art form, where the lines of code are strokes on a canvas. ListElegance is the palette that transforms these strokes into a masterpiece. It emphasizes code readability, efficiency, and elegance. Through its lens, list manipulation becomes not just a technical process, but a creative endeavor.Let's start by exploring basic list manipulation techniques. Consider a scenario where you want to append elements to a list:# Traditional Approachmy_list = []my_list.append(1)my_list.append(2)my_list.append(3)# ListElegance Approachmy_list = [1, 2, 3]Enter fullscreen modeExit fullscreen modeWith ListElegance, the code becomes concise and expressive. It allows you to initialize and populate a list in a single line, making your intentions clear and your code visually appealing.The Art of List ManipulationListElegance empowers you to shape lists with precision. It's not just about appending; it's about orchestrating data effortlessly. Consider the task of removing an item from a list:# Traditional Approachmy_list = [1, 2, 3, 4, 5]my_list.remove(3)# ListElegance Approachmy_list = [item for item in my_list if item != 3]Enter fullscreen modeExit fullscreen modeListElegance introduces list comprehensions, a powerful technique that elegantly filters and transforms data. This code not only removes the specified item but also communicates your intent clearly.ListElegance Filtering TechniquesThe heart of ListElegance lies in filtering. Imagine having a list of numbers and wanting to remove all even numbers:# Traditional Approachnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9]filtered_numbers = []for num in numbers:    if num % 2 != 0:        filtered_numbers.append(num)# ListElegance Approachfiltered_numbers = [num for num in numbers if num % 2 != 0]Enter fullscreen modeExit fullscreen modeThe ListElegance approach is concise, resembling a natural language sentence. List comprehensions condense the logic, creating a code symphony that's both efficient and beautiful.Iterative vs. ListElegance ApproachComparing the iterative and ListElegance approaches, the difference is akin to reading a novel versus reading a haiku. ListElegance transforms complex loops into concise expressions, making code both elegant and comprehensible.Consider filtering a list based on a condition:# Traditional Approachvalues = [10, 15, 20, 25, 30]filtered_values = []for val in values:    if val &gt; 20:        filtered_values.append(val)# ListElegance Approachfiltered_values = [val for val in values if val &gt; 20]Enter fullscreen modeExit fullscreen modeThe ListElegance approach gracefully abstracts away the iteration, leaving you with a clear and focused intent.Advanced List FilteringList comprehensions in ListElegance offer a portal to advanced filtering techniques. Suppose you have a list of words and want to filter out words shorter than a certain length:# Traditional Approachwords = [""apple"", ""banana"", ""grape"", ""kiwi"", ""orange""]filtered_words = []for word in words:    if len(word) &gt;= 5:        filtered_words.append(word)# ListElegance Approachfiltered_words = [word for word in words if len(word) &gt;= 5]Enter fullscreen modeExit fullscreen modeThe ListElegance approach celebrates the essence of coding as an art, embracing simplicity and creativity.Real World ApplicationListElegance finds its magic in real-world applications. Imagine processing a list of emails and filtering out spam:# Traditional Approachemails = [""alice@example.com"", ""bob@example.com"", ""spam@example.com"", ""charlie@example.com""]filtered_emails = []for email in emails:    if ""spam"" not in email:        filtered_emails.append(email)# ListElegance Approachfiltered_emails = [email for email in emails if ""spam"" not in email]Enter fullscreen modeExit fullscreen modeIn scenarios like data analysis or text processing, ListElegance shines as a beacon of clarity and efficiency.Another example of a real-world application, our program will involve processing a list of numbers to perform various filtering and transformation tasks. This will help us consolidate what we've learned and apply it in a practical context.Program: Number Cruncher with ListEleganceObjective: Create a program that takes a list of numbers, performs filtering and transformation tasks using ListElegance techniques, and displays the results.Steps:Input the List: Prompt the user to input a list of numbers, separated by spaces.Parse the Input: Convert the user input into a list of integers.Filter Out Odd Numbers: Use ListElegance to filter out odd numbers from the list.Double the Numbers: Apply ListElegance to double each remaining number in the list.Calculate the Sum: Calculate and display the sum of the filtered and transformed numbers.Display Results: Display the original list, filtered list, transformed list, and sum.# Step 1: Input the Listinput_numbers = input(""Enter a list of numbers separated by spaces: "")numbers = [int(num) for num in input_numbers.split()]# Step 3: Filter Out Odd Numbersfiltered_numbers = [num for num in numbers if num % 2 == 0]# Step 4: Double the Numbersdoubled_numbers = [num * 2 for num in filtered_numbers]# Step 5: Calculate the Sumsum_of_doubled_numbers = sum(doubled_numbers)# Step 6: Display Resultsprint(""Original Numbers:"", numbers)print(""Filtered Numbers (Even):"", filtered_numbers)print(""Doubled Numbers:"", doubled_numbers)print(""Sum of Doubled Numbers:"", sum_of_doubled_numbers)Enter fullscreen modeExit fullscreen modeExample Output:Enter a list of numbers separated by spaces: 1 2 3 4 5 6 7 8 9Original Numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9]Filtered Numbers (Even): [2, 4, 6, 8]Doubled Numbers: [4, 8, 12, 16]Sum of Doubled Numbers: 40Enter fullscreen modeExit fullscreen modeIn this program, we've applied ListElegance techniques to filter out odd numbers and double the remaining even numbers.This example demonstrates how concise and expressive ListElegance can be when performing multiple list manipulation tasks.You can further extend this program by incorporating more complex filtering conditions or additional transformation tasks to explore the versatility of ListElegance in various scenarios. ListElegance PrinciplesAs you embark on your ListElegance journey, remember these guiding principles:Clarity over Complexity: ListElegance celebrates clear intent and readability.Elegance in Efficiency: Expressiveness doesn't compromise efficiency.Learn, Experiment, Elevate: Embrace the artistry; experiment with list comprehensions, and evolve your skills.Curtain Call: Applause for a New BeginningAs the curtains draw close on our exploration of ListElegance, remember that this is just the beginning. Embrace the magic, the creativity, and the elegance.With ListElegance, you wield the power to craft code that transcends the mundane, a testament to the art of programming.In conclusion, ListElegance redefines the way we approach list manipulation and filtering in Python. It empowers us to transform code into a work of art, celebrating clarity, efficiency, and creativity. As you embark on your journey with ListElegance, remember that elegance is not just about the code you write, but the impact it creates.If you find this post exciting, find more exciting posts on Learnhub Blog; we write everything tech from Cloud computing to Frontend Dev, Cybersecurity, AI, and Blockchain.Resource20 Essential Python Extensions for Visual Studio CodeUsing Python for Web Scraping and Data Extraction13 Powerful Python Snippets To Automate TasksGetting Started with Python"
151,"When I was 5 years old, my Dad introduced me to the world of video games, igniting a hobby that would become a lasting passion. By the time I turned 6, I was already drawn to the extra layers of concept art and behind-the-scenes development that accompanied these games. With the arrival of our first family computer, and after downloading all my favorite games, I eagerly delved into the realm of Indie Game Development. I spent hours absorbed in learning various coding techniques, aiming to create simple games like Pac-Man or Snake. Each challenge brought new excitement, and whenever I felt burnt out, I'd find something fresh to reignite my enthusiasm.Over the years, I largely self-taught the art of indie game creation, utilizing the vast resources available online. Upon high school graduation, my career path was clear. Despite a somewhat complex school history due to life's unexpected turns, I remained determined.Post-graduation, I enrolled at my local community college with the intention of pursuing a degree in 3D Graphics and Design, which had piqued my interest in the visual aspects of game development. Regrettably, after just one semester, circumstances forced me to leave school and secure employment to support myself. This marked the beginning of my journey toward independence, as my parents urged me to assume more responsibility for my life. Nonetheless, I remained undeterred. Approximately a year later, I managed to gather basic necessities—a car, a phone, and a laptop—and re-enrolled, this time at a university.For the subsequent two years, Colorado Mesa University became my academic home, where I focused intently on achieving a degree in 3D Graphics and Design. Yet, midway through my second year, the global impact of COVID-19 abruptly halted my studies, prompting a return home during the worldwide quarantine.During the lockdown, I transitioned to a job in the food industry to sustain myself. Here, I discovered my knack for management, swiftly ascending the ranks to acquire a respectable title and income. However, my dream of becoming a programmer and game developer remained steadfast. Determined to forge ahead, I left this role for a more flexible position in package delivery, strategically balancing my need for a well-paying job with the time required to resume my education.As fate would have it, I stumbled upon a programming bootcamp just after learning of my girlfriend's pregnancy—a surprise that required me to carefully reconsider my priorities. Ultimately, family took precedence, and nine months later, my son was born. Navigating the uncharted waters of parenthood proved to be a formidable challenge, monopolizing much of my time. However, with time, my girlfriend and I established a comfortable routine, paving the way for me to reignite my educational pursuits. Driven by a newfound motivation, I re-enrolled at Flatiron School, eager to immerse myself once again in the world of programming.My young adult years have unfolded as an exhilarating adventure, marked by unwavering dedication to my aspirations. With the invaluable guidance of the remarkable individuals at Flatiron School, I am poised to embark on a fulfilling career in the tech industry. Whether my path leads me to the realm of Game Design, Web Development, or beyond, I am ready and eager to embrace the next chapter of my life in the world of technology."
152,"If you've been itching to create a mobile app that uses the power of Generative AI, you're in the right place.Let's dive into how you can build one using Flutter and OpenAI GPT-4. And don't worry, I'll keep it simple.Ready? Let's get started!1. Setting Up Your Developer Playground 🛠️First things first, let's get your developer environment all set up:Flutter SDK: If you haven't already, grab the latest Flutter SDK. It's the backbone of what we're doing.IDE Magic: Choose your favorite IDE and sprinkle in some Flutter plugins. Personally, I'm a big fan of VSCode. But hey, you do you!Testing, Testing, 1, 2, 3: Always test your app. Use both an emulator and a real device. It's like trying on shoes; you gotta make sure they fit everywhere!2. Crafting That Sleek Client UI 🎨Now, let's talk looks:Starting Point: Kick things off with Flutter's basic app template. Here's a nifty command to get you going: flutter create --org com.example -t skeleton exampleInspiration Time: Not sure about the design? No worries! Check out dribble or behance. They're like the Pinterest of UI design. Then, bring your vision to life with Flutter's widgets.User Experience: Remember, your app is for users. Design a clean UI where they can easily input their queries and marvel at the AI-generated content.3. Making Friends with OpenAI GPT-4 🤖This is where the magic happens:Getting Started: First, sign up with OpenAI and secure your API key. It's like your golden ticket.API Calls: Use Flutter's http package to chat with OpenAI.3.1 The Art of Prompting:Think of prompts as the questions you ask the AI. The better the question, the better the answer. So, be specific! Instead of just saying ""Translate"", go with ""Translate the following English text to French:"". Test and refine your prompts in the OpenAI playground. Need some tips? Here's a handy GPT best practices guide.3.2 Customizing Your AI:Want your AI to be a specialist? Fine-tuning is the answer. Gather data related to your app, like chat logs or specific content. Then, use OpenAI's platform to fine-tune your model. Once done, integrate it into your app.Here's a GPT Fine Tuning guide to help you out.4. Making It Shine on Android & iOS 📱Your app needs to look and work great, whether it's on an Android or an iPhone:Design Nuances: Each platform has its quirks. Get familiar with them.Native Functionalities: Use Flutter's platform channels to tap into native features.Consistency is Key: Ensure your app feels the same across both platforms.5. Launching Your Masterpiece 🚀You've built it, now let's get it out there:Building for Production: Use Flutter's tools to get your app ready for the big leagues.Store Time: Launch your app on the Google Play Store & Apple App Store. Let the world see your creation!Feedback Loop: Always keep an ear out for user feedback. It's how you make your app even better.Conclusion 🌟Whew! That was a ride, wasn't it? Sure, there's always more to add and learn, but this guide should set you on the right path. Thanks for sticking with me till the end! If you found this helpful, give me a follow for more such guides. And if you're scratching your head over something, drop a comment. Let's chat!Before we go...I'm building an online school for budding developers like you. Every week, there's a new podcast, tutorial, or coding tip waiting for you. Let's make you a 10x developer!          Videos will start dropping soon.About me: I am a coder with a keen interest in fixing real-world problems through shipping tech products. I love to read books. I have read multiple books on start-ups and productivity. Some of my favourite reads are Zero to One, Steve Jobs, The Almanack of Ravikant and Hooked. Nothing excites me more than exchanging opinions through productive conversations.                youtube.com      Got any doubt or wanna chat? React out to me on twitter or linkedin.Until next time, happy coding! 🚀👩‍💻👨‍💻"
153,"INTRO 🔊As a frontend developer, it is very important to know that routing and particularly private routing for user authentication. For example some applications are public i.e any one can see and modify content in it, but some other applications are not allowed all the users to modify the content inside the application like posting new data, deleting and modifying the data etc..., For that we have to use protected routes in ReactJS.In this post we will discuss how to create protected routes in ReactJS in simple and efficient way without any confusion.🔥 APPROACH 🔊I hope you people already created ReactJS application. Otherwise please follow this link to create react application📌 NOTE:  To handle protected routes in ReactJS, we have to install library react-router-domnpm i react-router-domEnter fullscreen modeExit fullscreen modereact router dom is the famous library which helps to routing in ReactJs.After install the library check the package.json file whether that library was installed or not.📌 NOTE:  This routing method will works only the library react-router-dom having the version >= 6 not for the version <= 5Now we have to create one helper file useAuth to check whether a token is preset or not.📌 NOTE: Token is specific key (response) provided from the backend when user logged in successfully. By using token we can check whether the user is logged in or logged out.//useAuth.jsexport const useAuth = () => {    //getting token from local storage    const user = localStorage.getItem('token')    //checking whether token is preset or not    if (user) {        return true;    } else {        return false    }};Enter fullscreen modeExit fullscreen modeNow we have to create two files named privateRoute and publicRoute. privateRoute file will execute when the user is logged in state and publicRoute file will execute when the user is logged out state.//privateRoutes.jsimport { Outlet, Navigate } from 'react-router-dom'import { useAuth } from './useAuth'function PrivateRoutes() {    const token = useAuth()    return token ? <Outlet /> : <Navigate to='/login' />}export default PrivateRoutesEnter fullscreen modeExit fullscreen mode//publicRoutes.jsimport { Outlet, Navigate } from 'react-router-dom'import { useAuth } from './useAuth'function PublicRoutes() {    const token = useAuth()    return token ? <Navigate to='/' /> : <Outlet />}export default PublicRoutesEnter fullscreen modeExit fullscreen modeThe routing setup completed successfully. 🎉 Now we have to use this setup in our application to handle private routing. 🔥//App.js//importing from react-router-dom libaryimport { Routes, Route } from 'react-router-dom'//importing previously created privateRoute.js fileimport PrivateRoutes from ""./privateRoutes""//importing previously created publicRoute.js fileimport PublicRoutes from './publicRoutes'//let's import some private componentsimport Home from './home'import ErrorComp from './error'//let's import some public componentsimport Login from './login'function App() {  return (    <Routes>      <Route element={<PrivateRoutes />}>        <Route element={<Home />} path='/' />        <Route element={<ErrorComp />} path='*' />      </Route>      <Route element={<PublicRoutes />}>        <Route element={<Login />} path='/login' />      </Route>    </Routes>  )}export default AppEnter fullscreen modeExit fullscreen modeFinally the protected routes in ReactJS completed successfully. 🎉 🎉 Now we can check those private routes and public routes by providing the token (let's take any string) manually in chrome devtools->inspect->application.Otherwise we can create login and home files to handle the routing in client side. 🚀Create login (public component) page to log the user in and redirect to home (private component) page after setting the token in local storage successfully (the app can redirect to home when only token is preset in local storage).//login.jsimport { useNavigate } from 'react-router-dom'function Login() {    const navigate = useNavigate()    const handleLogin=()=>{    const res = {**login api call***}    const token = res.data.token //let's take some string 'dev' as token    localStorage.setItem('token', JSON.stringify(token))    navigate('/')    }    return (        <>          <button onClick={handleLogin}>Login</button>        </>    )}export default LoginEnter fullscreen modeExit fullscreen modeCreate home (private component) page to view the user personal details and to log the user out.//home.jsimport {useNavigate} from 'react-router-dom'function Home() {    const navigate = useNavigate()    const handleLogout = () => {        localStorage.removeItem('token')        navigate('/login')    }    return (        <>            <button onClick={handleLogout}>log out</button>            <div>home page</div>            <div>hello user</div>        </>    )}export default HomeEnter fullscreen modeExit fullscreen modeCreate error page (optional) to display while doing wrong routing.//error.jsfunction Error() {  return (    <>      this is error page    </>  )}export default ErrorEnter fullscreen modeExit fullscreen modeFinally the whole routing setup and checking done successfully 🎉 🎉 🎉 📌 NOTE: In the same way we can create multiple components and add them in to App.js page.SOURCE CODE 🔊For the source code, you can check my git hub link here 💡CONCLUSION 🔊I hope you people understand, how to setup protected routes in ReactJS by using React Router Dom having version 6 and above. We will meet next time with another post. 🔥Peace 🙂"
154,"Have you ever faced a particularly challenging coding obstacle that seemed insurmountable? How did you approach it, and what strategies did you use to overcome it?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
155,"Recently on the r/dotnet Reddit community, a new post has been published with an alarming title: Does Moq in it's latest version extract and send my email to the cloud via SponsorLink?.Since then, there have been a lot of discussions around it, but what is this all about?  Starting from the beginningTo gain a proper understanding of the situation, let's begin by providing an overview of Moq itself.Moq was is a popular .NET mocking library that has accumulated over 475.7 million downloads as of now.For more than 10 years, Daniel Cazzulino (or @ksu) has been diligently building and refining it.When comparing it to one of its most well-known alternatives, NSubstitute, which has ""only"" reached 85.6 million downloads, it is fair to say that Moq is the most widely used mocking library in the .NET ecosystem.  Setting the sceneEarlier this year, @ksu released a new project named SponsorLink in a blog post named SponsorLink: trying something new-ish for OSS sustainability.The primary objective of this project, as outlined by the author, is to establish a direct connection between projects and your GitHub account:So the goal of SponsorLink is to connect in the most direct way possible your sponsorship with your library author’ sponsor account. And since the place where you spend most of the time enjoying your fellow developers’ open source projects is inside an IDE (..), I figured that’s the first place where you should be reminded that eitherThis approach allows sponsors of a GitHub library through the GitHub Sponsorship program to potentially access additional features, receive thank-you messages within their IDE, or more.However, an alternative perspective on SponsorLink, albeit less flattering, is that the project is capable of identifying individuals running a project containing it by transmitting their email addresses to the cloud.Worse: it doesn't merely capture your email address; it also extracts all email addresses present in the git history of your project. Depending on your project's lifespan, this could involve a significant number of addresses.Claims have been made that these addresses are hashed and so forth, but the DLL is closed-source and obfuscated. Given the nature of this project, such practices raise suspicions, to say the least.In the blog post itself, people raised concerns about its ethical considerations:  What went wrongBy now, you have likely guessed what went awry.A couple of days ago, @kzu submitted a Pull Request, announcing that SponsorLink was now integrated into Moq, thereby harvesting email addresses of the developers utilizing it in their projects:        Add 💜 SponsorLink support      #1363kzu posted on Aug 04, 2023See https://www.cazzulino.com/sponsorlink.html and https://github.com/devlooped/SponsorLinkLet's thank everyone who supports the project 💜View on GitHubThis Pull Request received a largely negative reception and prompted a significant number of projects to replace Moq within their codebases.Shortly after, various issues raising privacy concerns has been opened:        Privacy issues with SponsorLink, starting from version 4.20      #1372GeorgDangl posted on Aug 08, 2023There's a related discussion on Reddit: https://www.reddit.com/r/dotnet/comments/15ljdcc/does_moq_in_its_latest_version_extract_and_send/It seems that starting from version 4.20, SponsorLink is included. This is a closed-source project, provided as a dll with obfuscated code, which seems to at least scan local data (git config?) and sends the hashed email of the current developer to a cloud service. The scanning is provided as a .NET analyzer tool, which runs during the build. There is no option to disable this.I can understand the reasoning behind it, but this is honestly pretty scary from a privacy standpoint.Any chance this can be reverted?View on GitHub  What now?This update has some questionable points such as collecting the user's data by default without an opt-in/out option (defying GDPR) or adding closed source and obfuscated add-on without any consent of the community.For now, it seems that people are running away from it and companies are blocking the library. Some are also reporting the 4.20 version, which introduced SponsorLink.However, it's important to also take into account the perspective of the maintainer, especially given the challenging landscape many open-source maintainers face in sustaining their projects. Open-source maintainers often struggle to find sustainable ways of supporting their work.In a new issue, the maintainer of Moq expresses the desire to gather feedback on how their Open Source projects could receive better support:        SponsorLink and supporting OSS more broadly      #1374kzu posted on Aug 09, 2023Trying to aggregate the various issues into one to collect feedback.I invite everyone to read the SponsorLink announcement to understand the intention behind it. No nefarious purpose, I promise! 🙏With that in mind, I'm obviously open to suggestions that help achieve both your goals and mine :)NOTE: 4.20.2 removes SponsorLink since it breaks MacOS/Linux restore. I'll take the opportunity to collect more feedback.The underlying issue still needs addressing, IMHO.View on GitHubDespite the apparent goodwill, SponsorLink remains included in Moq as of now and, I think, its reputation permanently damaged as the implicit trust most people had in it has been broken.If you are more of a listener than a reader, check out @elfocrash video on the subject, who did a great job summarizing everything:I hope that you learnt something useful there!Pierre BouillonFollowSoftware Engineer | Privacy Advocate | Coffee LoverPhoto by Jason Blackeye on Unsplash"
156,"  TL;DRBegging to he hired devalues your worth and sets you off as desperateBe confident in your skillsFor every knowledge or skill gained, your value increases.Learn how to sell yourself properlyShowcase your knowledge and skills and value to potential employers.Be assertive, don't sell yourself short.  Why You should Not Beg for a JobGetting hired is a goal a lot of developers out there hope to achieve, but are you going about it the right way?The tech space today is highly competitive and landing a job within is a rather tasking endeavor which requires quite some effort and determination. A lot of developers seeking for jobs don't really know how to go about it, hence they find themselves in the comment sections or DMs of recruiters begging to be hired. Most times when I come across such posts or comments like that, I just find it completely wrong and mostly cringe.Doing this makes you devalue yourself and sets you off as desperate and unprofessional.You have taken the time to learn the skills and strengthen your knowledge base, so I don't see why you should still be begging to be hired. If you do, you probably fall in one of these categories:You are actually not confident in your skills enough.You probably feel there would be some sort of empathy towards you, hence landing you the job.You just don't know how to sell yourself.  Category 1If you fall under this category, you have learned the skills required for the job you are seeking, but you don't feel quite confident enough to actually land you the job hence you go beg for it, wanting to be hired on merits of  a favor rather than based on your actual value. All you have to do is work on your confidence level.There is one thing I like to say to people a lot, which is:Confidence would put you at the topConfidence will present you as a knowledgeable person in your field. You might actually not be 100% confident in your self or your skills within, I know a lot of people struggle with imposter syndrome daily. but don't ever let that reflect outwardly, you would just be setting yourself up for complete self devaluation. If your skills in reality aren't actually enough to land the job, then I don't think a job is what you should be searching for at that moment. Take your time to learn the required skills, broaden your knowledge base. Dont go learn HTML, CSS and JavaScript, then go begging for a job with a company that the core of their Frontend is React. You are of little to no value to them.   Category 2If you fall under category 2, you must have probably received some very bad advice somewhere. People would not hire you based on how much you beg for the job, 'software development' is not 'waiting tables'. People want to see how you can be a valuable asset to them and that you have the knowledge to take on the role. If you are begging for the job, it shows you don't know your value and if you don't know your own value, it's hard for someone else to see it.      Category 3For those in this category, the ability to sell yourself is a very crucial thing you need to understand if you are looking to be  hired. Here are a few ways you could sell yourself properly to potential employers and set yourself apart from over 50% of the other applicants.Be socially active: Being socially active doesn't necessarily mean you have to go out of your way to become a tech influencer or some thing. It simply means just showcase your knowledge on social platforms for the world to see. I would recommend LinkedIn and Twitter specifically, those are great platforms that can really help you get spotted by potential employers looking for your skills.Build and share your knowledge publicly: Show off what you can do always, no matter how small. I find this method really great because you are not only setting yourself above a whole lot of applicants for whatever role you are applying for, but you also create a public archive of your knowledge for both others and yourself. Follow hiring managers on your social platforms. Engage with their posts, not asking or begging for a job, but showcasing your knowledge. envision your self as a recruiter, look at your work and ask yourself: ""would I want to hire me?"". Your answer to this would give you some clarity on what it is you should do or don't do to make yourself better.Contribute to Open Source: Honestly this can't be overemphasized. Put yourself out there by contributing to open source projects. Pick a few targets companies that you would be interested in working for, learn one or two about what they do, and try to figure out how you can improve on their existing software and go ahead to make the contributions. A little twist you could add to it is as a beginner: After contributing to a project and your contributions were hopefully accepted, send an email to the software company, seeking an internship. Send them the contributions you made to their software, highlighting how you solved whatever issue and your interest in their company, stating your desire to work with and learn more about the company as an intern. This would put you about 50% ahead of most other applicants that would probably submit for an internship role with them, they would see your actual interest and understanding of their software. Your request of an internship role rather than a job would also be interesting to them, because it shows your willingness and interest to learn about the company, rather than you just looking for a paycheck. This method would help you put your foot in the door, and after working for an intern for a certain amount of time, you could apply for a full time role with a higher paycheck😉.Be assertive: No one wants to hire anyone who feels they don't really know what they are doing. Humans in general are programmed to have more faith in the assertive one, even before they actually get to learn what it is you can really do.When seeking a job opportunity, it's essential to avoid certain phrases such as ""I would be honored if you hire me"" ""you would not regret it if you hire me"" and ""I would like to work in your company because..."" can diminish your assertiveness.Instead, employ expressions such as ""I have had the opportunity to closely observe the impactful work undertaken by your company, which I find incredibly intriguing"" and ""Being a part of a team that consistently delivers innovative solutions aligns well with my career objectives"".The latter positions you as a confident candidate who values mutual benefits. It's important to convey your desire to contribute positively to the organization without compromising your professional integrity.Hopefully, this article have given you one or two insights on how to go about your job hunting without begging for it.If you have any question or techniques you feel people should also apply when seeking a job, please do not hesitate to share it in the comment section below. Till then✌."
157,"I first heard about the term Microfrontends during a JS Poland conference in Warsaw few years ago. There was a really good presentation by Luca Mezzalira about this topic and after seeing it, I thought about building such application myself. I created some simple proof of concept with React and Vue and I really liked that idea.However, in my work projects I never had an opportunity to build such systems. I really hope that in the next months or years I will be able to build such application as this architecture pattern looks really promising.  The general ideaThe term Micro Frontends first came up in ThoughtWorks Technology Radar at the end of 2016. It extends the concepts of micro services to the frontend world. The current trend is to build a feature-rich and powerful browser application, aka single page app, which sits on top of a micro service architecture. Over time the frontend layer, often developed by a separate team, grows and gets more difficult to maintain. That’s what we call a Frontend Monolith. Let's take a look at the following diagram about different architecture patterns.The idea behind Micro Frontends is to think about a website or web app as a composition of features which are owned by independent teams. Each team has a distinct area of business or mission it cares about and specialises in. A team is cross functional and develops its features end-to-end, from database to user interface. Let's take a look at the following diagram about Microfrontends architecture:So the example application might look like this:Source: https://martinfowler.com/articles/micro-frontends.htmlAs we know already what is Microfrontends architecture, let's take a look at pros and cons of using it.  Benefits of using MicrofrontendsImplementing Microfrontends architecture comes with several useful benefits that I listed below like:Being Technology Agnostic - Teams can choose technology stack that works for them best.Team Code is isolated - Build independent applications in isolated environments and repositoriesIndependent deployment - Applications in Microfrontend architecture can be deployed independently which is great for Continuous Deployment / DeliveryIncremental upgrades - Changes can be applied incrementally without affecting the whole application which is easier to test and less risky.  Cons of using MicrofrontendsUsing Microfrontends architecture comes with benefits but it can also lead to issues. Take a look at some of them below:Bigger complexity - Maintaining and aligning several product teams can be much more difficult.Terminology - Teams should have unique namespaces that will not colide with each other.Sharing context - In some cases like Auth, frontend apps might need to share context of authenticated user which may be complicated to implement.  ResourcesCheck out the following resources to learn more about Microfrontends Architecture:https://micro-frontends.org/https://martinfowler.com/articles/micro-frontends.htmlhttps://www.aplyca.com/en/blog/micro-frontends-what-are-they-and-when-to-use-them"
158,"Typing long commands can get tiresome, this is where aliases can come in handy!In this blog post I’ll share how you can set up aliases for your Git commands.  Using aliases allows you to set up shortcuts that will make your life easier.  There are two ways in which you can set up your aliases.  Set up aliases using the Git config commandYou can set up your aliases using a command within your command line tool. The format for the command is:git config --global alias.<alias-name> '<git-command>'Enter fullscreen modeExit fullscreen modeIn practice that means if you want to type git c instead of typing git checkout the alias you would configure is:git config --global alias.c checkoutEnter fullscreen modeExit fullscreen mode  Set up aliases using the .gitconfig fileAnother approach is to make modifications to the .gitconfig file.  This is usually stored within your home directory, on my Windows machine it was stored under _C:\users\sarah\ _Within this file create an alias section like below:[alias]# Shortcut for statusst = status# Shortcut for checkoutco = checkout# Shortcut for branchb = branch# Shortcut for helph = help# Shortcut for last commitlast = log -1 HEAD# Shortcut to query log for altered filesl = log --stat# Shortcut to query log and make it prettyld = log --graph --decorate --date=shortEnter fullscreen modeExit fullscreen mode  Deleting a Git aliasIf you want to remove an alias you can delete the configuration from the .gitconfig file or you can use the following command:git config --global --unset alias.<alias-name>Enter fullscreen modeExit fullscreen mode  Check all aliases in GitIf you want to check which aliases are currently set within your configuration you can use the command:git config --get-regexp '^alias\.'Enter fullscreen modeExit fullscreen mode  Using Git aliasesNow that the aliases are set up you can now use them when you are within your command line tool.  I can now use git l in lieu of git log –stat. 💡 It’s important to remember, these aliases are only applicable to your local machine."
159,"Because I thought I could make a living with - Seat your belts and see how I deluded myself for a year and learned a great many lessons from it.So my journey has started more than a year ago, around 2022 March. I had this million dollar idea to make a game out of rock paper scissors with extended rules. Like hitting the rock with scissors to create a spark and fire up a stack of paper to warm up and survive the night.But then I thought, why keep this to only three objects? There is only so much you can do with rock paper and scissors. Then I got reminded that I have no talent or interest to draw every goddamn object in the world, but still wanted to extend the original trio to an orchestra. I needed an artist. Wait, on a second thought, maybe not.I don't want to split the profits. Why not just borrow a set of established icons that everybody knows, uses and loves? You know what I'm talking about, the emojis! 🥳I immediately started working on a prototype, since the graphics were just fancy ""strings"". (Though I changed them to twemoji svgs later, nevermind.) The year long rabbit-hole of dedication, delusion and disillusion was begun.  Emojistan 🏝️Yeah, that's what I called it. Emojia or Emojiland didn't sound as cool imo. Anyways, back to the process.We have already established that there is only so much you can do with rock paper and scissors. But there is SO MUCH you can do with emojis with variable skin colors and that's a problem. I am not going to brainstorm and write algebraic equations with emojis all day and write zero lines of code. Instead, I'm going to write shit tons of code and provide the players some tools to write their own equations instead.And that's what I did for the next twelve months. Shitting code and creating a pseudo game engine with a javascript framework. I even created social media features like sharing your game, following people, liking people's games etc. If you are making a game you should also share it right? The answer is yes, but only if you are making a game in the first place. I'll come back to that later. Let me explain the core mechanic of the game (engine) first.So Emojistan has three views, Map Editor, Rulebox Editor and Dialogue Editor.  Map EditorThis is where you place emojis and color your map. There is also a test mode to playtest your game. There are 144 sections and 144 cells on each section, giving you a whopping 20.736 cells to color and populate in a single game!  Rulebox EditorRuleboxes are the building blocks of Emojistan. They define relationships and behaviors between emojis. There are six different ruleboxes. You can see how they construct the game logic in the tutorial  Dialogue EditorWell, nothing too fancy. Just a branching dialogue editor.So with these tools you can define things like:🌬️ will push 🍃If 👶 drinks 4 🍼s then it evolves to 🚶‍♂️If 🚶‍♀️ interacts 🌲 3 times with 🪓, 🌲 dies and drops [wood]Sounds fun right? Well because it is! But not the playing part, the developing part. You see, even before starting this project, I said to myself ""I'd never play this game"". Yet somehow, I convinced myself that there would be people who would want to play it 🤦‍♂️That's because the direction of my reasoning was reversed. I made the conclusion, and tried to find a reason later, or just made it up.  Reversed LogicReasoning: People will play this game (pretentious, smug, how the fuck did you even come to that conclusion?)Conclusion: I want to build it  Straight Up LogicReasoning: I want to build itConclusion: I don't care if nobody plays, it should exist (existential, cool)That's Lesson #1: Find reasons first, conclude later. Or simply, always challenge your assumptions.I think this also explains why I kept going for a year without showing this to any potential players. I unconsciously violated the ""fail early"" principle, so that I could keep working on it. (Lesson #2 Fail as early as possible) I found architecting this moderately complex project fun and tricked myself into thinking that ""I'm doing this for money"" where in reality it is not monetizable at all!  Why is it not monetizable?Because it has no users. And it's also statistically impossible for it to have any users. Let me explain.For someone to be interested in Emojistan, they have to be in the intersection of these three circles. And the number of people who are in the intersection zone is zero. Don't believe me? Let's ask to the most reliable source of internet, reddit.So there is this website called subredditstats.com. You enter a subreddit's name and it lists a bunch of subreddits along with the percentage of user overlap with the entered subreddit. Ranging from 100% to 1%.When you go into r/gamedev (1.2m) subreddit overlap and search for ""emoji""orWhen you go into and r/emojipasta (176k) subreddit overlap and search for ""game""You get the same result. 0/0.No intersection.And that's how you slam dunk yourself kids.(That's lesson #3 btw. Know your audience. They might not exist)  Going Open SourceSince I got convinced that I was creating a product for literally zero users and even creating a relational database for it (Shoutout to Supabase!) I thought it's time I face with reality and open source this project and write an article about it so that I can stop worrying about it's future. (Shoutout to Supabase again for inspiring me with this article)I think this project is a nice playground for junior devs who want to learn SvelteKit + TypeScript. Since there isn't a roadmap for the project. They can just hop in, learn how to read other people's code, refactor it, add new features, detect and solve bugs, create new bugs and solve them as well. Since what makes us a better developer is solving problems we haven't seen before I think Emojistan can provide that ground for anyone.Thanks for reading! You can check out the repo here and the deployed website here"
160,"The new AI tool ChatGPT is out there, though with such a powerful tool comes great responsibility.Uncle Ben to SpidermanThe main challenge is for companies and corporations that don't want secrets, passwords, codebase, Physical Health Indicator (PHI), medical data, or any other information to be leaked to OpenAI's ChatGPT.The web is full of articles and blog posts about the challenges, google for - ChatGPT regulation challenge.How does the company/organization/corporation you work for adopt ChatGPT? Do they block access to chat.openai.com? Have you been instructed not to use it at all? Are you aware of the risks of copy-pasting organization data when asking ChatGPT questions?I would love to hear your thoughts and discuss this topic, fire at will."
161,"In my previous article, we discussed how to configure TypeScript’s compiler to catch more errors, reduce usage of the any type, and obtain a better Developer Experience. However, properly configuring the tsconfig file is not enough. Even when following all the recommendations, there is still a significant risk of suboptimal type checking quality in our codebase.The issue is that our code is not the only code required to build an application. The standard library and runtime environment are also involved in type checking. These refer to the JavaScript methods and Web Platform APIs that are available in the global scope, including methods for working with arrays, the window object, Fetch API, and more.In this article, we will explore some of the most common issues with TypeScript's standard library and ways to write safer, more reliable code.  The Issue with TypeScript's Standard LibraryWhile the TypeScript’s Standard Library provides high-quality type definitions for the most part, some widely-used APIs have type declarations that are either too permissive or too restrictive.The most common issue with too permissive types is the use of any instead of more precise types, such as unknown. The Fetch API is the most common source of type safety issues in the standard library. The json() method returns a value of type any, which can lead to runtime errors and type mismatches. The same goes for the JSON.parse method.async function fetchPokemons() {    const response = await fetch('https://pokeapi.co/api/v2/pokemon');    const data = await response.json();    return data;}const pokemons = await fetchPokemons();//    ^?  anypokemons.data.map(pokemon => pokemon.name);//            ^  TypeError: Cannot read properties of undefinedEnter fullscreen modeExit fullscreen modeOn the other hand, there are APIs with unnecessarily restrictive type declarations, which can lead to a poorer developer experience. For example, the Array.filter method works counter-intuitively, requiring developers to manually type cast or write type guards.// the type of filteredArray is Array<number | undefined>const filteredArray = [1, 2, undefined].filter(Boolean);// the type of filteredArray is Array<number>const filteredArray = [1, 2, undefined].filter(    (item): item is number => Boolean(item));Enter fullscreen modeExit fullscreen modeThere is no easy way to upgrade or replace type declarations for the standard library since its type definitions are shipped with the TypeScript compiler. However, there are several ways to work around this issue if we want to get the most out of using TypeScript. Let's explore some options using the Fetch API as an example.  Using Type AssertionsOne solution that quickly comes to mind is to manually specify a type. To do this, we need to describe the response format and cast any to the desired type. By doing so, we can isolate the use of any to a small piece of the codebase, which is already much better than using the returned any type throughout a program.interface PokemonListResponse {    count: number;    next: string | null;    previous: string | null;    results: Pokemon[];}interface Pokemon {    name: string;    url: string;}async function fetchPokemons() {    const response = await fetch('https://pokeapi.co/api/v2/pokemon');    const data = await response.json() as PokemonListResponse;    //                                 ^  Manually cast the any    //                                    to a more precise type    return data;}const pokemons = await fetchPokemons();//    ^?  PokemonListResponseEnter fullscreen modeExit fullscreen modeIn addition, TypeScript will now highlight errors with access to non-existent fields. However, it should be understood that type casting imposes additional responsibility on us to accurately describe the type that is returned from the server.pokemons.data.map(pokemon => pokemon.name);//       ^  Error: Property 'data' does not exist on type 'PokemonListResponse'//          We shold use the 'results' field here.Enter fullscreen modeExit fullscreen modeType assertions can be risky and should be used with caution. They can result in unexpected behavior if the assertion is incorrect. For example, there is a high risk of making mistakes when describing types, such as overlooking the possibility of a field being null or undefined. Additionally, if the response format on a server changes unexpectedly, we may not become aware of it as quickly as possible.  Using Type GuardsWe can enhance the solution by first casting any to unknown. This clearly indicates that the fetch function can return any type of data. We then need to verify that the response has the data we need by writing a type guard, as shown below:function isPokemonListResponse(data: unknown): data is PokemonListResponse {    if (typeof data !== 'object' || data === null) return false;    if (typeof data.count !== 'number') return false;    if (data.next !== null && typeof data.next !== 'string') return false;    if (data.previous !== null && typeof data.previous !== 'string') return false;    if (!Array.isArray(data.results)) return false;    for (const pokemon of data.results) {        if (typeof pokemon.name !== 'string') return false;        if (typeof pokemon.url !== 'string') return false;    }    return true;}Enter fullscreen modeExit fullscreen modeThe type guard function takes a variable with the unknown type as input. The is operator is used to specify the output type, indicating that we have checked the data in the data variable and it has this type. Inside the function, we write all the necessary checks that verify all the fields we are interested in.We can use the resulting type guard to narrow the unknown type down to the type we want to work with. This way, if the response data format changes, we can quickly detect it and handle the situation in application logic.async function fetchPokemons() {    const response = await fetch('https://pokeapi.co/api/v2/pokemon');    const data = (await response.json()) as unknown;    //                                   ^  1. Cast to unknown    // 2. Validate the response    if (!isPokemonListResponse(data)) {        throw new Error('Неизвестный формат ответа');    }    return data;}const pokemons = await fetchPokemons();//    ^?  PokemonListResponseEnter fullscreen modeExit fullscreen modeHowever, writing type guards can be tedious, especially when dealing with large amounts of data. Additionally, there is a high risk of making mistakes in the type guard, which is equivalent to making a mistake in the type definition itself.  Using the Zod LibraryTo simplify the writing of type guards, we can use a library for data validation such as Zod. With Zod, we can define a data schema and then call a function that checks the data format against this schema.import { z } from 'zod';const schema = z.object({    count: z.number(),    next: z.string().nullable(),    previous: z.string().nullable(),    results: z.array(        z.object({            name: z.string(),            url: z.string(),        })    ),});Enter fullscreen modeExit fullscreen modeThese types of libraries are initially developed with TypeScript in mind, so they have a nice feature. They allow us to describe the data schema once and then automatically get the type definition. This eliminates the need to manually describe TypeScript interfaces and removes duplication.type PokemonListResponse = z.infer<typeof schema>;Enter fullscreen modeExit fullscreen modeThis function essentially acts as a type guard, which we don't have to write manually.async function fetchPokemons() {    const response = await fetch('https://pokeapi.co/api/v2/pokemon');    const data = (await response.json()) as unknown;    // Validate the response    return schema.parse(data);}const pokemons = await fetchPokemons();//    ^?  PokemonListResponseEnter fullscreen modeExit fullscreen modeAs a result, we get a reliable solution that leaves no room for human error. Mistakes in type definitions cannot be made since we don't write them manually. Mistakes in type guards are also impossible. Mistakes in the schema can be made, but we will quickly become aware of them during development.  Alternatives for ZodZod has many alternatives that differ in functionality, bundle size, and performance. For each application, you can choose the most suitable option.For example, the superstruct library is a lighter alternative to Zod. This library is more suitable for use on the client side since it has a relatively small size (13.1 kB vs 3.4 kB).The typia library is a slightly different approach with ahead-of-time compilation. Due to compilation stage, data validation works significantly faster. This can be especially important for heavy server code or for large volumes of data.  Fixing the Root CauseUsing libraries such as Zod for data validation can help overcome the issue of any types in TypeScript's standard library. However, it is still important to be aware of standard library methods that return any, and to replace these types with unknown whenever we use these methods.Ideally, the standard library should use unknown types instead of any. This would enable the compiler to suggest all the places where a type guard is needed. Fortunately, TypeScript's declaration merging feature provides this possibility. In TypeScript, interfaces have a useful feature where multiple declarations of an interface with the same name will be merged into one declaration. For example, if we have an interface User with a name field, and then declare another interface User with an age field, the resulting User interface will have both the name and age fields.interface User {    name: string;}interface User {    age: number;}const user: User = {    name: 'John',    age: 30,};Enter fullscreen modeExit fullscreen modeThis feature works not only within a single file but also globally across the project. This means that we can use this feature to extend the Window type or even to extend types for external libraries, including the standard library.declare global {    interface Window {        sayHello: () => void;    }}window.sayHello();//     ^  TypeScript now knows about this methodEnter fullscreen modeExit fullscreen modeBy using declaration merging, we can fully resolve the issue of any types in TypeScript's standard library.  Better Types for Fetch APITo improve the Fetch API from the standard library, we need to correct the types for the json() method so that it always returns unknown instead of any. Firstly, we can use the ""Go to Type Definition"" function in an IDE to determine that the json method is part of the Response interface.interface Response extends Body {    readonly headers: Headers;    readonly ok: boolean;    readonly redirected: boolean;    readonly status: number;    readonly statusText: string;    readonly type: ResponseType;    readonly url: string;    clone(): Response;}Enter fullscreen modeExit fullscreen modeHowever, we cannot find the json() method among the methods of Response. Instead, we can see that the Response interface inherits from the Body interface. So, we look into the Body interface to find the method we need. As we can see, the json() method actually returns the any type.interface Body {    readonly body: ReadableStream<Uint8Array> | null;    readonly bodyUsed: boolean;    arrayBuffer(): Promise<ArrayBuffer>;    blob(): Promise<Blob>;    formData(): Promise<FormData>;    text(): Promise<string>;    json(): Promise<any>;    //              ^  We are going to fix this}Enter fullscreen modeExit fullscreen modeTo fix this, we can define the Body interface once in our project as follows:.declare global {    interface Body {        json(): Promise<unknown>;    }}Enter fullscreen modeExit fullscreen modeThanks to declaration merging, the json() method will now always return the unknown type.async function fetchPokemons() {    const response = await fetch('https://pokeapi.co/api/v2/pokemon');    const data = await response.json();    //    ^?  unknown    return data;}Enter fullscreen modeExit fullscreen modeThis means that forgetting to write a type guard will no longer be possible, and the any type will no longer be able to sneak into our code.  Better Types for JSON.parseIn the same way, we can fix JSON parsing. By default, the parse() method returns the any type, which can lead to runtime errors when using parsed data.const data = JSON.parse(text);//    ^?  anyEnter fullscreen modeExit fullscreen modeTo fix this, we need to figure out that the parse() method is part of the JSON interface. Then we can declare the type in our project as follows:declare global {    interface JSON {        parse(            text: string,             reviver?: (this: any, key: string, value: any) => any        ): unknown;    }}Enter fullscreen modeExit fullscreen modeNow, JSON parsing always returns the unknown type, for which we will definitely not forget to write a type guard. This leads to a safer and more maintainable codebase.const data = JSON.parse(text);//    ^?  unknownEnter fullscreen modeExit fullscreen mode  Better Types for Array.isArrayAnother common example is checking if a variable is an array. By default, this method returns an array of any, which is essentially the same as just using any.if (Array.isArray(userInput)) {    console.log(userInput);    //          ^?  any[]}Enter fullscreen modeExit fullscreen modeWe have already learned how to fix the issue. By extending the types for the array constructor as shown below, the method now returns an array of unknown, which is much safer and more accurate.declare global {    interface ArrayConstructor {        isArray(arg: any): arg is unknown[];    }}if (Array.isArray(userInput)) {    console.log(userInput);    //          ^?  unknown[]}Enter fullscreen modeExit fullscreen mode  Better Types for structuredCloneUnfortunately, the recently introduced method for cloning objects also returns any.const user = {    name: 'John',    age: 30,};const copy = structuredClone(user);//    ^?  anyEnter fullscreen modeExit fullscreen modeFixing it is just as simple as the previous methods. However, in this case, we need to add a new function signature instead of augmenting the interface. Fortunately, declaration merging works for functions just like it does for interfaces. Therefore, we can fix the issue as follows:declare global {    declare function structuredClone<T>(value: T, options?: StructuredSerializeOptions): T;}Enter fullscreen modeExit fullscreen modeThe cloned object will now be of the same type as the original object.const user = {    name: 'John',    age: 30,};const copy = structuredClone(user);//    ^?  { name: string, age: number }Enter fullscreen modeExit fullscreen mode  Better Types for Array.filterDeclaration merging is not only useful for fixing the any type issue, but it can also improve the ergonomics of the standard library. Let's consider the example of the Array.filter method.const filteredArray = [1, 2, undefined].filter(Boolean);//    ^?  Array<number | undefined>Enter fullscreen modeExit fullscreen modeWe can teach TypeScript to automatically narrow the array type after applying the Boolean filter function. To do so, we need to extend the Array interface as follows:type NonFalsy<T> = T extends false | 0 | """" | null | undefined | 0n ? never : T;declare global {    interface Array<T> {      filter(predicate: BooleanConstructor, thisArg?: any): Array<NonFalsy<T>>;    }}Enter fullscreen modeExit fullscreen modeDescribing how the NonFalsy type works requires a separate article, so I will leave this explanation for another time. The important thing is that now we can use the shorthand form of the filter and get the correct data type as a result.const filteredArray = [1, 2, undefined].filter(Boolean);//    ^?  Array<number>Enter fullscreen modeExit fullscreen mode  Introducing ts-resetTypeScript's standard library contains over 1,000 instances of the any type. There are many opportunities to improve the developer experience when working with strictly typed code. One solution to avoid having to fix the standard library yourself is to use the ts-reset library. It is easy to use and only needs to be imported once in your project.import ""@total-typescript/ts-reset"";Enter fullscreen modeExit fullscreen modeThe library is relatively new, so it does not yet have as many fixes to the standard library as I would like. However, I believe this is just the beginning. It is important to note that ts-reset only contains safe changes to global types that do not lead to potential runtime bugs.  Caution Regarding Usage in LibrariesImproving TypeScript's standard library has many benefits. However, it is important to note that redefining global types of the standard library limits this approach to applications only. It is mostly unsuitable for libraries because using such a library would unexpectedly change the behavior of global types for the application.In general, it is recommended to avoid modifying TypeScript's standard library types in libraries. Instead, you can use static analysis tools to achieve similar results in terms of code quality and type safety, which are suitable for library development. I will write another article about this soon.  ConclusionTypeScript's standard library is a crucial component of the TypeScript Compiler, providing a comprehensive range of built-in types for working with JavaScript and Web Platform APIs. However, the standard library is not perfect, and there are issues with some of the type declarations that can lead to suboptimal type checking quality in our codebase. In this article, we explored some of the most common issues with TypeScript's standard library and ways to write safer and more reliable code.By using type assertions, type guards, and libraries such as Zod, we can improve the type safety and code quality in our codebase. Additionally, we can fix the root cause of the issue by using declaration merging to improve the type safety and ergonomics of TypeScript's standard library.I hope you have learned something new from this article. In the next article, we will discuss how to use static analysis tools to further improve type safety. Thank you for reading!  Useful LinksDeclaration MergingType NarrowingAny typets-resetZodSuperstructTypia"
162,"This post is the second in the series of posts about Debugging rules.Fixing problems without a genuine understanding can create unnecessary difficulties and compromise the program's quality. Thus, it's crucial to comprehend the system thoroughly before attempting any fixes. To achieve this, triangulate the defect by testing scenarios that should reproduce the error and those that shouldn't. Persevere in this process until you grasp the problem well enough to predict its occurrence accurately in every instance.  Read the manualA functional understanding of the system's intended behavior, design, and sometimes the rationale behind its design is essential. When there is a lack of comprehension in any particular aspect of the system, it often becomes the root cause of issues and problems.  Read everything in depthFrequently, individuals attempt to debug issues without delving into the system's manual comprehensively. Instead, they tend to skim through it, focusing only on sections they deem significant, inadvertently overlooking the crucial clue hidden in the unexplored section that could have revealed the problem's root cause.Programming guides and APIs may appear daunting due to their overwhelming nature, but it is essential to delve into them thoroughly. Often, the function that seems easily understandable at first glance can end up causing unexpected issues. Similarly, neglecting certain sections of the schematic may lead to unidentified sources of noise.Application notes and implementation guides offer a wealth of valuable information, not only about how a system operates but also regarding past issues encountered by others. Warnings about common mistakes prove incredibly beneficial, even if you believe you're likely to make uncommon errors.Reference designs and sample programs can serve as primary documentation for product usage, but caution is warranted. While they demonstrate one way to employ a product, they might not adhere to good design practices or cater to real-world applications.Merely adopting a design without fully understanding it may lead to discovering bugs later on. Even the best reference designs might not perfectly align with the unique requirements of your application, potentially resulting in breakdowns.  Know what's reasonableWhile exploring a system, having a clear grasp of its typical functioning is crucial. Understanding the standard operations enables you to detect deviations or abnormalities effectively. Many individuals struggle to identify issues simply because they lack a fundamental understanding of how the system is supposed to work.  Know the roadmapThe knowledge about the constituent elements of a system can also give us important insights into the structure of the system.Dietrich Dorner, The Logic of FailureWhen attempting to locate a hidden bug, it's essential to be familiar with the system's layout and structure. In cases where certain parts of the system are considered ""black boxes,"" meaning their internal workings are unknown, understanding how they should interact with other components helps in identifying whether the issue resides within the box or outside of it.  Understand your toolsDebugging tools serve as your system's eyes and ears, providing valuable insights. To effectively utilize these tools, you must master three essential aspects: selecting the appropriate tool for the task, employing it correctly, and interpreting the results accurately. Additionally, understanding the limitations of your tools is equally important in ensuring efficient and successful debugging processes.  Look up the detailsDon't waste your debugging time looking at the wrong stuffAvoid making assumptions. Instead, take the time to research and retrieve accurate information. Elaborate details have been documented either by you or by the originator of a library, API, or framework. It's unwise to rely solely on your memory.Engaging in guesswork could lead you down the wrong path, where incorrect information might seem correct. Assuming things may cause you to overlook critical issues. You might encounter perplexing data or, more troublingly, encounter falsely reassuring data.Emulate Einstein, who never bothered to memorize his own phone number. He would question, ""Why should I?"" He knew it could be found in the phone book."
163,"Among other things, I am a typist.I am comfortable with typing to the point that a long time ago I started to enter passwords by typing - without even looking at the keyboard.Earlier I had some data which I compressed, encrypted, and password-protected with the popular compression utility - 7z.I then chose an eight-letter password. It is weak by today's standards.The aim was to protect it from the prying eyes of other people who use the computer - nothing too serious.I compressed a few files and folders with 7z and deleted the original ones.But when I tried to open them later, some of them simply would not open.The passwords I thought I used were not the passwords 7z used to encrypt them.That was when I started to think about the ways to recover them.I started with rarcrack - an open source 51 kb tool for brute-forcing 7z files.This program would try to generate all types of combinations with the 8 letters we give - not in any particular order. Then it tries to brute-force it open with the passwords it generates.But after some time I found the process too slow.I felt that it would take an eternity before I get my files back.I hit ctrl + c.The next option was John the Ripper. Programs like 7z hash the password.Once hashed, no one - no program can find the original string.Hashing - the process is irreversible.So what does John the Ripper do?John breaks passwords by comparing the hash value of the password it generates with the original hash.Once it finds a match, John knows the password.Another hugely popular option is Hashcat.Again, I thought these would be overkill for a job like this.I did a little math.It is an 8-letter password.Every key has only two characters.This is a binary choice scenario.So, there would only be 256 possible password combinations.2^8 = 256If we know the password, we have this bash one-liner to execute on the command line.password=<password> ; 7z x -p$password name_of_the_file.7z I tried to automate the process.I generated all the possible 256 matches with this Python script.first_letter = ['r', 'R']second_letter = ['o', 'O']third_letter = ['c', 'C']fourth_letter = ['k', 'K']fifth_letter = ['s', 'S']sixth_letter = ['t', 'T']seventh_letter = ['a', 'A']eighth_letter = ['5', '%']password_string = '\""'for x in range (0,2):    for y in range (0,2):        for z in range (0,2):            for a in range (0,2):                for b in range (0,2):                    for c in range (0,2):                        for d in range (0,2):                            for e in range (0,2):                                password_string = password_string + first_letter[x]+ second_letter[y] + third_letter[z] + fourth_letter[a] + fifth_letter[b] + sixth_letter[c] + seventh_letter[d] + eighth_letter[e] + '\"", \""'print(password_string)Enter fullscreen modeExit fullscreen modeThen another script to generate the bash file.passwd_array = [ ""rocksta5"", ""rocksta%"", ""rockstA5"", ""rockstA%"", ""rocksTa5"", ""rocksTa%"", ""rocksTA5"", ""rocksTA%"", ""rockSta5"", ""rockSta%"", ""rockStA5"", ""rockStA%"", ""rockSTa5"", ""rockSTa%"", ""rockSTA5"", ""rockSTA%"", ""rocKsta5"", ""rocKsta%"", ""rocKstA5"", ""rocKstA%"", ""rocKsTa5"", ""rocKsTa%"", ""rocKsTA5"", ""rocKsTA%"", ""rocKSta5"", ""rocKSta%"", ""rocKStA5"", ""rocKStA%"", ""rocKSTa5"", ""rocKSTa%"", ""rocKSTA5"", ""rocKSTA%"", ""roCksta5"", ""roCksta%"", ""roCkstA5"", ""roCkstA%"", ""roCksTa5"", ""roCksTa%"", ""roCksTA5"", ""roCksTA%"", ""roCkSta5"", ""roCkSta%"", ""roCkStA5"", ""roCkStA%"", ""roCkSTa5"", ""roCkSTa%"", ""roCkSTA5"", ""roCkSTA%"", ""roCKsta5"", ""roCKsta%"", ""roCKstA5"", ""roCKstA%"", ""roCKsTa5"", ""roCKsTa%"", ""roCKsTA5"", ""roCKsTA%"", ""roCKSta5"", ""roCKSta%"", ""roCKStA5"", ""roCKStA%"", ""roCKSTa5"", ""roCKSTa%"", ""roCKSTA5"", ""roCKSTA%"", ""rOcksta5"", ""rOcksta%"", ""rOckstA5"", ""rOckstA%"", ""rOcksTa5"", ""rOcksTa%"", ""rOcksTA5"", ""rOcksTA%"", ""rOckSta5"", ""rOckSta%"", ""rOckStA5"", ""rOckStA%"", ""rOckSTa5"", ""rOckSTa%"", ""rOckSTA5"", ""rOckSTA%"", ""rOcKsta5"", ""rOcKsta%"", ""rOcKstA5"", ""rOcKstA%"", ""rOcKsTa5"", ""rOcKsTa%"", ""rOcKsTA5"", ""rOcKsTA%"", ""rOcKSta5"", ""rOcKSta%"", ""rOcKStA5"", ""rOcKStA%"", ""rOcKSTa5"", ""rOcKSTa%"", ""rOcKSTA5"", ""rOcKSTA%"", ""rOCksta5"", ""rOCksta%"", ""rOCkstA5"", ""rOCkstA%"", ""rOCksTa5"", ""rOCksTa%"", ""rOCksTA5"", ""rOCksTA%"", ""rOCkSta5"", ""rOCkSta%"", ""rOCkStA5"", ""rOCkStA%"", ""rOCkSTa5"", ""rOCkSTa%"", ""rOCkSTA5"", ""rOCkSTA%"", ""rOCKsta5"", ""rOCKsta%"", ""rOCKstA5"", ""rOCKstA%"", ""rOCKsTa5"", ""rOCKsTa%"", ""rOCKsTA5"", ""rOCKsTA%"", ""rOCKSta5"", ""rOCKSta%"", ""rOCKStA5"", ""rOCKStA%"", ""rOCKSTa5"", ""rOCKSTa%"", ""rOCKSTA5"", ""rOCKSTA%"", ""Rocksta5"", ""Rocksta%"", ""RockstA5"", ""RockstA%"", ""RocksTa5"", ""RocksTa%"", ""RocksTA5"", ""RocksTA%"", ""RockSta5"", ""RockSta%"", ""RockStA5"", ""RockStA%"", ""RockSTa5"", ""RockSTa%"", ""RockSTA5"", ""RockSTA%"", ""RocKsta5"", ""RocKsta%"", ""RocKstA5"", ""RocKstA%"", ""RocKsTa5"", ""RocKsTa%"", ""RocKsTA5"", ""RocKsTA%"", ""RocKSta5"", ""RocKSta%"", ""RocKStA5"", ""RocKStA%"", ""RocKSTa5"", ""RocKSTa%"", ""RocKSTA5"", ""RocKSTA%"", ""RoCksta5"", ""RoCksta%"", ""RoCkstA5"", ""RoCkstA%"", ""RoCksTa5"", ""RoCksTa%"", ""RoCksTA5"", ""RoCksTA%"", ""RoCkSta5"", ""RoCkSta%"", ""RoCkStA5"", ""RoCkStA%"", ""RoCkSTa5"", ""RoCkSTa%"", ""RoCkSTA5"", ""RoCkSTA%"", ""RoCKsta5"", ""RoCKsta%"", ""RoCKstA5"", ""RoCKstA%"", ""RoCKsTa5"", ""RoCKsTa%"", ""RoCKsTA5"", ""RoCKsTA%"", ""RoCKSta5"", ""RoCKSta%"", ""RoCKStA5"", ""RoCKStA%"", ""RoCKSTa5"", ""RoCKSTa%"", ""RoCKSTA5"", ""RoCKSTA%"", ""ROcksta5"", ""ROcksta%"", ""ROckstA5"", ""ROckstA%"", ""ROcksTa5"", ""ROcksTa%"", ""ROcksTA5"", ""ROcksTA%"", ""ROckSta5"", ""ROckSta%"", ""ROckStA5"", ""ROckStA%"", ""ROckSTa5"", ""ROckSTa%"", ""ROckSTA5"", ""ROckSTA%"", ""ROcKsta5"", ""ROcKsta%"", ""ROcKstA5"", ""ROcKstA%"", ""ROcKsTa5"", ""ROcKsTa%"", ""ROcKsTA5"", ""ROcKsTA%"", ""ROcKSta5"", ""ROcKSta%"", ""ROcKStA5"", ""ROcKStA%"", ""ROcKSTa5"", ""ROcKSTa%"", ""ROcKSTA5"", ""ROcKSTA%"", ""ROCksta5"", ""ROCksta%"", ""ROCkstA5"", ""ROCkstA%"", ""ROCksTa5"", ""ROCksTa%"", ""ROCksTA5"", ""ROCksTA%"", ""ROCkSta5"", ""ROCkSta%"", ""ROCkStA5"", ""ROCkStA%"", ""ROCkSTa5"", ""ROCkSTa%"", ""ROCkSTA5"", ""ROCkSTA%"", ""ROCKsta5"", ""ROCKsta%"", ""ROCKstA5"", ""ROCKstA%"", ""ROCKsTa5"", ""ROCKsTa%"", ""ROCKsTA5"", ""ROCKsTA%"", ""ROCKSta5"", ""ROCKSta%"", ""ROCKStA5"", ""ROCKStA%"", ""ROCKSTa5"", ""ROCKSTa%"", ""ROCKSTA5"", ""ROCKSTA%"" ]for passwd in passwd_array:    print(f'password={passwd} ; 7z x -p$password archive8.7z ')Enter fullscreen modeExit fullscreen modeSimple enough, I saved the bash script with the name brute_forcing.sh#! /bin/bash# Brute-forcing by vmspassword=rocksta5 ; 7z x -p$password archive8.7z password=rocksta% ; 7z x -p$password archive8.7z password=rockstA5 ; 7z x -p$password archive8.7z password=rockstA% ; 7z x -p$password archive8.7z password=rocksTa5 ; 7z x -p$password archive8.7z password=rocksTa% ; 7z x -p$password archive8.7z password=rocksTA5 ; 7z x -p$password archive8.7z password=rocksTA% ; 7z x -p$password archive8.7z password=rockSta5 ; 7z x -p$password archive8.7z password=rockSta% ; 7z x -p$password archive8.7z password=rockStA5 ; 7z x -p$password archive8.7z password=rockStA% ; 7z x -p$password archive8.7z password=rockSTa5 ; 7z x -p$password archive8.7z password=rockSTa% ; 7z x -p$password archive8.7z password=rockSTA5 ; 7z x -p$password archive8.7z password=rockSTA% ; 7z x -p$password archive8.7z password=rocKsta5 ; 7z x -p$password archive8.7z password=rocKsta% ; 7z x -p$password archive8.7z password=rocKstA5 ; 7z x -p$password archive8.7z password=rocKstA% ; 7z x -p$password archive8.7z password=rocKsTa5 ; 7z x -p$password archive8.7z password=rocKsTa% ; 7z x -p$password archive8.7z password=rocKsTA5 ; 7z x -p$password archive8.7z password=rocKsTA% ; 7z x -p$password archive8.7z password=rocKSta5 ; 7z x -p$password archive8.7z password=rocKSta% ; 7z x -p$password archive8.7z password=rocKStA5 ; 7z x -p$password archive8.7z password=rocKStA% ; 7z x -p$password archive8.7z password=rocKSTa5 ; 7z x -p$password archive8.7z password=rocKSTa% ; 7z x -p$password archive8.7z password=rocKSTA5 ; 7z x -p$password archive8.7z password=rocKSTA% ; 7z x -p$password archive8.7z password=roCksta5 ; 7z x -p$password archive8.7z password=roCksta% ; 7z x -p$password archive8.7z password=roCkstA5 ; 7z x -p$password archive8.7z password=roCkstA% ; 7z x -p$password archive8.7z password=roCksTa5 ; 7z x -p$password archive8.7z password=roCksTa% ; 7z x -p$password archive8.7z password=roCksTA5 ; 7z x -p$password archive8.7z password=roCksTA% ; 7z x -p$password archive8.7z password=roCkSta5 ; 7z x -p$password archive8.7z password=roCkSta% ; 7z x -p$password archive8.7z password=roCkStA5 ; 7z x -p$password archive8.7z password=roCkStA% ; 7z x -p$password archive8.7z password=roCkSTa5 ; 7z x -p$password archive8.7z password=roCkSTa% ; 7z x -p$password archive8.7z password=roCkSTA5 ; 7z x -p$password archive8.7z password=roCkSTA% ; 7z x -p$password archive8.7z password=roCKsta5 ; 7z x -p$password archive8.7z password=roCKsta% ; 7z x -p$password archive8.7z password=roCKstA5 ; 7z x -p$password archive8.7z password=roCKstA% ; 7z x -p$password archive8.7z password=roCKsTa5 ; 7z x -p$password archive8.7z password=roCKsTa% ; 7z x -p$password archive8.7z password=roCKsTA5 ; 7z x -p$password archive8.7z password=roCKsTA% ; 7z x -p$password archive8.7z password=roCKSta5 ; 7z x -p$password archive8.7z password=roCKSta% ; 7z x -p$password archive8.7z password=roCKStA5 ; 7z x -p$password archive8.7z password=roCKStA% ; 7z x -p$password archive8.7z password=roCKSTa5 ; 7z x -p$password archive8.7z password=roCKSTa% ; 7z x -p$password archive8.7z password=roCKSTA5 ; 7z x -p$password archive8.7z password=roCKSTA% ; 7z x -p$password archive8.7z password=rOcksta5 ; 7z x -p$password archive8.7z password=rOcksta% ; 7z x -p$password archive8.7z password=rOckstA5 ; 7z x -p$password archive8.7z password=rOckstA% ; 7z x -p$password archive8.7z password=rOcksTa5 ; 7z x -p$password archive8.7z password=rOcksTa% ; 7z x -p$password archive8.7z password=rOcksTA5 ; 7z x -p$password archive8.7z password=rOcksTA% ; 7z x -p$password archive8.7z password=rOckSta5 ; 7z x -p$password archive8.7z password=rOckSta% ; 7z x -p$password archive8.7z password=rOckStA5 ; 7z x -p$password archive8.7z password=rOckStA% ; 7z x -p$password archive8.7z password=rOckSTa5 ; 7z x -p$password archive8.7z password=rOckSTa% ; 7z x -p$password archive8.7z password=rOckSTA5 ; 7z x -p$password archive8.7z password=rOckSTA% ; 7z x -p$password archive8.7z password=rOcKsta5 ; 7z x -p$password archive8.7z password=rOcKsta% ; 7z x -p$password archive8.7z password=rOcKstA5 ; 7z x -p$password archive8.7z password=rOcKstA% ; 7z x -p$password archive8.7z password=rOcKsTa5 ; 7z x -p$password archive8.7z password=rOcKsTa% ; 7z x -p$password archive8.7z password=rOcKsTA5 ; 7z x -p$password archive8.7z password=rOcKsTA% ; 7z x -p$password archive8.7z password=rOcKSta5 ; 7z x -p$password archive8.7z password=rOcKSta% ; 7z x -p$password archive8.7z password=rOcKStA5 ; 7z x -p$password archive8.7z password=rOcKStA% ; 7z x -p$password archive8.7z password=rOcKSTa5 ; 7z x -p$password archive8.7z password=rOcKSTa% ; 7z x -p$password archive8.7z password=rOcKSTA5 ; 7z x -p$password archive8.7z password=rOcKSTA% ; 7z x -p$password archive8.7z password=rOCksta5 ; 7z x -p$password archive8.7z password=rOCksta% ; 7z x -p$password archive8.7z password=rOCkstA5 ; 7z x -p$password archive8.7z password=rOCkstA% ; 7z x -p$password archive8.7z password=rOCksTa5 ; 7z x -p$password archive8.7z password=rOCksTa% ; 7z x -p$password archive8.7z password=rOCksTA5 ; 7z x -p$password archive8.7z password=rOCksTA% ; 7z x -p$password archive8.7z password=rOCkSta5 ; 7z x -p$password archive8.7z password=rOCkSta% ; 7z x -p$password archive8.7z password=rOCkStA5 ; 7z x -p$password archive8.7z password=rOCkStA% ; 7z x -p$password archive8.7z password=rOCkSTa5 ; 7z x -p$password archive8.7z password=rOCkSTa% ; 7z x -p$password archive8.7z password=rOCkSTA5 ; 7z x -p$password archive8.7z password=rOCkSTA% ; 7z x -p$password archive8.7z password=rOCKsta5 ; 7z x -p$password archive8.7z password=rOCKsta% ; 7z x -p$password archive8.7z password=rOCKstA5 ; 7z x -p$password archive8.7z password=rOCKstA% ; 7z x -p$password archive8.7z password=rOCKsTa5 ; 7z x -p$password archive8.7z password=rOCKsTa% ; 7z x -p$password archive8.7z password=rOCKsTA5 ; 7z x -p$password archive8.7z password=rOCKsTA% ; 7z x -p$password archive8.7z password=rOCKSta5 ; 7z x -p$password archive8.7z password=rOCKSta% ; 7z x -p$password archive8.7z password=rOCKStA5 ; 7z x -p$password archive8.7z password=rOCKStA% ; 7z x -p$password archive8.7z password=rOCKSTa5 ; 7z x -p$password archive8.7z password=rOCKSTa% ; 7z x -p$password archive8.7z password=rOCKSTA5 ; 7z x -p$password archive8.7z password=rOCKSTA% ; 7z x -p$password archive8.7z password=Rocksta5 ; 7z x -p$password archive8.7z password=Rocksta% ; 7z x -p$password archive8.7z password=RockstA5 ; 7z x -p$password archive8.7z password=RockstA% ; 7z x -p$password archive8.7z password=RocksTa5 ; 7z x -p$password archive8.7z password=RocksTa% ; 7z x -p$password archive8.7z password=RocksTA5 ; 7z x -p$password archive8.7z password=RocksTA% ; 7z x -p$password archive8.7z password=RockSta5 ; 7z x -p$password archive8.7z password=RockSta% ; 7z x -p$password archive8.7z password=RockStA5 ; 7z x -p$password archive8.7z password=RockStA% ; 7z x -p$password archive8.7z password=RockSTa5 ; 7z x -p$password archive8.7z password=RockSTa% ; 7z x -p$password archive8.7z password=RockSTA5 ; 7z x -p$password archive8.7z password=RockSTA% ; 7z x -p$password archive8.7z password=RocKsta5 ; 7z x -p$password archive8.7z password=RocKsta% ; 7z x -p$password archive8.7z password=RocKstA5 ; 7z x -p$password archive8.7z password=RocKstA% ; 7z x -p$password archive8.7z password=RocKsTa5 ; 7z x -p$password archive8.7z password=RocKsTa% ; 7z x -p$password archive8.7z password=RocKsTA5 ; 7z x -p$password archive8.7z password=RocKsTA% ; 7z x -p$password archive8.7z password=RocKSta5 ; 7z x -p$password archive8.7z password=RocKSta% ; 7z x -p$password archive8.7z password=RocKStA5 ; 7z x -p$password archive8.7z password=RocKStA% ; 7z x -p$password archive8.7z password=RocKSTa5 ; 7z x -p$password archive8.7z password=RocKSTa% ; 7z x -p$password archive8.7z password=RocKSTA5 ; 7z x -p$password archive8.7z password=RocKSTA% ; 7z x -p$password archive8.7z password=RoCksta5 ; 7z x -p$password archive8.7z password=RoCksta% ; 7z x -p$password archive8.7z password=RoCkstA5 ; 7z x -p$password archive8.7z password=RoCkstA% ; 7z x -p$password archive8.7z password=RoCksTa5 ; 7z x -p$password archive8.7z password=RoCksTa% ; 7z x -p$password archive8.7z password=RoCksTA5 ; 7z x -p$password archive8.7z password=RoCksTA% ; 7z x -p$password archive8.7z password=RoCkSta5 ; 7z x -p$password archive8.7z password=RoCkSta% ; 7z x -p$password archive8.7z password=RoCkStA5 ; 7z x -p$password archive8.7z password=RoCkStA% ; 7z x -p$password archive8.7z password=RoCkSTa5 ; 7z x -p$password archive8.7z password=RoCkSTa% ; 7z x -p$password archive8.7z password=RoCkSTA5 ; 7z x -p$password archive8.7z password=RoCkSTA% ; 7z x -p$password archive8.7z password=RoCKsta5 ; 7z x -p$password archive8.7z password=RoCKsta% ; 7z x -p$password archive8.7z password=RoCKstA5 ; 7z x -p$password archive8.7z password=RoCKstA% ; 7z x -p$password archive8.7z password=RoCKsTa5 ; 7z x -p$password archive8.7z password=RoCKsTa% ; 7z x -p$password archive8.7z password=RoCKsTA5 ; 7z x -p$password archive8.7z password=RoCKsTA% ; 7z x -p$password archive8.7z password=RoCKSta5 ; 7z x -p$password archive8.7z password=RoCKSta% ; 7z x -p$password archive8.7z password=RoCKStA5 ; 7z x -p$password archive8.7z password=RoCKStA% ; 7z x -p$password archive8.7z password=RoCKSTa5 ; 7z x -p$password archive8.7z password=RoCKSTa% ; 7z x -p$password archive8.7z password=RoCKSTA5 ; 7z x -p$password archive8.7z password=RoCKSTA% ; 7z x -p$password archive8.7z password=ROcksta5 ; 7z x -p$password archive8.7z password=ROcksta% ; 7z x -p$password archive8.7z password=ROckstA5 ; 7z x -p$password archive8.7z password=ROckstA% ; 7z x -p$password archive8.7z password=ROcksTa5 ; 7z x -p$password archive8.7z password=ROcksTa% ; 7z x -p$password archive8.7z password=ROcksTA5 ; 7z x -p$password archive8.7z password=ROcksTA% ; 7z x -p$password archive8.7z password=ROckSta5 ; 7z x -p$password archive8.7z password=ROckSta% ; 7z x -p$password archive8.7z password=ROckStA5 ; 7z x -p$password archive8.7z password=ROckStA% ; 7z x -p$password archive8.7z password=ROckSTa5 ; 7z x -p$password archive8.7z password=ROckSTa% ; 7z x -p$password archive8.7z password=ROckSTA5 ; 7z x -p$password archive8.7z password=ROckSTA% ; 7z x -p$password archive8.7z password=ROcKsta5 ; 7z x -p$password archive8.7z password=ROcKsta% ; 7z x -p$password archive8.7z password=ROcKstA5 ; 7z x -p$password archive8.7z password=ROcKstA% ; 7z x -p$password archive8.7z password=ROcKsTa5 ; 7z x -p$password archive8.7z password=ROcKsTa% ; 7z x -p$password archive8.7z password=ROcKsTA5 ; 7z x -p$password archive8.7z password=ROcKsTA% ; 7z x -p$password archive8.7z password=ROcKSta5 ; 7z x -p$password archive8.7z password=ROcKSta% ; 7z x -p$password archive8.7z password=ROcKStA5 ; 7z x -p$password archive8.7z password=ROcKStA% ; 7z x -p$password archive8.7z password=ROcKSTa5 ; 7z x -p$password archive8.7z password=ROcKSTa% ; 7z x -p$password archive8.7z password=ROcKSTA5 ; 7z x -p$password archive8.7z password=ROcKSTA% ; 7z x -p$password archive8.7z password=ROCksta5 ; 7z x -p$password archive8.7z password=ROCksta% ; 7z x -p$password archive8.7z password=ROCkstA5 ; 7z x -p$password archive8.7z password=ROCkstA% ; 7z x -p$password archive8.7z password=ROCksTa5 ; 7z x -p$password archive8.7z password=ROCksTa% ; 7z x -p$password archive8.7z password=ROCksTA5 ; 7z x -p$password archive8.7z password=ROCksTA% ; 7z x -p$password archive8.7z password=ROCkSta5 ; 7z x -p$password archive8.7z password=ROCkSta% ; 7z x -p$password archive8.7z password=ROCkStA5 ; 7z x -p$password archive8.7z password=ROCkStA% ; 7z x -p$password archive8.7z password=ROCkSTa5 ; 7z x -p$password archive8.7z password=ROCkSTa% ; 7z x -p$password archive8.7z password=ROCkSTA5 ; 7z x -p$password archive8.7z password=ROCkSTA% ; 7z x -p$password archive8.7z password=ROCKsta5 ; 7z x -p$password archive8.7z password=ROCKsta% ; 7z x -p$password archive8.7z password=ROCKstA5 ; 7z x -p$password archive8.7z password=ROCKstA% ; 7z x -p$password archive8.7z password=ROCKsTa5 ; 7z x -p$password archive8.7z password=ROCKsTa% ; 7z x -p$password archive8.7z password=ROCKsTA5 ; 7z x -p$password archive8.7z password=ROCKsTA% ; 7z x -p$password archive8.7z password=ROCKSta5 ; 7z x -p$password archive8.7z password=ROCKSta% ; 7z x -p$password archive8.7z password=ROCKStA5 ; 7z x -p$password archive8.7z password=ROCKStA% ; 7z x -p$password archive8.7z password=ROCKSTa5 ; 7z x -p$password archive8.7z password=ROCKSTa% ; 7z x -p$password archive8.7z password=ROCKSTA5 ; 7z x -p$password archive8.7z password=ROCKSTA% ; 7z x -p$password archive8.7z Enter fullscreen modeExit fullscreen modeThen I edited the file permissions to make it executable.chmod +x brute_forcing.sh && ./brute_forcing.shEnter fullscreen modeExit fullscreen modeIt ran for a few seconds, ran all the 256 key combinations, and came to a grinding halt.Still, the file is not open.A bug in the code?To test, I made a 7z container. I then added some files to the archive and took a password from the middle of the brute_forcing.sh to encrypt it.I ran the script again.Voila! It works. It only took two seconds.Now, I have to expand my wordlist with keys where my fingers would have accidentally hit. For example, I could have pressed the z button instead of 'a'. It is directly beneath the 'a' key on a qwerty keyboard.Still, there is also a chance that this might not work.But I have not lost hope.I shall get a machine running John or Hashcat. Again, my wordlist shall be much smaller since this is a binary choice problem.Also, I was thinking about passwords in general. Given access to systems, hackers can easily break a lot of weak passwords in minutes, if not seconds. This is a case in point for using long complex passwords where it matters the most - at least on the login prompt."
164,"In today's data-driven world, efficient management of information is critical for the success of various applications and systems. Databases serve as the backbone of data storage and retrieval, and designing them effectively is vital to ensure optimal performance and scalability. In this article, I will delve into the art of ""Visualizing Data Structures and Relationships"", where we explore the power of diagramming in database design to visualize data structures and relationships as well as Tools and software for database diagramming, empowering software developers, database administrators, and data enthusiasts with unparalleled visualization prowess. I hope this article helps you say goodbye to complexity and hello to crystal-clear data models, entity relationships, and data flows within databases.  PrerequisitesTo make the most of the invaluable insights provided in this article, I recommend a foundational understanding of the following concepts:Basic Database Concepts: Familiarity with fundamental database concepts such as tables, fields, records, and relationships will be beneficial.SQL (Structured Query Language): Having a basic knowledge of SQL will help you understand the data manipulation and retrieval processes within databases.Data Modeling Fundamentals: A grasp of data modeling principles will enhance your ability to conceptualize data structures and relationships.Diagramming Tools: Familiarity with diagramming tools or software, such as ER diagram tools and UML modeling tools, will facilitate practical application.However, if you're a passionate learner with a determination to delve into the world of data visualization and database design, these prerequisites are not mandatory. This article will give you a solid foundation for your journey to become a proficient data visualizer.  Overview of Diagramming in Database DesignDiagrams are the visual blueprints that bring clarity and understanding to the intricate world of database design. In this section, we explore the significance of visual representation, the various types of diagrams commonly employed, and the art of selecting the perfect diagram for a given task.Importance of Visual Representation:In the realm of complex data structures and relationships, visual representation plays a pivotal role in simplifying the design process. Diagrams offer an intuitive and comprehensive view of the database, making it easier for stakeholders to grasp the system's architecture and functionality. They act as powerful communication tools, fostering collaboration between developers, designers, and stakeholders, leading to more informed decision-making and streamlined development.Types of Diagrams Used:Entity-Relationship (ER) Diagrams: The backbone of database design, ER diagrams showcase the entities, attributes, and relationships within a database. They help us understand how data entities interact with each other, defining cardinality, and providing a blueprint for data modeling.Data Flow Diagrams (DFD): DFDs illustrate the flow of data within a system. They visualize how data moves from input to processing and finally to output. DFDs are particularly useful for understanding data transformations and identifying potential bottlenecks in the data flow.Unified Modeling Language (UML) Diagrams: Widely used in software engineering, UML diagrams can be adapted for database design. Class diagrams represent the static structure of data and its relationships, while object diagrams show specific instances of data objects. Associations and multiplicity depict how data elements interact in a database.Choosing the Right Diagram for the Task:Selecting the appropriate diagram type for a specific task is crucial to accurately represent the underlying database structure. Consider the complexity of the data, the level of detail required, and the purpose of the visualization. For database architecture and data modeling, ER diagrams shine, while DFDs are preferred for showcasing data flow and system behaviour. UML diagrams, on the other hand, excel in representing the relationship between data elements in object-oriented systems.By mastering the art of choosing the right diagram, you can unleash the true potential of data visualization in database design, transforming abstract concepts into lucid blueprints for success.In the next section, we dive deeper into the world of Entity-Relationship (ER) Diagrams.  Entity-Relationship (ER) DiagramsEntity-Relationship (ER) diagrams are the bedrock of database design, providing a visual representation of the data model's fundamental building blocks. Let us delve into the core elements of ER diagrams, uncovering the secrets behind entities, attributes, relationships, and the cardinality that binds them.Understanding Entities and Attributes:Entities are the fundamental objects or concepts represented within the database. Each entity corresponds to a table in the database, and it encompasses all instances or occurrences of the entity's concept. Attributes, on the other hand, define the characteristics or properties of the entities. They represent the data elements that describe an entity's attributes, providing valuable information about the entities' features.Defining Relationships and Cardinality:The essence of an ER diagram lies in its portrayal of relationships between entities. Relationships define how entities interact or associate with one another. Cardinality further refines these relationships, indicating the number of occurrences of one entity that are associated with the occurrences of another entity. Cardinality can be one-to-one (1:1), one-to-many (1:N), many-to-one (N:1), or many-to-many (N:N), depending on the specific scenario.Conventions and Symbols Used:ER diagrams employ standardized conventions and symbols to create uniform representations. Entities are typically depicted as rectangles, with their respective attributes listed within them. Relationships are shown as diamond-shaped connectors between entities, with cardinality indicators specified near the connectors. Various lines and crow's foot notations signify the cardinality type, helping to precisely define the relationship between entities.For a clear and consistent understanding of ER diagrams, mastering these conventions and symbols is crucial, ensuring smooth communication and collaboration among all stakeholders involved in the database design process.  Data Flow Diagrams (DFD)Data Flow Diagrams (DFDs) are powerful tools for understanding how data moves within a system and between various components. I will explore with you how they map data flows and processes, the different levels of DFDs, and guidelines for creating these insightful visual representations.Mapping Data Flows and Processes:DFDs illustrate the path of data as it travels through a system, from its point of origin to its final destination. These diagrams focus on the data movement between processes, data stores, and external entities. By mapping data flows and processes, DFDs highlight the interactions and transformations data undergoes during its journey through the system.Different Levels of DFDs:DFDs come in multiple levels, each offering a specific level of detail and abstraction. The highest-level DFD, Level 0, provides a bird's-eye view of the entire system, depicting major processes and their interconnections. As we move to lower-level DFDs, such as Level 1 and beyond, more intricate details emerge, breaking down processes into subprocesses and revealing finer data flows within the system.Guidelines for Creating DFDs:To create effective and insightful DFDs, consider the following guidelines:Identify Boundaries: Define the scope of the system by identifying its boundaries and external entities that interact with it.Start with Level 0: Begin by creating a Level 0 DFD to establish a high-level overview of the system and its major processes.Decompose Processes: Break down complex processes into smaller subprocesses for greater clarity and granularity.Balancing Data Flows: Ensure that data flows are balanced, meaning the input and output data of a process remain consistent.No Process Explosion: Avoid excessive decomposition of processes to prevent ""process explosion"" and maintain readability.Use Descriptive Labels: Employ clear and descriptive labels for data flows and processes to enhance understanding.Validation and Feedback: Validate your DFDs with stakeholders and subject matter experts to ensure accuracy and incorporate feedback for improvement.By adhering to these guidelines, you can craft DFDs that unravel the intricacies of data movement in your system, facilitating effective communication and decision-making.  UML Diagrams for Database DesignUnified Modeling Language (UML) diagrams provide a standardized and versatile notation for visualizing data structures and relationships in database design. In this section, let's journey into the world of UML diagrams, exploring how Class Diagrams facilitate data modeling, how Object Diagrams depict instances, and the significance of Associations and Multiplicity in database visualization.Using Class Diagrams for Data Modeling:Class Diagrams serve as a powerful tool for data modeling in database design. They present a static view of the data structure, showcasing classes (representing entities or tables) and their attributes. By defining associations between classes, Class Diagrams unveil the relationships between data elements, providing a blueprint for creating well-organized databases.Object Diagrams for Instances:Object Diagrams, a subset of Class Diagrams, zoom in on specific instances of classes, offering a snapshot of the data at a particular point in time. They illustrate the objects (representing data instances) and the relationships between them, giving a concrete view of data in action.Associations and Multiplicity:Associations in UML diagrams depict the connections between classes, revealing how they are related. Multiplicity, represented by numeric values, defines the number of objects associated with a particular class. It enables us to understand the cardinality of the relationships, guiding us in designing database tables and establishing proper foreign key constraints.By leveraging UML diagrams, you gain a robust and standardized approach to represent data models and relationships, enhancing collaboration among developers and stakeholders and paving the way for effective database design.  Database NormalizationBefore we look at some wonderful tools and popular software which are used for Diagramming and database design, Let's take a look into one important concept of database which plays an indelible role in your database design and even implementation.Normalization is a fundamental concept in database design, playing a pivotal role in creating efficient and robust database structures. In this section, we highlight the paramount importance of normalization in diagramming and database design. We delve into the various Normal Forms, outlining the step-by-step normalization process and elucidating the compelling benefits it brings to database management.Importance of Normalization in Diagramming and Database Design:Normalization is vital in database diagramming as it helps organize data systematically, reduces redundancy, and minimizes data inconsistencies. By breaking down data into smaller, manageable units, normalization fosters a clear representation of the data structure in diagrams, paving the way for better understanding and maintainability.Explanation of Normal Forms:Normalization follows a set of rules known as Normal Forms, each designed to address specific data anomalies and improve data integrity. The prominent Normal Forms include First Normal Form (1NF), Second Normal Form (2NF), Third Normal Form (3NF), and beyond. Each Normal Form builds upon the previous one, ensuring data is free from redundancy and adheres to atomicity and integrity.Step-by-Step Normalization Process:The normalization process involves identifying functional dependencies within the data and organizing it into appropriate tables. The step-by-step approach involves breaking down complex data into simpler components, eliminating data repetition, and establishing proper relationships between tables. This iterative process leads to a well-structured, normalized database design.Benefits of Normalization:Normalization bestows several compelling advantages upon the database design:Data Integrity: Normalization ensures data consistency and integrity, reducing the risk of anomalies and data corruption.Flexibility: A normalized database allows for easier data modification and updates without affecting other parts of the database.Reduced Redundancy: By eliminating data redundancy, normalization optimizes data storage, minimizing storage requirements.Improved Performance: Well-normalized databases tend to perform better in data retrieval and querying operations, leading to enhanced system performance.Easier Maintenance: With a clear and organized structure, maintaining the database becomes more straightforward, reducing the likelihood of errors and issues.By grasping the significance of normalization and adhering to the Normal Forms, you can elevate your database design, leading to more efficient, scalable, and maintainable systems.Normalized vs no-normalized diagramNormalized Diagram:A normalized diagram represents a database that adheres to the principles of normalization. Entities are organized into separate tables, and relationships between entities are carefully defined using primary keys and foreign keys. Each table is designed to store specific types of data, reducing data redundancy and improving data integrity. Normalized diagrams provide a clear and concise view of the database, making it easier to understand and maintain.Non-Normalized Diagram:A non-normalized diagram, also known as a denormalized diagram, depicts a database structure that does not adhere to the principles of normalization. In denormalized databases, data may be duplicated across multiple tables, leading to data inconsistencies and wastage of storage space. Relationships between entities may not be adequately defined, making it challenging to understand the data model's intricacies.In the next section, we explore Tools and Software for Database Diagramming. Let's continue our exploration of database Diagramming! 📊🔍🧬  Tools and Software for Database Diagramming💡Unlock the Potential of Database Visualization with Cutting-Edge Tools!In this section, we embark on an exploration of the leading tools and software that empower you to create stunning database diagrams with ease and precision. From popular diagramming tools to specialized Integrated Development Environments (IDEs) with robust database features, you'll discover a wealth of resources to enhance your database design journey. Let's delve into the world of database diagramming software, compare their strengths, and find the perfect fit for your unique needs.Popular Diagramming Tools:Unleash your creativity with a diverse range of popular diagramming tools that support various diagram types, including ER diagrams and UML diagrams. Tools like:Lucidchart: An intuitive cloud-based diagramming tool with an extensive library of shapes and templates. Collaborate in real-time with team members and seamlessly integrate with other productivity apps.draw.io: A free and feature-rich diagramming tool with an open-source option. Create professional-quality diagrams with ease and save your work to your preferred cloud storage.Creately: A versatile online diagramming and design tool that supports various diagram types. Access thousands of templates and collaborate with team members effortlessly.offer intuitive interfaces, drag-and-drop functionality, and an array of symbols to craft expressive and polished diagrams. Empower your team with collaborative features, real-time editing, and seamless integration with other productivity tools.Integrated Development Environment (IDE) Features:Supercharge your database design process by leveraging the power of Integrated Development Environments (IDEs) with built-in database support. IDEs like: Visual Studio Code: A lightweight yet powerful IDE with an extensive library of extensions. Leverage database extensions to manage and visualize databases directly from the editor.IntelliJ IDEA: A feature-rich Java IDE with support for database development. Use dedicated database tools and plugins for seamless data visualization and manipulation.Eclipse: A widely-used IDE with an ecosystem of plugins for various languages and frameworks. Install database-related plugins to enhance your database design capabilities.provide dedicated plugins and extensions for database management, allowing you to create, visualize, and modify databases seamlessly from within the development environment. Experience the convenience of integrated version control, SQL query execution, and schema comparison tools.Comparing Diagramming Software:Navigate the myriad options by comparing diagramming software based on key features, usability, collaboration capabilities, and pricing models. Consider factors like: Cloud-based vs. desktop applicationsOffline access and sync capabilitiesUser interface and ease of useCollaboration and team featuresAvailability of industry-specific templates and stencilsLicensing models and pricing optionsBy carefully evaluating these aspects, you can find the ideal software that aligns perfectly with your database diagramming aspirations.Empowered with cutting-edge tools, you're ready to unleash your creativity and transform complex data into captivating diagrams.  Best Practices for Effective Database DiagramsCrafting Clear and Cohesive Visualizations!Let us look into the best practices that will elevate your database diagrams to new heights. Follow these guidelines to ensure your diagrams remain consistent, up-to-date, and effectively communicate complex database structures and relationships to your team and stakeholders.Keeping Diagrams Consistent and Up-to-date:Version Control: Use version control systems to track changes and revisions in your diagrams. This ensures you have a historical record of modifications and allows you to revert to previous versions if needed.Naming Conventions: Adopt a consistent naming convention for entities, attributes, and relationships in your diagrams. This promotes clarity and helps everyone understand the structure at a glance.Regular Review: Set a schedule for reviewing and updating your diagrams to reflect any changes in the database schema. Keeping diagrams current avoids confusion and discrepancies.Collaborating on Diagrams in a Team:Centralized Repository: Store your diagrams in a centralized location that is accessible to all team members. Cloud-based storage or version control repositories are ideal for collaborative efforts.Real-time Collaboration: Leverage tools that support real-time collaboration, enabling team members to work simultaneously on diagrams and providing instant feedback.Communicate Changes: When updating diagrams, communicate the changes to the team, and seek feedback. Transparent communication fosters better collaboration and a shared understanding of the database design.Documenting Diagrams for Clarity:Add Descriptions: Include brief descriptions or comments within the diagrams to explain complex relationships or special considerations.Contextual Information: Provide context for the diagrams by explaining the purpose and scope of the database. This ensures everyone understands the broader context of the system.Use External Documentation: For extensive databases, supplement your diagrams with external documentation, such as data dictionaries or entity-relationship descriptions, for comprehensive reference.By adhering to these best practices, you empower your team with clear, accurate, and up-to-date database diagrams. Effective diagrams enhance communication, streamline development, and serve as invaluable resources for everyone involved in the database design process.  ConclusionIn this article, we explored the art of database diagramming, delving into essential concepts like ER diagrams, DFDs, and UML diagrams. Visualizing data structures is vital for effective database design, enabling clear communication and shared understanding among teams and stakeholders.By embracing best practices such as consistency, regular updates, and collaborative efforts, we create cohesive and up-to-date diagrams. These visualizations serve as powerful blueprints for building efficient and scalable databases.As you venture forward, remember that data visualization in database design is an evolving skill. With dedication to best practices and the right tools, you can unleash the transformative power of data and drive innovation in the data-driven world.Happy Hacking!🥳Bentil here🚀I hope this article empowers you to unravel the magic of data visualization, and may your database design endeavours bring forth innovative solutions and transformative experiences. Together, let's harness the power of data to shape a future where information thrives and possibilities abound! 📊🔍🚀"
165,"This blog is originally published on my Blog website, where you can find the full version with detailed insights and examples. Click the link below to read the complete article and explore more tech-related content!👉 Click Here  IntroductionImagine you're building a house. HTML (Hypertext Markup Language) is like the strong foundation that holds everything together. Knowing some cool HTML tricks can make you a superstar in job interviews.Welcome back to the second part of our series! We're going to start from the basics and gradually climb up to advanced concepts, just like taking steps up a ladder of knowledge.In this series, we're unlocking the answers to the first 10 tricky HTML interview questions. Don't worry, we'll keep it super easy with examples. These answers will give you a boost of confidence during interviews, showing off what you know. Let's dive into these questions!If you're curious to learn more about HTML and its magic, check out the official guide from the World Wide Web Consortium (W3C) at HTML — World Wide Web Consortium.For nifty tips and tricks on making HTML work like a charm, the Mozilla Developer Network (MDN) has a user-friendly guide just for you. Discover it at HTML — Mozilla Developer Network.And if you're interested in making your website easy for everyone to use, the Web Accessibility Initiative (WAI) website is a goldmine of helpful resources. Find them at Web Accessibility Initiative.Remember, these extra resources can provide more information to help you grasp HTML better, along with the questions and examples we're covering.  Table Of ContentsHow can you create a responsive image that scales with the screen size?What is the purpose of the <figure> and <figcaption> tags?How can you add a background image to a webpage using HTML?How can you create a responsive video that adjusts to different screen sizes?How can you embed an audio file in HTML?Explain the purpose of the defer attribute in <script> tags.Explain the purpose of the pattern attribute in <input> tags.How can you make an HTML element draggable?How can you create a sticky/fixed navigation bar in HTML?  1- How can you create a responsive image that scales with the screen size? 👉 Answer:Use the max-width CSS property set to 100% to make an image responsive. This ensures that the image’s width adjusts to fit the container while maintaining its aspect ratio.<img src=""image.jpg"" alt=""A responsive image"" style=""max-width: 100%;"">Enter fullscreen modeExit fullscreen mode  2- What is the purpose of the <figure> and <figcaption> tags? 👉 Answer:The  tag is used to encapsulate media content, such as images or videos, along with an optional caption provided by the <figcaption> tag. It helps associate the media with its description.<figure>  <img src=""image.jpg"" alt=""A beautiful landscape"">  <figcaption>A breathtaking view of nature.</figcaption></figure>Enter fullscreen modeExit fullscreen mode  3- How can you add a background image to a webpage using HTML? 👉 Answer:To add a background image to a webpage, you can use the background-image CSS property within the <style> tag or in an external CSS file.<style>  body {    background-image: url(""background.jpg"");    background-repeat: no-repeat;    background-size: cover;  }</style>Enter fullscreen modeExit fullscreen mode  4- How can you create a responsive video that adjusts to different screen sizes? 👉 Answer:To create a responsive video, use the max-width CSS property and set the height to auto. Wrap the video element in a container to maintain its aspect ratio.<style>  .video-container {    max-width: 100%;    height: auto;  }</style><div class=""video-container"">  <video src=""video.mp4"" controls></video></div>Enter fullscreen modeExit fullscreen mode  5- How can you embed an audio file in HTML? 👉 Answer:To embed an audio file, use the <audio> element and specify the source file using the src attribute. You can include additional attributes like controls to add playback controls.<audio src=""audio.mp3"" controls></audio>Enter fullscreen modeExit fullscreen mode  6- Explain the purpose of the defer attribute in <script> tags. 👉 Answer:The defer attribute is used to indicate that the script should be executed after the HTML content has been parsed. It helps improve page load performance by allowing other resources to load in parallel.<script src=""script.js"" defer></script>Enter fullscreen modeExit fullscreen mode  7- Explain the purpose of the pattern attribute in <input> tags. 👉 Answer:The pattern attribute is used to specify a regular expression pattern that the input value must match. It is commonly used for form field validation.<input type=""text"" pattern=""[0-9]{3}-[0-9]{3}-[0-9]{4}"" placeholder=""XXX-XXX-XXXX"">Enter fullscreen modeExit fullscreen mode  8- How can you make an HTML element drag-gable? 👉 Answer:To make an HTML element drag-gable, use the drag-gable attribute and set it to true. You can then define event handlers to control the drag-and-drop behavior.<div draggable=""true"">Drag me!</div>Enter fullscreen modeExit fullscreen mode  9- How can you create a sticky/fixed navigation bar in HTML? 👉 Answer:To create a sticky/fixed navigation bar, use CSS to set the position of the navbar to fixed and specify a top or bottom value.<style>  .navbar {    position: fixed;    top: 0;    width: 100%;  }</style><div class=""navbar"">  <!-- Navigation links --></div>Enter fullscreen modeExit fullscreen mode  10- How can you embed a YouTube video in HTML?>👉 Answer:To embed a YouTube video, use the <iframe> tag with the video’s embed code provided by YouTube. <iframe     width=""560""     height=""315""     src=""https://www.youtube.com/embed/VIDEO_ID""     frameborder=""0""     allowfullscreen > </iframe>Enter fullscreen modeExit fullscreen mode  ConclusionIn this part of our series on tricky HTML interview questions, we've dived into some really cool stuff like responsive images, video embedding, sticky navigation, and more. By understanding these tricks, you'll feel super confident in your interviews. Stay tuned for the next part, where we'll unravel even more amazing HTML secrets!I'm curious to hear your thoughts! Feel free to share your comments.Let's connect on Twitter, LinkedIn, and GitHub to stay updated and join the conversation!"
166,"There are already many stories about Vim, detailing how it is useful for developers' lives. It makes screen sharing easier during the interview process or when pair programming at your current job, as familiarity with Vim makes you faster at coding. This enables you to quickly test all your ideas and select the best one. This is my story of adopting Vim and how I grew to love it.  First attempts 👶When I began my journey as a programmer, I used to work in the Sublime Text editor—almost everyone at that time used it. And I was content. Only now do I realize how slow I was. However, back then, I wasn't very proficient in programming; I had just started. The pace of my thoughts matched the speed of my typing. So, everything was satisfactory for me—I had never been hindered by typing speed or my efficiency.After several years of active programming, I switched to VSCode and began to realize that something was amiss with my efficiency—not due to VSCode itself, but due to how I worked and wrote my code. This was despite the fact that I had learned all the hotkeys that my teammates had never heard of. One day, I came across a video on YouTube showcasing a person performing editor magic. It seemed like he was a hacker character from those movies where they never touch a mouse and just type incredibly fast. It was at that moment I comprehended how slow my speed was and that I needed to make some changes. That experience provided me with motivation; I wanted to be like that guy.So, I discovered that the best way to learn Vim is through vimtutor. I'm using macOS, and if you are too, you already have it on your computer. Simply run this command in your terminal:> vimtutorEnter fullscreen modeExit fullscreen modeIt's a nice starting point if you want to give Vim a try. By the way, in lesson 1.2, they will explain how to exit from Vim, so you will not be lost. Don't worry.I gave it a try as well, attempting to integrate it into my actual coding workflow, but I found myself uncertain about the next steps. It seemed that everyone in the Vim world had their own Vim configuration with plugins and customized settings. For me, this complexity felt like a challenge—it wasn't user-friendly, and I couldn't even locate the starting point for this journey. So, I abandoned it and returned to VSCode. Nevertheless, thoughts of Vim lingered. I tried it time and again, but without success, ultimately leading me to give up.After several months of tormenting myself, feeling ineffective, I finally reached a compromise.  The compromise 🤝The compromise came in the form of the Vim extension for VSCode. It seemed to offer the easiest way to integrate Vim into my real-life workflow; all I needed was familiarity with vimtutor. So, I installed it and began using it. Admittedly, my initial progress was slow—slower than my regular mouse movements and VSCode shortcuts. However, I was determined to improve. After two weeks of consistent effort, my speed surpassed what I had achieved without Vim.Some Vim enthusiasts, who are deeply attached to the Vim editor, often contend that Vim plugins are inferior versions of Vim itself. These plugins are often restricted to the code area of your editor, whereas the original Vim gives you full control over various aspects, such as navigating through your file tree using Vim commands, among other things.I discovered a way to bring this functionality to VSCode. If you're already familiar with VSCode's keybinding system, you know that you can map keys to specific VSCode actions. Now, armed with Vim knowledge, you can adapt this to your keybinding system. For instance, if you want to move between tabs in VSCode, you can press alt+h or alt+l since h and l correspond to left and right movements in Vim. Similarly, to focus on the explorer panel, ctrl+h can be pressed as it's located on the left side of your text editor, and so on.To make adoption for you easier, I'm happy to share my keybinding configuration with you.  Conclusion 🎉To summarise, here's all you need to do, to bring VIM in your coding life now: Complete vimtutor. Install the Vim extension in VSCode. Edit your keybindings.json file (navigate to keyboard shortcuts in Settings, then switch to the JSON version)."
167,"Error handling and the way it is done is a crucial part of software engineering. Poorly returned errors and non-informative ones can cause unimaginable headaches. In this article I’m going to demonstrate the problems that I’ve faced with regards to gRPC error handling and what we might be able do to in order to improve upon our originally not-so-useful gRPC errors.I make lots of mistakes on a daily basis and I try to fix them and learn from them. If you’ve noticed one, I’d be more than grateful if you would correct me however you like.  IntroductionFirst of all, let’s start with explaining the actual problem that got me here. Inter-service communication (and the way it’s done) is probably one of the more important concerns in a microservice architecture. While here are certain concerns when using RPCs as a whole, (which can be mitigated as beautifully described by Netflix Tech Blog) it can’t be denied that the self-documenting nature of request/response messages and RPCs (via protobuf), coupled with server reflection has proved extremely comfortable and handy.One of the most overlooked aspects of gRPC might be the way the errors are returned from one service to another. The most simplistic way to return an error in an RPC might be as follows:func (s *serverImpl) UnaryRPC(ctx context.Context, req *pb.Request) (*pb.Response, error) {    // do something    if somethingFailed {        return nil, errors.New(""custom error"")    }    return resp, nil}Enter fullscreen modeExit fullscreen modeThe problem with the example above is that it provides nearly zero information to the caller about what went wrong and why. From the caller perspective the error might be handled like this:    reps, err := client.UnaryRPC(ctx, req)    if err != nil {      st, ok := status.FromError(err)      if ok {        if st.Message() == ""custom error"" {          // handle custom error        } else {          // handle other errors        }      }    }Enter fullscreen modeExit fullscreen modeHopefully this is already bothering you a lot simply because we are tightly coupled to an error string from another service which might get changed at any moment which renders our glorious error handling useless. Let’s take a look at how status.FromError works to see if we have any other useful information available:    func FromError(err error) (s *Status, ok bool) {      if err == nil {        return nil, true      }      // doing some stuff with interface{ GRPCStatus() *Status } type      // our simple error does not implement any custom interface      // ...      return New(codes.Unknown, err.Error()), false    }Enter fullscreen modeExit fullscreen modeThis signals to us that other attributes of the status.Status (e.g. Code and Details ) are simply meaningless. Code is automatically set to Unknown and Details will be zero-valued.You can safely use st := status.Convert(err) which just skips the ok handling part since the Go implementation of gRPC guarantees that all RPCs return status type errors. We can also confirm this by heading to the http2_client.go operateHeaders method:    func (t *http2Client) operateHeaders(frame *http2.MetaHeadersFrame) {      // ...      var (        // ...        grpcMessage string        statusGen *status.Status        rawStatusCode = codes.Unknown        // ...      )      // ...      for _, hf := range frame.Fields {        switch hf.Name {        // ...        case ""grpc-message"":          grpcMessage = decodeGrpcMessage(hf.Value)        case ""grpc-status"":          code, err := strconv.ParseInt(hf.Value, 10, 32)          handle(err)          rawStatusCode = codes.Code(uint32(code))        case ""grpc-status-details-bin"":          statusGen, err = decodeGRPCStatusDetails(hf.Value)          handle(error)        // ...        }        // ...      }       // ...      if statusGen == nil {        statusGen = status.New(rawStatusCode, grpcMessage)      }      // ...      t.closeStream(s, io.EOF, rst, http2.ErrCodeNo, statusGen, mdata, true)    }Enter fullscreen modeExit fullscreen modeLet’s be polite and provide more information to our caller:    func (s *serverImpl) UnaryRPC(ctx context.Context, req *pb.Request) (*pb.Response, error) {      // do something      if somethingFailed {        return nil, status.Error(codes.Internal, ""internal error"")      }      return resp, nil    }Enter fullscreen modeExit fullscreen modeNow, the client can also make important and useful assumptions about the returned code:    resp, err := client.UnaryRPC(ctx, req)    if err != nil {      st := status.Convert(err)      switch st.Code() {      case codes.Internal:        // handle internal error      default:        // handle other errors      }    }Enter fullscreen modeExit fullscreen modeAs informative and descriptive as it might look, this method falls short of explaining and reasons behind its (status) code and error.  Status DetailsReturning status codes was the farthest we’ve come with regards to returning descriptive errors from our microservices. But there are certain scenarios in which we simply can’t afford to solely rely on the status codes. Why, you might ask? Let me explain.Assume that we have two services, the first one which interacts with our end users is called Submit and the other one,Storage, is considered an internal service, talking only to other services and not to external clients/customers or end users.Consider the flow as follows: the end user tries to submit his/her data through our Submit service, which in turn tries to persist the users data by saving it in the Storage service (let’s say that Storage simply wraps some arbitrary DB).In a peculiar scenario, due to some business logic,Storage denies to save the data provided by Submit and returns the reason like below:    func (s *storageService) Save(ctx context.Context, req *pb.Req) (*pb.Resp, error) {      // the actual logic      if cantSave {        return nil, status.Error(codes.FailedPrecondition, ""the fully described reason here"")      }        // ...    }Enter fullscreen modeExit fullscreen modeAssuming that the described reason is specific to Storage service domain, meaning that Submit won’t be able to reproduce the exact descriptive reason in order to show the client, let’s explore different ways that Submit can handle this scenario and return some error to the end user.Return the error as is    func (s *submitService) Submit(ctx context.Context, req *pb.Req) (*pb.Resp, error) {      resp, err := storageClient.Save(ctx, req)      if err != nil {        st := status.Convert(err)        switch st.Code() {        case codes.FailedPrecondition:          return nil, st.Err()        default:          return nil, status.Error(codes.Internal, ""oops!"")        }      }    }Enter fullscreen modeExit fullscreen modeWhile this method might simply solve our problem (the end user gets to see the fully descriptive error as is) a major headache is introduced as well: Debugging this error will be an absolute hassle. Submit is actually returning this error, but good luck finding the text in this repo. Imagine doing the same thing with a couple of other services apart from Storage. Soon you’ll find yourself searching all your client services for some error string that seeminglySubmit returns, scratching your head and regretting every decision you’ve made in your life. (just think about what happens if Storage returns codes.FailedPrecondition in several scenarios, some with error strings containing private information and details that end users should not know about)Drop the original error and replace with our own    func (s *submitService) Submit(ctx context.Context, req *pb.Req) (*pb.Resp, error) {      resp, err := storageClient.Save(ctx, req)      if err != nil {        st := status.Convert(err)        switch st.Code() {        case codes.FailedPrecondition:          return nil, errors.New(""dear end user, you can not do that"")        }      }    }Enter fullscreen modeExit fullscreen modeThis way we can at least make sure that Submit won’t return unwanted error messages or ones that are not available in the Submit repo, yet the returned error string is not exactly what we wanted our end user to see. It’s not descriptive enough. Also, we still have the same problem with multiple codes.FailedPrecondition errors as above.Storage service provides further error detailsIn order to enable effective communication between these two services, it might be a good idea that the error details are structured as a proto message. The first (and probably) more obvious approach is to extend the Storage response message and add the extra Error message inside it:    message SaveError {      int32 first_field = 1;      bool second_field = 2;    }    message SaveResp {      string first = 1;      string second = 2;        SaveError error = 3;      }    service Storage {      rpc (SaveRequest) returns (SaveResponse);      }Enter fullscreen modeExit fullscreen modeThis way the SaveError provides enough information for the Submit service to reproduce the descriptive error string and finally show it to the end user.     func (s *submitService) Submit(ctx context.Context, req *pb.Req) (*pb.Resp, error) {      resp, err := storageClient.Save(ctx, req)      if err != nil {        // some other error      }      if resp.Error != nil {        return nil, createCustomError(resp.Error)        }    }Enter fullscreen modeExit fullscreen modeBut there’s something off with this kind of error handling. The fact that we should handle two sources of error from a single RPC doesn’t sound like a good idea and might introduce some unnecessary complexity and confusion (it suggests that our client call might still be failed even though the RPC itself was successful!).What if we want the Storage service to provide the much needed error details but not exactly in the body of the response? We can add Details to our status in form of proto messages:    func (s *storageService) Save(ctx context.Context, req *pb.Req) (*pb.Resp, error) {      // some logic      if cantSave {        st := status.New(codes.FailedPrecondition, ""any grpc message"")        st, err := st.WithDetails(&pb.SaveError{...})        handle(err)          return nil, st.Err()        }    }Enter fullscreen modeExit fullscreen modeThe st.WithDetails() should be given an instance of proto.Message. Feel free to pass your own custom proto messages, or use the errdetails package. From the caller perspective, the detail can be simply retrieved as well:    func (s *submitService) Submit(ctx context.Context, req *pb.Req) (*pb.Resp, error) {      resp, err := storageClient.Save(ctx, req)      if err != nil {        st := status.Convert(err)        for _, d := range st.Details() {          switch detail := d.(type) {          case *pb.SaveError:              return nil, createCustomError(detail)            default:            // other details          }        }      }    } Enter fullscreen modeExit fullscreen modeNow we have the luxury of not only conditioning on the status code, but to rely on a documented and agreed upon detail without being overly dependent on any other service. Yay!More on status details in this wonderful article by Johan Brandhorst.  Status under the hoodWe’ve seen how the client transport provides status in any gRPC error, so we might have a rough idea of how the situation is handled from the server’s point of view, e.g. what happens under the hood when we return a status.Status with Code, Message and Details. Basically if we take a look at the http2_server.go WriteStatus method we can see how these grpc-specific headers are written in action:    func (t *http2Server) WriteStatus(s *Stream, st *status.Status) error {      // ...      headerFields := make([]hpack.HeaderField, 0, 2)      // ...      headerFields = append(headerFields, hpack.HeaderField{        Name: ""grpc-status"",         Value: strconv.Itoa(int(st.Code())),      })      headerFields = append(headerFields, hpack.HeaderField{        Name: ""grpc-message"",        Value: encodeGrpcMessage(st.Message()),      })      if p := st.Proto(); p != nil && len(p.Details) > 0 {        stBytes, err := proto.Marshal(p)        handle(err)        headerFields = append(headerFields, hpack.HeaderField{          Name: ""grpc-status-details-bin"",          Value: encodeBinHeader(stBytes),        })      }        // use the headerFields ...    }Enter fullscreen modeExit fullscreen modegRPC uses “Trailers” to convey its final status as well as any messages and/or details in case of an error. Trailers are just a subset of headers which are sent after the response body (in contrast to the actual response headers that are sent before the response body in the HTTP protocol). More about these trailers is available in Carl Mastrangelo’s “Why does gRPC insist on Trailers?” and SoByte’s “Talking about gRPC’s Trailers Design”, both of which I really encourage you to take a look at, they’re extraordinary. Here is a couple of quotes from the latter:So the question is, why does gRPC rely on Trailers? The core reason is to support a streaming interface. Because it is a streaming interface, it is not possible to determine the length of the data in advance, and it is not possible to use the HTTP Content-Length header. The corresponding HTTP request looks like this.    GET /data HTTP/1.1    Host: example.com    HTTP/1.1 200 OK    Server: example.com    abc123Enter fullscreen modeExit fullscreen modeWhat? Uncertain length? Carl points out that using chunked is ambiguous. He gives the following example.    GET /data HTTP/1.1    Host: example.com    HTTP/1.1 200 OK    Server: example.com    Transfer-Encoding: chunked    6\r\n    abc123\r\n    0\r\nEnter fullscreen modeExit fullscreen modeSuppose there is a proxy before the client and the server. The proxy receives the response and starts forwarding the data to the client. The first thing is to send the Header part to the client, so the caller determines that this time the status code is 200, which is successful. Then the data part is forwarded paragraph by paragraph. If the server is down after the proxy forwards the first abc123, what signal does the proxy need to send to the client? Because the status code has been sent, there is no way to change 200 to 5xx. You can’t send 0\r\n directly to end the chunked transfer, so that the client learns that the server has quit abnormally. The only thing you can do is to close the corresponding underlying connection directly, but this will consume additional resources as the client creates a new connection. So we needed to find a way to notify the client of the server error while reusing the underlying connection as much as possible. The gRPC team finally decided to use Trailers for transport.  Trailers in actionImagine that we have a server-side streaming RPC like below. It basically sends 3 valid response messages and then an error:    func (s *serverImpl) ServerStream(req *pb.GreetRequest, stream pb.Greeter_ServerStreamServer) error {      ctx := stream.Context()      for i := 0; i < 5; i++ {        select {        case <-ctx.Done():          return status.Error(codes.DeadlineExceeded, ""deadline exceeded"")        default:          if i == 3 {            st := status.New(codes.Internal, ""something went wrong"")            st, _ = st.WithDetails(&errdetails.ErrorInfo{              Reason: ""some random reason"",              Domain: ""some.random.domain"",              Metadata: map[string]string{                ""first"": ""something"",                ""second"": ""another thing"",              },            })            return st.Err()          }          err := stream.Send(&pb.GreetResponse{Greet: fmt.Sprintf(""hello %s!"", req.Name)})          if err != nil {            log.Print(""failed to send: "", err)          }        }      }      return nil    }Enter fullscreen modeExit fullscreen modeAfter calling this method with a client (I chose just a simple gRPC client written in go) we can take a look at what’s being transmitted in something like Wireshark (I’ve omitted certain lines to reduce unwanted clutter):    POST /test.Greeter/ServerStream    HyperText Transfer Protocol 2        Stream: DATA, Stream ID: 1, Length 15            Flags: 0x01                .... ...1 = End Stream: True    Protocol Buffers: /test.Greeter/ServerStream,request        Message: test.GreetRequest            [Message Name: test.GreetRequest]            Field(1): name = homayoon (string)Enter fullscreen modeExit fullscreen modeIn the response stream, first we’ll receive the following packet:    HyperText Transfer Protocol 2        Stream: HEADERS, Stream ID: 1, Length 14, 200 OK            Flags: 0x04                .... ...0 = End Stream: False                .... .1.. = End Headers: True            Header: :status: 200 OK            Header: content-type: application/grpc        Stream: DATA, Stream ID: 1, Length 22            Flags: 0x00                .... ...0 = End Stream: False            0... .... .... .... .... .... .... .... = Reserved: 0x0            .000 0000 0000 0000 0000 0000 0000 0001 = Stream Identifier: 1            [Pad Length: 0]            DATA payload (22 bytes)    Protocol Buffers: /test.Greeter/ServerStream,response        Message: test.GreetResponse            [Message Name: test.GreetResponse]            Field(1): greet = hello homayoon! (string)Enter fullscreen modeExit fullscreen modefollowed by two other packets without the :status 200 OK header (since it’s already sent in the first one):    HyperText Transfer Protocol 2        Stream: DATA, Stream ID: 1, Length 22            Flags: 0x00                .... ...0 = End Stream: False    Protocol Buffers: /test.Greeter/ServerStream,response        Message: test.GreetResponse            [Message Name: test.GreetResponse]            Field(1): greet = hello homayoon! (string)Enter fullscreen modeExit fullscreen modeFinally we’ll have the final packet which contains the gRPC trailers (notice the End Stream: True:    HyperText Transfer Protocol 2        Stream: HEADERS, Stream ID: 1, Length 226            Flags: 0x05                .... ...1 = End Stream: True                .... .1.. = End Headers: True            Header: grpc-status: 13            Header: grpc-message: something went wrong            Header: grpc-status-details-bin: CA0SFHNvbWV0aGluZyB3ZW50IHdyb25nGoEBCih0eXBlLmdvb2dsZWFwaXMuY29tL2dvb2dsZS5ycGMuRXJyb3JJbmZvElUKEnNvbWUgcmFuZG9tIHJlYXNvbhISc29tZS5yYW5kb20uZG9tYWluGhIKBWZpcnN0Eglzb21ldGhpbmcaFwoGc2Vjb25kEg1hbm90aGVyIHRoaWEnter fullscreen modeExit fullscreen modeNeedless to say that we’ll easily be able to retrieve the original details in the grpc-status-details-bin, let’s do it the hard way and just copy the base64 encoded string above (rather than retrieving it in the gRPC client):    import (       spb ""google.golang.org/genproto/googleapis/rpc/status""    )    d := ""CA0SFHNvbWV0aGluZyB3ZW50IHdyb25nGoEBCih0eXBlLmdvb2dsZWFwaXMuY29tL2dvb2dsZS5ycGMuRXJyb3JJbmZvElUKEnNvbWUgcmFuZG9tIHJlYXNvbhISc29tZS5yYW5kb20uZG9tYWluGhIKBWZpcnN0Eglzb21ldGhpbmcaFwoGc2Vjb25kEg1hbm90aGVyIHRoaW5n""    b, _ := base64.StdEncoding.DecodeString(d)    st := &spb.Status{}    proto.Unmarshal(b, st)    for _, dt := range st.Details {      errD := &errdetails.ErrorInfo{}      dt.UnmarshalTo(errD)      b, _ := json.MarshalIndent(errD, """", ""  "")      fmt.Println(string(b))    }Enter fullscreen modeExit fullscreen modeViola!    {      ""reason"": ""some random reason"",      ""domain"": ""some.random.domain"",      ""metadata"": {        ""first"": ""something"",        ""second"": ""another thing""      }    }Enter fullscreen modeExit fullscreen mode  ConclusionIn this article we explored how to provide descriptive and informative errors in a gRPC microservice architecture communicating via gRPC. We did also take a look at how different gRPC trailers are handled under the hood. Finally, we discussed the gRPC trailers and experimented with a mock server to better understand how and when these headers/trailers are passed. I hope you’ve found this article helpful. I’d be grateful if you would like and share this article as well."
168,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers.🎒 What was your favorite 'tech' gadget during school days that now seems hilariously outdated?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
169,"Hello fellow DEV community!Today, I want to dive into an essential topic that often gets overlooked but plays a crucial role in creating clean, readable, and maintainable GDScript code: coding conventions. Consistent coding conventions not only make your code more organized but also contribute to the overall productivity and collaboration within your development team. So, let's explore some best practices for writing GDScript code, including naming conventions for assets, scenes, and nodes.  Introduction to GDScript Coding ConventionsCoding conventions are a set of guidelines and rules that developers follow to maintain consistency in their codebase. They help create a standardized format, making it easier for developers to understand each other's code and contribute effectively. GDScript, as a flexible and Python-like scripting language, allows developers to write code in various ways. However, sticking to a common set of conventions enhances code quality and makes your projects more robust.In this post, we'll cover some general coding conventions and delve into naming conventions for variables, functions, classes, and more. Additionally, we'll explore how to apply these conventions to assets, scenes, and nodes in your Godot projects.  General Coding Conventions  IndentationConsistent indentation is vital for code readability. GDScript generally uses tabs for indentation. Avoid using spaces, as different editors might interpret them differently.# Bad indentation examplefunc calculate_score(score_value: int) -> int:    if score_value > 100:        return score_value * 2    else:        return score_valueEnter fullscreen modeExit fullscreen mode# Good indentation example (using tabs)func calculate_score(score_value: int) -> int:    if score_value > 100:        return score_value * 2    else:        return score_valueEnter fullscreen modeExit fullscreen mode  Line LengthTo enhance code readability, aim to keep your lines of code within a reasonable length. A common practice is to limit lines to around 80 characters. If a line becomes too long, consider breaking it into multiple lines or using parentheses for better formatting.# Good line length examplefunc _ready():    var message = ""Hello, Godot developers! Welcome to our community.""    print(message)# Bad line length examplefunc _ready(): var message = ""Hello, Godot developers! Welcome to our community.""; print(message)Enter fullscreen modeExit fullscreen mode  WhitespaceUse whitespace judiciously to separate different parts of your code and improve readability. Add spaces after commas, around operators, and between function arguments.# Good use of whitespace examplefunc calculate_total_score(score1: int, score2: int) -> int:    return score1 + score2# Bad use of whitespace examplefunc calculate_total_score(score1:int,score2:int)->int:    return score1+score2Enter fullscreen modeExit fullscreen mode  CommentsAdd comments to explain your code and its purpose. Well-commented code helps other developers, including your future self, understand the logic and functionality of your code.# Good use of comments example# This function calculates the total score by adding two individual scores.func calc_total(s1: int, s2: int) -> int:    return s1 + s2# Bad use of comments examplefunc calc_total(s1: int, s2: int) -> int:    return s1 + s2Enter fullscreen modeExit fullscreen modeNevertheless, the best code is the code that doesn't require comments as it is innately self explanatory.func calculate_total_score(score1: int, score2: int) -> int:    return score1 + score2Enter fullscreen modeExit fullscreen mode  Naming Conventions  Variables and ConstantsUse descriptive names for variables and constants that indicate their purpose. Names should be in lowercase, with words separated by underscores.# Good variable naming examplevar player_health: int = 100const MAX_ENEMIES: int = 10# Bad variable naming examplevar p: int = 100const max: int = 10Enter fullscreen modeExit fullscreen mode  Functions and MethodsFunction and method names should also be descriptive and use lowercase letters with underscores to separate words.# Good function naming examplefunc calculate_score(score_value: int) -> int:    return score_value * 2# Bad function naming examplefunc clc(score: int) -> int:    return score * 2Enter fullscreen modeExit fullscreen mode  Classes and EnumsUse PascalCase for class and enum names. Class names should be nouns, while enum names should be singular nouns.# Good class and enum naming exampleclass Player:    enum Direction { UP, DOWN, LEFT, RIGHT }# Bad class and enum naming exampleclass playeR:    enum direction { UP, DOWN, LEFT, RIGHT }Enter fullscreen modeExit fullscreen mode  Naming Conventions for Assets and Scenes  AssetsWhen naming assets, camel_case, use lowercase letters and separate words with underscores. Be descriptive and use meaningful names that indicate the asset's purpose. The reason why we use all lowercase letters is that each platforms have different ways in treating uppercase and lowercase in file names.# Good asset naming examplemain_room.tscnmain_room.gdbackground_image.pngenemy_sprite.pngjump_sound.wav# Bad asset naming examplemainRoom.tscnmainRoom.gdbg.pngspr1.pngsound1.wavEnter fullscreen modeExit fullscreen mode  NodesNodes in scenes should follow PascalCase conventions. Choose descriptive names that represent the node's functionality.# Good node naming examplePlayerCharacterEnemySpawnerScoreLabel# Bad node naming examplePlayerNode2DLabelEnter fullscreen modeExit fullscreen mode  Coding StyleConsistency is key when it comes to coding style. Ensure that you and your team members follow the same conventions throughout your project. Adopting a consistent coding style improves readability and makes your code look professional.In addition to the conventions mentioned above, consider adopting the following practices:Use Meaningful Names: Always choose meaningful names for variables, functions, classes, and nodes. Avoid single-letter or vague names that might confuse other developers.Be Mindful of Abbreviations: While abbreviations can save typing, be cautious with them. Avoid using obscure or ambiguous abbreviations that might not be immediately understandable.Avoid Magic Numbers: Instead of using literal values in your code, assign them to constants with descriptive names. This improves code readability and makes it easier to maintain.Limit Function Length: Aim to keep your functions short and focused. Long functions can become difficult to manage and understand.Organize Code Logically: Structure your code in a logical manner, breaking it into meaningful sections or using comments to group related code together.  Code ReusabilityAn essential benefit of following coding conventions is that it promotes code reusability. When your code is well-organized and follows consistent conventions, you can easily reuse functions, methods, and classes across different projects.By applying the same conventions to your assets, scenes, and nodes, you can also streamline your workflow when working with Godot Engine. Consistent naming and organization help you find and manage resources more efficiently, resulting in a smoother development process.  SummaryCoding conventions are an invaluable tool for any Godot developer seeking to create clean, readable, and maintainable code. In this post, we explored some general coding conventions, including indentation, line length, whitespace, and commenting. We also discussed naming conventions for variables, functions, classes, enums, assets, scenes, and nodes.Adopting coding conventions in your projects enhances code quality, increases collaboration within your team, and facilitates code reuse. Consistent naming and organization make it easier for you and other developers to understand and contribute to the codebase effectively.Remember that while coding conventions offer a set of guidelines, they are not set in stone. You can adapt them to suit your team's preferences and requirements. What matters most is that you and your team members follow the same conventions consistently throughout your projects.Happy coding, and may your Godot projects thrive with clean and maintainable code! 🚀🎮"
170,"Failure is a natural part of coding. Share an experience where a coding project or attempt didn't go as planned. How did you handle the setback, and what did you learn from the experience?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
171,"No this isn’t what you expect, comments are useful but we are as developers at all levels bad at them. Could it be that the future of documentation code comments and tests amalgamated through AI?I’ve seen GPT4s code interpreter understand, describe and test my code and it’s only a matter of time before we move to a workflow and pipeline that takes a wholistic perspective.Such a tool would be a guidebook of the code with unit tests right in the code, it would make source maps and plug into dev tools, it would be the unified guide to your codebase.I think this is the death of comments but what do you think?"
172,"The standard git log command is functional, providing the necessary information, but it can come across as somewhat dull and verbose. What if there was a way to make the git log not just informative, but also visually appealing? Something like this:Yes, it's entirely possible! And the good news is that we can achieve this by simply using a bunch of flags and subcommands. There's no need to install or download anything.Here's the command:git log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit --branchesEnter fullscreen modeExit fullscreen modeBut typing this command every time could be tiresome. A solution to this is using Git aliases, which allow you to create shortcuts for lengthy commands. If you're unfamiliar with Git aliases, I recommend reading my recent article that dives into the topic:Mastering Git Shortcuts: A Guide to Git AliasesPradumna Saraf ・ Jul 28#git#opensource#programming#beginnersNow, let's set up an alias for our beautiful git log command:git config --global alias.lg ""log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit --branches""Enter fullscreen modeExit fullscreen modeNow you can invoke the beautified git log using a simpler git lg."
173,"Hey folks 👋What y'all learning about this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Expand your mind!"
174,"I’ve heard the advice over and over, “find a mentor.” While having a mentor can be valuable, relying solely on one mentor isn’t the most effective approach to learning and growing. Instead, let's redefine what it means to receive mentorship to benefit the most people. What does that mean? It means that we see mentorship as daily opportunities to learn and grow with people that we may or may not have direct contact regularly. It means that we see communities as the most valuable resource for mentorship. That we can receive mentorship by interacting with people in online environments, and by seeing every conversation as an opportunity to learn something new. That we ask questions, provide feedback, and that we mentor ourselves as part of that journey.  Why Community Mentorship is Better than 1:1 MentorshipI want to take a second to define what I mean here. When I say 1:1 mentorship, it means that you have a regular or semi-regularly scheduled time to meet with the same person for guidance and the opportunity to learn. I’m not saying you shouldn’t do this. But I am saying that community mentorship, or seeing a group of people and your interactions with them as mentorship, is better. Below you’ll find some of the reasons why.  Diverse PerspectivesIf you’re meeting 1:1, you’re limited to that person’s knowledge, exposure, and perspective. One of the key advantages of having a community of mentors is the diverse perspectives you’ll see and hear. Different voices and experiences provide a broader understanding of the industry, new ideas, and offer more opportunities. The community perspective can come from online communities on discord or slack, meetups, or by interacting with various authors through blogs and forums. That experience will allow you to hear a variety of viewpoints, allowing for a more well-rounded understanding of tech and best practices.  Supportive and Diverse NetworkBuilding a network can consist of peers, experienced techies, and even experts in the industry and benefit you throughout your career. Engaging with a diverse group of people in tech at all stages of the journey allows you to learn from different perspectives and also facilitates knowledge sharing, collaboration, and the formation of lasting connections that may lead to future opportunities. It becomes an opportunity to peer mentor and grow through teaching and collaborating with others, key skills we all need in tech.  Accessible KnowledgeWhat happens if you have a question that determines an important part of your tech journey and your mentor is unavailable for an extended period of time? Having the collective knowledge of a community allows for availability at all times. That means that you can seek guidance and answers to your questions whenever you need them, without being limited by a mentor's schedule.  Continuous LearningEvery interaction in a community is an opportunity to learn, whether that’s active or passive. Early in my career, I worked mostly 1:1 with an experienced developer. I learned a lot from that experience, but I learned the most when I actively engaged in a community. A lot of that learning came from reading slack conversations between developers. I was able to see how they asked each other questions, the processes they used to debug, and read different approaches to the same problems. Communities are a constant stream of fresh ideas and insights.  Supportive EnvironmentCommunity mentorship can create a continual support system. You might find that other community members have the same goals and you can support each other, sustain motivation, and get emotional support through the journey. One of the most beneficial experiences I had when I was learning to code was hearing people who were ahead of me in their journey saying that they experienced the same frustrations. I stopped feeling so alone and was able to gain confidence as they shared their stories and advice with me.  Continuous Opportunities for GrowthI strongly believe in horizontal mentorship–the ability to mentor at any stage. We all have our strengths and weaknesses, and you can always share those strengths to help others. Community mentorship often provides these opportunities for growth and development. You can contribute your expertise, collaborate on projects, and become a mentor yourself.   Resilience and ContinuityHaving a community of mentors ensures that you’ll continue to be mentored even if one individual's mentorship ends. The collective support of a community empowers you to overcome challenges and setbacks.  Empowering Self-Directed LearningRedefining mentorship as an amalgamation of learning experiences enables a more self-directed and proactive approach to skill development, and builds the skills you need to thrive as a person in tech who needs to problem-solve and learn to work independently. Rather than relying on a mentor's schedule, you can own your learning process and explore topics that interest you most at your own pace. This autonomy cultivates self-reliance. It can be challenging to discern what information is right, follows best practices, or isn’t there just for clickbait. This is where you leverage your community of mentors. Ask for recommendations and references. Let people know what’s worked for you in the past or what style of learning you find most effective. Once you’ve settled on resources, don’t forget that many of those learning resources come with a community built in. There might be a forum for the class or an async communication platform. The ability to create your own learning experience allows you to access the newest information, tailor your learning pace, and explore areas of tech that you most enjoy. If a structured learning experience isn’t for you, you can also find a particular content creator or content creators that you learn well from, and consume their content as a form of mentorship. As part of that, you might have the opportunity to ask questions, suggest future content, or let the creator know how valuable the information has been to your journey.   The Power of Online CommunitiesOver the last couple of years, online communities and forums have exploded with opportunity. I’m confident that there is a community that suits your needs out there already (but that doesn’t mean you can’t start your own if you can’t find one!) If you’re not sure where to start OpenSauced offers a lot of different opportunities to be part of a community and ask questions:#100DaysOfOSSOpenSauced DiscordOpenSauced Twitter + Twitter SpacesActively participating in communities allows you to seek guidance, ask questions, and contribute your expertise. While mentors can provide awesome guidance, the traditional 1:1 mentorship model might not be the most effective or accessible option for everyone. Redefining mentorship to include various online resources and interactions can empower you to find your own path to success. Remember, it's not about having a single mentor; it's about building a network of support that uplifts and inspires you on your tech journey."
175,"Image by freepic.diller on FreepikTitle: Navigating the Digital Restaurant: A Taste of Authentication and Authorization in JavaScriptIntroduction:Picture yourself stepping into a bustling restaurant, ready to savor a delectable meal. Just as this restaurant experience is organized and secure, websites and web applications ensure your online interactions are safe and personalized. In this article, we'll embark on a journey through the world of web development, using the restaurant analogy to unravel the concepts of authentication and authorization in the realm of JavaScript.Unlocking Doors with Authentication:Image by macrovector on FreepikImagine you've reserved a table at your favorite restaurant. As you approach, the host kindly asks for your name to confirm your reservation. This process mirrors authentication in web development. Authentication is all about proving you're you before being granted access to a website. When you log in to a website, it's like saying, ""Hey, it's me!"" just as you confirm your identity with the restaurant host. In the digital realm, you provide your username and password, ensuring only authorized users gain entry.Ordering Dishes with Authorization:Image by macrovector on FreepikNow, picture yourself seated at your reserved table, perusing the menu. Each dish is carefully curated to match your preferences and permissions. This aligns with the concept of authorization in web development. Authorization determines what actions and resources users are allowed to access. Just as the restaurant's menu tailors offerings based on your reservation, websites tailor content based on user roles and permissions. Certain features are reserved for specific roles, ensuring a personalized and secure experience.The JavaScript Ingredient:In our digital restaurant, JavaScript plays a pivotal role. Let's explore how authentication and authorization are implemented using this powerful language.Authentication in JavaScript:Consider authentication as the process of proving your identity, much like telling the restaurant your name. In JavaScript, users provide their credentials – usernames and passwords – to access their accounts. This data is securely validated to ensure the right individuals are granted access. Additionally, token-based authentication issues a digital ""key"" upon login, which is used to identify users in subsequent interactions.Authorization in JavaScript:Authorization is akin to the restaurant offering you a menu based on your reservation. In JavaScript, it controls what users can see and do. Through role-based access control (RBAC), users are assigned roles like ""guest,"" ""user,"" or ""admin."" These roles dictate their level of authorization. Custom logic is applied to ensure that users interact with only the content and features they're permitted to access.Conclusion: A Satisfying Web ExperienceMuch like a restaurant ensures your dining experience is secure and tailored, websites prioritize authentication and authorization to create a satisfying online journey. By understanding these concepts through the lens of a restaurant visit, you've gained a flavorful insight into how JavaScript makes the digital world equally inviting and secure. Just as you savor each bite at a restaurant, relish your web interactions, knowing that the principles of authentication and authorization are working harmoniously to serve you a delightful online experience."
176,"Hey everyone, the past few months have been pretty electric in terms of advancements in AI and actual/imagined changes to our workflow and industry.This is a regular open thread where everyone is encouraged to share...Notable news in the field of AIPersonal experiences and insightsConcerns and fearsSuccess stories and demosAnd any other related discussions you'd like to bring to the tableThis thread will go out every week.      "
177,"I tweet technical content that I consider interesting, but the funny tweets are the ones that get the most engagement. I attended the JavaLand conference in March, stumbled upon the Gradle booth, and found this gem:Of course, at some point, a fanboy hijacked the thread and claimed the so-called superiority of Gradle. In this post, I'd like to shed some light on my stance, so I can direct people to it instead of debunking the same ""reasoning"" repeatedly.To manage this, I need to get back in time. Software development is a fast-changing field, and much of our understanding is based on personal experience. So here's mine.  My first build tool: AntI started developing in Java in 2002. At the time, there were no build tools: we compiled and built through the IDE. For the record, I first used Visual Age for Java; then, I moved to Borland JBuilder.Building with an IDE has a huge issue: each developer has dedicated settings, so artifact generation depends on the developer-machine combination.Non-repeatable builds are an age-old problem. My first experience with repeatable builds is Apache Ant:Apache Ant is a Java library and command-line tool whose mission is to drive processes described in build files as targets and extension points dependent upon each other. The main known usage of Ant is the build of Java applications. Ant supplies a number of built-in tasks allowing to compile, assemble, test and run Java applications. Ant can also be used effectively to build non Java applications, for instance C or C++ applications. More generally, Ant can be used to pilot any type of process which can be described in terms of targets and tasks.-- https://ant.apache.org/Ant is based on three main abstractions:A task is an atomic unit of work, e.g., javacto compile Java files, war to assemble a Web Archive, etc. Ant provides lots of tasks out-of-the-box but allows adding custom ones.A target is a list of tasksYou can define dependencies between tasks, such as package depending on compile. In this regard, you can see Ant as a workflow execution engine.I soon became ""fluent"" in Ant. As a consultant, I went from company to company, project to project. Initially, I mostly set up Ant, but Ant became more widespread as time passed, and I encountered existing Ant setups. I was consistent in my projects, but other projects were very different from each other.Every time, when arriving at a new project, you had to carefully read the Ant setup to understand the custom build. Moreover, each project's structure was different. Some put their sources in src, some in sources, some in a nested structure, etc.I remember once a generic build file that tried accommodating the whole of an organization's project needs. It defined over 80 targets in over 2,000 lines of XML. It took me a non-trivial amount of time to understand how to use it with help and even more time to be able to tweak it without breaking projects.  My second build tool: MavenThe above project got me thinking a lot. I wanted to improve the situation as the maintainers had already pushed Ant's limits. At the time, I was working with my friend Freddy Mallet (of Sonar fame). We talked, and he pointed me to Maven. I had once built a project with Maven but had no other prior experience. I studied the documentation for hours, and through trial-and-error attempts, under the tutelage of Freddy, migrated the whole Ant build file to a simple parent POM.In Ant, you'd need to define everything in each project. For example, Ant requires configuring the Java files location for compilation; Maven assumes they are under src/main/java, though it's possible to override it. Maven did revolutionize the Java build field with its Convention over Configuration approach. Nowadays, lots of software offer sensible configuration by default.For developers who go from project to project, as I did, it means there's much less cognitive load when joining a new project. I expect Java sources to be located under src/main/java. Maven conventions continue beyond the project's structure. They also define the project's lifecycle, from compilation to uploading the artifact in a remote registry, via unit and integration testing.Finally, junior developers tend to be oblivious about it, but Maven defined the term dependency management. It introduced the idea of artifact registries, where one can download immutable dependencies from and push artifacts to. Before that time, each project had to store dependencies in its dedicated repository.For the record, there were a couple of stored dependencies on the abovementioned project. When I migrated from Ant to Maven, I had to find the exact dependency version. For most, it was straightforward, as it was in the filename or the JAR's manifest. One, however, had been updated with additional classes. So much for immutability.Maven had a profound influence on all later build tools: they defined themselves in reference to Maven.  No build tool of mine: GradleGradle's primary claim was to fix Maven's shortcomings, or at least what it perceived as such. While Maven is not exempt from reproach, Gradle assumed the most significant issue was its lack of flexibility. It's a surprising assumption because that was precisely what Maven improved over Ant. Maven projects have similar structures and use the same lifecycle: the principle of least surprise in effect. Conversely, Gradle allows customizing nearly every build aspect, including the lifecycle.Before going to confront the flexibility argument, let me acknowledge two great original Gradle features that Maven implemented afterward: the Gradle daemon and the Gradle wrapper.Maven and Gradle are both Java applications that run on the JVM. Starting a JVM is expensive in terms of time and resources. The benefit is that long-running JVM will optimize the JIT-ed code over time. For short-term tasks, the benefit is zero and even harmful if you take the JVM startup time into account. Gradle came up with the Gradle daemon. When you run Gradle, it will look for a running daemon. If not, it will start a new one. The command-line app will delegate everything to the daemon. As its name implies, the daemon doesn't stop when the command line has finished. The daemon leverages the benefits of the JVM.Chances are that your application will outlive your current build tools. What happens when you need to fix a bug five years from now, only to notice that the project's build tool isn't available online? The idea behind Gradle's wrapper is to keep the exact Gradle version along with the project and just enough code to download the full version over the Internet. As a side-effect, developers don't need to install Gradle locally; all use the same version, avoiding any discrepancy.  Debunking Gradle's flexibilityGradle brought the two above great features that Maven integrated, proving that competition is good. Despite this, I still find no benefit of Gradle.I'll try to push the emotional side away. At its beginning, Gradle marketing tried to put down Maven on every possible occasion, published crazy comparison charts, and generally was very aggressive in its communication. Let's say this phase lasted far more than would be acceptable for a young company trying to find its place in the market. You could say that Gradle was very Oedipian in its approach: trying to kill its Maven ""father"". Finally, after all those years, it seems it has wised up and now ""loves Maven"".Remember that before Maven took over, every Ant project was ad hoc. Maven did put an end to that. It brought law to the World Wild West of custom projects. You can disagree with the law, but it's the law anyway, and everybody needs to stand by it. Maven standards are so entrenched that even though it's possible to override some parameters, e.g., source location, nobody ever does it.I did experience two symptoms of Gradle's flexibility. I suspect far more exist.  Custom lifecycle phasesMaven manages integration testing in four phases, run in order:pre-integration-test: set up anything the tests needintegration-test: execute the testspost-integration-test: clean up the resources, if anyverify: act upon the results of the testsI never used the pre- and post-phases, as each test had a dedicated setup and teardown logic.On the other side, Gradle has no notion of integration tests whatsoever. Yet, Gradle fanboys will happily explain that you can add the phases you want. Indeed, Gradle allows lifecycle ""customization"": you can add as many extra phases into the regular lifecycle as you want.It's a mess, for each project will need to come up with both the number of phases required and their name: integration-test, integration-tests, integration-testing, it (for the lazy), etc. The options are endless.  The snowflake syndromeMaven treat every project as a regular standard project. And if you have specific needs, it's possible to write a plugin for that. Writing a Maven plugin is definitely not fun; hence, you only write one when it's necessary, not just because you have decided that the law doesn't apply to you.Gradle claims that lack of flexibility is an issue; hence, it wants to fix it. I stand by the opposite: lack of flexibility for my build tool is a feature, not a bug. Gradle makes it easy to hack the build. Hence, anybody who thinks their project is a special snowflake and deserves customization will happily do so. Reality check: it's rarely the case; when it is, it's for frameworks, not regular projects. Gradle proponents say that it still offers standards while allowing easy configuration. The heart of the matter is that it's not a standard if it can be changed at anybody's whim.Gradle is the de facto build tool for Android projects. In one of the companies I worked for, somebody wrote custom Groovy code in the Gradle build to run Sonar and send the metrics to the internal Sonar instance. There was no out-of-the-box Sonar plugin at the time, or I assume it didn't cut it. So far, so good.When another team created the company's second Android project, they copy-pasted the first project's structure and the build file. The intelligent thing to do would have been, at this time to make an internal Gradle plugin out of the Sonar-specific code. But they didn't do it because Gradle made it so easy to hack the build. And I, the Gradle-hater, took it upon myself to create the plugin. It could have been a better developer experience, to say the least. Lacking quality documentation and using an untyped language (Groovy), I used the console to print out the objects' structure to progress.  ConclusionCompetition is good, and Gradle has brought new ideas that Maven integrated, the wrapper and the daemon. However, Gradle is built on the premise that flexibility is good, while my experience has shown me the opposite. Ant was very flexible, and the cognitive load to go from one project to the next was high.We, developers, are human beings: we like to think our projects are different from others. Most of the time, they are not. Customization is only a way to satisfy our ego. Flexible build tools allow us to implement such customization, whether warranted or not.Irrelevant customizations bring no benefit and are easy to develop but expensive to maintain. If managing software assets is part of my responsibilities, I'll always choose stability over flexibility for my build tool.Originally published at A Java Geek on August 6th, 2023"
178,"In the dynamic landscape of software development, a transformative concept is gaining prominence: ""Egoless Programming."" Rooted in collaboration and humility, this approach transcends individual ego to prioritize collective success. This article delves into the tenets of egoless programming, its impact on project quality, and its role in cultivating a harmonious development environment. A fresh perspective that could steer developers toward more efficient and fulfilling horizons.Egoless programming,"" also known as ""programming without ego"" in French, is a concept in the field of computer programming that encourages developers to embrace a humble and collaborative approach when creating software. The fundamental idea behind egoless programming is for developers to set aside their ego, biases, and personal desires in order to work together constructively and produce high-quality code.The key principles of egoless programming include:Focus on Results, Not Individuals: Emphasis is placed on achieving project objectives rather than seeking personal credit or recognition. Programmers prioritize what's best for the software and its users, rather than their own glory.Embrace Constructive Criticism: Programmers should be open to feedback and suggestions from peers. They should be willing to challenge their own code and make improvements based on received feedback.Team Collaboration: Egoless programming promotes effective collaboration and communication among team members. Programmers should be ready to share knowledge and learn from others, rather than monopolizing expertise.Continuous Learning: Programmers acknowledge that there's always something new to learn and discover. They should be open to continuous learning and skill improvement.Minimize Code Ownership: Instead of clinging to specific code as if it were their exclusive creation, programmers should encourage code sharing and collective improvement.Egoless programming can contribute to code quality enhancement, reduce conflicts within the development team, and foster a more positive and collaborative work environment. Ultimately, the focus is on creating high-quality software rather than individual programmer ego."
179,"Sinatra is often seen as a tool for simple APIs, but it can also be used to manage big applications. dry-rb libraries can help you create a modular architecture with system wide dependency injection for your application.  Table of contents1. Introduction2. What do we do when our applications start to grow?3. How do we solve these problems? dry-system to the rescue4. Improving our Sinatra application5. Adding dry system and dry auto_inject gems as our dependency injection layer6. Adding database connections with ROM and our modular architecture7. Conclusion  IntroductionToday, among beginners with Ruby, it's common to think about two possible paths when developing an application; if you want a simple single-file API, just use Sinatra and for everything else, use Ruby on Rails. Well, in this article, allow me to provide a way to manage a big application using Sinatra as the HTTP library and dry-rb libraries as the glue to a modular architecture.Note: All the code produced on this article can be found at: https://github.com/cherryramatisdev/api-with-dry-ruby  What do we do when our applications start to grow?What do we do when an application with a single Ruby file starts to grow with more dependencies? For me personally, the answer is dependency injection. Basically, I start thinking about how I'll manage the configuration of all these new libraries and use them quickly on my routes, so it's trivial to split routes into services and controller classes in the future.OK, but how do we do that?The basic understanding of dependency injection can be seen from the following perspective:Consider this ""service"" class:class SomeService  def something_important    # doing something important here    'information'  endendEnter fullscreen modeExit fullscreen modeIf we want to inject this service, we can simply instantiate it in our constructor, for example, on a controller:require_relative 'services/some_services'class SomeController  def initialize    @service = SomeService.new  end  def index    response = @service.something_important    {result: response}.to_json  endendEnter fullscreen modeExit fullscreen modeBut what problem does this approach have? Well, this doesn't provide much complexity for a small-scale application, and it's pretty simple to keep all the components isolated and available, but we introduce some annoyances for medium to large-scale applications, such as:Not all providers have simple setups :: Some providers, like ORMs need more configuration, and this can be hard to maintain and make available through the application.Some providers depend on another provider :: It's quite hard to manage by hand when you want one provider for the database connection and another one for the repositories, and this happens a lot.Require hell :: On Ruby, we don't have the habit of importing all our libraries and internal code on every single file; frameworks such as Ruby on Rails provide auto-require for files with business logic, and when you roll an application by hand, it's hard to develop without this feature.  How do we solve these problems? dry system to the rescueWe'll assume a simple Sinatra application and evolve from that by adding dry-system to manage our dependencies; later on, we'll even add a persistence layer using a gem called rom-rb to increase the functionality for a more realistic API example.  A simple Sinatra applicationSinatra is a lightweight library that's quite simple to set up, but let's start with a more structured project, shall we?DISCLAIMER: This part assumes basic knowledge about ruby language and the sinatra library.  Start a bundle projectmkdir myproject && cd myproject && bundle initEnter fullscreen modeExit fullscreen mode  Add our gemsbundle add sinatra pumaEnter fullscreen modeExit fullscreen mode  Create a router class to encapsulate our executionLocated at config/router.rbrequire 'sinatra/base'class Router < Sinatra::Base  get '/' do    {message: 'Hello world'}.to_json  endendEnter fullscreen modeExit fullscreen modeAdd a config.ru to serve as the entry point for our applicationLocated at config.ru on the project rootrequire_relative 'config/router'Router.run!Enter fullscreen modeExit fullscreen modeWith this initial setup, we should be able to run the application with bundle exec puma and see a JSON as the response.  Improving our Sinatra applicationTo make it easier for us to visualize the benefit of dependency injection, let's add some structure to this simple route by creating two simple abstractions: controller and service.First, we'll create a service located at lib/service/user.rb with the following content:module Services  class User    def index      'teste'    end  endendEnter fullscreen modeExit fullscreen modeThen let's create a sample controller located at lib/controllers/user.rb with the following content:require_relative 'lib/services/user'module Controllers  class User    def initialize      @service = Services::User.new    end    def index      {message: @service.index}.to_json    end  endendEnter fullscreen modeExit fullscreen modeAs you can see, we're already instantiating the service the old way, so we can compare by adding dry-system to it!To wrap up, just update the content of config/router.rb file:require 'sinatra/base'require_relative 'lib/controllers/user'class Router < Sinatra::Base  get '/' do    Controllers::User.new.index  endendEnter fullscreen modeExit fullscreen modeSimple right? Now everything should work fine, but we won't stop there, so let's start integrating dry-system into it and seeing the benefits.  Adding dry system and dry auto inject gems as our dependency injection layer  Adding our gemsbundle add dry-system dry-auto_inject zeitwerkEnter fullscreen modeExit fullscreen mode  Making our application REPL workA REPL (Read-Eval-Print Loop) is a very important tool for Ruby developers. Both the Rails and Hanami frameworks provide one, so we'll set up a simple REPL for our application. This will allow us to further integrate the dependency injection layer, which will make our code more modular and easier to test.To do this, we'll create a file called config/boot.rb and add the following code:ENV['APP_ENV'] ||= 'development'require 'bundler'Bundler.setup(:default, ENV.fetch('APP_ENV', nil))Enter fullscreen modeExit fullscreen modeAfter that create a script file under bin/console with the following content:#!/usr/bin/env rubyrequire 'irb'IRB.startEnter fullscreen modeExit fullscreen modeTo make it executable you can run chmod +x ./bin/consoleNow we should have a working REPL for the application!  Creating our main containerThis container will be used to register all the other components of our applicationCreate a file under config/application.rb with the following:require 'dry/system'class Application < Dry::System::Container  configure do |config|    config.root = Pathname('.')    config.component_dirs.loader = Dry::System::Loader::Autoloading    config.component_dirs.add 'lib'    config.component_dirs.add 'config'  endendloader = Zeitwerk::Loader.newloader.push_dir(Application.config.root.join('lib').realpath)loader.push_dir(Application.config.root.join('config').realpath)loader.setupEnter fullscreen modeExit fullscreen modeYou can see with this code that we're already solving one of the problems; the component_dirs.add method and the Zeitwerk instance will automatically require all our code inside the lib and config folders.Note: The zeitwerk gem is doing the lazy loading for us.Let's include this in our entry points to make it work right away.On the config.ru and on the bin/console we'll add the following:require_relative 'config/application'Application.finalize!Enter fullscreen modeExit fullscreen modeThe finalize! method makes the Application instance variable available for the whole application and lazy-loads our files under the lib and config folders.Tip: You can and it's encouraged to remove the require_relative from your controller and router fileNow you can run bin/console and check the application instance by typing Application on the REPL.  Adding a sample service as a providerNow that we have our main container, it's just a matter of registering providers to it, just like the following:Create a file located at config/providers/services.rb with the following content:Application.register_provider(:services) do  start do    register('services.user', Services::User.new)  endendEnter fullscreen modeExit fullscreen modeAnd after creating this provider, we'll load it on our entry point files; these are the only places where we'll require files.On config.ru:require_relative 'config/providers/services'Enter fullscreen modeExit fullscreen modeAnd on bin/console:require_relative '../config/providers/services'Enter fullscreen modeExit fullscreen mode  Enjoying the benefits of our workGoing back to our controller class, we can rewrite it like this:module Controllers  class User    def initialize      @service = Application['services.user']    end    def index      {message: @service.index}.to_json    end  endEnter fullscreen modeExit fullscreen modeSee how the controller class doesn't know anything about which class it's getting from Application['services.user']? This is so cool because if you want to change your service completely, you can simply change the class instantiation on the provider file.This initial purpose already works for us, right? But we'll keep going further.  Adding database connections with ROM and our modular architectureNow that we have a basic understanding of how dry-system works to modularize our application, let's add a database layer using this knowledge while levering rom-rb with it.  Adding our gemsbundle add rom rom-repository rom-sql pgEnter fullscreen modeExit fullscreen mode  Registering a database connection as a provider for our systemSince we're already using dry-system up to this point, let's work with it by adding the database connection as a provider:Create a file located at config/providers/db.rb with the following contentDisclaimer: This assumes you're running a PostgreSQL database.Application.register_provider(:db) do  prepare do    require 'rom'    require 'rom-sql'  end  start do    connection = Sequel.connect('postgres://postgres:postgres@localhost:5432/example_database', extensions: %i[pg_timestamptz])    register('db.connection', connection)    register('db.config', ROM::Configuration.new(:sql, connection))  endendEnter fullscreen modeExit fullscreen modeAs you can see, the register_provider method provides a simple DSL that we can use to isolate our whole setup by requiring the correct libraries on prepare and then instantiating or registering the objects on start.  Adding support for migration commandsNow that we have our base connection done, let's create a Rakefile on the root of our project with the following content:require 'rom-sql'require 'rom/sql/rake_task'require_relative 'config/boot'require_relative 'config/application'require_relative 'config/providers/db'namespace :db do  task :setup do    Application.start(:db)    config = Application['db.config']    config.gateways[:default].use_logger(Logger.new($stdout))  endendEnter fullscreen modeExit fullscreen modeAs you can see, we can use the start method as an alternative to the finalize! that injects all our providers. That way, we only enable the database layer through the :db symbol. This allows us to inject on the :setup task.Now we should be able to run the following command:rake ""db:create_migration[create_users]""Enter fullscreen modeExit fullscreen modeThis should create a file located at db/migrate/3128932189_create_users.rb, on this file, we can complement the following DSL to create a sample table for our application:ROM::SQL.migration do  change do    create_table :users do      primary_key :id      column :name, String      column :email, String    end  endendEnter fullscreen modeExit fullscreen modeAnd finally, by running the following command, we can persist this migration on the Postgres database:rake db:migrateEnter fullscreen modeExit fullscreen mode  Defining our relations and repositoriesIn the rom-rb gem, we define our main classes as relations and repositories. Relations mimic the structure of our Postgres table, while repositories define our actions on that relation.First, we'll define a relation to represent the new table we created. To do this, we'll create a file called lib/relations/users.rb and add the following code:module Relations  class Users < ROM::Relation[:sql]    schema(:users) do      attribute :id, Types::Integer      attribute :name, Types::String      attribute :email, Types::String      primary_key :id    end  endendEnter fullscreen modeExit fullscreen modeHere we're using the simple DSL provided by ROM::Relation class to mimic our migration with the correct types for each attribute.Now for the repository, we can create a file at lib/repos/user.rb with the following content:require 'rom-repository'module Repos  class User < ROM::Repository[:users]    commands :create    # @param limit Integer    def all(limit = 10)      users.limit(limit).to_a    end  endendEnter fullscreen modeExit fullscreen modeRepositories on ROM have sample commands for common actions, such as creating, updating, and deleting records. However, for more complex queries, we need to write our own methods. In this case, I have provided a simple all method that returns all the users, limited to a certain number.  Making our code available through the codebaseSince we defined two new components for our applications, we'll create two new providers on the system.First, let's create a provider at config/providers/persistence.rb with the following content:Application.register_provider(:persistence) do  start do    target.start :db    config = target['db.config']    config.register_relation(Relations::Users)    register('container', ROM.container(config))  endendEnter fullscreen modeExit fullscreen modeSimilar to our Rakefile we're using the start method to make the db provider available when we're instantiating our relation class.Then let's create another provider at config/providers/repos.rb with the following content:Application.register_provider(:repos) do  start do    target.start :persistence    register('repos.user', Repos::User.new(target['container']))  endendEnter fullscreen modeExit fullscreen modeSee how we start the persistence provider we defined previously ? We don't need to start the db provider because dry-system will go to the persistence provider and start there, so we can have as many co-dependent providers as we want.Since we added new providers, we'll update our entry points files as usual:At config.ru:require_relative 'config/providers/persistence'require_relative 'config/providers/repos'Enter fullscreen modeExit fullscreen modeAnd at bin/console:require_relative '../config/providers/persistence'require_relative '../config/providers/repos'Enter fullscreen modeExit fullscreen mode  Refactor time, shall we?Now that we've defined our required providers, it's just a matter of using them on the layer we want; this layer will be the service class for us.On the service class at lib/services/user.rb, we'll rewrite to use the repository:module Services  class User    def initialize      @repo = Application['repos.user']    end    def list_all      users = @repo.all      users.map do |user|        { id: user.id, name: user.name, email: user.email }      end.to_json    end  endendEnter fullscreen modeExit fullscreen modeThe refactor is done! Pretty easy, right? Our route should now use the database to provide a list of users.  ConclusionI hope this article is useful for anyone who ends up reading it. I tried to demonstrate how easy it is to decouple application parts and manage them, even when each part requires complex setups.Furthermore, I'm always available to help with any doubt or just to chat about cool Ruby stuff. May the force be with you!"
180,"Sometimes, coders feel hesitant to ask questions they perceive as basic. Share a time when you overcame this hesitation and asked a question that turned out to be valuable to your learning process.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
181,"August 2023 check-in — what is different in your approach in the ChatGPT, Copilot, etc. era of development?If not much has changed, speak to that."
182,"If you're a JavaScript or TypeScript developer, you've likely noticed the skyrocketing interest in building AI applications, especially since the launch of ChatGPT in November 2022. With AI on the rise, many are exploring new and creative ways to integrate models into applications, chatbots, and agents. But here's a common roadblock: there are few libraries designed specifically for JS/TS developers that ease working with AI models, including LLMs (Large Language Models).Maybe you've experienced this yourself, as I did: You start with something like LangChain, build your first app, and feel a sense of accomplishment. But then, you hit a wall as you realize it's not easily adjustable to your unique needs. You might then resort to using OpenAI or other APIs directly, only to end up rolling your own framework. It's a path filled with complexity and unnecessary hassle.That's why I created ModelFusion. I went through this exact process and recognized the need for a solution that provides many reusable elements and unification across models without being too constraining. Unlike other tools that may feel like ""black magic,"" ModelFusion is designed as a library, not a framework. Think of it as a toolbox that empowers you with full power and control over the underlying models, adding support features with minimal overhead.  Quick ExampleHere's a simple example demonstrating how you might use ModelFusion to generate text with OpenAI:const text = await generateText(  new OpenAITextGenerationModel({ model: ""text-davinci-003"" }),  ""Write a short story about a robot learning to love:\n\n"");Enter fullscreen modeExit fullscreen modeThe response also contains additional information such as the metadata and the full response. The ModelFusion documentation contains many examples and demo apps.  Key FeaturesHere are the features that make ModelFusion stand out:Type Inference and Validation: Leveraging TypeScript and Zod, ModelFusion ensures that you get exactly what you expect from your models. No more guesswork, only clear and validated responses.Flexibility and Control: You're in charge of your prompts, settings, and raw model responses. Adjust and adapt without feeling boxed in by the framework.No Chains and Predefined Prompts: Start from examples and build applications using familiar JavaScript concepts. Clear and explicit, without any confusing black magic.Support for different AI Models: Go beyond text with integrations like text-to-image and voice-to-text. ModelFusion supports a variety of models to suit your creative vision.Integrated Support Features: Focus on your application with essential features like logging, retries, throttling, tracing, and error handling built right in.ModelFusion integrates with a diverse range of model providers, vector indices, and observability tools, such as OpenAI, Llama.cpp, Pinecone, and Helicone. This growing list of integrations offers you, the JS/TS developer, a flexible and adaptable toolbox to suit your unique needs, without any unnecessary complexity.  Getting StartedHere's what you need to kickstart your journey with ModelFusion:Explore the Code: Visit the ModelFusion GitHub repository to take a closer look at the source code, contribute, or even raise an issue if you encounter any challenges.Read the Docs: If you want to dive deep into the functionalities, the ModelFusion documentation is packed with examples, demo apps, and tutorials that will guide you through various use cases and integrations.Join the Community: Have any questions or need help? Don't hesitate to engage with other like-minded developers in the ModelFusion Discord. We're here to support each other.If you're working with AI models in JavaScript or TypeScript, explore ModelFusion; your feedback and participation can shape this toolkit to better serve the developer community."
183,"We're going back to coding school with Nostalgia Bytes this week! Don't forget your TI calculators, Trapper Keepers, Lisa Frank folders, and USB drives. Each decade has its own story to tell. So get ready to relive the past and share your nostalgic memories with fellow developers!📚 Back to School Memories: What's the funniest coding-related incident you recall from your early days as a developer?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
184,"If the debuggers captured a candid shot of you coding, what quirky behavior, habit, or unusual thing would they discover?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
185,"  What is Database Indexing?Database indexing is a technique that makes searching and retrieving data from a database faster. It is like creating a quick guide for finding information in a large book. It helps speed up searches and makes finding things easier.Indexing speeds up  SELECT queries and  WHERE clauses. On the other hand slows down INSERT and  UPDATE queries.Fig: Database Index Data Structure  Why Indexing?Imagine you have a database of books, and you want to find all the books that have the word ""programming"" in the title. Without an index, the database would have to scan every row in the table to find the books that match the search criteria. This could take a long time, especially if there are a lot of books in the table.However, if you create an index on the title column, the database can quickly find the rows that match the search criteria. The index is a separate data structure that stores the values of the title column in sorted order. The database can use the index to quickly find the rows that contain the word ""programming"" in the title.  Indexing A Table With 50 Million RowsFor this example, we will create a database pg-million in PostgreSQL containing table customers with columns: first_name, last_name, mobile_no, country.  Insert 50 million rows of random dataCREATE TABLE customers(first_name VARCHAR(50), last_name VARCHAR(50), mobile_no INTEGER, country VARCHAR(50))INSERT INTO customers (first_name, last_name, mobile_no, country)SELECT substr(md5(random()::text), 1, 10),       substr(md5(random()::text), 1, 10),       (random() * 70 + 10)::integer,       (CASE WHEN random() < 0.5 THEN 'India' ELSE 'United Kingdom' END)FROM generate_series(1, 50000000);Enter fullscreen modeExit fullscreen mode  Create an index on country columnWe create an index on country column to have a well-organized list that lets us quickly locate all the customers from a particular country without searching through the entire list.CREATE INDEX idx_partial_country ON customers (country) WHERE country IN ('India', 'United Kingdom')Enter fullscreen modeExit fullscreen modeTime to create index: 2m 2sFor this example, we are using partial indexes. A partial index is created based on a condition that filters rows for specific values. This allows the database to index and optimize only the relevant rows, reducing the index size and improving query performance for those specific values.Note: The syntax for creating indexes and types of indexes differs among different databases. You should use appropriate syntax and index type depending on your database and use-case.   Measuring Query Execution Time Before and After IndexingConsider the following querySELECT * FROM customers WHERE country='United Kingdom';Enter fullscreen modeExit fullscreen modeQuery Execution Time without index: 41836.270 msQuery Execution Time with index: 24254.644 msImprovement in query execution time ~42.03%(For better understanding you can find all the code here  How Well Are The Indexes Performing?It is important to gain insights into index effectiveness. A few helpful metrics include:Index Usage Statistics: Monitor the usage of indexes to understand which indexes are actively contributing to query performance. (Ex: Track the size of indexes, as larger indexes may impact disk space and I/O performance)Query Performance Metrics: Monitor query execution times and response times for queries that involve indexed columns. (Ex: A sudden increase in query execution time may indicate index-related issues.)Index Maintenance Metrics: Regularly assess the health of indexes and their impact on database operations. (Ex: Track index bloat, which occurs when indexes become inefficient due to excessive insertions, updates, or deletions.)  When To Use Indexing?Frequent Search Queries: Use indexing when you frequently search for specific data in a large dataset. It helps to find the desired information quickly.Performance Improvement: Indexing can improve the speed of data retrieval operations, especially for complex queries, by avoiding scanning the entire dataset.Large Data Volumes: Indexing is used when dealing with sizable amounts of data, as it helps maintain efficient query performance even as the dataset grows.  When To Not Use Indexing?Frequent Write Operations: Avoid excessive indexing if your database experiences frequent insert, update, or delete operations, as indexes can slow down these write operations and consume additional storage space. Indexes should not be used on the columns that are frequently manipulated.Small Datasets: For relatively small datasets, indexing may not provide significant performance gains and can introduce unnecessary overhead. In such cases, the benefits may not outweigh the costs.  ConclusionIf you are looking for ways to improve the performance of your database, then database indexing is a good place to start. By creating indexes on the columns that are frequently used in queries, you can significantly improve the performance of your database and make your queries faster. However, it is important to weigh the benefits and drawbacks of indexing before making a decision.If you like what you read, consider subscribing to my newsletter.Find me on GitHub, Twitter"
186,"This week we're chatting all things remote work, and we want to hear from you about your experiences, pros, cons, and advice for those transitioning or considering remote work options.Let's dive into today's topic of conversation... Remote work can present communication challenges. How do you ensure effective collaboration and avoid misunderstandings? Share your tips for clear and concise communication across remote teams.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
187,"One of my favorite interview prompts is, ""In as much detail as you can, tell me what happens when you hit enter after typing a domain in the URL bar?""This seemingly basic question is a litmus test. It reveals the depth and breadth of a candidate's understanding of our digital ecosystem. From DNS lookups to the TLS handshake, from CDN optimizations to browser rendering - this prompt touches multiple domains (pun intended) of web technology.It's a probe into the unseen layers beneath our digital interactions. It allows the candidate to dive as deep as they want in areas they understand and skim over others that remain, to them, opaque. But more importantly, it sparks a conversation about something in which we (hopefully) both have an interest.  The Gap in Our MagicIt's always intriguing, and sometimes a bit alarming, to witness seasoned developers stumble over this question. They find themselves on uncertain ground, hesitating as they try to piece together the puzzle. They might wonder, ""What exactly does the interviewer want to hear?""Developers have been hard at work, crafting tons of code, meticulously refining solutions, and making sure that systems scale seamlessly. However, there seems to be a mysterious oversight. Their expertise has burrowed so profoundly into a single domain, they unintentionally overlook the multitude of other cogs in the machine that transform an ordinary URL into a beautifully rendered webpage.So, why is there such a chasm? Why do so many overlook the magic happening outside their specialized sandbox?  The Pitfalls of Not KnowingOur industry has become increasingly complex. And with complexity comes the need for compartmentalization, especially as organizations scale. Developers often rely on other departments, third-party tools, automated processes, or platforms to handle tasks outside their core expertise. This reliance breeds a certain level of ignorance.But there are dangers in not understanding the broader landscape:Performance Woes: When developers lack insight into how the entire system interacts, it can lead to unexpected performance bottlenecks. Understanding the journey from server to browser can lead to more informed decisions about optimization.Security Gaps: Every interaction, from the DNS lookup to the TLS handshake, can be a potential vulnerability. Not understanding these processes can inadvertently expose applications to threats.Integration Challenges: A developer who understands only their piece of the puzzle might struggle when trying to integrate their work into a larger system or when collaborating with other teams.  Bridging the Knowledge GapWhile it's unrealistic to expect every developer to become an expert in every facet of technology, there's a middle ground. Developers can strive to:Educate Themselves Broadly: Taking the time to understand the basics of areas outside one's specialty can be immensely beneficial. This doesn't mean becoming an expert but rather gaining a holistic view of the system.Engage in Cross-functional Collaboration: Actively seeking input from colleagues in different roles can provide fresh insights and uncover potential challenges before they escalate.Continuously Learn: The tech world is ever-evolving. Regularly revisiting foundational concepts and updating knowledge ensures that a developer doesn't get left behind.  Wrapping UpOur technological world thrives on a balance of specialization and holistic understanding. As developers, while it's essential to deep-dive into specific areas, it's equally crucial to surface now and then, to see the bigger picture. The true magic isn't just in the code we write or the systems we design, but in understanding the interconnection that brings a digital idea to life.Embrace that magic, and you'll find yourself better equipped to navigate the multifaceted universe behind every press of the ""Enter"" key."
188,"As tech workers, we sit down quite a bit during the day. I have a standing desk that helps me stretch out a bit or lets me dance for a while (yes, desk dancing is a thing if you weren't aware), but we need to move more.I'm generally active. I work out Monday, Wednesday, and Friday, along with a long daily walk, and do other seasonal activities.If you don't get up to much and are curious about a fitness regime, you may want to come to hang out with Anna Nettles and me tomorrow. Even if you're already pretty active, you may also enjoy it.I'm super excited to do a live stream with her where she will put me through a fantastic workout. Anna is a certified personal trainer, so I know I'll be in good hands. Come work out with us if you're up for it from the comfort of your home or wherever you're tuning in.Aside from pumping some iron, she'll answer personal fitness questions while I'm sweating away, and we will also discuss her journey into tech. Anna is a career transitioner who landed her first job in tech recently! It's a tough job market out there right now, especially for early career devs, so I'm excited to hear about Anna's job search and what she did to land her first gig.It should be fun, and you all get to see me ugly sweat on Twitch, lol.Come hang with us tomorrow, Wednesday, August 9th, at 5 pm UTC!Update August 9, 2023: Here's some highlights from the stream!P.S.: Yes I tagged this post with #healthydebate (channeling my inner dad jokes)P.P.S.: I'd love to hear what you get up to to stay active! Drop a comment with what you get up to!Photo by Heidi Erickson on Unsplash"
189,"This week we're chatting all things remote work, and we want to hear from you about your experiences, pros, cons, and advice for those transitioning or considering remote work options.Let's dive into today's topic of conversation... How do you maintain a sense of camaraderie and social interaction with colleagues while working remotely? Share creative ways you've connected with team members outside of work-related discussions and/or any virtual team-building activities that have helped strengthen team bonds.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
190,"The world of software engineering influencers, what I typically like to refer to as “tech-fluencers”, has grown significantly in the last few years. There are people who have built entire personal brands and businesses solely on the basis of their online tech content. And many massive technology companies now participate in the same spheres that 5 years ago would have been unheard of (just think about all the memes major tech companies have created in the last few years).And with the rise of platforms that promote short form video content, like TikTok and YouTube shorts, it’s now easier then ever to build branding and create a catalog of niche content designed to fulfill a void somewhere out there on the internet.But I’ve seen a big problem with all of this.We often see others with significant reach in online tech spaces and assume that the only way to achieve that kind of corporate success, financial well-being, confidence, seniority status, or whatever else their persona amplifies, is to emulate them and make content to also achieve that reach, success, and influence in the industry.From my first hand experience, this is simply not true.Years ago, I fell into the mental trap of creating tech content online: partly out of boerdum during the pandemic and partly because I was looking for new ways to level up my career. I thought that creating content online, like I saw so many other people doing, would be an accelerator for me. I started a TikTok account. During it’s heyday, the account reached over 140 thousands followers. This lead to a YouTube channel, a Twitch stream, daily content generation, and much more.And honestly, after hundreds and hundreds of videos, none of it really sticks out as actually being significant to my career. After all, most of it was fluff and memes without alot of sustenance.This is the trap of content creation that is all too tantalizing: maybe start with pure intent but eventually find yourself feeding the algorithms a never ending stream of content for the hopes of achieving some amorphous goal that has bastardized into something you don’t recognize anymore.I eventually took a big step back from the content creator grind and ultimately felt pretty disappointed in what seemed like a huge wasted effort.I think Will Larson sums this all up incredibly well in his piece “How to be a tech influencer”. He says:Most successful people are not well-known online. If you participate frequently within social media, it’s easy to get sucked into the reality distortion field it creates. Being well-known in an online community feels equivalent to professional credibility when you’re spending a lot of time in that community. My experience is that very few of the most successful folks I know are well-known online, and many of the most successful folks I know don’t create content online at all.Instead, there is an alternative approach: prestige.Building a long term, successful tech career is not about having large followings in online tech spaces or massive engagement on content. Chasing those metrics will only lead you down that road of churning out content for the sake of staying relevant in whatever algorithm you’re participating in.No, one of the many puzzle pieces in building a fruitful tech career involves building prestige.Prestige is the “idea” of someone and is based on the respect for the things achieved, battles won, and quality of their character.When I was at AWS, I could tell who the prestigious engineers were based on the way other people talked about them, how others approached that person’s code, and how that person could command a room. Prestige is easy to see, difficult to measure, and illusive to obtain.Don’t be mistaken: you may read that and assume prestige and fear are close neighbors. But prestige is not about control, making others do what you want, or power. Prestige on one hand is about gaining other’s respect. But on the other, it’s about having self respect, owning your mistakes, being humble, kindness, and above all, keeping yourself accountable to the high bar of quality and character that you hold for yourself.Measuring your prestige is much more difficult than tracking your influence. It’s easy to see the number of followers on your online accounts go up, but tracking the respect and repute people have for you is a whole different challenge.This can make attempting to generate prestige difficult. How can I drum up respect and prestige for myself across the industry if I can’t really measure it effectively?Ironically, generating prestige with online content can be a very successful way to go about amplifying your existing reputation. Experimenting with different forms of content and distribution models is important, but I want to stress that creating content to amplify your prestige should not be the same as content creation (at least in the typical, 2023 sense). You should not fall prey to the temptations of algorithms designed to steal your attention and sap your creative energy. You should simply use them as a tool of distribution if necessary.But more importantly, the quality of your content matters significantly more than the quantity. Typical social media influence dictates that you must post on a regular schedule. But for the engineering leader looking to grow their prestige, one or two extremely high quality pieces go a very very long way. It’s not necessary that you always be chugging out content since relevance in typical social media algorithms should not be your end goal.So, how do you actually go about building prestige? Here are my 5 approaches to growing your prestige within your engineering organization and online:  1. InventYou should be finding ways to solve big technical problems that have increasing impact and that grow your status within the engineering org.This should really be the prerequisite to building any sort of prestige. But it may not be obvious to all: it can be easy to get stuck in a loop of finishing tickets and completing all your tasks during a sprint without expanding into more challenging territories.But if you’re not finding technical problems to solve that require innovation, expertise, and abit of the inventors mindset, you’ll eventually hit a career ceiling.It is possible to build prestige without inventing. You can get pretty good at taking credit for others work or faking it till you make it. But eventually, this catches up with you and you reach a point where your persona is hollow and it’s clear the achievements where your reputation is build upon can’t be trusted or respected.Inventing, building, and solving increasingly challenging technical problems is the backbone of building any kind of technical prestige.  2. NewslettersInternal newsletters to your organization are a great way to communicate what you’re doing, what you’ve invented, and brag abit about some of your technical achievements.For some, this may seem too out of reach. Aren’t these types of newsletters within my company only for VPs and engineering leaders?Not necessarily. An opt-in type newsletter is the best place to start (i.e. don’t start a newsletter and send it to everyone in the company). Your manager and other teammates will likely want to opt in. After all, why wouldn’t they want a regular email of what you’ve been working on, things that interest you, and pieces of work you’re particularly proud of that week?Newsletters are also a great habit to be in since they force you to quantify and qualify your work on a regular cadence which can then be translated latter into talks, deep dives, promotion documents, or other content that you can share with your org or the wider world.Some people take this to the next level and publish a public newsletter. This can be a really cool avenue for those working “in public” and can be a great way to start connecting with other technical leaders out in the industry.  3. TalksTechnical talks come in many different shapes and sizes. I would consider a “talk” to be anythying from showing something off during your team weekly demos all the way up to international keynotes at large conferences.The different ends of that spectrum obviously have different levels of reach and impact, but both help to establish you as a subject area expert in that thing you’re talking about. It’s an automatic way to gain some prestige about the topic and it’ll likely open you up to connecting with others in the audience that may lead to further opportunities (as the wheels of prestige go round)!  4. Deep divesTechnical deep dives also come in many shapes and forms. It may be a written piece (like this!), a video, a seminar, or really anything that can deeply communicate a technical topic.Deep dives are great for generating some prestige since they can be easily referenced latter. They sort of end up being a time machine for you to use and recycle in powerful ways. I’ve seen people take deep dives and turn them into conference talks, business pitches, and even entire products!But they are ultimately useful for establishing your expertise and prowess in a given technical matter.  5. Get others to talk about itThe most powerful, and maybe most difficult avenue to building prestige, is to get other people to talk about you and your work. At this point, the wheels of prestige are fully turning and they will move on their own for a fair amount of time.Having a wealth of talks, deep dives, and newsletters ensures that other people (like your boss or your co-workers) have something to talk about.And remember, prestige holds you to the highest bar of quality. So at this point, regardless of how many years it’s been, you can be assured that if people are talking about you, discussing a talk you gave, or chatting about something you’ve achieved, you know that it’s something that you can be proud of and respect yourself for.Prestige is an incredible tool to build within your engineering organization and out in public. It should be a good approach for anyone looking to really leveling up their career. And in my experience, it’s a much preferred method to the typical “tech-fluencers” content grind."
191,"Yes, let’s talk a little about being agile and the Brazilian definition of the current state agile generated called “eXtreme Go Horse” methodology.  The misconceptionsThe first thing is to get the common misconceptions out of the way.  Agile is going fastBy now, we all (should) know that agile is not about being faster. It’s about delivering value sooner and in a constant manner and being able to react and change course earlier.  Sprint is doing all in the time slotSo… you’re saying agile is not about being fast, but that it also means having… sprints?It might have been an unfortunate term used by the developers of Scrum, but it certainly doesn’t help with all the “agile is being fast” people like to think.Sprints, however, are just a time box for a certain amount of work to be done.  The problemExecutives push for agile and scrum because they think about being fast, sprints!But the biggest problem is that making software is not a sprint, it’s a marathon.And unless you’re not human, you know that you can’t sprint a marathon. It’s a really bad idea.Hell! Most people can’t even sprint a short race. And I’m also talking about software.  The people resultBurnout. Plain and simple, the profession loses a lot of good people because of burnout.Not to be confused with “burndown” (charts), also from scrum, but somehow that doesn't generate any confusion from the same people expecting more and more from developers.At one point companies had too many developers, many doing basically bloatware features and “not generating enough value”. Then the mass layoffs came and went (or are still going) and now you have developers even more overworked.  The software resultBecause people are pressured into going fast and then faster yet, quality drops, and “quick and dirty” becomes the norm.There’s no time for testing, there’s no time for code quality, or clean code and good practices, but there’s always time and overtime for fixing bugs.  Deliver software not fast, but with consistencyThe first thing people see in new frameworks is how fast they can make a “todo app”… but that’s not the reality for most of us.Go Horsing quick and dirty to make a big bowl of muddy pasta is ok for an MVP, side project, or throw-away project. But most time you’ll be working for months on end on something.What matters making one thing fast and then slowing down on each new feature until you jump ship (XGH axiom 8) or decide to rewrite the whole thing (see XGH axiom 10).  XGH: eXtreme Go HorseGo Horse Process logo: a badly drawn horse head inside a circle.As I was writing this post it came to my attention that XGH is commonly known only by Brazilian devs, but not enough around the world.This was made by who knows when, by who knows who, it’s a little outdated in the writing (I’ll refactor as needed), but as you’ll see… it’s timeless (see axiom 14) and relevant to what I was saying.Disclaimer: This is, basically, a “not to do” list. It’s funny as a meme, but as I like to say: if all you do are things from memes… then your life is a joke.There were some translations out there, but I translated them here trying to update things to make more sense today.Enjoy but don’t follow it. (little note: people usually just read XGH as “go horse”)  eXtreme “Go Horse” Manifesto:  1. If you had to think, it’s not XGH.in XGH you don’t think, you do the first thing that comes to mind. There’s no second option, the only option is the fastest one.  2. There are 3 ways of solving a problem: the right, the wrong, and the XGH, which is like the wrong one, but faster.XGH is faster than any other methodology of software development you know. (see axiom 14).  3. The more XGH you do, the more you’ll need to do.For each problem solved using XGH, about 7 more will be created. But all of them will be solved using XGH. XGH tends to infinity.   4. XGH is completely reactive.Errors only exist when they surface.  5. XGH accepts everything.Solved the problem? Compiled? Commit and that’s it.  6. Always commit before updating.If shit happens, your part will always be correct... and your colleagues can go fuck themselves.  7. XGH has no deadline.The deadlines set by your client are mere details. You will ALWAYS be able to implement EVERYTHING in the given time (even if it involves accessing the database with a shady script).  8. Be prepared to jump ship when it starts to sink... or blame someone or something else.For those who use XGH, one day the ship will sink. The more time passes, the more the system becomes a monster. The day the house falls, it's better to have your LinkedIn updated or have something to blame.  9. Be authentic, XGH does not respect standards.Write the code however you want, if it solves the problem, commit and that's it.  10. There is no refactoring, only rework.If shit happens, redo a quick XGH that solves the problem. The day that the rework involves rewriting the entire application, jump ship, the boat will sink (see axiom 8).  11. XGH is completely anarchic.The figure of a project manager is completely disposable. There is no owner, everyone does what they want when problems and requirements arise (see axiom 4).  12. Always delude yourself with promises of improvement.Putting TODO in the code as a promise of improvement helps the XGH developer not feel remorse or guilt for the shit they made. Of course, refactoring will never be done (see axiom 10).  13. XGH is absolute, it does not cling to relative things.Time and cost are absolute, quality is totally relative. Never think about quality, only about the shortest time the solution can be implemented, in fact... don't think, just do it!  14. XGH is timeless.Scrum, XP... all of that is just a fad. XGH does not cling to the fads of the moment, that's for the weak. XGH has always been and will always be used by those who disregard quality.  15. XGH is not always Workaround-Oriented Programming.Many Workaround-Oriented Programmings require a very high level of thinking, but XGH does not think (see axiom 1).Translator Note: In the original, it uses Gambiarra Oriented Programming. Since I understand some people will know what gambiarra is… it’s a more encompassing term than just “hack” or “workaround”.  16. Don't try to swim against the tide.If your colleagues use XGH for programming and you are a stickler who likes to do things properly, forget it! For each Design Pattern you use correctly, your colleagues will generate 10 times more rotten code using XGH.  17. XGH is not dangerous until a little order arises.This axiom is very complex, but assumes that the project using XGH is in the midst of chaos. Don't try to add order into XGH (see axiom 16), it's useless and you can waste precious time. This will make the project sink even faster (see axiom 8). Don't try to manage XGH, it is self-sufficient (see axiom 11), just like the chaos.  18. XGH is your ally, but it is vengeful.As long as you want, XGH will always be on your side. But be careful, don't abandon it. If you start a system using XGH and abandon it to use a trendy methodology, you're fucked. XGH does not allow refactoring (see axiom 10), and your new system full of frills will collapse. And at that time, only XGH can save you.  19. If it's working, don't touch it.Never change, let alone question, working code. That's a waste of time, especially since refactoring doesn't exist (see axiom 10). Time is the gear that moves XGH and quality is a negligible detail.  20. Testing is for the weak.If you've put your hands on an XGH system, you better know what you're doing. And if you know what you're doing, why test? Testing is a waste of time, if the code compiles, that's enough.  21. Get used to the feeling of imminent failure.Failure and success always go hand in hand, and in XGH it's no different. People often think that the chances of a project failing using XGH are always greater than it being successful. But success and failure are a matter of perspective. Did the project go down the drain but you learned something? Then it was a success for you!  22. The problem is only yours when your name is in the git blame.Never put your hand on a file whose author is not you. If a team member dies or is sick for a long time, the boat will sink! In this case, use axiom 8.  23. More is more.With XGH, you thrive on code duplication - code quality doesn't matter, and there's no time for abstractions, code reviews, or refactoring. Time is essential, so copy and paste quickly!  24. The code is the documentation.In XGH, the code is the only documentation needed. Comments and additional documentation are just a waste of time. If someone can’t figure out how the code works, they shouldn’t be working on it (see axiom 20).  25. Security doesn’t matter.In XGH, security is a secondary detail. It’s a waste of time to implement robust security (see axioms 5 and 7). Trust in luck, in the lack of interest from hackers, and axiom 8."
192,"  IntroductionAs data scientists, being able to investigate and visualize the geographic world around us is often a critical tool in our toolkitWhether we'retracking the spread of a global pandemicinvestigating the effects of climate changeor helping a city develop its public transportation systemthere are limitless insights to be gleaned and communicated from geographic dataWith geographic data being as complex as it is, it's essential to have the right tools to simplify our lives (and code) as much as possibleBy leveraging R and its rich package ecosystem, we're able to take advantage of powerful tools such as sf and ggplot2 to bring our geographic data to life and quickly spin up meaningful analyses and graphicsSo let's jump in and learn how to synthesize these packages together and create quick visualizations from shapefiles!NOTE: The complete code and dataset for this blog post can be found on GitHub here  Table of contentsPrerequisites and installationWhat is sf?What are shapefiles and why do they matter?Loading shapefiles with sfVisualizing the geographic data with ggplot2ConclusionAdditional resources          Chris Greening - Software Developer                  Hey! My name's Chris Greening and I'm a software developer from the New York metro area with a diverse range of engineering experience - beam me a message and let's build something great!                christophergreening.com        Prerequisites and installation The following packages are prerequisite installations for following along with this blog post!sfggplot2tidyverse (optional but recommended)To install them open RStudio (or wherever your R is installed) and run:install.packages(c(""sf"", ""ggplot2"", ""tidyverse""))Enter fullscreen modeExit fullscreen mode  What is sf? If you've worked on geographic data before you may have come across a wide range of file formats, tools, and jargonIt can get overwhelming especially when we just need to perform a quick spatial analyses or generate some visually appealing maps. That's where the sf package in R comes in handyShort for ""Simple Features"", sf is a package designed to simplify spatial data handling within R via the Simple Features standard that specifies a common storage and access model for geographic dataBy using sf, we're able to leverage its:Ease of use: sf enables us to work with spatial data as if it were a regular data.frame, data.table, or tibble (pick your poison). This intuitive handling makes life much easier as it opens up the robust and familiar support R has for tabular dataIntegration with other tools: sf seamlessly integrates with popular R packages like tidyverse and ggplot2, allowing us to wrangle and visualize spatial data with some of our favorite toolsVersatility: From reading and writing various spatial file formats to spatial operations like joining and aggregating data, sf is wonderfully versatile. It supports a wide array of geometric operations, coordinate reference systems, etc.Now that we're situated with what sf is, let's jump into shapefiles and learn what they are and how we can leverage them for quick visualizations!  What are shapefiles and why do they matter? Shapefiles are a crucial part of geographic data handling and if you're working with spatial data you'll undoubtedly encounter them. But what exactly are they and why are they so important?Let's break it down:Definition: A shapefile is a common geospatial vector data format used in Geographic Information System (GIS) software. It stores the geometric location and attribute information of geographic featuresComponents: A shapefile is not just a single file but consists of at least three mandatory files:.shp: Holds the feature geometry stored as a set of vector coordinates.shx: Stores the shape index format of the geometry.dbf: Contains attributes or metadata associated with the shapesUse cases: Shapefiles can be applied to a wide variety of fields and use cases:Mapping: Shapefiles enable the creation of maps, displaying roads, rivers, landforms, etc.Analysis: They facilitate spatial analyses such as distance calculations, area measurements, and overlaysData integration: Shapefiles are versatile and can be integrated with other data types, aiding comprehensive analysesWidespread use: Shapefiles are one of the most commonly used formats in GISAccessibility: Many governmental and environmental organizations provide data in shapefile format, making it widely accessibleCompatibility: They are supported by various GIS software, enhancing their usabilityIn short, shapefiles act as a bridge between raw geographic data and the insights we can synthesize and draw from themTheir accessibility and flexibility make them indispensable in the world of geographic data analysis and by leveraging the sf package in R, we can effortlessly load and manipulate these complex files into informative visual insights  Loading shapefiles with sf Reading a shapefile with sf is incredibly straightforward and requires only a single line of code using sf::st_readFor this example, we're going to load geographic regions of Europe from a shapefile sourced directly from an official European Union data source and filter it to only show Italian geographic regions using dplyr::filterlibrary(sf)library(dplyr)shape.data <- sf::st_read(""NUTS_RG_01M_2021_3035.shp"") %>%    dplyr::filter(CNTR_NAME == ""IT"")Enter fullscreen modeExit fullscreen modeAnd that's it! Our geographic data is now ready for analyzing and visualizing  Visualizing the geographic data with ggplot2 To visualize our shape data we can now leverage ggplot2 like we would with any other analysis using ggplot2::geom_sf!ggplot2::ggplot(data = shape.data) +    ggplot2::geom_sf() +    ggplot2::labs(title = ""Italian NUTS-3 regions"") +    ggplot2::theme(        panel.background = ggplot2::element_blank(),        axis.text = ggplot2::element_blank(),        axis.title = ggplot2::element_blank(),        axis.ticks = ggplot2::element_blank(),        legend.position = ""none""    )Enter fullscreen modeExit fullscreen mode  Conclusion And thus, in this post we've explored how R makes working with and visualizing geographic data accessible and efficient through the use of the sf and ggplot2 packagesThanks so much for reading and if you liked my content, be sure to check out some of my other work or connect with me on social media or my personal website 😄          Chris Greening - Software Developer                  Hey! My name's Chris Greening and I'm a software developer from the New York metro area with a diverse range of engineering experience - beam me a message and let's build something great!                christophergreening.com      Cheers!Joining multiple datasets on the same column in R using dplyr and purrrChris Greening ・ Jan 28#datascience#r#tidyverse#beginnersConnecting to a relational database using SQLAlchemy and PythonChris Greening ・ Apr 30 '22#python#beginners#tutorial#database  Additional resources Simple Features for RR graph gallery - ggplot2Creating maps from sf objects"
193,"Heyo folks! Sloan, DEV Moderator and resident mascot, back with another question sent in from a DEV community member. 🦥For those unfamiliar with the series, this is another installment of Sloan's Inbox. You all send in your questions, I ask them on your behalf anonymously, and the community hops in to offer advice. Whether it's career development, office politics, industry trends, or improving technical skills, we cover all sorts of topics here. If you want to send in a question or talking point to be shared anonymously via Sloan, that's awesome; just scroll down to the bottom of the post for details on how.So, let's get down to business...  Today's question is:I've been applying to various dev jobs as a new developer, but am feeling insecure about having minimal activity on my GitHub. How important is it to recruiters and hiring managers that I have an active GitHub profile?Share your thoughts and lets help a fellow DEV member out! Remember to keep kind and stay classy. 💚Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
194,"This post is a short overview of an Abto Software R&D project.  A platform with accurate 3D body measurement technologyAbto Software was hired for the solution design and implementation of a 3D body measurement technology. Our company has covered every stage from investigation, product design, and prototyping, to deployment. During the first stages, the concept was unfinished – it required many photographs to capture every angle. Having conducted in-depth discovery, we implemented another concept, which works with only 2 photographs and ensures high accuracy.Abto Software has joined to deliver an intricate R&D project, but with extensive expertise in delivering:AI-based pose detection technologyCV-based body measurement technologyand some great results after the initial stages, our engineers were involved to provide full-cycle services, including additional functionality updates, as well as ongoing product support and maintenance.  Enabling contact-free body scanning in real-timeAt the first stage, we determined our priorities, which were:Building a SaaS 3D measuring technology to provide valuable services to businesses across industries – clothing manufacturers, online and offline retailers, fitness companies, and moreIntegrating the custom 3D measuring technology into businesses and handling additional servicesDuring the complex project, we covered multiple services, which are:In-depth investigationSolution designProduct prototypingWeb and mobile developmentThird-party integrationsFunctionality extensionOngoing support and maintenance   3D measurement technology implementation: Our solutionThe concept we introduced:During registration, the user first provides personal informationBefore utilization, the user must place the smartphone at knee- to waist-levelThe app will provide audio guidance on how to position the bodyThe app will use the smartphone’s front camera to take two photosWhen finished, the system will conduct image segmentation to remove the backgroundAfter that, the system will send the avatar to the cloud server to perform the measurement The features to mention:Simple registrationData protectionQuick processingProgress tracking  3D measurement technology implementation: Key challenges  Concept fine-tuningAt first, the concept was way too difficult – the system has required 24 images to perform the measurement. After research and some major re-configurations, the concept we introduced has exceeded our expectations – the system could handle the measurement with only 2 images, and without external assistance.   Data protectionTo provide accurate measurements, the system uses photos, which, naturally, raises serious privacy concerns. To resolve this problem, we conducted thorough investigation and implemented cutting-edge technology, which performs image segmentation, so that personal information isn’t uploaded to the cloud server.  Exposure adjustmentEvery additional light source – windows, lamps, mirror reflections – might disfigure final exposure and quality.  Having configured dynamic adjustments at the algorithm level, we eliminated any disturbance.  Architecture refactoringTo customize their product, the customers would need numerous configurations, which disrupts system logic. To handle this challenge, we optimize the configurations for each individual customer and even take over architecture refactoring.  Summing upBy leveraging domain-specific knowledge & experience, we implemented 3D body measurement technology. To date, the product is benefiting mature businesses – apparel manufacturers, online and offline retailers, fitness providers, – and end-users across industries.At the very moment, we assist the client in the smooth integration of the 3D body measurement technology into the customer platforms, also providing ongoing support and maintenance.By leveraging exhaustive expertise in utilizing advanced technology, in particular:Artificial intelligence, data analytics, and other related subfieldsComputer visionWe delivered an accurate 3D body measurement technology, which efficiently:Increases reach and share – by providing unique features and precision, the system is helping the client to reach more customers and enter new marketsDrives revenue – by rising sales volumes, the solution multiplies performance and revenue"
195,"This week we're chatting all things remote work, and we want to hear from you about your experiences, pros, cons, and advice for those transitioning or considering remote work options.Let's dive into today's topic of conversation... Reflect on your remote work journey and share the most valuable lessons you've learned. How has remote work influenced your personal and professional growth? What advice would you give to someone new to remote work to make the most of the experience?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
196,"Astro is still a relatively new JavaScript framework, having been around since 2021, but, in my opinion, it addresses two major issues that face developers doing full stack JavaScript: the cost of that JavaScript and the forces of inertia. Let's discuss the problems first and then look at how Astro addresses them. Finally, we'll explore an example of an Astro application to help you get started using it.  The Cost of JavaScriptEvery year since 2018, Addy Osman writes or speaks about The Cost of JavaScript. JavaScript remains the most expensive resource on your site and has been the same since he first talked about it in 2018. That's because it's not just about the weight of the resources, which continues to grow, but also the time it takes to process it.This past year saw a smaller than usual increase in the size of JavaScript, but it was still up 10% according to the Web Almanac.From 2021 to 2022, an increase of 8% [in the amount of JavaScript shipped to browsers] for mobile devices was observed, whereas desktop devices saw an increase of 10%. ...The fact remains that more JavaScript equates to more strain on a device’s resources.Web AlmanacThe raw numbers can be shocking, with sites at p90 loading about 1.5MB of JavaScript. I'll hazard a guess that these same sites will have lots of blocking scripts, meaning the site is unusable while the user waits for the JavaScript to process. But, even worse, much of this JavaScript is unused.  Unnecessary JavaScriptUnused JavaScript is obviously wasteful, and should be addressed, but, in my view, nearly as wasteful is a category of JavaScript that I am calling ""unnecessary JavaScript"". This is JavaScript that is used but ultimately isn't needed because it does things that could have been done without JavaScript by just using the web platform.The rise of unnecessary JavaScript is related to the fact that at some point we also started using tools like React, that were meant to solve problems of complex and interactive application development, to build everything including sites that were heavy on content or basic application functionality with limited interactivity.For example, let's imagine a SaaS company site. There is probably a public facing portion of the site that is mostly marketing with perhaps some forms and simple interactions. Meanwhile there is likely a console of some sort that is fairly complex and represents the core of how the customer interacts with the SaaS application. The needs of the console probably make the cost, in terms of JavaScript, necessary enough to warrant a framework like React. The needs of the public facing site...yeah, not so much.I think a big reason why developers continue to load on more JavaScript and use frameworks like React for things the framework isn't really designed for is because we've built up years of dependency that makes it increasingly difficult to move without staring down a steep learning curve and/or starting from scratch.But the good news is that new tools, like Astro are beginning to address these issues.New front-end frameworks like Solid and Qwik are suggesting that React might not have all the answers after all, and on the server Astro, Remix and Next.js (among others) are making us reconsider how much code we really need to ship to the client.State of JavaScript 2022  The Benefits of AstroAstro addresses the two big issues I talked about above: unnecessary JavaScript; and the difficulty of transitioning. Let's explore how by first diving into how it deals with unnecessary JavaScript.  IslandsBy default, Astro delivers 0kb of JavaScript to the client. Of course, very few sites today can function with zero JavaScript, but Astro helps you eliminate unnecessary JavaScript via something called the ""islands architecture.""First coined by Etsy's frontend architect Katie Sylor-Miller in 2019 as the ""Component Islands"" pattern, the idea behind an islands architecture is to only send the JavaScript for components that require client-side hydration or interactivity. Here's how it is described from the canonical article on it by Jason Miller:The general idea of an “Islands” architecture is deceptively simple: render HTML pages on the server, and inject placeholders or slots around highly dynamic regions. These placeholders/slots contain the server-rendered HTML output from their corresponding widget. They denote regions that can then be ""hydrated"" on the client into small self-contained widgets, reusing their server-rendered initial HTML.Islands Architecture by Jason MillerThis leads to a page that might look like the below diagram wherein the header and image carousel require JavaScript but the remainder of the page does not. The typical single page application (SPA) architecture would hydrate the entire page using JavaScript. But the islands architecture proposes that by sending only the JavaScript required for rendering these components, we can ultimately minimize the amount of JavaScript necessary on the client.  How islands work in AstroSo how does this work? In the below example (borrowed from the Astro docs), the Astro component (don't worry, we'll talk about the different types of components in a bit) requires no JavaScript to render but the React component does and thus has the directive for client: load.---// Example: Use a dynamic React component on the page.import MyAstroComponent from '../components/MyAstroComponent.astro';import MyReactComponent from '../components/MyReactComponent.jsx';---<!-- This component is now interactive on the page! --><MyReactComponent client:load /><!-- This component loads zero js ---><MyAstroComponent />Enter fullscreen modeExit fullscreen modeAstro actually offers a ton of flexibility with its hydration directives that allow you to set the appropriate priority for each component all the way to forcing full client-side rendering where necessary.load – high priority. Elements that will be immediately visible on the page.idle – medium priority. Elements that do not need to be immediately interactive.visible – low priority. Typically below the fold elements that become active when in the viewport.media – low priority. Elements that might only be visible on certain screen sizes.only – skip server rendering entirely and only render on the client.So to summarize, Astro will send zero JavaScript by default but allows you to designate a component ""island"" that requires JavaScript to render or otherwise enable interactivity. However, you have fine-grained control over how that JavaScript is loaded to help ensure the best performance for your users.  Components in AstroSo we've talked about how Astro reduces JavaScript, but how does it ease transitioning from an existing SPA architecture? It does this by supporting a variety types of components, including components built in other frameworks like React, Vue, Svelte and more. This eases the learning curve but also means that developers don't necessarily need to toss all of their existing code as components can be reused or shared within the Astro site.You can even mix and match components from different frameworks. I'm not sure I'd recommend this but you can do it.---// Example: Mixing multiple framework components on the same page.import MyReactComponent from '../components/MyReactComponent.jsx';import MySvelteComponent from '../components/MySvelteComponent.svelte';import MyVueComponent from '../components/MyVueComponent.vue';---<div>  <MySvelteComponent />  <MyReactComponent />  <MyVueComponent /></div>Enter fullscreen modeExit fullscreen modeBut Astro also offers their own component syntax for an Astro component (.astro). These are HTML only components on the client, though you can include JavaScript via <script> tags or run JavaScript on the server. As we'll see, you can still even build full sites and even simple web applications using just Astro components.  When to use AstroAll of the above may sound amazing and you may be feeling like, ""Build all the things with Astro!"" But, in truth, Astro isn't designed to be the solution to everything. Their docs make this clear:Astro was designed for building content-rich websites. This includes most marketing sites, publishing sites, documentation sites, blogs, portfolios, and some ecommerce sites.By contrast, most modern web frameworks are designed for building web applications.Why Astro?This makes sense but I'll admit that the dividing line is fuzzy. Can you build applications using Astro? Most definitely. Just as you could build a blog with Next.js (something it feels like serious overkill for), you could likely build (to use my prior example) a SaaS application dashboard with Astro, but it wouldn't be the best tool for the job.Ultimately, that dividing line is up to you but it is worth pointing out that it's not all or nothing. You could move the more content-focused aspects of your site to Astro and leave the rest to something like Next.js. This would help you only use the necessary JavaScript.  Building an Example Astro ApplicationLet's explore an example I built using Astro. As someone who speaks frequently at conferences, I usually do a fairly poor job of tracking both the content of my CFP submissions and where I submitted them to. The application I built is fairly simple one that allows me to save my CFP titles and abstracts as well as which conferences I have submitted them to and whether they were accepted or not.You can find the repo here on GitHub. It currently doesn't support multiple users or any advanced functionality (plans for the future!) but it will help us cover the basics of getting started building apps with Astro. The backend uses AppWrite Cloud but I did do another version porting the data portion to Postgres that you can find here.This application uses no JavaScript, but still allows for dynamic output. It's a great example that, while React/Vue/Svelte components have their place, you can do a lot using just Astro components. Let's go through some of the basics.  Getting StartedThe easiest way to get started is via some of the templates on Astro.new. In this case, I used the Tailwind template which, as the name implies, integrates Tailwind. In Astro integrations are handled like plugins that you install separately. This even includes things like adding support for deployment options like Netlify for example.To generate a site using the Tailwind template, I just used the command line:npm create astro@latest -- --template with-tailwindcssEnter fullscreen modeExit fullscreen modeThis will walk you through a command line based wizard that ultimately generates a set of project files using the default Astro folder structure. It will also, if you choose, install all the necessary dependencies.The key thing to note first is the Astro configuration file, astro.config.mjs. Let's look at mine because I made a couple small tweaks to the one that was generated.import { defineConfig } from ""astro/config"";import tailwind from ""@astrojs/tailwind"";// https://astro.build/configexport default defineConfig({  integrations: [tailwind()],  output: ""server"",});Enter fullscreen modeExit fullscreen modeFirst off, I have removed the MDX plugin as my application doesn't use MDX, so the only integration is the Tailwind one. Second, I added the output: server because my application is fully server-side rendered. By default, Astro outputs as static files but it also supports two other rendering modes:server which is fully server side rendered. Since my application, as it currently exists, isn't designed to pregenerate any pages as static (it's all effectively user generated content), SSR was the right choice.hybrid which is a combination of server-side rendering and static rendering. This probably suits most sites as it allows pages like your about page, for example, or even static blog posts to opt-out of server-side rendering and be pre-rendered for even better performance.  Creating LayoutsLayouts are typically placed in a /src/layouts folder, but that's a convention not a requirement. Since my app doesn't have many different views, I only created one layout, main.astro, which just serves as the shell of the application.The two key things to point out in the code below (note that for brevity I will be removing the Tailwind classes) is that you can pass props into an Astro component (in this case I am just passing an HTML title) and that you use the <slot /> tag to indicate where the generated content should be output.You should also note that the JavaScript that runs on the server, either at build time for static rendering or runtime for SSR, is placed at the top of the file bracketed by --- as you might typical frontmatter.---const { title } = Astro.props;---<html lang=""en"">    <head>        <meta charset=""utf-8"" />        <meta name=""viewport"" content=""width=device-width"" />        <link rel=""icon"" type=""image/svg+xml"" href=""/favicon.svg"" />        <title>{title}</title>    </head>    <body>        <section>            <div>                <div>        <slot />                </div>            </div>        </section>    </body></html>Enter fullscreen modeExit fullscreen modeI can then import and use a layout anywhere in my application or, in the case of Markdown or MDX, specify a layout to use in the frontmatter. You can also nest layouts, for example if I had this shell as the base and sub-layouts for different sections of my site.  ComponentsAs the UI is fairly simple, the sample application only uses a couple of simple Astro components. Let's look at the component that renders a session in the list page. It is very similar to the layout above in that it can do imports and run JavaScript on the server in the block at the top of the page. I am passing in the session as a prop which is then used to render the output between { and }. Notice that I can run arbitrary JavaScript within these as I do in the date formatting.---import Button from '../components/Button.astro';const {session} = Astro.props;---<div>    <h2>        <a href=`/sessions/${session['$id']}`>{session.Title}</a></h2>    <div>        <a>            <svg xmlns=""http://www.w3.org/2000/svg"" width=""16"" height=""16"" fill=""currentColor"" viewBox=""0 0 16 16"">                <path d=""..."" />            </svg>Created: {new Date(session['$createdAt']).toDateString()}        </a>        <a>            <svg xmlns=""http://www.w3.org/2000/svg"" width=""16"" height=""16"" fill=""currentColor"" viewBox=""0 0 16 16"">                <path d=""..."" />            </svg>Updated: {new Date(session['$updatedAt']).toDateString()}        </a>    </div>    <p>{session.Abstract}</p>    <div>        <Button url={`/addSession?sessionID=${session['$id']}`}>            Edit        </Button>        <Button url={`/addCFP?sessionID=${session['$id']}`}>            Add a CFP        </Button>    </div></div>Enter fullscreen modeExit fullscreen modeUsing the layout and component in a page works just as you would expect. You simply import them at the top of the file. You can pass in props via attributes to the tag. Notice that you can do things like output a list using map() as you typically would in a React component. Also note that the server-side JavaScript supports top-level await.---import BaseLayout from '../layouts/main.astro';import CFPCard from '../components/CFPCard.astro';import Button from '../components/Button.astro';import {getSessions} from '../lib/AppWrite.js';const sessions = await getSessions();---<BaseLayout title=""My CFP Submissions"">    <div class=""w-36 m-4 float-right"">        <Button url=""/addSession"">New Session</Button>    </div>    <h2        class=""mb-4 text-3xl font-bold leading-tight tracking-tighter text-gray-700 md:text-5xl dark:text-gray-300"">        Current Sessions</h2>    {        sessions.map((session) => (<CFPCard session={session} />))    }</BaseLayout>Enter fullscreen modeExit fullscreen mode  RoutingAs is a common convention in full-stack JavaScript frameworks, Astro supports file based routing but routing is different than you may be used to because Astro is what's now commonly referred to as an MPA or multi-page application. Essentially, instead of loading an app shell and then rehydrating the shell based upon the route, Astro renders a new page with a full request/response – just like we did in the old days (except back then they were just web sites and not MPAs). You can read more about MPAs vs SPAs in Astro's docs.The routing is based off the structure within the /pages directory. This means that if there is an /src/pages/about.astro that will resolve to route of /about.html. Again, this doesn't cause the app to rehydrate but will do a full server request and response, whether or not that route is statically rendered or server-side rendered.Astro also supports dynamic routes as well as things like catchall routes. Here's some examples:/pages/about.md // renders /about/pages/blog/[post].astro // renders /blog/post1 and /blog/post2/pages/api/[version]/posts.json.js // renders /api/v2/posts.json/pages/[...path].astro // renders /about and /about/teamEnter fullscreen modeExit fullscreen modeIf you are statically rendering a dynamic route, you do need to supply predefined paths for a route via a getStaticPaths() method in the file. If you are server side rendering as I am, this isn't required. However, this means that someone could hit a route that doesn't exist, in which case you'll need to handle that.In the example app, I have one dynamic route that renders a page for any of the sessions that I submit. Because this is server side rendered, I do not need to predefine the paths, but I am returning a 404 response if the path doesn't exist (I could alternately use Astro.redirect() to redirect them to a page instead).You'll also note that I am using a URL variable to update a CFP as accepted. This is possible because this page is server side rendered. Otherwise I would have to have used client-side JavaScript to manage the request and updating the page HTML to reflect the change.---import BaseLayout from '../../layouts/main.astro';import Button from '../../components/button.astro';import { getSession, getCFPs, acceptCFP } from '../../lib/AppWrite.js';const currentPath = Astro.url.pathname;const { id } = Astro.params;const cfpid = Astro.url.searchParams.get('cfp');// if the URL variable for a CFP ID is present, we're accepting that sessionif (cfpid) {    acceptCFP(cfpid);}const session = await getSession(id);if (!session) {    return new Response(null, {        status: 404,        statusText: 'Not found'    });}const cfps = await getCFPs(id);---<BaseLayout title={`Session: ${session.Title}`}>    <div>        <h2>{session.Title}</h2>        <div>            <p>Created: {new Date(session['$createdAt']).toDateString()}</p>            <p>Updated: {new Date(session['$updatedAt']).toDateString()}</p>        </div>    </div>    <div>        <div>{session.Abstract}</div>            <h2>Submissions</h2>        <ol>            {                cfps.map((cfp) => {                    let acceptLink = `<a href=""${currentPath}?cfp=${cfp['$id']}"">Accepted?</a>`;                    return (<li>{ cfp.Conference} | Submitted on: {new Date(cfp.SubmissionDate).toDateString()} | { cfp.Accepted ? ""Accepted"" : <span set:html={acceptLink}></span> }</li>)                })}        </ol>        <Button url=""/"">            Back Home        </Button>    </div></BaseLayout>Enter fullscreen modeExit fullscreen mode  Handling form submissionsThe only other thing I want to point out in this demo app is that it's pretty easy to handle form submissions via standard HTML and server-side JavaScript using an Astro component. For example, let's look at the page that handles the form for adding a new session title and abstract.The form submission is handled by looking for the POST method and then getting the values from the submitted form data. The same form is used for updating an existing session by looking for an URL variable and populating the form values. If the form submission is successful, I am redirecting back to the session list on the home page using Astro.redirect().One thing worth noting is that there is no real error handling on the server side in this example. The form does use basic HTML form validation, but an improvement would be to ensure that there is some degree of server-side error handling as well. In addition, the alert() method where I dump the error message if there is one is a server-side alert rather than a client-side one, so, as it exists today, the user wouldn't know if the server submission failed.---import BaseLayout from '../layouts/main.astro';import { createSession, getSession, updateSession } from '../lib/AppWrite.js';// handle the form submissionif (Astro.request.method === ""POST"") {  try {    const data = await Astro.request.formData();    const sessionID = data.get(""sessionID"");    const title = data.get(""title"");    const abstract = data.get(""abstract"");    if (sessionID)        await updateSession(sessionID, title, abstract);    else        await createSession(title, abstract);    return Astro.redirect('/')  } catch (error) {    if (error instanceof Error) {      alert(error.message);    }  }}// if a URL variable is present, we are editing an existing session// we can handle URL variables on the server because this is SSRconst sessionID = Astro.url.searchParams.get('sessionID');let title;let abstract;if (sessionID) {  const session = await getSession(sessionID);  if (session) {    title = session.Title;    abstract = session.Abstract;  }}---<BaseLayout title=""Add/Edit a Session Abstract"">    <div>        <h2>            Add/Edit Session Abstract        </h2>    </div>    <form method=""POST"">    <input type=""hidden"" name=""sessionID"" value={ sessionID }>    <div>        <div>            <div>                <div>                    <p>                        Session Title                    </p>                </div>                <div>                    <input name=""title"" required                        type=""text"" placeholder=""title"" value={title}>                </div>            </div>        </div>    </div>    <div>        <div>            <div>                <div>                    <p>Abstract</p>                </div>                <div>                    <textarea name=""abstract"" rows=""4"" placeholder=""your text here.."" required>{abstract}</textarea>                </div>            </div>        </div>    </div>    <div>        <div>            <a href=""/"">                <p>Cancel</p>            </a>        </div>        <div class=""w-full md:w-auto p-1.5"">            <button>                <p>Save</p>            </button>        </div>    </div>    </form></BaseLayout>Enter fullscreen modeExit fullscreen mode  Prepare for your launch! 🚀I hope that this has given you all the foundations you need to get started with Astro and you are ready to take off! As I noted, the key benefits Astro offers of reduced JavaScript and better performance are going to be increasingly important as we try to deal with the JavaScript bloat that the SPA era has left behind. But Astro's support of existing framework components and relatively gentle learning curve will help you make the transition from a SPA framework. So, give Astro a try by going to Astro.new and starting a new project or digging into their extensive and well-written documentation."
197,"We all have moments of doubt, even when achieving something significant. Describe a coding accomplishment you were hesitant to share but ended up being proud of. How did you celebrate that achievement?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by Freepik"
198,"Have you ever wanted more from GitHub Copilot? Has GitHub Copilot ever made a suggestion where you thought ""I wish I had more options?"" Good news, you can! GitHub Copilot can provide you with multiple suggestions for your code.Here's how.  GitHub Copilot suggestionsWhen you normally use GitHub Copilot, you'll be provided with a suggestion. This is known as ""ghost text"". You can accept GitHub Copilot's response by pressing ENTER on your keyboard.GitHub Copilot's ghost text:Accepting GitHub Copilot's output:If you don't like GitHub Copilot's idea, then you can continue to type, or press DELETE on your keyboard.Wouldn't it be great to be given a few options to chose from when working with GitHub Copilot? Here's how to get more than one idea when using GitHub Copilot.  Get multiple suggestions1. When using GitHub Copilot in your editor, instead of waiting for the ghost text to appear, press `CTRL` + `ENTER` on your keyboard (⌘ + `ENTER` on Mac).2. Instead of ghost text, you'll see a pop-up window appear. This is called the completions panel. The panel will provide you with up to ten different suggestions.The completions panel pops up in the GitHub Copilot tab on VS Code:Up to 10 code blocks will be provided:3. Select the suggestion you like by hovering over the desired code and clicking ""Accept Suggestion"".Accepting the suggestion:  Try it outOpen your editor of choice and try it out for yourself. Check out the video tutorial if you want to see GitHub Copilot suggestions in action:"
199,"Please, don’t tell me you’re still using console.log to debug your application.Ok, everyone does that, sometimes I use console logs too… BUT Chrome has a perfectly working debugger and there’s no configuration required, it just… works.Let me show you:Or if you prefer reading, here's a summary of what the video is about (but let me recommend you watch the demo in the video).If you never used a debugger, imagine being able to run the code line by line, where you can see all values of your variables at any given time, you can run some extra code to validate your assumptions, you can pause the code only if a condition is met and much more!Ok cool, but how?I’m Leonardo and I talk every week about Web Development and Open Source. Today, let’s see together the Chrome Debugger.  Accessing the debuggerOn Chrome, you can press F12 or right-click on the page and select “Inspect” to open the developer tools.You already know this, but most often you use the Console or the Network tab, but there’s much more than that.To access the debugger, you can click on the “Sources” tab and then on the left, you’ll see all the files that compose your application.From here you can either navigate to the file you want to debug or you can use the search bar to find it. A smart way is with the command palette (Cmd + P on Mac, which should be Ctrl + P on Windows) and then type the name of the file you want to debug.From here you can click on the line number to add a breakpoint and the code will pause when it reaches that line.  Using the debugger; statementAlternatively, you can add a debugger; statement in your code. When you switch to the browser and you use your app, you will see that nothing happens.However, if you have the developer tools open, you’ll see that the debugger will pause the execution of the code on that line.This can be useful if you want to debug a specific part of your code and you want a quick shortcut to add a breakpoint from your editor, but please don't forget to remove it before committing and pushing your code.  BreakpointsIf you're not too familiar with debuggers, I already mentioned breakpoints without explaining what they are... but it's not much more complicated than what I already said.In short, you tell the debugger that you want your code execution to pause when it reaches a specific line... and that's it!On Chrome, the browser will pause and from there you'll be able to manually control the execution of the code... and do some more cool stuff I'll explain in a moment.Last call, you can watch it on video!  Conditional breakpointsThe name is self-explanatory, but I'll explain it with an example.for (let i = 0; i < 100; i++) {  const winner = calculateWinner(players[i]);  winner.doSomething();}Enter fullscreen modeExit fullscreen modeI want to debug the calculateWinner function but only for the 87th iteration of the loop. With a regular breakpoint I would have to pause and resume the execution of the code 86 times... not ideal.Instead, I can add a conditional breakpoint and tell the debugger to pause only if i === 87.You can add a condition to a breakpoint by right-clicking on it and selecting ""Conditional Breakpoint"".As simple as that, but reeeally powerful!  LogpointsBut console logs? I can't live without them!Ok ok, you can set special breakpoints that are actually logpoints, it's the option right below conditional breakpoints in the menu.This means that instead of pausing the execution of the code, the debugger will just log a message in the console.Advantages? You don't need to spread a ton of console.logs in the code that you would need to remove later, to begin with!Removing a logpoint, as well as other breakpoints, really quick. How? Read the next chapter 👇  Removing breakpointsYou can remove a breakpoint by clicking on it. If you want to remove all breakpoints, you can click on the ""Deactivate breakpoints"" button on the top right. This doesn't actually remove them, but it deactivates them so you can reactivate everything in a single click.In any case, from the Breakpoints tab you can enable/disable and even remove breakpoints in a nice overview.  Event listenersIf breakpoints, conditional breakpoints, logpoints and the debugger statement are not enough, I don't know what else you might be looking for.Oh wait, it's in the title of this chapter: event listeners.You can add special breakpoints that are triggered only when a specific event is fired.To name one, you can add a breakpoint that is triggered only when you click on an element, as long as there's an event listener attached to it.Building a React app? You press a button and the execution will pause on the first line of the function you attached to the onClick event.  Using Chome's debuggerOk, at this point you can't really say you don't know how to launch the debugger or that it's long or complicated. There are so many different ways of pausing the code exactly at the point you need.Now, cool, but what can you do once there? Let's see some cool tricks ;)  ValuesThe first thing you'll notice is that if you move your mouse over a variable, you'll see its value. This is already a huge improvement over console logs as you can see all of them without having to dig through a wall of text in the logs.There's also the Scope tab that shows you all the variables in the current scope, grouped in Block, Local, Scope, Module and Global.  WatchIf you want to keep an eye on a specific variable, you can add it to the Watch tab and it will be there for you to check at any time.But this doesn't work only for variables, you can also add expressions. For example, you can add players[i].name and it will show you the name of the player at the current iteration of the loop, or if you're manipulating an array you can do players.map(p => p.name) and it will show you the names of all the players.Last example, you can write a boolean expression like players[i].name === 'Leonardo' and it will show you if the condition is true or false while you step through the code.  Call stackThe Call Stack tab shows you the current stack of function calls. This is useful to understand how you got to the current point in the code.For example, you have a function that is called from many different places and you want to know which one is calling it at the moment.On the call stack you can exactly see that, all the previous functions that led the execution to the current one.  Moving through time and spaceOk maybe the title is a bit too much, but you can do some cool stuff with the debugger to control the execution of the code.  ResumeThe first one is the Resume button. This will resume the execution of the code until the next breakpoint. If there are no more breakpoints, it will just run until the end.You will find yourself using it quite often, for example if you have just one breakpoint to peek at the current state, or if the breakpoint was mostly to validate that the code was executed at all.  Step overOn the second podium for usage you'll probably find the Step over button. This will execute the current line and then pause again on the next one.If the current line is a function call, it will execute the function and pause on the next line after the function call.  Step intoThe Step into button is similar to the previous one, but instead of executing the current line, it will execute the function call and pause on the first line of the function.  Step outThe Step out button is the opposite of the previous one. It will execute the current function and pause on the line after the function call.  ConclusionAnd that's it! This was just the tip of the iceberg, there are many more things you can do with the debugger, but I think this is enough to get you started and to make you curious to learn more.After all these cool features, are you gonna continue using console log?Here’s my answer, yes, because I’m lazy.Or at least, if it’s only ONE console log to print a value once, yeah, why not, but as soon as you find yourself writing TWO console logs, or looking at the same log two or three times… think about the debugger. It will save you quite some time.I tried to describe this tool and add some screenshots, but this was kind of a dynamic demo. The video already shows some cool tricks, but now it's your turn to try it out and see what you can do with it. Just use it for some days and you'll find yourself using it more and more.Thanks for reading, and happy debugging! 🎉Thanks for reading this article, I hope you found it interesting!I recently launched my Discord server to talk about Open Source and Web Development, feel free to join: https://discord.gg/bqwyEa6We6Do you like my content? You might consider subscribing to my YouTube channel! It means a lot to me ❤️You can find it here:Feel free to follow me to get notified when new articles are out ;)Leonardo MontiniFollowI talk about Open Source, GitHub, and Web Development. I also run a YouTube channel called DevLeonardo, see you there!"
200,"Welcome to our #100DaysOfOSS series. Until October 31, we'll be doing  Open Source Software (OSS) terms from A to Z. We'll be diving into a different letter of the English alphabet, uncovering OSS concepts, and sharing our thoughts on them.Today, we're covering the letter ""F"" for Fork. Fork: Forking is the process of creating a new independent project from an existing open-source project. It allows developers to take the existing codebase in a new direction or make modifications while maintaining the original project's core principles.Now, we want to hear from you! What other OSS terms can you think of that start with the letter ""F""? Remember to use the hashtag #100DaysOfOSS if you share on social media, and don't forget to tag us @saucedopen so we can follow along."
201,"Whenever we put in our details to register on any website,attackers are always on the lookout to steal our details. We hear terms like encoding and encryption ,but they can never be like the bcrypt hash format,where we hash passwords with bcrypt. Lately I have been working on the backend and one password protection tool I always see and have come to really love and understand  is bcrypt .In this article we specify the differences between Encryption, Encoding and hashing,we also go to the bone of contention which is how to create bcrypt password hash.  Differences between Encryption, Encoding and Hashing.  EncryptionThis is basically a method of securing data to make it unreadable by using an algorithm and a key.The drawback with Encryption is that it is reversible.The original data can be retrieved with the right decryption key.  EncodingEncoding is mainly done for system compatibility and not for protection , even though it converts data to a different format so that it can be stored on certain systems but definitely not for protection against Hackers   HashingThe main difference between a hashed password and an encrypted one is that hashing only works one way and cannot be reversed,so you can hash a password but cannot unhash it unlike encryption that can be decrypted. Although Brute force attacks (learn about brute force attacks https://en.m.wikipedia.org/wiki/Brute-force_attack ) and ""Rainbow table attacks"" can be used to break them ( learn about rainbow table attack. https://en.m.wikipedia.org/wiki/Rainbow_table) . So to minimize these , we add salt to the password before it is hashed. The salt is randomly generated data that is added to your password to make sure it is unique.   What is bcryptBcrypt is  a short form for ""Blowfish-crypt "". It is a cryptographic algorithm designed for password hashing. Not all hash algorithms are the same, and there are many options available. It was developed by Niels Provos and David Mazières, to address vulnerabilities and weaknesses found in other hash functions. Bcrypt is widely recognized as a secure and reliable choice for password hashing.It is a password hashing function ( learn more about password hashing functions here https://en.m.wikipedia.org/wiki/Password-hashing_function ).  How does bcrypt workThe salt is a major ingredient in this process. The salt helps mitigate against Brute force attacks and Rainbow table attacks. Bcrypt uses the blowfish cypher which is slow enough and mitigates the limitations of the SHA functions which are designed to be computationally fast. If a hash password is calculated or generated with too much speed,the faster brute force attacks can get through so we use the bcrypt hash format to protect against this. Bcrypt is used across various programming languages but on this article I will be concentrating on Node js because that's what I use.  Password Hashing in Node js with Bcrypt.We know that to use Bcrypt we first need to install the library.npm install bcryptWe then include the bcrypt module in our code.const bcrypt = require(""bcrypt"")Now bcrypt has several methods and we can choose to perform our hash synchronously or asynchronously. You can find npm documentation for Bcrypt via this link  https://www.npmjs.com/package/bcryptHowever as a personal preference I like to use the asynchronous method, async await precisely.  Example of password hashing with bcrypt in node js.Suppose we are making an online registration form where users are required to input their emails and passwords.async function register(email, password){/*We know salt is needed to hash our passwords,let's create it*/const saltRounds = 10const salt = await bcrypt.genSalt(saltRounds)/*we now have our salt ,we use it to hash our password with the hash method*/const hashedPassword=await bcrypt.hash(password,salt) }Enter fullscreen modeExit fullscreen modeNow we have our hashed password as hashedPassword. Suppose we have a User model made with mongoose for a Mongodb database which we want to  create documents from,where document properties are email and password which will be taken from client input. we can now pass the hashedPassword as value of password.like below.async function register(email, password){const saltRounds = 10const salt = await bcrypt.genSalt(saltRounds)const hashedPassword=await bcrypt.hash(password,salt) //create user const user = await User.create({email, password: hashedPassword})return user}Enter fullscreen modeExit fullscreen modeIt's a very easy to understand package so straightforward.Now let's assume the above to be a signup function.We could also utilize it for a login function.Assume we have the same User model which we used above.We could use the bcrypt.compare methodasync function login(email,password){if(!email||!password){    throw Error(""All fields must be filled"")}// check if user exists via emailconst user=await this.findOne({email})if(!user){    throw Error('incorrect login details')}//via passwordlet match=await bcrypt.compare(password,user.password) //where user.password is hashed passwordif(!match){    throw Error('incorrect login details')}return user}Enter fullscreen modeExit fullscreen modein the above,we compared the initial password that must have been input from client side with user.password,as we saw above user.password is now hashedPassword from the first register function where we passed hashedPassword as value of password in our user document. If there is a match as a result of bcrypt.compare,only then can the user login otherwise it is assumed that they haven't previously signed up because signing up automatically hashes the password.  TakeawaysFor security purposes,it is necessary to hash passwords before storing them in a secure databaseBefore hashing a password we apply a salt. A salt is a random string that makes the hash unpredictable.saltRounds: The number of times the hashing function is added to the password  and salt combination. An increase in the number makes the time and resources that will be required to crack the password more . So a saltRound of 11 for instance will take longer to crack than a 10.You can also  click the links below to watch the videos below for a more visual perspective and a real world example.https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://m.youtube.com/watch%3Fv%3DZqMftcuKuIE&ved=2ahUKEwiB_YHZ9M6AAxXqVEEAHXSKAU0QwqsBegQIERAG&usg=AOvVaw26Gb2W9XHeR4eOVgDQj9kMhttps://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://m.youtube.com/watch%3Fv%3DKPplWOCZd5A&ved=2ahUKEwiB_YHZ9M6AAxXqVEEAHXSKAU0QwqsBegQIEhAG&usg=AOvVaw3LE2KL9ps5REd129xrW9eL"
202,"It's a constant trade-off.Push forward with innovation? The new? Greenfield?Hunker down and refine? Improve existing? Refactor?At first glance, it may seem like an either-or decision, but the interplay between innovation and maintenance is more like a dance, where both must be in sync for the performance to shine.Let's discuss the balance, the importance of both elements, and the consequences of neglecting one for the sake of the other.  The Two Sides of the Coin  1. InnovationOur industry thrives on change. New technologies emerging daily, offering novel solutions and redefining user expectations. It's about envisioning what could be, challenging the status quo, and breathing life into groundbreaking ideas.Importance: Growth: New features and improved functionality can lead to user growth and increased market share. Relevance: In a competitive market, staying stagnant can be lethal. Innovation keeps products and services aligned with emerging trends and user demands. Meeting Evolving Customer Needs: As user behavior and expectations change, products must adapt to stay valuable and useful.Risks of Over-Innovation: Losing Core Value: Constantly chasing new features can divert focus from a product's core value, potentially alienating loyal users. User Confusion: Overloading a product with features can make it cumbersome and confusing for users, leading to decreased satisfaction. New Bugs and Issues: Each added feature is a new potential point of failure, increasing the risk of bugs or other technical issues.  2. MaintenanceWhile innovation is the new shiny toy often gets the attention, maintenance is the unsung hero that ensures the lights stay on and folks get paid. Maintenance in software development is the rigorous (often tedious) process of updating, refining, and ensuring that existing systems function smoothly.Importance: Product Integrity: Regular maintenance ensures that a product works as intended, offering a consistent and reliable user experience. Security: Regular updates are vital to protect user data and system integrity. Adapting to New Tech Standards: Deep dependency trees and framework progression means means maintenance must have dedicated cycles.Risks of Over-Maintenance: Stagnation: Focusing solely on maintenance can lead to a product becoming stale, missing out on new opportunities or market shifts. Resource Drain: Excessive maintenance can consume resources that might have been allocated to more growth-focused initiatives. Missed Market Opportunities: While a team is caught up refining what they have, competitors might be racing ahead with new innovations.  Factors Influencing the BalanceWhile there's no one-size-fits-all answer, several key factors can influence how we might strike the balance between innovation and maintenance:  1. Business ObjectivesUnderstanding the overarching goals of the business is paramount. If a company is in a rapid growth phase or entering a new market, there might be a stronger emphasis on innovation to capture market share. On the other hand, if the focus is on building a reputation for stability and reliability, then maintenance could take precedence.  2. Competitive LandscapeThe state of the market plays a significant role. In a saturated market with many similar products, innovative features could be the differentiator. However, if competitors are frequently introducing new features with bugs and security issues, there might be an opportunity to stand out by emphasizing stability and reliability.  3. User FeedbackRegularly sourcing and prioritizing user feedback can offer insights into areas needing improvement or innovation. If users frequently request a feature or report issues with current functionalities, this can guide the balance between developing new features and refining existing ones.  4. Resource AvailabilityThe availability of resources, both in terms of manpower and finances, can sway the balance. Limited resources might be better spent on maintenance and ensuring a stable product, while abundant resources could be channeled into R&D and innovation.  5. Technical DebtHigh technical debt can hinder innovation. If a product's codebase is cluttered with legacy code, hacks, and workarounds, the focus might need to shift towards maintenance, refactoring, and reducing this debt before significant innovation can occur.  6. Industry Standards and RegulationsIn certain industries, especially those heavily regulated like finance or healthcare, maintaining compliance can be crucial. In such environments, the balance might lean more towards maintenance to ensure adherence to evolving regulations.  7. Team Expertise and PassionSometimes, the balance can be influenced by the team itself. A team that's passionate about exploring new technologies and methodologies might naturally gravitate towards innovation. Conversely, a team with deep domain expertise in a mature product might emphasize maintenance and perfection.  Strategies for Striking the Right Balance  1. Iterative Development and Feedback LoopsBy breaking development into smaller iterations and frequently gathering feedback, teams can nimbly adjust their focus. This approach allows for quicker course corrections, reducing the time and resources spent on unwanted features while addressing maintenance needs in a timely manner.  2. Dedicated Maintenance SprintsAllocate specific sprints or time blocks solely for addressing technical debt, bugs, and maintenance tasks. This ensures that maintenance doesn't get perpetually pushed to the back burner in the race for innovation.  3. Feature Flags and Dark LaunchesImplementing feature flags allows teams to roll out new features gradually. This method not only tests the water with innovations but also ensures that the team can revert or modify features based on real-world feedback without major disruptions.  4. Prioritization FrameworksUse frameworks like the MoSCoW method (Must have, Should have, Could have, and Won't have) to determine the importance of various tasks. This can help in allocating resources effectively between innovative projects and necessary maintenance.  5. Continuous Education and TrainingEquip the team with the latest tools, techniques, and best practices. A team that's well-versed in modern development practices will be better prepared to juggle innovation and maintenance without sacrificing quality.  6. User-Centric Decision MakingBy focusing on user needs and feedback, teams can ensure they're not innovating just for the sake of it. This user-centric approach ensures that innovations align with genuine user desires, while maintenance tasks enhance user satisfaction.  7. Establish Clear KPIsSetting clear Key Performance Indicators related to both new feature adoption and system stability can provide a tangible measure of where efforts should be directed. If stability KPIs are dropping, it's a clear signal to shift focus towards maintenance.  8. Cross-functional CollaborationEncourage collaboration between development, operations, sales, and customer support teams. This integrated approach can provide a holistic view of where the product stands, helping to identify areas in need of innovation or maintenance.  The Delicate Dance of ProgressIts tempting to always push for the development of the new, but building new must be balanced with the maintenance of existing. Every time something new is released, it's maintenance must be taken into account.Finding this balance is an art. It requires an understanding of where we've been and a vision of where the team or organization is headed. Recognize there is value in both creating and caring."
203,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
204,"Time for #DEVDiscuss — right here on DEV 😎Should New Developers Use AI Coding Tools?Catalin Pit ・ Aug 2#ai#developer#beginners#programmingInspired by @catalinpit's Top 7 post, tonight’s topic is... AI Coding Tools!  Questions:What are the most significant benefits of using AI coding tools? Drawbacks?How do you see AI coding tools evolving over the next few years?What advice would you give to those who are hesitant to use AI coding tools?Any triumphs, fails, or other stories you'd like to share on this topic?"
205,"Lately, we can bloc GPT bots from scraping our pages for a site that we control, by setting the following lines in the robots.txt file:User-agent: GPTBotDisallow: /Enter fullscreen modeExit fullscreen modeI, myself, found out this from a tweet from Gergely Orosz:My stance on this is similar to what Gergely is saying. GPT offers no citation to the information it provides. While I did update the robots.txt file on my personal website, I am also cross-posting to DEV. If we look at the robots.txt from DEV.to, we can notice that it does not have the same rule for GPTBot.There are thousands of people posting to DEV, many of whom have different views about scraping information for LLM training. I'm in no position to request changes that will affect how the site works. I'm just curious of what is the opinion of other fellow authors about scraping your article for ML training.  Does updating your robots.txt actually solve something?Obviously not. Adding this statement to your site is just a hint, a request for a bot to please not scrape your data.This won't stop huge LLM bots (including GPT) to get the information it wants.So, I'm curious about what do other people think about this topic? "
206,"I don’t know anyone who is still using the Oracle JDK. It has been my recommendation for quite a while to just switch to an OpenJDK distribution as they are roughly drop-in replacements for Oracle’s official JDK. I’ve repeated that advice quite frequently but I guess I glossed over a lot of details that might be insignificant for hackers but can become a pretty big deal in an enterprise setting.Following the review from Bazlur I chose to also pick up Simon Ritter's “OpenJDK Migration for Dummies”. This book has two things going against it:For dummies - I’ve never read one of these before and never considered reading those. While it does use overly simplified language I think the Dummies brand hurts this book. The subject matter is sophisticated and geared towards developers (and DevOps) who can follow the nuances. I think it might deter some developers from reading it, which is a shame.It's a corporate book - Simon is the Deputy CTO at Azul. This creates the justified concern that the book is a promotion for Azul products. It has those. But having read through it, the material seems objective and valuable.It does give one advantage: we're getting the book for free.  Unique AnalysisThere are many Java books but this is the first time I read a book that explains these specific subjects. The first chapter discusses licensing, TCK (Test Compatibility Kit) and similar issues. I’m familiar with all of them since I worked for Sun Microsystems and Oracle, I had a team composing TCKs for the mobile platform at Sun Microsystems. However, even experienced engineers outside of Sun might be unfamiliar with these tests.The TCK is how we verify that our port of OpenJDK is still compatible with Java. The book illustrates why a reputable OpenJDK distribution can be trusted due to the TCK. This is knowledge that’s probably not available elsewhere if you aren’t deeply involved in the JVM. Simon explained nicely the scope of the current TCK (139k tests for Java 11), but I think he missed one important aspect: TCK isn’t enforced. Oracle doesn’t know you ran the TCK “properly”, it can’t verify that. This is why OpenJDK vendors must have a good reputation and understanding of the underlying QA process.This is just the beginning but pretty much every chapter covered material that I haven’t seen in other books.As a side note, the whole TCK creation process is pretty insane. The engineers in my team would go over the JavaDoc like religious scholars and fill up Excel sheets with every statement made by the JavaDoc or implied by the Javadoc. Then devise tests to verify in isolation that every statement is indeed true. In that sense, TCK doesn’t test quality. It tests compliance to a uniform, consistent standard. A JDK can fail after running for a week and we might not be able to tell from running the TCK alone, early releases of JDK 8 did exactly that at that time…  Learning from a For Dummies BookI mentioned at the top of this post that I treat the OpenJDK migration casually as a drop-in replacement. This book convinced me that this is not always the case, there are some nuances. I was casually aware of most of them e.g. I worked a lot with Pisces back in the day, but I never saw all of these nuances in a single place.This is an important list for anyone considering a migration of this type. One should comb over these and verify the risks before embarking on such a migration. As a startup, you might not care about exact fonts or NTLM support, but in an enterprise environment, there are still projects that might rely on that.In a later chapter comparing the various OpenJDK distributions, Simon included a great chart illustrating the differences. Take into consideration that Simon works for Azul and it is obvious in the chart. Still, the content of the chart is pretty accurate. I am missing the Microsoft VM in the comparison but I guess it’s a bit too new to be registered as a major vendor.  Business Related AspectsI did consulting work for major organizations quite often; such as banks, insurance companies etc. In these organizations commercial support is crucial. I used to scoff at that notion but as I ran into some of the edge cases those organizations run into, I get it. We had a senior engineer from IBM debug AIX and Websphere issues. Similarly, a bank I worked with was having issues with RTL support in newer versions of Swing. As the older JDKs were nearing the end of their life cycle they were forced to migrate but had no way of addressing these issues. Oracle’s support for those issues was a dud in that case. Commercial support for the JVM isn’t something I ever needed or wanted to buy, but I understand the motivation. At the end of the book, Simon goes into more detail on the extra value that can be layered on top of an OpenJDK distribution. This was interesting to me as I often don’t understand the “it’s free” business model. It helped me both in understanding the motivation for offering (and maintaining) an OpenJDK release. It’s also valuable when I work with larger organizations, I can advise better on the value they can deliver for Java (e.g. fast response to zero-days, etc).  Who Should Read This Book?It’s not a book for everyone. If you’re using the Oracle JDK then you need to pick this up and review it. Make sure the reasons you picked Oracle JDK are still valid, they probably aren’t. If your job includes picking the JDKs for provisioning or development then you should make sure you’re familiar with the materials in the book.If you’re just learning Java or using it in a hobbyist capacity then there’s an appendix on Java’s history that might be interesting to you. But the book as a whole is probably more targeted at developers who are handling production. In that regard, it’s useful both for server and desktop developers.BTW if you or someone you know is interested in learning Java please check out my new book for learning Java."
207,"Updated 2023-08-15 to mention that our Facebook page is back up.There's a lot that happens behind the scenes when managing an Open Source project that many people don't ever see. In this post we're going to cover two recent events that have personally caused me a lot of stress as I'm at the mercy of others. These are also completely orthogonal to Pidgin's development and instead have drastic effects on the communities around the project.  Debian and Cyrus-SASLOn May 15th, 2023, a bug was created in Debian's issue tracking about a license incompatibility between libpurple (GPLv2) and Cyrus-SASL (many licenses) that threatened to remove Pidgin from Debian before the Bookworm release.Fortunately, Richard Laager, a Pidgin developer and the maintainer of our Debian package stepped up and stopped that from happening. However, we still had to deal with the licensing issues. But before we get into that, we of course need to look at some history.Pidgin gained support for Cyrus-SASL back in 2005 via commit 32f6f8bf3a57. I'm not sure anyone checked for license compatibility back then or what, but it was merged and would be used if it was found.At some point it got added to the Debian build. We don't know exactly because not all of the history is in the repository for the Debian packaging. This commit is the earliest one for the file that controls the build parameters and it has it. This revision is 16 years old at the time of this writing.Again, I'm not sure what if any due diligence was done when it comes to licenses or if Cyrus-SASL even was maybe even compatible back then, but as you can see, this was the status quo for a very long time.Thanks to the hard work of Richard, who was able to contact the original author of some of the problematically licensed code and get it re-licensed and got consensus on whether BSD-3-Clause-Attribution is GPL compatible or not the threat to libpurple and 27 other dependent packages being removed from Debian has been resolved.  FacebookOn August 6th, 2023, I got a notification that our Facebook page for Pidgin had been taken down for violations of their Community Standards when it came to ""misrepresentation"". They didn't state what we're misrepresenting so we're completely at their mercy right now.This page was created on April 21st, 2008 and has never had any previous warnings or violations or anything. So just removing it seems a bit heavy handed. It isn't super large or anything, but over the past 15 years we've accumulated 1,700 followers and we do end up doing a fair amount of support via it.I've tried a number of ways to contact Facebook about this, starting with just an appeal of their original decision, but that was upheld within a few hours. Since then I've written a blog post on our website mentioning it, hoping they'll connect the dots as at that point I was unable to find a way to actually say anything to them.I also tried reaching out via a contact form I found in the Meta Business Suite stuff, but as you might have guessed, haven't gotten a response from that either.That brings me to today (Monday August 7th), where I decided to try and post as the page to see what'd happen. The thought was that the post might just be moderated until we're restored or whatever. But when trying to post it gave me this message:So I filled out the feedback talking about everything and posting a link to the blog post on the main site. That was a few hours ago and we're still blocked, so who knows what will happen at this point.Update 2023-08-15, sorry been busy...As of Wednesday August 9th our page was published again by Facebook. The short story is that Meta launched a new AI to help them find and remove impersonators of their products. It was a bit over zealous and saw Messenger in our page title and unpublished our page. My appeal was denied with out any investigation, but thanks to some contacts of contacts, an internal appeal was initiated and got everything sorted out.  ClosingI hope you're enjoying these posts! Remember they go live for patrons at 9AM CST on Mondays and go public at 12AM CST on Thursdays! If there's something specific you'd like to see me cover here, please comment below!"
208,"The conventional wisdom in software engineering advocates for breaking down code into loosely coupled functions, classes, and modules, among other things. Numerous books and blog posts discuss various approaches that help us achieve the best possible design for our code.Sometimes, we may get lucky and find a design pattern that perfectly matches our business logic. However, there's a risk of making premature assumptions, which can result in our code being misaligned with the business problem.I propose an alternate approach that may sound counterintuitive.Start by writing messy code—-messy code that diverges from the traditional ""clean"" code, following design patterns, programming paradigms, or any opinionated design methodologies.  What do I mean by messy code here?I begin by putting all my code in a single function (or method). This means disregarding principles like Separation of Concerns, Single Responsibility Principle, or even DRY (Don't Repeat Yourself).Then, I write tests to verify that my code works.At this point, I am technically ready to open a Pull Request, meaning somebody will need to read my code and review it. This is when I check my code for readability.Based on my experience, having as much context available in one place makes code more readable. When I have a function with all the code in it, I have all the context I need to inform my design. If I feel the code is unreadable, I break the large function into meaningful blocks. On the contrary, figuring out the building blocks from scratch would take me much longer.Having all the code in one place can be considered messy, but it is much more malleable than having code implemented in mismatched design pattern.  What about working with existing codebase?An existing codebase may have predefined patterns. But that doesn't mean they should be unchangeable. As described above, these patterns may be a perfect fit. In that case we use them to inform the design of new features. But if they aren't, there is no reason why we should stick to them for all future code. If all future implementation is dictated by initial design decisions, then it means that our software is hard to change. Software is supposed to be ""soft"" i.e. easy to change, and change is a good indicator of a healthy and successful software project.  How did I arrive here?My fascination with architectural patterns and design methodologies began early in my career. Initially, I felt embarrassed by my code, which worked perfectly but lacked the elegance of a well-designed system. To address this, I immersed myself in studying design patterns, only to later realize that many of these patterns were primarily designed for Object-Oriented Programming. As I continued to develop my coding skills in Python, a more flexible language, I learned the importance of seeking design patterns native to Python.Over time, I also encountered counterarguments such as WET (Write Everything Twice) versus DRY (Don't Repeat Yourself), which expanded my perspective on coding.Given the abundance of strongly worded literature in the software industry, it is easy to become too fixated on the means of accomplishing our tasks and lose sight of our ultimate goals. Therefore, I find it valuable to approach coding from a first principles perspective—breaking down a problem into its fundamental elements and rebuilding a solution from those elements. Starting with messy code represents my personal approach to this philosophy, and I encourage you to find your unique path in coding as well.If you liked reading this post, you can follow me on LinkedIn for more.Cover Photo by Peter Olexa on Unsplash"
209,"Ever heard of Pseudocode? It's a combination of simple language and programming elements that helps you represent your code.Understanding it is a time-saving trick you can integrate into your process at any time - so you don't have to be stressed and frustrated when explaining your code to others.Here's more about Pseudocode, how it's used, and why it's an essential tool for any developer.What Is Pseudocode?Pseudocode is a simplified way of explaining coding elements like algorithms, functions, or other processes, using a mix of everyday language and programming-like elements.It’s called “pseudo” code because it’s not actually executable. Instead, it’s a way for humans to understand and plan out the logic in coding — to describe the steps of a program in a way that’s easy for humans to understand, while still being detailed enough to be rapidly converted into a specific programming language.Here’s a simple example of pseudocode, in which we’re working out the basic logic to greet a visitor by name when they navigate to our site or app:PROCESS GreetUser    INPUT userName    DISPLAY ""Hello, "" + userName + ""!""ENDEnter fullscreen modeExit fullscreen modeAs you can see, the above pseudocode isn’t written with syntax from any actual language or framework. Instead, it uses simple, universally understandable language and programming elements — like PROCESS, DISPLAY, and + — to stand in as syntax, making it simple for anyone to follow.That’s one of the powers of writing pseudocode: By laying the code’s intentions out in a common syntax, you can jump all programming and skill-based language barriers.How To Write PseudocodePseudocode's flexibility comes from its lack of specific syntax, which means there's no single correct way to write it. While languages like Pascal and Basic provide specific pseudocode rules, you can use any language or terminology, as long as it's universally understood and the logic is clear.Despite its open-ended nature, developers usually follow some basic pseudocode guidelines. Let's dive into these next.SequencesA sequence is a group of statements that are executed in a specific order. They’re used to perform or repeat a series of simple actions. Some familiar sequence commands commonly used in pseudocode include INPUT, SET, PRINT, READ, DISPLAY, SHOW, and CALCULATE.Here’s an example of pseudocode that uses some of these commands:PROCESS CalculateCost    INPUT price, quantity    SET cost = price * quantity    PRINT ""The cost is: "" + costENDEnter fullscreen modeExit fullscreen modeThis pseudocode defines a process called CalculateCost that takes in a price and quantity, multiplies them together to calculate the cost, and then displays the result.ConditionalsConditional statements allow a program to make decisions based on certain conditions, then direct the program to execute certain statements if a condition is met (or not met). IF-ELSE, IF-IF ELSE-ELSE, and CASE statements are frequently utilized in pseudocode.Here’s an example showing an IF-ELSE script in pseudocode:IF user = returning    PRINT ""Welcome back!""ELSE    PRINT ""Welcome!""Enter fullscreen modeExit fullscreen modeIn the above example, we’re describing a process that shows a “Welcome back!” message to users who have visited before, but shows only “Welcome!” to new users.IterationsIteration statements repeat a set of steps within a larger function or process. They’re often tasked to perform the same operation on multiple items in a list or to repeat a process until certain conditions are met.Iterations are useful for repeating a set of steps multiple times and can be implemented using various types of loops, including FOR, WHILE, and DO-WHILE loops.Let’s look at some pseudocode that uses a FOR loop to iterate through a list of numbers:PROCESS PrintWholeList    INPUT listOfNumbers     FOR each number in listOfNumbers    PRINT number    END FORENDEnter fullscreen modeExit fullscreen modeIn the above pseudocode, our PrintWholeList process takes in a list of numbers and then iterates through the list, displaying each number on the screen. The FOR loop allows the process to repeat the PRINT command for each item in the list.Alternatively, we could utilize the common pseudocode to accomplish the same as our above loop. In pseudocode, it’s more common to use the keywords REPEAT and UNTIL in place of DO-WHILE:PROCESS PrintWholeList    INPUT listOfNumbers     SET counter = 0    REPEAT    PRINT listOfNumbers[counter]    SET counter = counter + 1    UNTIL counter = length of listOfNumbersENDEnter fullscreen modeExit fullscreen modeAs shown here, we can switch out the names, keywords, and syntax pieces all we like. This is just one demonstration of pseudocode’s flexibility. The key is to ensure that the logic is stable while using names that are ubiquitous enough to be read by anyone.You can see some of these constructs used in the pseudocode examples we’ll work with later on.Pseudocode Examples and TranslationsHere are some examples of pseudocode, along with their translations into executable code in various languages and frameworks.PHPTo start, let’s write some pseudocode that’s meant to mimic the logic of adding up all the numbers in a given list:PROCESS FindTotal    INPUT listOfNumbers    SET sum = 0    FOR EACH number IN listOfNumbers    SET sum = sum + number    END FOR    PRINT sumENDEnter fullscreen modeExit fullscreen modeOur pseudocode logic follows these steps:Give the function a name.Get the list of numbers from the end user.Create a variable called sum to house the numerical total as it gets calculated.Iterate through every number in the list one by one, adding each number to the sum’s total.After all the numbers have been added, end the iteration (loop).Display the final sum obtained from adding all the numbers together.End the function.Now that we know the logic of our function, we can translate this pseudocode into any other language or framework. Let’s see what it might look like translated into PHP:function findTotal($listOfNumbers) {    $sum = 0;    foreach ($listOfNumbers as $number) {    $sum += $number;    }    echo $sum;}Enter fullscreen modeExit fullscreen modeNode.jsNext, let’s write some pseudocode we can use to check what the current time is for our visitors, then send them the appropriate greeting based on their time of day:PROCESS TimedGreeting    GET userTime    IF userTime > 6:00 + < 12:00    PRINT ""Good morning!""    ELSE IF userTime > 12:00 + < 18:00    PRINT ""Good afternoon!""    ELSE    PRINT ""Good evening!""ENDEnter fullscreen modeExit fullscreen modeOur pseudocode logic follows these steps:Give the function a name.Find the user’s time.If the user’s time is between 6:00 AM and 12:00 PM, show the message “Good morning!”If the user’s time is between 12:00 PM and 6:00 PM, show the message “Good afternoon!”For any other time, show the message “Good evening!”End the function.Translated into Node.js, it might look like this:function timedGreeting() {    const userTime = new Date();    if (userTime.getHours() > 6 && userTime.getHours() < 12) {    console.log('Good morning!');    } else if (userTime.getHours() > 12 && userTime.getHours() < 18) {    console.log('Good afternoon!');    } else {    console.log('Good evening!');    }}Enter fullscreen modeExit fullscreen modePythonFor our next example, let’s write some pseudocode to outline the logic for reversing a string (in this case, a sentence) that’s given to us by a user:PROCESS ReverseString    INPUT string    SET reversed_string = reverse of string    PRINT ""The reversed sentence is: "", reversed_stringENDEnter fullscreen modeExit fullscreen modeOur pseudocode logic follows these steps:Give the function a name.Prompt the user for a string and accept what they provide.Store the value of the user’s string variable.Slice the stored string value to reverse it, and store the result in a new variable.Display the reversed string on the screen.End the function.When translated to Python, it might look like this:string = input(""Enter a sentence: "")reversed_string = string[::-1]print(""The reversed sentence is: "", reversed_string)Enter fullscreen modeExit fullscreen modeIn some cases, your actual translated code will be shorter than your pseudocode. That’s fine. As long as your pseudocode’s logic is sound and your translated code functions as it should, you can disregard the discrepancies in length.💡 Got any other use-case idea for Pseudocode? Drop them below!"
210,"I am 35, I have been coding for 15 years and i am finding it boring now. How do you get past these slumps? Are slumps becoming more common? Please share your thoughts."
211,"  Table Of ContentsUnit TestsCI/CD PipelinesFeature FlagsConclusionAs a software developer, there's this awesome rush when you see your code bring new features to life. It's like watching your digital creations come alive!However, this excitement is often accompanied by the challenge of ensuring a smooth release that doesn't disrupt the user experience or introduce new bugs. In this post, we'll dive into the art of releasing features with confidence, exploring not only the basics but also when to use feature flags and A/B tests.  Automated tests and CI/CD pipelines  Unit Tests Before we embark on our journey of releasing features, it's essential to emphasize the importance of unit tests. Preferably written using Test-Driven Development (TDD), unit tests serve as the bedrock of your codebase, ensuring that individual components of your application function as intended.With TDD (writing tests before the actual code), you're compelled to think deeply about the code you write and potential edge cases, resulting in more robust and reliable code.  CI/CD Pipelines Continuous Integration and Continuous Deployment (CI/CD) pipelines automate the process of building, testing, and deploying your code.Like described in the video above (and with a few twists from my side), the ideal CI/CD pipeline for critical applications should include: 1) Source code integration step with installing dependencies, build or compiling the coderunning quality checks (for example SonarQube, linting, etc)running unit tests (quality of the unit tests can be checked with mutation testing)check and enforce code coverage2) Deploy to test environmentrunning integration tests3) Deploy to productionobservabilityalertsFor more critical systems or advanced use cases, a canary deployment strategy can be implemented. This means a gradual roll-out while traffic is gradually shifted from the old deployment to the new one.  Feature Flags and A/B Tests  Feature Flags Feature flags (FF), also known as feature toggles or feature switches, are a technique that allows you to enable or disable certain features within your application without deploying new code.There are many types of flags, but the most common would be to just turn a toggle on or off in a certain environment. Example of a FF: Google_Login (dev - enabled, stage - enabled, prod - disabled). The power here is that we can turn the feature flag off in case we discover a bug with the Google Login, so we don't need to do a rollback or even worse a hotfix. We just disable the flag in production, push a fix then re-enable it.Managing Feature FlagsIt's important to have a system (external or internally built) to easily manage feature flags. While FFs provide flexibility, it's essential to strike a balance. Keeping the number of active flags to a minimum reduces complexity and avoids potential confusion among developers. Just as you regularly refactor your codebase, it's important to remove old feature flags both from your code and your flag management system.  A/B Tests A/B testing, or split testing, involves comparing two versions of a feature or webpage to determine which one performs better. By dividing your users into two groups (A and B) and exposing them to different versions of a feature, you can gather empirical data to make informed decisions.How A/B Testing Works: A/B testing allows you to release a new feature or design change to a subset of your users while keeping the original version for another group. By comparing user behavior and engagement metrics, you can objectively measure the impact of the change.Primary & Secondary Metrics: When setting up an A/B test, it's essential to define primary and secondary metrics. Primary metrics directly measure the success of the feature, while secondary metrics provide additional insights. Analyzing both types of metrics helps you make well-rounded decisions.Example: We observe that only 2% of the traffic in our website results in a user signing for our newsletter. We do some UX research and come up with an updated design of the landing page, and we try it out in a A/B test. Our current page (the control group) and the variation are both served to our customers. During a 2 week period we observe the new page results in 4% of the traffic subscribing to thew newsletter. Succes!Clean-Up After A/B Tests: Just as with FFs, A/B test clean-up is crucial. Once you've collected enough data and made your decision, be sure to remove the code related to the alternative version, and also archive the test in the A/B test management system.   Conclusion Releasing features with confidence requires a delicate balance of foundational practices and advanced strategies. Automated tests instill thoughtfulness in your code, while CI/CD pipelines ensure consistent and reliable deployments. However, the real magic happens when you embrace feature flags and A/B tests.And it will also make you look cool, imagine you just discussed with the Product Manager whether to release that new stuff you worked on last 2 weeks, and he tells you to release it. You switch the feature toggle on, and there it is, one minute later.So while feature flags empower you to release and iterate on features with flexibility and control, A/B tests provide the empirical data needed to make informed decisions about the usefulness of the changes you are making in the software. "
212,"Hey folks 👋What y'all learning about this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Learn your way! 🧠"
213,"SUPPORTThe last known statistic about WordPress is that it runs 44% of the web. That's a lot of websites out there! Even with the growth of SAAS platforms like Squarespace, Wix, Webflow, etc. WordPress takes the cake. One major proponent to this is that it has a large open source community who keeps the core code maintained. There's also a healthy presence of third party software out there that adds substantial extensions to the over ecosystem. Everything from contact forms, image galleries, e-commerce features, data table displays, security settings, organization settings, etc. The plugin space for WordPress is HUGE!AFTER THE HONEYMOONAfter the launch of a new site, more often than not, we abandon the site to its owners. We don't have continuous contracts with our clients or perhaps they have moved on with another vendor to maintain or to redesign the site all over again.Obviously the cost of time and manpower is needed to maintain these sites. But what if the company doesn't have the luxury of paying someone to work on the site? Well, the way I see it from a developer standpoint, you either help the open source community and improve the overall system of WordPress or you volunteer your time to help maintain these sites. Most often, it is the non-profits out there who are in need of some assistance.I know there are those who may frown upon the idea on working for an unpaid website project, but that's no different than offering your time to maintain open source code. You're not getting paid to work on the project. In the end, your work is shared amongst developers and other companies abroad, showcasing your work. You're adding value and reassurance to the owner of the site that WordPress isn't just a one off tool that should be replaced after a year or two. Someone has suggested the software in the past, but they did not continue to help maintain it. However, YOU can jump in at anytime and offer the assistance.For me, I think being the constant gardener and helping out companies such as non-profits who need assistance is just as vital. Your open source code may benefit other technologies down the road, but in my view, helping an established non-profit's business objectives by maintaining their site has a greater impact on society.PART-TIMEI have never contributed to open source code except for when I worked at a large software firm in the past. There's probably a lot of good value in contributing and helping out technology. There's also lessons to be learned with moving parts within a larger system and also working with multiple developers towards a common goal or release version. What I don't know is how much a typical developer provides his or her time to the technology on a weekly basis. There probably is a strict timeline. Helping out non-profits is a completely different timeline all together. Ever since I started juggling these projects, I have to keep tabs on my own. I utilize Toggl to keep track of my hours. Even though these projects are unpaid, I like to keep a tally of how much time I am investing. Because there are other organizations out there that could use my assistance.ALL HUMANRemember, we're all human. No matter which path you take. Either open source or helping in assisting non-profits. There's a great deal of finesse one has to consider when mitigating each project. In open source technology, you would have to work with like minded developers in bringing together a new feature. With non-profits, not everyone is tech savvy and they will rely more on your expertise to do the job correctly.My most recent project involves moving a website from a UK hosting server to a US based hosting provider. The site was often down, more than 24 hours at a time, and this prevented the owner from accepting donations and promoting their campaigns. I got together with the owner and two others who are more IT centric and brainstormed on a more viable web hosting platform. Since I am not familiar with the realms of deep IT nuances, I rely on their judgement call. My roll comes later when I need to secure all site assets, secure the current copy of the database, update WordPress core, and update Elementor, which is their theme builder of choice.The owner entrusts all to do their part in getting the site up and running again. By the way, each and every one of us are volunteers. We can only devote so much time, but we are also ensuring that if one of us leaves, there is a good safety net set in place for the owner to debug on their own if they need to.CONCLUSIONIn the end, I recommend everyone to devote some time to help out others whether it is paid or unpaid. Giving back to the community is important. If you're a WordPress user and would like to help out the open source community, you can check out Make WordPress. And if you want to help out a non-profit organization with their website (even if it is not WordPress based), you can checkout VolunteerMatch.Let's all go out there and make a difference!This was initially published on my site at jameslau.com (https://jameslau.com/the-constant-gardener/). Please come by and check out more of my writing and other works!Thanks for reading!"
214,"If you’re starting out in writing, you probably have little idea about what to blog about and where to do it, but the last thing you want to do is to follow my mistakes. Take a look at my journey, and find answers to these questions.Table of contentsStarting out 👶The mistake 🤦‍♂️Reflection 🤔Learning and building in public 🧠You document your progressYou meet new people, give and get help along the wayYou make notes about what you’re studying, which helps you remember it.This ignites your motivation to continue learning and building.You build your brand, but that’s secondary.If you want to start 📣What blogging platform?What am I going to do? 📅1. Teaching is not the best learning technique!2. It takes A LOT of time for little gainPlans for the futureChallenge 💪My SMART goalConclusion  Starting out 👶In March this year, I registered on DEV community. I vaguely imagined what was the actual reason for doing that. But what I knew for sure, was that coding alone, I wouldn’t go far. The initial plan was to share my programming notes to possibly help others and gain followers. This way, I wanted to show myself to the world and meet new people.To realize these plans, I started making tutorials about what I was learning. That’s because no one would’ve read my notes unless I’d made guides from them. And I discovered that these were not easy to make. It, first of all, took A LOT of time. But being goal-oriented, I tried to make everything to get them popular, to read how I can make my tutorials better, improve them in various ways, learn about SEO, and even switch the platform.  The mistake 🤦‍♂️But that approach turned out to be a mistake. I found myself learning things only for the sake of making tutorials. In fact, now I have bad impressions of multithreading in Java, only because I spent a lot of time on that. Although this knowledge will certainly come in handy, I could be so much better off doing what I do now. I’ve loved writing since my childhood. But, honestly, I didn’t really enjoy the process when I was writing those articles. In addition, except for the one that was successful, they didn’t get very popular and useful for others. So I decided to turn up to @jmfayard for some advice. He told me a very interesting thing that got stuck in my head for a long time:On your blog, you are currently writing about race exceptions, threads, that kind of Java things.If I had magical growth hacking techniques, and would make your blog more popular, what kind of people would you attract?The kind of people whose primary interest are race exceptions in Java and such technico-technical questions.There is no point in going faster in the wrong direction. Start writing about you and your projects. Write for and with your real audience.I was relieved that I found a solution to my problem and that I no longer needed to write those tutorials. And it seems very logical, cause what you do should be aligned with your goals. My goals are:I want to meet new people and showcase my work to others. My dream is to work in a team of passionate developers who are friends with each other and work together.I think that communication is one of the key things on the way to success, and a very important one if I want that dream to come true. Attracting people that are interested in me, not in my tutorials, makes so much sense here. And while I chose the right blogging platform that meets my goals, I wasn’t doing the right things there.  Reflection 🤔However, my initial plans and ideas didn’t come from nowhere. And if you do the same thing, you probably didn’t come up with this idea yourself.Lots of people make tutorials and succeed. There are many good educators whom I follow and who give out very helpful information in an understandable way, and help lots of other devs. I think, there is some part of their followers, who are interested in them and are ready to work with them if they invite. And the bigger audience they have, the more people are in that part.Educating work assures a potential recruiter about your experience in a certain field. Teaching others is also known as a great learning technique. What if I possess a latent passion for educating and if I make things right, I'll enjoy the process and achieve my desires?So, I was torn between these two, by sight, contradicting choices. I couldn’t start doing both because I usually do something only when I clearly see what my goals are and how I achieve them.The common sense pushed me to choose the second approach. But, I didn’t know what I could write about myself and my projects, unlike when it comes to writing about technical things.Meanwhile, life went on, I engaged on DEV, and once found a post about the Virtual Coffee community. I was interested by the described level of communication. There were regular Zoom conferences and a Slack channel where people could support each other, give and get advice, talk about their wins and challenges, and work together. I was really impressed by how all of these meet my goals, I could also get an opportunity to speak to native English speakers for the first time in my life. Imagine my surprise when I found out that I was approved to enter!But the reason I’m telling you that is that Virtual Coffee was exactly what caused me to discover the learning and building in public concept. Before that, I’d, honestly, found things like the following weird:What was your win this week?Michael Tharrington for The DEV Team ・ Jul 28#discuss#weeklyretroWhat you learning about this weekend?Michael Tharrington for CodeNewbie ・ Jul 29#codenewbie#discuss#learning#beginnersBuild in Public: Week One Check-inBekahHW for Virtual Coffee ・ Jul 7#beginners#learning#discussI thought, like, “Who cares about what you are learning or building?” and didn’t understand the guys who shared this info.People are selfish. They wanna find something valuable for themselves in your articles.But the warmth of the Virtual Coffee community in their monthly challenge, caused me to do some more research on this topic.  Learning and building in public 🧠It appears that:some people actually do care;that’s exactly you who should not care whether somebody cares or not.I tried to see things from a different perspective. What do people who share their progress get? Turns out there are plenty of benefits:  You document your progress 📝You don’t just blindly go in an indefinite direction. You track your progress by regularly writing about what you achieved, what setbacks you encountered, and what your future plans are. When you face up to a challenge, you can look back, appreciate how far you've come, and how many adversities you’ve already encountered, and get determined and motivated to continue.Moreover, it may be even beneficial to your career, cause future employers will see the evidence that you've gained the knowledge over time.  You meet new people, give and get help along the waySharing your journey sparks a conversation, and lets you meet new people. Talking about ourselves is what we are usually doing in daily conversations, that's what creates new relationships.There are so many people, who faced and will face the challenges you encounter, so you may give help to less experienced, and get it from more experienced.   You make notes about what you’re studying, which helps you remember it.As explained in the “Make It Stick” book, recalling what you’re learning helps to put that knowledge into long-term memory, and is a great studying technique.Everything gets forgotten over time though, no matter how hard you try. But taking notes minimizes forgetting. It will be also easier to recall the knowledge if you have notes.   This ignites your motivation to continue learning and building.To my mind, the most important benefit of this activity is that making some public promises forces you to continue learning and building consistently. If I promise to post at least 5 tweets and 1 article a week documenting my progress, I’ll not break this promise. That’s because people will expect me to do that, and if I don’t, they’ll see me as a not responsible person.  You build your brand, but that’s secondary.Your blog may get many views, after all. If that happens, you achieve all of these goals. Your next project will get seen and used, your future employers will appreciate your audience, your knowledge, and your experience. However, this benefit is secondary. You write for yourself in the first place. You actually get most of the benefits even if you do it privately, publicity only introduces some more cool things and motivates you. Following this approach and trying to become famous is the last thing you wanna spend time on. Here is the reasoning ⬇️BTW, I also started to notice that even educators don’t post only about technical things. Talking about their journeys and giving advice to other devs is an integral part of their work. For example: Florian Walther, Donn Felker, Rahul Pandey.  If you want to start 📣If you plan to start learning and building in public, definitely check out this post ⬇️ for lots of valuable advice from an experienced person.How to learn in publicRizèl Scarlett ・ Dec 18 '22#learninpublic#career#leadership#community  What blogging platform?Speaking about the blogging platform, I’ll never regret choosing DEV, cause thanks to this platform, I found Virtual Coffee. I feel like DEV is the most suited for my needs.If you, like many people, also consider Medium, DEV is about the community, whereas on Medium you’re a product. They aim for their membership program. I don't want my articles to ever become paid.There are other platforms, but if you're on DEV and like it here, why not stay? For people like me, I see little benefit in cross-posting unless you have your own website or cross-post to LinkedIn.I think, having a personal website is great in terms of promoting, being a better specialist in the eyes of an employer, keeping all your work in one place, and owning it. But blogging on DEV is also a great thing to do. Don't wait until you get a website or any other resource that stops you from doing what you want.  What am I going to do? 📅All of those look appealing, but what did you decide at the end, Daniel?Well, first of all, I’m certain that tutorials are not a way to go. That’s still a great way if you want to be an educator, but I don’t. Here is what I’m passionate about ⬇️Daniel RendoxFollowA junior Android developer with a passion for sharing knowledge, communicating with people, and a never-ending curiosity.And if you’re in a similar position, I would encourage you to consider learning and building in public instead of making tutorials because of these two reasons:  1. Teaching is not the best learning technique!There are many people who will tell you the opposite. Lies! There has never been a better learning technique than practice.University professors may know more, but they don’t do a good job if they don’t practice in side projects, or don't work at some company. On the contrary, good educators often work as freelancers or make their own projects. I don’t argue that teaching is great. It's the best after practice. It's great when you quickly explain a learned concept to your mate, but a different story when you spend a lot of time when you could be better off applying that knowledge to personal projects.  2. It takes A LOT of time for little gainAs I see it, to get successful in educating, you should do that seriously and firmly by growing your social media, publishing consistently, eventually transitioning to YouTube, etc. Otherwise, you will not get popular and will not make a profit from this. Therefore IMO, this does not worth that amount of time.In addition, there are lots of people who are already in that business. They are doing well. The are a lot of great learning resources nowadays. So there is a lot of competition and if you want your guides to really help people, you should make them better than existing ones.  Plans for the futureHowever, understand me correctly, if I’m learning a difficult topic and I don’t seem to find any resources that would explain it well, I’ll certainly make my own article with an explanation. That’s what I did in this post ⬇️Delegation vs Inheritance in KotlinDaniel Rendox ・ Jul 5#kotlin#tutorial#oop#programmingOn the other hand, the concept of learning and building in public combines almost all the benefits of talking about your journey and writing about technical things. This approach is the most suited for beginners. That’s what I plan to do in the first place.And I’ll try to make these posts helpful for other people so that they could benefit from my journey and get some advice.And there are also general topics when you write about your experience in life, programming, etc. This, obviously, attracts more people than some tutorials about Race conditions. And these people are my real audience. That’s what I plan to do in the second place.  Challenge 💪For me, this idea of learning and building in public seems very exciting. This really stirs up my productivity soul, taking into account that last time I’m trying to stabilize my schedule. So I wanna take the following challenge:At the end of each day, at least 5 days a week I’ll post on my Twitter about what I’ve learned and made today.And over on DEV, I'll write at least 1 summary article every week, talking about what I did, what I learned, my wins, and difficulties.  My SMART goalSpecific: I want to learn Android to get a freelance job and create an Android app to practice my skills, get myself organized, and help other people.Measurable: I'll spend at least 40 hours a week learning and working.Attainable: I'm already familiar with Jetpack Compose, Kotlin, and the View system, so I have about 30% knowledge of Android.Relevant: After I achieve my goal I see further development in Kotlin multiplatform, Android is widely used and in demand, and I’ll certainly get relevant knowledge that’ll come in handy in my career.Time-bound: I’ll give myself 2 months. In this period of time, I should have the app with the basic functionality.The challenge starts today!  ConclusionSo write about you and your projects. Absolutely recommend considering learning and building in public. Don't care much about getting famous, write for yourself in the first place.With that being said, I think I'm on the right way now, I hope you're too, my dear reader. Either way, let's just do what we like and follow our passion."
215,"  IntroI'm a big fan of Backstage.If you don't know what Backstage is, have a look on this short video:  Software templatesThere is a lot of interesting features in Backstage, but one of my favorite is the Software Templates. This feature is already well explained by Ricardo Castro on dev.to.I like this feature because it permit what I call ""standardization by ease"", in opposition to standardization by constraint when somewhere in your organization, a ""code police"", impose a law without telling how to implement it in your code.With Software Templates, you can provide to your developers some state-of-the-art project (in term of coding, ci/cd, security, documentation) which will be automatically pushed in a repo of your scm system (Github, Gitlab  Bitbucket, ...). And they will follow the best practices because it helps them.Software Templates can also be used to onboard an existing component in Backstage by creating a pull request (on Github) or a merge request (on Gitlab) which propose to the project to add in the repo the catalog-info.yaml file used by Backstage to index the project.  Learn from the communityThe best way to start with Software Templates is to learn from others.The first place to learn is, of course, the Backstage documentation.But, in my opinion, it's easier to see how others are building their templates. For that you should have a look on:Backstage's Github, simple but very good to begin,Janus's Github which shows, among many other interesting things, a way to share some piece of templates,Roadie's Github where you can find some tips  to debug your templates  Use Backstage toolsWhen you begin on Software Templates, as for any other languages, you make mistakes and it's a little bit boring to modify your code, to push it in your Software Templates repository, then to try it in Backstage, to see it does not work.Fortunately, Backstage will help you with that. There is a special place in Backstage for trying and tuning your templates. You can try it on https://YourBackstageInstance/create/edit. For instance, on the janus showcase portal:  Edit template formWhen you click on Edit template form, you access to a place where you will be able to write your template, and to see immediately if it works:  Custom field explorerParaphrasing the documentation of Backstage, collecting input from the user is a very large part of the scaffolding process and Software Templates as a whole. These input are made in software templates by using custom fields, for instance the Repository Picker.Sometimes, it's not easy to understand all the possibilities of these objects.Here again, you can explore them with the custom field explorer, for instance the OwnerEntityPicker:In this example, we add group in allowedKinds to limit the choice on groups, and we can see immediately the result:   Built-in actionsThere are three parts in a software template:the parameters where you get inputs from your customerthe steps where you do some things with information collected in the first partthe output where you give some information to your customer about the tasks done by the template.To do things in steps, you use builtin actions, and all these actions are not listed in the documentation. But there are listed directly in the application on https://YourBackstageInstance/create/actions. For instance, on the janus showcase portal:It's very useful when you want to know all capabilities of an action, for instance publish:gitlabSome actions have even some examples:  ConclusionTo faster you Backstage Software Templates learning curve:learn from the communityuse Backstage embedded toolsask for help on Backstage's discord"
216,"This week we're chatting all things remote work, and we want to hear from you about your experiences, pros, cons, and advice for those transitioning or considering remote work options.Let's dive into today's topic of conversation... Share your experience transitioning to remote work and how it affected your daily routine. What challenges did you face in adapting to the new work environment, and how did you overcome them?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
217,"As AI tools improve to aid software development, it is increasingly noticeable how language-specific semantics and syntax become obsolete, as well as libraries and frameworks. Tools like Github Copilot and Amazon's Code Whisperer translate intent from the developer and deliver the block or algorithm done, with few or no adjustments it is possible to have entire code pages working.A possible collision and intersection of all languages and frameworks for a single development package is expected for the future, probably as machine-optimized as possible, since we will only interact with AI to develop our systems.In DevOps we can already find tools like AWS Copilot, a tool capable of automatically creating deployment flows, based on the best configurations made by specialists over the years.To say that a person has a better capacity to validate an algorithm than an AI is a contentious statement, it would take several years of study for someone to be able to beat a machine that already has all this information, however it is necessary to take some care so that the instructions are provided appropriately.The AI Developer will be at the forefront of decision-making with the business that is intended to be served, he will have to develop skills much more similar to that of a salesperson than a technician, he will need to understand the business in order to deliver the best solution, he will practically configure the solution intended by the customer.Obviously, this all sounds simple in words, but those who have already taken the AWS, Azure or GCP certifications know that there are countless possibilities to solve the same problem, and that from the point of view of business, budget and customer needs.Conclusion:In my view, highly technical people will continue to work behind AI tools for a long time, as there is a need to code them, until one day they can solve their own limitations and upgrade themselves.The current developer, who is not working with AI development needs to start thinking more like an architect and salesperson and look to solve real world problems with the help of AI, as the software developer will not exist in a few years, but to do maintenance or migrating existing code bases. Why not create tools to migrate codes or systems?Despite everything read above, the future looks promising, in all my career I met few people really dedicated to technology, many used it only as a business or a means to an end, from now on, I begin to realize that the market will need extremely technical people (scientists) while the rest will look more like business consultants to meet market needs."
218,"This post is based off a talk given at Google I/O Extended for Google Developers Group London in July 2023. The slides for the talk are available hereIt’s hard to imagine Jetpack Compose 1.0 was released in July 2021. Fast forward two years and with 24% of the top 1000 apps on Google Play adopting Compose it’s easy to understand why.Amongst all the excitement, one corner of Modern Android Development I feel recieves little attention is Google Maps. It’s been a while since I used the SDK, so was pleasantly surprised to see Google Maps was catching up with the times and released their own Compose library.This will be welcome news to companies & engineers working in the mapping space. Mobile mapping is a $35.5B industry, with predictions of it raising to $87.7B by 2028. An Compound Annual Growth Rate (CAGR) of 19.83%. SourceWhy is this important? A bigger market means more opportunities for companies to derive revenue from applications of mobile mapping. These range from the usual use cases, food, grocery delivery and ride hailing services. If you dig deep however, there are applications that aren’t immediately obvious. Below are the examples I could find after a brief search.Mobile maps are great for Smart Cities, helping to manage the heartbeat of a city and visualising data in a way to better understand and react to its challenges. Useful for city planners, emergency response organisations or everyday residents.Resource management also benefits from mapping solutions. Ranging from agriculture to fishing, mining to forestry, maps provide those in this line of work a perspective to make the right decisions to harvest materials in a sustainable way.Transportation relies heavily on mapping technology. Not just consumer apps like Google Maps or Uber, but business level functions like understanding what a businesses fleet of vehicles are located. Transportation agencies also use maps to manage traffic and help make decisions on where to direct traffic to ease the flow.Finally, with climate change and the weather being increasingly unpredictable, maps allows meteological agencies, emergency response units, and wildlife conservationists to understand how our world is changing and what we can do to take positive steps to reduce this.Sources: Mordor Intelligence, GMInsights, Allied Market Research, EMR Research, Google Earth Outreach, Research & MarketsWith the world providing more and more data, it’s a good time to learn how to put that data on a map. Let’s do that and get back to the code.Using Google Maps for ComposeGoogle Maps for Compose relies on the following dependencies:dependencies {  implementation ""com.google.maps.android:maps-compose:2.11.4""  implementation ""com.google.android.gms:play-services-maps:18.1.0""  // Optional Util Library  implementation ""com.google.maps.android:maps-compose-utils:2.11.4""  implementation 'com.google.maps.android:maps-compose-widgets:2.11.4'  // Optional Accompanist permissions to request permissions in compose  implementation ""com.google.accompanist:accompanist-permissions:0.31.5-beta""}Enter fullscreen modeExit fullscreen modeGoogle Maps for Compose is built on top of the Google Maps SDK, so you need to import the Compose library and the maps SDK. You won’t need to use most objects in the Google Maps SDK, as the compose library wraps most of these in Composables.The utils and widgets libraries are an optional dependency. The utils library provides the ability to cluster markers on the maps, whilst widgets provides additional UI components. You’ll see these in use later.For this post, I’ve included the request permissions library from Accompanist to demonstrate how to request location permissions, an often used permission with maps. Accompanist is an experimental library for Google to try out and gather feedback for features not yet part of Jetpack Compose.Finally, you need to go to the Google Developer Console, sign up for a Google Maps SDK API key, and add it to your project. There’s a guide on the Google Maps Developer Docs on how to do this.Security Tip: In the Google Developer Console lock down your API key so it only works with your application. This is avoids any unauthorised use.Showing a MapShowing a map is as simple as below: setContent {    val hydePark = LatLng(51.508610, -0.163611)    val cameraPositionState = rememberCameraPositionState {        position = CameraPosition.fromLatLngZoom(hydePark, 10f)    }    GoogleMap(        modifier = Modifier.fillMaxSize(),        cameraPositionState = cameraPositionState) {            Marker(                state = MarkerState(position = hydePark),                title = ""Hyde Park"",                snippet = ""Marker in Hyde Park""            )        } }Enter fullscreen modeExit fullscreen modeCreate a LatLng object with the position of an area, and use it in conjunction with rememberCameraPositionState to set the initial position of the camera. This method remembers the position of the map as you move about using your hands or programmatically. Without this method Compose would recalulate the map back to its initial position on every state change.Next, create a GoogleMap compose and pass in a modifier of your choice and the camera state. GoogleMap also provides a Slot API to pass in additional composables, these composables are what you want to draw on the map.Add a Marker composable, then add a MarkerState containing the position of the marker inside. Finally, add a title and description of the marker.Running this gives a nice aerial view of West London with a marker in Hyde Park.Customising the Marker WindowYou can customise the window of the marker by using a MarkerInfoWindowContent Composable. This also has a slot based API, meaning you can pass in your own composables to render your custom UI in the window.setContent {    val hydePark = LatLng(51.508610, -0.163611)    val cameraPositionState = rememberCameraPositionState {        position = CameraPosition.fromLatLngZoom(hydePark, 10f)    }    GoogleMap(        modifier = Modifier.fillMaxSize(),        cameraPositionState = cameraPositionState) {            MarkerInfoWindowContent(                state = MarkerState(position = hydePark),                title = ""Hyde Park"",                snippet = ""Marker in Hyde Park""            ) { marker ->                Column(horizontalAlignment = Alignment.CenterHorizontally) {                    Text(                        modifier = Modifier.padding(top = 6.dp),                        text = marker.title ?: """",                        fontWeight = FontWeight.Bold                    )                    Text(""Hyde Park is a Grade I-listed parked in Westminster"")                    Image(                        modifier = Modifier                            .padding(top = 6.dp)                            .border(                                BorderStroke(3.dp, color = Color.Gray),                                shape = RectangleShape                            ),                        painter = painterResource(id = R.drawable.hyde_park),                        contentDescription = ""A picture of hyde park""                    )                }            }        }}Enter fullscreen modeExit fullscreen modeRunning this shows the custom window above the marker when you tap on it.Showing multiple markersShowing multiple markers is as simple as adding as many as you need. Let’s add markers for a few different parks in West London. setContent {    val hydePark = LatLng(51.508610, -0.163611)    val regentsPark = LatLng(51.531143, -0.159893)    val primroseHill = LatLng(51.539556, -0.16076088)    val cameraPositionState = rememberCameraPositionState {        position = CameraPosition.fromLatLngZoom(hydePark, 10f)    }    GoogleMap(        modifier = Modifier.fillMaxSize(),        cameraPositionState = cameraPositionState) {            // Marker 1            Marker(                state = MarkerState(position = hydePark),                title = ""Hyde Park"",                snippet = ""Marker in Hyde Park""            )            // Marker 2            Marker(                state = MarkerState(position = regentsPark),                title = ""Regents Park"",                snippet = ""Marker in Regents Park""            )            // Marker 3            Marker(                state = MarkerState(position = primroseHill),                title = ""Primrose Hill"",                snippet = ""Marker in Primrose Hill""            )        } }Enter fullscreen modeExit fullscreen modeRun the code and you will see your markers appear on the map.Clustering MarkersA map can get busy within a short amount of time. If you’re trying to show 300 markers, it’s going to be visually hard for a user to understand what is going on. Google Maps and your device won’t thank you ether, since it will have to render every single marker, impacting performance and battery life.The solution to this is Clustering, a technique grouping markers close to each other into a single marker. This Clustering happens on a zoom level basis. As you zoom the map out the markers will group together into a cluster, as you zoom in the cluster will split into individual markers.Google Maps for Compose provides this out of the box via a Clustering composable. There’s no need to write complex sorting or filtering for the clustering to occur. setContent {    val hydePark = LatLng(51.508610, -0.163611)    val regentsPark = LatLng(51.531143, -0.159893)    val primroseHill = LatLng(51.539556, -0.16076088)    val crystalPalacePark = LatLng(51.42153, -0.05749)    val greenwichPark = LatLng(51.476688, 0.000130)    val lloydPark = LatLng(51.364188, -0.080703)    val cameraPositionState = rememberCameraPositionState {        position = CameraPosition.fromLatLngZoom(hydePark, 10f)    }    GoogleMap(        modifier = Modifier.fillMaxSize(),        cameraPositionState = cameraPositionState) {            val parkMarkers = remember {                mutableStateListOf(                    ParkItem(hydepark, ""Hyde Park"", ""Marker in hyde Park""),                    ParkItem(regentspark, ""Regents Park"", ""Marker in Regents Park""),                    ParkItem(primroseHill, ""Primrose Hill"", ""Marker in Primrose Hill""),                    ParkItem(crystalPalacePark, ""Crystal Palace"", ""Marker in Crystal Palace""),                    ParkItem(greenwichPark, ""Greenwich Park"", ""Marker in Greenwich Park""),                    ParkItem(lloydPark, ""Lloyd park"", ""Marker in Lloyd Park""),                )            }            Clustering(items = parkMarkers,            onClusterClick = {                // Handle when the cluster is tapped            }, onClusterItemClick = { marker ->                // Handle when a marker in the cluster is tapped            })        }}data class ParkItem(    val itemPosition: LatLng,    val itemTitle: String,    val itemSnippet: String) : ClusterItem {        override fun getPosition(): LatLng =            itemPosition        override fun getTitle(): String =            itemTitle        override fun getSnippet(): String =            itemSnippet}Enter fullscreen modeExit fullscreen modeNotice the ParkItem data class added. We need this because items passed into a Clustering composable have to conform to the ClusterItem interface. The interface provides the Cluster with the position, title and snippet for each marker.Zoom in and out, and you’ll see the clustering in action.Getting Location PermissionMaps and user position often go hand in hand, so it makes sense for some mapping apps to ask permission for the users location.Treat a users permission with respect if you do this, location permission is one of the most sensitive permissions to acquire from a user. Make sure you inform the user of why you need this permission and actively show the benefits of granting it. Bonus points if your app partially functions without the need for permission at all.Google provide some great guides on how to handle users location, as well as a separate guide for accessing location data in the background.So you’ve done your due diligence and decided you do need the users permission to access location. With the permissions library in Accompanist you do it like so:// Don't forget to add the permissions to AndroidManifest.xmlval allLocationPermissionState = rememberMultiplePermissionsState(    listOf(android.Manifest.permission.ACCESS_COARSE_LOCATION,           android.Manifest.permission.ACCESS_FINE_LOCATION))// Check if we have location permissionsif (!allLocationPermissionsState.allPermissionsGranted) {    // Show a component to request permission from the user    Column(        horizontalAlignment = Alignment.CenterHorizontally,        verticalArrangement = Arrangement.Center,        modifier = Modifier        .padding(horizontal = 36.dp)        .clip(RoundedCornerShape(16.dp))        .background(Color.white)    ) {        Text(            modifier = Modifier.padding(top = 6.dp),            textAlign = TextAlign.Center,            text = ""This app functions 150% times better with percise location enabled""        )        Button(modifier = Modifier.padding(top = 12.dp), onClick = {            allLocationPermissionsState.launchMultiplePermissionsRequest()        }) {            Text(text = ""Grant Permission"")        }    }}Enter fullscreen modeExit fullscreen modeVia accompanist we’re checking to see if the app has access to the ACCESS_FINE_LOCATION permission, or a high level of GPS accuracy in english. It’s important to include the requested permissions in the Android manifest, as you won’t be able to request the permissions otherwise. The Android system and Google Play store also use the manifest to understand how your app works and inform users.If permission isn’t granted, a small dialog composable is shown explaining the need for the permission and a button to launch the permission request via the system.Animating the MapWhilst most map apps require a user to move the map via touch, Google Maps for Compose provides APIs to move the map programmatically. This can be useful if you want to navigate to an specific area in response to an event.In this example, we’ll gently navigate the app through our collection of markers.Box(contentAlignment = Alignment.Center) {    GoogleMap(        modifier = Modifier.fillMaxSize(),        cameraPositionState = cameraPositionState    ) {        Clustering(items = parkMarkers,            onClusterClick = {                // Handle when the click is tapped                false            }, onClusterItemClick = { marker ->                // Handle when the marker is tapped            })        LaunchedEffect(key1 = ""Animation"") {            for (marker in parkMarkers) {                cameraPositionState.animate(                    CameraUpdateFactory.newLatLngZoom(                        marker.itemPosition, // LatLng                        16.0f), // Zoom level                      2000 // Animation duration in millis                    ),                    delay(4000L) // Delay in millis            }        }    }}Enter fullscreen modeExit fullscreen modeThe key part here is the code inside the LaunchedEffect. For each marker the app sets up a cameraPositionState.animate() call to navigate to the marker. The camera receives this information via an update to the camera, created using CameraUpdateFactory.newLatLngZoom().This method takes a LatLng, a float indicating the zoom level of the map and a long to set the duration of the animation.Finally, to space the animations we use delay() to add a 4 second pause between each animation.Showing Street ViewIt’s not just an aerial map Google Maps for Compose helps you with. You can also give apps access to Street View, showing a 360 view of a location. You do this by using the StreetView composable:var selectedMarker: ParkItem? by remember { mutableStateOf(null) }if (selectedMarker != null) {    StreetView(Modifier.fillMaxSize(), streetViewPanoramaOptionsFactory = {        StreetViewPanoramaOptions().position(selectedMarker!!.position)    })} else {    Box(contentAlignment = Alignment.Center) {        GoogleMap(            modifier = Modifier.fillMaxSize(),            cameraPositionState = cameraPositionState        ) {            Clustering(items = parkMarkers,            onClusterClick = {                // Handle when the cluster is clicked                false            }, onClusterItemClick = { marker ->                // Handle when a marker in the cluster is clicked                selectedMarker = marker                false            })        }    }}Enter fullscreen modeExit fullscreen modeIn this example, we’re setting the selectedMarker variable whenever a marker is tapped. If a marker is selected we show Street View, passing in the position of the marker.Drawing ShapesYou may want to draw your own shapes and annotations onto the map. Google Maps for Compose provides a number of composables to do this, in this post we’re going to use the Circle composable.A circle is a good shape to use if your app uses Geofences to react to changes from a users location. A circle can represent the area a geofence is active within. Box(contentAlignment = Alignment.Center) {        GoogleMap(            modifier = Modifier.fillMaxSize(),            cameraPositionState = cameraPositionState        ) {            Clustering(items = parkMarkers,            onClusterClick = {                // Handle when the cluster is clicked                false            }, onClusterItemClick = { marker ->                // Handle when a marker in the cluster is clicked                selectedMarker = marker                false            })        }    }    parkMarkers.forEach {        Circle(            center = it.position,            radius = 120.0,            fillColor = Color.Green,            strokeColor = Color.Green        )    }Enter fullscreen modeExit fullscreen modeHere, we setup a circle for each of our markers. Creating a circle involves passing it a position and the size of the radius for the circle. We also use two optional parameters to set the color of the border and fill color for the circle.Showing a ScaleBarA good map often comes with legends and diagrams showing what a measure of space on the map is equivalent to in distance. This gives you an idea of the spaces involved in the map, as not every map may use the same form of measurements.For digital maps that can zoom in and out, this adds a particular layer of complexity as the distances represented can change dynamically. Fortunately, Google Maps for Compose has you covered.Using the Widgets library, you gain access to the DisappearingScaleBar and ScaleBar composables. These are UI components that sit at the top of the map, providing users with a measure of distance that changes depending on the zoom level. Box(contentAlignment = Alignment.Center) {        GoogleMap(            modifier = Modifier.fillMaxSize(),            cameraPositionState = cameraPositionState        ) {            // You can also use ScaleBar            DisappearingScaleBar(                modifier = Modifier                .padding(top = 5.dp, end = 15.dp)                .align(Alignment.TopStart),                cameraPositionState = cameraPositionState            )            Clustering(items = parkMarkers,            onClusterClick = {                // Handle when the cluster is clicked                false            }, onClusterItemClick = { marker ->                // Handle when a marker in the cluster is clicked                selectedMarker = marker                false            })        }    }    parkMarkers.forEach {        Circle(            center = it.position,            radius = 120.0,            fillColor = Color.Green,            strokeColor = Color.Green        )    }Enter fullscreen modeExit fullscreen modeAfter adding the composable, you get a ScaleBar that changes depending on the zoom level at the top of the map.Help and SupportGoogle Maps for Compose is a great way to work with Google Maps and there’s plenty more to learn. Here are a few places I recommend if you need help:Google Maps for Compose Repo: The repo containing the source code for the library. Contains code samples on how to use the library and also where you can submit your bug reports and contributionsGoogle Maps for Android Website: The place to go to learn the concepts behind Google Maps for Android. These are high level and don’t use the Compose library, but are nevertheless important to know as these are used in the background.Google Maps Platform Discord The official Discord server for Google Maps. Here you can find people discussing Google Maps for multiple platforms, asking and offering help, and showcasing their own work."
219,"While building web apps, I usually like to take inspiration from other sites. I'm always fascinated by beautifully designed websites with subtle yet cool animations. Vercel is one of those sites I really like as a web developer. Also, Vercel's design & frontend team is one of the best out there. So, a few days back while I was deploying one of my apps on Vercel, I noticed there navbar component had a subtle hover animation which felt really smooth. Basically, what was happening was that each navbar link / tab had a background color which would follow the cursor on hover over the navbar. Since, I'm currently building the next version of my personal site (using Next.js v13), I decided to implement it in my site as well. You can think of this article as a guide to creating the navbar yourself! Here's what the navbar will look and work like -   First StepsI already mentioned earlier that the site is being built using Next.js v13. So, the first thing you would need to do is scaffold a next app using this command. While doing this, you will get prompted about whether you want to add Tailwind to the project, make you're you add it and also make sure you use the app directory and /src folder so that we are on the same page while working -pnpm create next-app@latestEnter fullscreen modeExit fullscreen modeThe next thing would be to install the dependencies required, mainly Framer-Motion in this case -pnpm i framer-motionEnter fullscreen modeExit fullscreen modeStart the dev server -pnpm devEnter fullscreen modeExit fullscreen modeNow that we have our basic project ready, we can start building the navbar!  Building the Navbar componentLet's create our basic styled navbar component first and it to our global layout file in the project. If you're not familiar with what a layout file is - it's basically a new file type introduced in Next.js v13 which can be used to create the layout for your site. By default, Next.js would create a layout file for you in the root of your app named layout.tsx. Create a /components folder inside your /app directory and create a file named Navbar.tsx inside it.// src/app/components/Navbar.tsx""use client"";import { usePathname } from ""next/navigation"";import Link from ""next/link"";const navItems = [  {    path: ""/"",    name: ""Home"",  },  {    path: ""/now"",    name: ""Now"",  },  {    path: ""/guestbook"",    name: ""Guestbook"",  },  {    path: ""/writing"",    name: ""Writing"",  },];export default function NavBar() {  let pathname = usePathname() || ""/"";    return (    <div className=""border border-stone-800/90 p-[0.4rem] rounded-lg mb-12 sticky top-4 z-[100] bg-stone-900/80 backdrop-blur-md"">      <nav className=""flex gap-2 relative justify-start w-full z-[100]  rounded-lg"">        {navItems.map((item, index) => {          const isActive = item.path === pathname;          return (            <Link              key={item.path}              className={`px-4 py-2 rounded-md text-sm lg:text-base relative no-underline duration-300 ease-in ${                isActive ? ""text-zinc-100"" : ""text-zinc-400""              }`}              href={item.path}            >              <span>{item.name}</span>            </Link>          );        })}      </nav>    </div>  );}Enter fullscreen modeExit fullscreen modeThis is the basic navbar component we can have. If you don't understand what ""use client"" at the top of the file is, you need to read the Next.js docs and a little about React Server Components. In short, all react components in Next.js v13 are server components by default which means that they run on the server. So, if you want to use client based hooks like useState or useEffect , you need to make them client components using the line ""use client"".Now let's break down the rest of the code. Firstly, I have defined an array of the items I want to have on my navbar. In my case they are, /, /now, /guestbook, & /writing . The next thing you see is our navbar component's function. I'm using the usePathname() hook provided by Next.js to get the active pathname. The next thing is our actual UI code styled using Tailwind CSS. I'm mapping over the navItems array and returning Next.js's in-built Link component for navigation. Notice I'm conditionally setting the text color of the links based on whether the link is active or not. The link activity can be checked by seeing if the path is equal to our active pathname we get from usePathname() hook.  Creating the layoutNow that our basic navbar component is done, let's create our layout file and add the navbar component to it so that each page in our web app has access to the navbar. Look for the layout.tsx file in the root of your app folder and change the code to this.// src/app/layout.tsximport ""./globals.css"";import NavBar from ""@/components/navbar"";export const metadata = {  title: ""Create Next App"",  description: ""Generated by create next app"",};export default function RootLayout({  children,}: {  children: React.ReactNode;}) {  return (    <html lang=""en"">      <body className=""bg-gradient-to-tr overflow-x-hidden min-w-screen from-zinc-950 via-stone-900 to-neutral-950 flex min-h-screen flex-col items-center justify-between"">        <main className=""p-4 py-24 gap-6 w-full lg:w-[55%]"">          <section className=""w-full flex gap-4 justify-start mb-6 p-2"">            <div>              <img                src=""https://avatars.githubusercontent.com/u/68690233?s=100&v=4""                alt=""avatar""                className=""w-12 h-12 rounded-full shadow-lg grayscale hover:grayscale-0 duration-300""              />            </div>            <div className=""flex flex-col gap-2 justify-center"">              <h2 className=""mb-0 text-zinc-100 font-bold"">Ashish</h2>              <p className=""mb-0 text-zinc-400 font-semibold leading-none"">                Student • Dev • Ailurophile              </p>            </div>          </section>          <NavBar />          {children}        </main>      </body>    </html>  );}Enter fullscreen modeExit fullscreen modeLet's break down the code. The first thing you need to do is import your Navbar component in your layout import NavBar from ""@/components/navbar"";. The ""@"" here is an import alias you can set while scaffolding your app. The next thing you would see is the metadata object. Don't worry if you don't understand what it is, it's used to define the metadata for your pages - for now let's not change it. The last thing is our actual RootLayout function or global layout (global as it applies to all of your routes). I have added some basic styles for the layout along with an header section with my name and bio on it. The navbar component is added right below it. Now, if you head over to localhost:3000 after starting the dev server, you would be able to see a basic page like this with the navbar on it.  Adding the animations to navbarHere comes the last step of this guide. We will be adding the hover animations inspired from Vercel to our navbar. Here's what the navbar component will look like after adding the animation code -// src/app/components/Navbr.tsx""use client"";import { motion } from ""framer-motion"";import { useState } from ""react"";import { usePathname } from ""next/navigation"";import Link from ""next/link"";const navItems = [  {    path: ""/"",    name: ""Home"",  },  {    path: ""/now"",    name: ""Now"",  },  {    path: ""/guestbook"",    name: ""Guestbook"",  },  {    path: ""/writing"",    name: ""Writing"",  },];export default function NavBar() {  let pathname = usePathname() || ""/"";  if (pathname.includes(""/writing/"")) {    pathname = ""/writing"";  }  const [hoveredPath, setHoveredPath] = useState(pathname);  return (    <div className=""border border-stone-800/90 p-[0.4rem] rounded-lg mb-12 sticky top-4 z-[100] bg-stone-900/80 backdrop-blur-md"">      <nav className=""flex gap-2 relative justify-start w-full z-[100]  rounded-lg"">        {navItems.map((item, index) => {          const isActive = item.path === pathname;                    return (            <Link              key={item.path}              className={`px-4 py-2 rounded-md text-sm lg:text-base relative no-underline duration-300 ease-in ${                isActive ? ""text-zinc-100"" : ""text-zinc-400""              }`}              data-active={isActive}              href={item.path}              onMouseOver={() => setHoveredPath(item.path)}              onMouseLeave={() => setHoveredPath(pathname)}            >              <span>{item.name}</span>              {item.path === hoveredPath && (                <motion.div                  className=""absolute bottom-0 left-0 h-full bg-stone-800/80 rounded-md -z-10""                  layoutId=""navbar""                  aria-hidden=""true""                  style={{                    width: ""100%"",                  }}                  transition={{                    type: ""spring"",                    bounce: 0.25,                    stiffness: 130,                    damping: 9,                    duration: 0.3,                  }}                />              )}            </Link>          );        })}      </nav>    </div>  );}Enter fullscreen modeExit fullscreen modeSince this code could look a bit complex to some, let's break it down to bits and understand what's happening here.Firstly, we need to add a few more imports - motion from framer-motion and useState hook from react.The second thing that's been added is this block of code, it's a simple trick I'm using to ignore the slug of my blog posts so that the active pathname is still /wriiting.if (pathname.includes(""/writing/"")) {   pathname = ""/writing"";}Enter fullscreen modeExit fullscreen modeThe third thing is our state hoveredPath, it's being used to keep track of the link which is being hovered as we are using framer-motion and not simply css hover property.The fourth thing that's been added is this code block to our Link component, The onMouseOver property is being used to set the pathname to the link's pathname whenever someone hovers over the link & the onMouseLeave property is being used to set the hovered pathname back to ""/"" after the cursor leaves the link. This is important as we don't want the background to be stuck on the same link even after we stop hovering over it....onMouseOver={() => setHoveredPath(item.path)}onMouseLeave={() => setHoveredPath(pathname)}...Enter fullscreen modeExit fullscreen modeThe fith and the last thing added to our code is the motion component that will be used to show the hover animation. If you don't know what motion does, consider reading the framer-motion docs. For now, you can think of it as an animatable component. We are using the motion.div component here as we need a div component to act as the background for our links. You can also see that the motion component is being rendered conditionally whenever item.path === hoveredPath. So, whenever a link is hovered our motion div becomes visible creating the background effect! The motion div is being positioned relative to the Link component and has a z-index of -10 so that it appears below our Link component. It also has a styling of width 100% which would make sure it covers the whole Link component and the transition property which can be used to control the animation. You can play around with the values to see how they work. Don't forget to read the framer-motion docs though.Note: Please remove all the styles from the Next.js default template from globals.css. Your CSS file should look like this -/* /src/app/globals.css */@tailwind base;@tailwind components;@tailwind utilities;Enter fullscreen modeExit fullscreen modeWith this, our animated navbar is complete and you can test it out in you dev server, Here's what it would look like if you did everything correctly -Clicking on other links would lead to a 404 as we haven't created the pages for the routes yet. After adding routes for those pages the navbar would work like this -   ConclusionThis might seem like ""over-engineering"" to some, but to me it's not as I was able to add a simple yet beautiful animation to my earlier boring-looking navbar by adding just a few lines of code. If you find anything hard to understand or something you don't get, feel free to leave a comment - I'll get back to you. Thanks for reading :)"
220,"AI coding tools like GitHub Copilot, ChatGPT and similar tools took the software development world by storm.Some developers love them, some dismiss them, and the rest are neutral.Personally, I enjoy using them, and I believe they can help developers of all levels, including new developers. However, there are some things to consider if you are a new developer.With this article, I want to answer whether new developers should use AI coding tools and how to make the most of them.Mention: This article is also useful for experienced developers, but its focus is on people new to software development.  Should new developers use them?My short answer is yes. Developers should use any tool that makes them faster and better.I believe AI coding tools are one example of tools that help developers code faster than ever.But there is one crucial mention. These AI tools generate erroneous, incomplete, and inefficient code quite often. Also, they sometimes generate code that looks fine at first sight but has very subtle errors/inefficiencies. If you blindly trust them, you will get into trouble. By trouble, I mean that you will learn the wrong stuff and also build unreliable & insecure applications.So, what should you do then?Treat these AI tools like you treat any other resource on the internet. Would you copy & paste code from a website and blindly use it without understanding it? Do the same with these AI coding tools. They can be beneficial, but they can also be very dangerous if you misuse them.The idea is to use them but with caution.  How to use AI coding toolsSince these tools were born, people have said they will replace developers.My opinion is that they are nowhere near replacing developers. And the more I use them, the more they reinforce that opinion. They're just not good enough to generate correct, efficient code at the moment — at least not complex code.But that does not mean they're not excellent tools. They're a great companion for coding.For now, they're handy for the following use cases:removing the entry barrier No more ""how to get started"" questions. These AI tools are super valuable for giving you ideas on how to get started with a project or tool. Even if they do not generate the correct code, they give you pointers on how to get started.The above GIF illustrates how ChatGPT helps you to get started with Zod. It generates both the code and explanations, so you understand what the code does.speeding up development by generating boilerplate codeWriting the boilerplate code is one of the most tedious parts of the software development process. Thankfully, AI coding tools can help with that as well.The above pictures show Cody AI generating the boilerplate code for a Node.js and Express application. It also helps you configure the ES module imports in your project.finding/solving simple bugs and errorsThese AI tools are also helpful for spotting bugs and errors. You can give them the code and ask them to find possible issues with your code. Then you can ask them to solve them but do not expect to get perfect answers. Use the solutions proposed to get an idea of how you could solve the issues.re-factoring simple codeYou can also use them to get ideas on how you can refactor and improve your code. Sometimes, they make suggestions that are not obvious to you. It happened many times for me to get ideas from these tools that were not obvious to me.generating documentation and testsIt's well known (unfortunately) that documentation and tests are not the highest priorities when developing software. With these tools, you can add your code as input and ask them to generate documentation and tests based on your code.These are some of the ways you can use AI coding tools to help you with coding. I emphasize again that you should not trust them blindly. Treat them as any other resource - only use the code if you understand it.   The AI coding tools I useAt the moment of writing this article, I use:GitHub CopilotOpenAI ChatGPTSourcegraph Cody AIWe have a community for developers. Join us hereThe article Should New Developers Use AI Coding Tools? was originally published on my blog."
221,"In the ever-evolving world of tech, some gadgets were hyped to be revolutionary but turned out to be quite amusing instead. Can you recall any tech gadgets that turned out to be more comical than cutting edge? Share your favorite tales of tech trends gone awry.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
222,"  Unraveling growth challenges: Could a system architect be the solution?Serverless Architecture from Classic Programmer PaintingsMost startups that go through hyper-growth tend to face the inevitable Bottlenecks of Scaleups, as masterfully described by ThoughtWorks.Having navigated the hyper-growth journey myself, I’ve witnessed firsthand how these technical bottlenecks can impede business progress, causing churn and chaos.Bottlenecks of ScaleupsIn light of these challenges, I wondered if a system architect's role could hold the key to identifying and circumventing these bottlenecks and reducing complexity like this infamous Amazon Deathstar.Amazon internal service dependency visualizationTo that end, this article explores the benefits, operating philosophy, guiding principles, job description, career progression, success criteria, and implementation approaches for the role of a system architect.  Benefits of having a System ArchitectMy hypothesis is rooted in the belief that a clear and purposeful approach to technical architecture can prevent false starts and accumulating tech debt.Picture a system architect whose sole responsibility is to observe the big picture and facilitate knowledge sharing across teams, breaking down silos for better collaboration.This individual would need to possess exceptional skills in designing and managing the overall technical architecture of a system. Their role includes assisting teams in defining system components, services, and interactions.The benefits of having a system architect would ultimately translate into: Improved alignment and coordination — Foster a common goal and architecture across teams, leading to more efficient and effective development. Enhanced technical expertise — Offer a deep understanding of system design and architecture, guiding and mentoring other engineering team members to elevate the organization’s overall technical capabilities. Improved quality and performance — Co-create a well-designed system architecture to boost performance and reliability, resulting in quicker time-to-value, better user experiences, and heightened customer satisfaction. Reduced technical debt — Proactively manage system architecture to prevent tech debt buildup, saving time and resources in the long run.  Harmonizing With the Agile PhilosophyYou may be curious how this role fits into the agile methodology that many organizations follow. On the surface, the role of an architect may be antithetical to being agile.However, several sources discuss the role of an architect in an agile environment. For example, Agile Architecture describes it as:The role of the architect in an agile project is to provide guidance and direction to the team on the technical aspects of the project. The architect is not a dictator, but rather a facilitator and coach, who helps the team find the best solutions to their technical challenges.Similarly, the Scrum Alliance discusses the role, stating that:[the architect] is responsible for guiding the team to make technical decisions that align with the project’s goals, scope, and delivery schedule. They should be able to communicate the technical vision to the team and help the team understand how their work contributes to that vision.Large-Scale Scrum (LeSS) Framework’s view on the architecture role is more philosophically aligned with how I see the role. The following statements on the Architecture & Design page in the chapter “Technical Excellence” shape their opinion about software architects:  The sum of all the source code is the true design blueprint or software architecture.  The real software architecture evolves (better or worse) every day of the product, as people do programming.  The real living architecture needs to be grown daily through programming by master programmers.  A software architect who is not in touch with the evolving source code of the product is out of touch with reality.  Every programmer is some kind of architect–whether wanted or not. Every act of programming is some kind of architectural act–good or bad, small or large, intended or not.LeSS promotes the idea that architects are regular team members. They should participate in hands-on engineering and especially mentoring through design workshops and pair programming. LeSS warns against architecture astronauts (a.k.a. PowerPoint architects):These are the people I call Architecture Astronauts. It’s very hard to get them to write code or design programs, because they won’t stop thinking about the architecture… They tend to work for really big companies that can afford to have lots of unproductive people with really advanced degrees that don’t contribute to the bottom line.#211 — The Architect by Comic Agile  Guiding PrinciplesNow that we have some grounding philosophy behind a system architect’s role in an agile organization, let’s discuss the guiding principles of this role.For this, we don’t need to reinvent the wheel. Principles proposed by Agile Architecture hold strong: Value people — You must recognize the value and importance of people and their expertise. No dictators or PowerPoint architects. Communicate! — Communicate effectively with all stakeholders and tailor information to their needs. Less is more — Minimize complexity and strive for simplicity in design and communication. Embrace change — Be prepared for change and welcome it as an opportunity for competitive advantage. Choose the right solution for the enterprise — Customer centricity. Make sure the solution is right by verifying it with the customer. Deliver quality — Foster a culture of craftspersonship and sustainable development at a pace that can be maintained indefinitely. Model and document in an Agile fashion — Leverage proven and effective modeling/mapping and documentation strategies.  Carving the Job DescriptionEquipped with the guiding philosophy and principles, if you were to recruit someone for this role, let’s see what the job description could look like. A system architect typically collaborates with other teams in several ways: Guide system design and architecture — Provide guidance and expertise to other teams on how to design and build systems that align with the overall architecture of the organization. This can involve working closely with teams to understand their needs and requirements and recommending the best approaches. Review and provide feedback for technical designs — Review and provide timely feedback for RFCs proposed by teams. This can involve evaluating the proposed designs to ensure they align with the system’s overall architecture and do not introduce any potential issues or technical debt. Help resolve technical challenges — Help teams resolve technical challenges during development. This may involve providing guidance on approaching a particular problem or working with the team to develop a solution. Participate in planning and estimation — Participate in planning and estimation meetings with other teams. This can involve providing input on the technical feasibility of proposed features and estimates for the time and resources required to implement them.Overall, the specific ways in which a system architect collaborates with other teams will vary depending on the needs and goals of the initiative and the members working on it.Enterprise Architecture Footprints  Navigating Career ProgressionNow that we have a job description, one may wonder how someone would become an architect and what would their career trajectory look like.Various avenues exist for senior engineers to advance in their careers. On the individual contributor (IC) path, adding a system architect role alongside roles like SRE, Data Engineer, and Staff Engineer is a viable option.Illustrations below help visualize what that may look like courtesy of CodeCapsule.Career Growth: What Paths After Senior EngineerThe Skills Map of Senior Tech Career ProgressionNote the key difference between an architect and staff/principal engineers: while the latter focus on ensuring their teams’ work functions correctly, architects take a broader view, looking after how all the pieces fit together.Before you ask, yes, staff and principal engineers also do think about how their work fits into the broader ecosystem, but most often, they don’t consider that their full-time concern.This role sits at the intersection of ‘What’ (is it we are trying to do/solve) and ‘How’ (are we going to approach the design), and ‘Why’ (are we doing it this way) as described by Peter Cripps.On Thinking ArchitecturallyBecoming an architect also has to do with having increased communication and relationship skills, on top of solid tech skills, as ‌architects have to deal with and influence larger groups of people across multiple teams and organizations.  Measuring SuccessIntroducing the role of a system architect into an organization is a strategic move aimed at improving the technical architecture, fostering collaboration, and overcoming growth challenges.However, to validate the effectiveness of this role, it's essential to measure its impact and quantify the value it brings to the organization.Here are some potential KPIs that can help gauge the effectiveness of the role: Technical debt reduction: Measure the decrease in technical debt over time as a result of proactive architectural decisions made by the system architect. (Related: How Google Measures and Manages Tech Debt) System performance and reliability: Evaluate the performance and reliability metrics of the system after the system architect makes architectural improvements. Collaboration and team satisfaction: Conduct surveys or feedback sessions to gauge how well the system architect facilitates collaboration and team communication. Time-to-Market reduction: Determine how architectural improvements by the system architect have contributed to faster product development and time-to-market. Resource optimization: Assess how architectural decisions have led to better resource utilization, whether regarding hardware, cloud services, or personnel. Impact on productivity: Analyze the impact of architectural improvements on the productivity of engineering teams.Measuring success should not be a one-time activity. Adopting a continuous improvement approach is crucial, wherein feedback from stakeholders, teams, and customers is regularly collected and incorporated into the system architect’s strategies.Feedback loops enable the system architect to adjust their approach based on real-world experiences and emerging challenges. This will help protect the organization against a gatekeeper or an ivory tower architect, which would be antithetical to the role’s intention.  Considerations for Implementation  Differentiating from EMs and Senior/Staff/Principal EngineersWhile engineering managers (EMs) and engineers are usually involved in making architectural decisions, their focus is typically on the domain or squad they operate in. The system architect’s distinctiveness lies in their primary focus on enabling effective cross-squad collaboration and communication, particularly regarding cross-cutting technical implications.  Reporting structureA role like a system architect often reports directly to engineering leadership, offering broad oversight and visibility across multiple teams. As such, it may be positioned under a Director or VP, or above, depending on the organization’s hierarchy.  Determining the number of architectsGiven the depth of domain knowledge required, complex domains may require experienced architects. Hiring for this role may entail identifying existing engineers with the right skills and interest in stepping into the architect role. This may affect the pace of filling the role based on the current team’s availability and skills.  In ClosingIn conclusion, I hope this exploration helps gives you a better sense of how this role could be introduced and the benefits it could bring.I’ll leave you with this timeless video by KRAZAM. Enjoy!If you liked this post, 🗞 subscribe to my newsletter and follow me on 𝕏!"
223,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
224,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Consider your work environment preferences, from collaborative offices to remote coding adventures. Where do you thrive?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
225,"  OverviewIn the ever-evolving landscape of front-end development, the ability to manipulate state effectively is a crucial skill. Imagine having the power to rewind and fast-forward through your application's state changes, pinpointing bugs and gaining a deeper understanding of your code's behavior. Welcome to the world of time travel debugging.In this in-depth tutorial, we will dive into the realm of time travel debugging in React, leveraging the remarkable capabilities of Immer. Immer is a powerful library that simplifies state management by enabling you to work with immutable data structures in a mutable-like manner. But it doesn't stop there – Immer's magic truly shines when combined with time travel debugging, offering developers a profound way to visualize and debug state changes over time.Throughout this tutorial, we will guide you step-by-step on how to integrate Immer into your React application and unlock the captivating potential of time travel debugging. We will cover essential concepts such as immutability, state transitions, and the magic of Immer's produce function. As we progress, you will witness firsthand how to set up your development environment for time travel debugging, manipulate and navigate state snapshots, and even replay past state sequences.  The demoThe upcoming demo will feature a compact app where users can create, resize, and move boxes within an interactive canvas. Notably, the app will incorporate an undo-redo feature, allowing users to easily navigate through their actions. This seamless blend of functionalities offers users the freedom to experiment while ensuring they can effortlessly backtrack or redo their steps. This engaging experience will spotlight the potential of modern front-end development by showcasing a seemingly simple concept turned into a powerful application.  Set upActually we only need Immer as a compulsory library for this demo, but I also install theme-ui and react-resizable to speed up the development time.  The ReducerFirst thing we need is a reducer so we can listen to actions and return the desired results:import  { produceWithPatches, applyPatches } from ""immer"";export const boxAction = (draft, action) => {  const { width, height, id, color, position } = action;  let box = draft.boxes[draft.selectBox];  switch (action.type) {    case ""ADD_BOX"":      draft.boxes[id] = {        id,        width,        height,        color,        position,      };      break;    case ""SELECT_BOX"":      draft.selectBox = id      break;    case ""MOVE_BOX"":      if (!box) return;      box.position = position;      break;    case ""RESIZE_BOX"":      if (!box) return;      box.width = width;      box.height = height;      box.position = position;      break;    case ""DELETE"":      delete draft.boxes[draft.selectBox];      break;    case ""APPLY_PATCHES"":      return applyPatches(draft, action.patches);  }};Enter fullscreen modeExit fullscreen modeWe can start looking at each action:ADD_BOX : we add a new box to the storeSELECT_BOX: we select a box ( to delete, resize or move )MOVE_BOX: we move a box to the new positionRESIZE_BOX: we resize the boxDELETE: we delete the selected boxAPPLY_PATCHES: we use Immer’s applyPatches function for this. During the run of a producer, Immer can record all the patches that would replay the changes made by the reducer. This function allows us to patch the stateThen we will create a producer using Immer’s produceWithPatches and create a initial state:export const patchGeneratingBoxesReducer = produceWithPatches(boxAction);export function getInitialState() {  return {    boxes: {},  };}Enter fullscreen modeExit fullscreen mode  The dispatch functionHere’s the thing, we need a function that will be called every time we emit an action, and this function should be implemented with a stack, since we will put every “patch” into the stack  const undoStack = useRef([]);  const undoStackPointer = useRef(-1);  const dispatch = useCallback((action, undoable = true) => {    setState((currentState) => {      const [nextState, patches, inversePatches] = patchGeneratingBoxesReducer(        currentState,        action      );      if (undoable) {        const pointer = ++undoStackPointer.current;        undoStack.current.length = pointer;        undoStack.current[pointer] = { patches, inversePatches };        }      return nextState;    });  }, []);Enter fullscreen modeExit fullscreen modeDon’t worry, I will explain in details:The undoStack and the undoStackPointer: undoStack is a reference to an array that will store the history of state changes (patches) for undoable actions.undoStackPointer is a reference to a number that keeps track of the current position in the undo stack.The undoable parameter: A boolean flag indicating whether the action should be considered undoableManaging undo history:If the action is marked as undoable (undoable is true), the code adds the patches and inverse patches to the undoStack for potential undo operations. undoStackPointer is incremented to point to the current position in the stack.The previous undoable actions beyond the pointer are removed from the stack to maintain a linear historyOverall, this code manages a history of state changes in an undo stack, allowing users to perform undoable actions on a set of ""boxes"" while maintaining the ability to revert those changes. The dispatch function updates the state and also manages the undo stack accordingly.  The ButtonsWe would have 4 buttons in this application: Create - Delete - Undo - Redo. Let’s go into each of them:Create Button:const createButton = () => {    const width = Math.floor(Math.random() * (300 - 100 + 1) + 100)    const height = Math.floor(Math.random() * (300 - 100 + 1) + 100)    dispatch({      type: ""ADD_BOX"",      width: width,      height: height,      id: uuidv4(),      color:        `#` +        Math.floor(16777215 * Math.random()).toString(16),      position: {        x: window.innerWidth * 0.8 / 2 - width / 2,        y: window.innerHeight / 2 - height / 2,      }    });  };Enter fullscreen modeExit fullscreen modeWhen crafting a fresh box, you'll observe that I've introduced randomness to its dimensions encompassing width and height, as well as imbuing it with a distinctive hue and a one-of-a-kind identifier. This newly generated box is thoughtfully positioned at the screen's center by skillfully manipulating the x-axis and y-axis coordinates. Ultimately, the culmination of these steps is manifested through the invocation of the aforesaid ""dispatch"" function, effectively bringing the envisioned creation to life.Delete Button:const deleteButton = () => {    dispatch({      type: ""DELETE"",    });    dispatch({      type: ""SELECT_BOX"",      id: null    }, false)  }Enter fullscreen modeExit fullscreen modeThere isn't a great deal to elaborate on in this context; we simply initiate a dispatch action to delete, subsequently ensuring that the box is unselected.Undo and Redo buttonsconst undoButton = () => {    if (undoStackPointer.current < 0) return;    const patches = undoStack.current[undoStackPointer.current].inversePatches;    dispatch({ type: ""APPLY_PATCHES"", patches }, false);    undoStackPointer.current--;    dispatch({      type: ""SELECT_BOX"",      id: null    }, false)  };  const redoButton = () => {    if (undoStackPointer.current === undoStack.current.length - 1) return;    undoStackPointer.current++;    const patches = undoStack.current[undoStackPointer.current].patches;    dispatch({ type: ""APPLY_PATCHES"", patches }, false);    dispatch({      type: ""SELECT_BOX"",      id: null    }, false)  };Enter fullscreen modeExit fullscreen modeI put these 2 functions together so you can see the contrasts. We won’t allow the users to be undoed if they are at the bottom of the stack, and won’t allow the users to redo if they are on top of the stack. Then we get the patches and apply it using the “APPLY_PATCHES” action. Remember to unselect the box to avoid bugs  The Results  ConclusionBy the end of this tutorial, you will not only have a firm grasp of how to implement time travel with Immer in React, but you will also possess a powerful debugging technique that can drastically improve your development workflow. Join us on this journey to unravel the secrets of time travel and revolutionize the way you approach debugging in React applications.Source code: https://github.com/superdev163/immer-squareLive demo: https://immer-square.web.app/"
226,"Recently I decided to learn Go and my first impressions were quite good. Go is a very nice language and easy to get started with. The go routines is probably the best feature of the language and I really wish other languages followed this model. The defer feature is also very nice.However, as I continued learning, some things started feeling odd, some design decisions that looked strange. For example, the only loop construct is for, and there is no way to create a loop that iterates over a sequence of numbers, like for i in range(10) in Python or for i in 0..10 in Rust, you have to use a for loop as in C: for i := 0; i <= 10; i++.After a while I realized: Go tries so hard to be like C that it does not even try make improvements that make it look too different than C.Now let's compare the RWMutex from Go with RWLock from Rust:lock := sync.RWMutex{}lock.RLock()// do sometinglock.Unlock()Enter fullscreen modeExit fullscreen modeThis code will compile just fine, but will fail at runtime, because I called lock.Unlock() instead of lock.RUnlock(). You might say that is the developer's fault for no paying attention and calling the wrong method, and you are right, but let's take a look at the equivalent in Rust:let lock = RwLock::new(1);{    let read = lock.read().unwrap();    // do something}Enter fullscreen modeExit fullscreen modeFirst thing we notice is that the RWLock operates with a value, since is very common the use a lock to synchronize access to something. Then we open curly braces to start a scope because lock.read() returns a guard that releases the lock when it goes out of scope, so there is no wrong method to be called. The error handling may look annoying but it is there for a reason.For me this design decision for the Go RWMutex seems very strange, it could be much better if RLock returned a handle in which you would call Unlock and I cannot think of any reason for this other than to look more like C.But Rust is not perfect, though, function signatures can become messy, specially with async, and dealing with lifetimes is not fun. And compilation time...I will continue learning Go, it is really a nice language, but I still prefer Rust, I feel much safer with it (pun intended)."
227,"Photo from Unsplash by Daniel ThomasI started at a community college, drawn into a computer science class based in C++ by an enthusiastic chemistry professor who also knew some basic to intermediate C++. The class was intense and interesting and after meandering through a series of courses in a half hearted attempt to prep for medical school and pivot from nursing, I was left with a sense of pride once I finished the class. I had a working project, a (now basic) C++ program that calculated an integral and also performed a Riemann sum until the Riemann sum was within an error tolerance. I was also left with a sense of being alone. The class wasn’t small and out of the people there I was one of only a few women there and the only Black woman. However, everyone in class was pleasant and cooperative and it was a great experience. I didn’t let that sense of feeling out of place stop me, after graduating high school at 14 and starting college at 15 I was used to being out of place with my peers. I spent a little time soul searching then quickly applied and was accepted into a OSU.OSU was a different experience all together. It took a long time to find other’s like me even with the resources of slack and discord and group projects to this day I only know four other Black female software engineers and a handful of Black men, from my school. All of these I sought out myself and introduced myself and formed a sort of community. I started to do more research and found the disheartening statistics of the field. I read up on factors of why Black people aren’t entering into CS degrees, the difficulties in being hired and seen as competent. I felt the impostor syndrome on a personal level. I learned the history of black women in computing and felt and lived parts of the movie Hidden Figures (2016) in real life.When I started interning I was faced with even more hurdles and triumphs than I had ever anticipated. I was left with a feeling of exhaustion. I joke with friends and family that the title of the book “Black Girls Must Die Exhausted” by Jayne Allen sums up my life. It wasn’t the work, it was the complex intersection of people and me; It was the raised eyebrows, the looks, the comments, the stares at my different hairstyles, the feeling of needing to police my every breath so as to not cause anymore strain to those who were already offended or standoffish about me taking up space in a club I how somehow gotten admittance to. I felt the words unsaid and said hang around my neck like a weight so heavy some days. Slowly, begrudgingly I gained respect, and each day, each new person was a new battle. I was not presumed to have a level of competence when I walked in. I learned to speak up for myself. I learned to bite my tongue. I learned to learn more. I learned to know the answer before asking the question if possible. I learned to hide my true feelings.I ran in the cold every night after finishing up work each day at one internship. -5F, ice on the streets, I ran, letting the cold leech out the heat I felt at the day’s events. Letting the burn of my muscles sear away the anxiety and anger I felt. Letting each puff of air I exhaled melt away the stress. 1 hour, 2 hours, sometimes 3. I went to bed too tired to feel, ready for the next day even when I wasn’t.As someone of two minorities in computer science this is a question I have known the answer to since starting my journey. The answer to this question has been felt in emotions, stares, comments and so much more throughout my education and blossoming professional career. For some who read this post , the topic I am about to discuss might seem like a downer or too heavy for blog I am writing. But when asked to discuss my career and my experiences and my education, I am drawn back to how the world see’s me first. I am not my skills first. I am not my creativity, I am not my drive or passion. I am Black. I am a woman. Everything else comes second when the first two are known.Black women make up around 3% of computer science jobs (Daley, 2021). This statistic to some seems insignificant. I am sure some of you reading this will roll your eyes and click away citing “woke” agenda or not wanting to read something you have little interest in. But for the rest of you here is how my journey has started in computer science and then I will tell you how I want it to end.Why does all I have written above even matter?It matters when you are in a class and it’s a group of men and when during the course of casual conversation a student brings up faking sexual assault to get out of a class and makes it a joke. It matters when you are interning at a company and you ask your boss the best way to stand out and without even knowing you he says “be nice”, with the passive aggressive tone you know to well , reeking of the implied “Angry Black Woman” stereotype you have to tone done your whole being to avoid even giving any credence too. It matters when you are the only woman on a team, time and time again and other engineers make comments, like joking that only a “friend can touch your privates” then laughing crassly , after only just saying moments before “I know this isn’t PC but I will say it anyway”. It matters when they don’t care for your discomfort and only for their amusement.It matters when every time you are hired, you have to fight the side looks, and side whispers that you are hired for your skin, for DEI metrics, for pictures. It matters when you attend a new intern event filled with over a hundred people, none of which look like yourself, you walk into a room head held high as eyes turn and you are called to the front to show prominently for when there are photos and media taken. It matters when you have to take almost a year off for recuperating and soul searching after a horrible internship experience you have to strongly about if you even want to continue in CS anymore.And it matters when you choose to come back, and to push on so that one day, some girl who is maybe not even born will be the last person to experience the things you have.Now you have the answer of how it feels to be alone in a crowd, and not to just be part of the crowd.“Do the best until you know better. Then when you know better, do better.”Maya AngelouDaley, S. (2021, March 31). Women in tech statistics show the industry has a long way to go. Built In. Retrieved January 11, 2023, from https://builtin.com/women-tech/women-in-tech-workplace-statistics"
228,"In today's data-driven world, the ability to extract and synthesize information from various online sources is not just a powerful skill - it's often a necessity!And often, that data comes in the form of HTML <table>'s scattered across the web. The challenge then becomes: How do we extract and transform this data into a form that's easily accessible in Python?With the pandas.read_html function, we're offered a convenient solution to extract our data into the highly versatile pandas.DataFrame and get our analyses running quick and efficiently!from pandas import read_htmlEnter fullscreen modeExit fullscreen mode  Table of ContentsPrerequisitesWhat is pd.read_html?Using pd.read_html in practiceConclusion          Chris Greening - Software Developer                  Hey! My name's Chris Greening and I'm a software developer from the New York metro area with a diverse range of engineering experience - beam me a message and let's build something great!                christophergreening.com        Prerequisites pandaslxml  What is pd.read_html? pd.read_html is a function within pandas, a popular data manipulation library in Python. Its purpose is to scrape an HTML page (either from a URL or as a string) and extract all the table's found on the pageHere's a quick breakdown of how it works:Specify the source: We tell pd.read_html where to find the HTML content. This could be a URL pointing to a webpage or a string containing raw HTML codeScrape the tables: pd.read_html scans the HTML content and identifies the tables within itTransform into pd.DataFrame's: Once the tables are found, pd.read_html converts them into pd.DataFrames for easy analysis and manipulationSo with just one line of code we can scrape all the tables on a webpage and get right into our analyses without having to worry about manual entry or extraction  Using pd.read_html in practice Leveraging pd.read_html is a straightforward process that can save us significant time and effortHere's a step-by-step guide to using this function to get tables from a webpage right into our Python environments:Import pandas: First let's import pandas into our script:import pandas as pdEnter fullscreen modeExit fullscreen modeSpecify the source and call pd.read_html: Determine where pd.read_html should look for the HTML content. It could be a URL or a string containing HTML code. For this example let's pull some tables off of the Python Wiki page:url = ""https://en.wikipedia.org/wiki/Python_(programming_language)""tables = pd.read_html(url)Enter fullscreen modeExit fullscreen modeAccess the tables: The result is a list of pd.DataFrames, each representing a table found on the page. We can access them by their index:df = tables[0]Enter fullscreen modeExit fullscreen modeAnalyze and manipulate: From here, we're free to work with the data just like we would with any other DataFrame in pandas - filtering rows, calculating statistics, or visualizing the data!Here's what a complete snippet might look like:import pandas as pdurl = ""https://en.wikipedia.org/wiki/Python_(programming_language)""tables = pd.read_html(url)df = tables[0]Enter fullscreen modeExit fullscreen mode  Conclusion Using pd.read_html to scrape an HTML string offers flexibility and control over the content we're working withWhether we're handling locally stored HTML files or scraping right from the web, this method allows us to fully leverage pd.read_html's table extraction capabilitiesThanks so much for reading and if you liked my content, be sure to check out some of my other work or connect with me on social media or my personal website 😄Leveraging the pipe method to write beautiful and concise data transformations in pandasChris Greening ・ Jan 29#python#datascience#tutorial#codequalityCompleting missing combinations of categories in our data with pandas.MultiIndex!Chris Greening ・ Feb 4#python#datascience#tutorial#pandas          Chris Greening - Software Developer                  Hey! My name's Chris Greening and I'm a software developer from the New York metro area with a diverse range of engineering experience - beam me a message and let's build something great!                christophergreening.com      "
229,"  OverviewThe world of JavaScript development has been transformed by TypeScript's robust static typing abilities. Amidst its numerous attributes, type guards emerge as a potent instrument, enhancing the language's type safety significantly. This article embarks on an exploration of Type guards in TypeScript, delving into their intricacies, utilization, and indispensable contribution to fortifying code integrity and eliminating errors.  DefinitionType guards in TypeScript are a set of techniques that allow developers to narrow down the type of a variable or expression within conditional blocks of code. They provide a way to perform runtime checks on the type of a value and refine the TypeScript type of that value accordingly.Type guards are particularly useful when dealing with union types, where a variable can have multiple possible types. By using type guards, developers can make more precise assumptions about the actual type of a value at runtime, enabling better type inference and enhanced type safety.Type guards can be implemented using various methods, such as checking for specific properties or using JavaScript runtime constructs like instanceof or typeof. These techniques help TypeScript's type system understand the changes in the type of a variable after a successful type check.  Examples and UsagesAbsolutely, let's go through each of the examples and their explanations:Typeof Type Guard:   function printLength(value: string | number): void {     if (typeof value === ""string"") {       console.log(value.length);     } else {       console.log(""Value is not a string"");     }   }Enter fullscreen modeExit fullscreen modeExplanation: In this example, typeof value === ""string"" acts as a type guard. If the type of value is narrowed down to ""string"" within the if block, TypeScript understands that the length property can be safely accessed.Instanceof Type Guard:   class Dog {     bark() {       console.log(""Woof!"");     }   }   class Cat {     meow() {       console.log(""Meow!"");     }   }   function makeSound(animal: Dog | Cat): void {     if (animal instanceof Dog) {       animal.bark();     } else if (animal instanceof Cat) {       animal.meow();     }   }Enter fullscreen modeExit fullscreen modeExplanation: The instanceof operator is used as a type guard here. It narrows the type of animal to either Dog or Cat based on the condition. This allows TypeScript to determine which methods are accessible on the animal object.Custom User-Defined Type Guard:   interface Circle {     kind: ""circle"";     radius: number;   }   interface Square {     kind: ""square"";     sideLength: number;   }   type Shape = Circle | Square;   function isCircle(shape: Shape): shape is Circle {     return shape.kind === ""circle"";   }   function area(shape: Shape): number {     if (isCircle(shape)) {       return Math.PI * shape.radius ** 2;     } else {       return shape.sideLength ** 2;     }   }Enter fullscreen modeExit fullscreen modeExplanation: This demonstrates a custom user-defined type guard (isCircle). The type of shape is narrowed to Circle if isCircle returns true, which allows safe access to the radius property.Key Existence Type Guard:   interface Person {     name: string;     age?: number;   }   function greet(person: Person): void {     console.log(`Hello, ${person.name}!`);     if (""age"" in person) {       console.log(`You are ${person.age} years old.`);     }   }Enter fullscreen modeExit fullscreen modeExplanation: The in operator is used here as a type guard to check if the ""age"" property exists in the person object. If it does, TypeScript narrows the type of person to { name: string; age: number }.Null and Undefined Type Guard:   function printLength(value: string | null): void {     if (value !== null) {       console.log(value.length);     } else {       console.log(""Value is null"");     }   }Enter fullscreen modeExit fullscreen modeExplanation: By checking value !== null, TypeScript narrows down the type of value to exclude null, allowing safe access to the length property.In all these examples, type guards enable TypeScript to intelligently narrow down the types of variables or expressions within conditional blocks, leading to more accurate type inference and safer coding practices.  ConclusionIn the TypeScript landscape, type guards serve as a pivotal tool that elevates the language's static typing prowess. By refining variable types within conditional contexts, type guards fortify code integrity and clarity.Through diverse examples, we've witnessed type guards empower decisions about data types at runtime. Whether through typeof, instanceof, or custom checks, each approach preemptively averts errors.Type guards stand as a shield against runtime mishaps, fostering error-free development. They embody the synergy between developers and TypeScript, culminating in reliable, scalable code.As you embrace type guards, you embark on a journey toward steadfast applications in the dynamic software realm."
230,"Last week, the AppMap team shared their 8 favorite tech and software podcasts.We're developers, so the media we consume covers the complexity of the software industry... and a ton of NERDY stuff, too! Like Linux, web dev, and the 2000s. Let's get into it.[Out now! Early access to AppMap for GitHub Actions]Shop Talk ShowDave Rupert and Chris Coyier produce a weekly podcast about building websites - front end web design, development, and UX. They have guests and answer listener submitted questions. This one features a banjo! and thoughts on long-dead Google Reader.GIANT ROBOTS... SMASHING INTO OTHER GIANT ROBOTS. Rotating between three hosts, this podcast is ""about the design, development, and business of great software."" Recently they interviewed Brittany Martin, a co-host of The Ruby on Rails Podcast, a podcast featured in our last post. Oh, and here's my friend Lauren Maffeo, the author of Designing Data Governance from the Ground Up.Cathode Ray DudeThe host of this YouTube channel quit his day job a month ago and is now much happier spending his energy on his video channel (not really a podcast) about ""cameras, computer mice, and the 2000s.""PROOFThis podcast is all about in-depth NFT coverage. Venture capitalist Kevin Rose and team ""interview NFT artists, both up-and-coming and industry icons. [They] also cover the generative art scene, the NFT gaming/metaverse, and founders building new tools for creators and collectors."" I like cool domains so will be checking out this one with David Greenstein, co-founder of sound.xyz.The Linux ExperimentThe host, Nick, treats this as a safe space with ""no techno babble, no super technical content"" that focuses on ""Linux desktop news, simple tutorials, application spotlights, and opinion pieces trying to stay positive, without gatekeeping."" It's no surprise that his step-by-step walkthrough of how to switch to Linux has a gazillion views.The a16z PodcastThe team at Andreessen Horowitz, a silicon valley venture capital firm, interviews ""industry experts, business leaders, and other interesting thinkers and voices from around the world."" Interestingly, they are looking for the next host of the podcast!Got any super nerdy podcasts or video channels to share with us? We need more, clearly."
231,"  IntroductionWhen building a modern, responsive website, navigation plays a crucial role in user experience. A sticky or affix navigation bar remains visible at the top of the screen as users scroll, making it easy for them to access the main menu items without having to scroll back to the top. Tailwind CSS, a popular utility-first CSS framework, makes it simple to create elegant, functional sticky navigation bars. In this tutorial, we'll walk you through the process of creating a sticky navigation bar using Tailwind CSS and showcase some stylish designs to inspire your project.  Step 1: Setting Up the ProjectBefore we start, make sure you have Tailwind CSS installed in your project. You can either use the CLI, include it from a CDN, or set up a custom build. Visit the official Tailwind CSS documentation to learn how to set up Tailwind CSS for your specific project.  Step 2: Creating the Basic NavBarFirst, let's create a simple navigation bar using Tailwind CSS. Add the following HTML code to your project:<!DOCTYPE html><html lang=""en""><head>    <meta charset=""UTF-8"">    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">    <link href=""https://cdn.jsdelivr.net/npm/tailwindcss@2.2.16/dist/tailwind.min.css"" rel=""stylesheet"">    <title>Sticky NavBar using Tailwind CSS</title></head><body class=""bg-gray-100"">    <header class=""bg-white"">        <nav class=""container mx-auto px-6 py-3"">            <div class=""flex justify-between items-center"">                <a href=""#"" class=""text-2xl font-bold text-gray-800"">MyWebsite</a>                <div class=""flex space-x-4"">                    <a href=""#"" class=""text-gray-800"">Home</a>                    <a href=""#"" class=""text-gray-800"">About</a>                    <a href=""#"" class=""text-gray-800"">Services</a>                    <a href=""#"" class=""text-gray-800"">Contact</a>                </div>            </div>        </nav>    </header>    <!-- Add your page content here --></body></html>Enter fullscreen modeExit fullscreen modeThis code sets up a basic navigation bar with a container, logo, and menu links.  Step 3: Making the NavBar StickyTo make the navigation bar sticky, we need to add the fixed, top-0, and w-full classes to the <header> element. This will fix the header at the top of the viewport and span the full width of the screen. Update your <header> tag as follows:<header class=""bg-white fixed top-0 w-full"">Enter fullscreen modeExit fullscreen modeNow, when you scroll down the page, the navigation bar will remain at the top.  Step 4: Adding a ShadowTo create a subtle separation between the sticky navigation bar and the page content, add a shadow using the shadow-md class:<header class=""bg-white fixed top-0 w-full shadow-md"">Enter fullscreen modeExit fullscreen mode  Step 5: Design InspirationsNow that you've created a basic sticky navigation bar using Tailwind CSS, you can customize its design by applying various utility classes or creating your own. Here are a few design ideas to inspire you:Transparent background with a color change on scroll: Add a transparent background to the navigation bar and change the background color when the user scrolls down, creating a smooth transition effect. You can achieve this by using JavaScript to toggle a class when the user scrolls.Hover effect on menu items: Enhance user experience by adding a hover effect to the menu items. Use the hover: prefix to change the text color or background color of the menu items when users hover over them. For example:<a href=""#"" class=""text-gray-800 hover:text-blue-600"">Home</a>Enter fullscreen modeExit fullscreen modeAdd a call-to-action button: Encourage users to take a specific action, such as signing up or contacting you, by adding a CTA button to the navigation bar. Use the bg-, text-, and rounded- classes to style the button:<a href=""#"" class=""bg-blue-600 text-white px-4 py-2 rounded-md"">Sign Up</a>Enter fullscreen modeExit fullscreen modeResponsive design with a hamburger menu: For mobile devices, you can create a responsive design by hiding the menu items and displaying a hamburger menu instead. Use Tailwind CSS's responsive classes (e.g., lg:hidden and lg:flex) and JavaScript to toggle the mobile menu.Add a search bar: Enhance your sticky navigation bar by integrating a search bar. Use the border-, rounded-, and focus: classes to style the input field and search button:<div class=""flex items-center space-x-2"">    <input type=""search"" placeholder=""Search"" class=""border border-gray-300 rounded-md px-3 py-2 focus:outline-none focus:border-blue-600"">    <button class=""bg-blue-600 text-white px-4 py-2 rounded-md"">Search</button></div>Enter fullscreen modeExit fullscreen mode  Complete exampleHere is the complete HTML code for a basic sticky navigation bar with some additional design elements, including hover effects, a CTA button, and a search bar:<!DOCTYPE html><html lang=""en""><head>    <meta charset=""UTF-8"">    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">    <link href=""https://cdn.jsdelivr.net/npm/tailwindcss@2.2.16/dist/tailwind.min.css"" rel=""stylesheet"">    <title>Sticky NavBar using Tailwind CSS</title></head><body class=""bg-gray-100"">    <header class=""bg-white fixed top-0 w-full shadow-md"">        <nav class=""container mx-auto px-6 py-3"">            <div class=""flex justify-between items-center"">                <a href=""#"" class=""text-2xl font-bold text-gray-800"">MyWebsite</a>                <div class=""hidden md:flex items-center space-x-4"">                    <a href=""#"" class=""text-gray-800 hover:text-blue-600"">Home</a>                    <a href=""#"" class=""text-gray-800 hover:text-blue-600"">About</a>                    <a href=""#"" class=""text-gray-800 hover:text-blue-600"">Services</a>                    <a href=""#"" class=""text-gray-800 hover:text-blue-600"">Contact</a>                    <a href=""#"" class=""bg-blue-600 text-white px-4 py-2 rounded-md"">Sign Up</a>                </div>                <div class=""md:hidden flex items-center"">                    <button class=""text-gray-800 focus:outline-none""> <!-- Add a hamburger menu icon here -->                        <svg class=""w-6 h-6"" fill=""none"" stroke=""currentColor"" viewBox=""0 0 24 24"" xmlns=""http://www.w3.org/2000/svg"">                            <path stroke-linecap=""round"" stroke-linejoin=""round"" stroke-width=""2"" d=""M4 6h16M4 12h16M4 18h16""></path>                        </svg>                    </button>                </div>            </div>            <div class=""mt-4"">                <div class=""flex items-center space-x-2"">                    <input type=""search"" placeholder=""Search"" class=""border border-gray-300 rounded-md px-3 py-2 focus:outline-none focus:border-blue-600 w-full"">                    <button class=""bg-blue-600 text-white px-4 py-2 rounded-md"">Search</button>                </div>            </div>        </nav>    </header>    <!-- Add your page content here --></body></html>Enter fullscreen modeExit fullscreen modeThis example includes hover effects for menu items, a CTA button, and a search bar. You can further customize the design by applying different utility classes or creating your own. Remember to test your designs on various devices and screen sizes to ensure a seamless experience for all users.  ConclusionIn this tutorial, we demonstrated how to create a sticky navigation bar using Tailwind CSS and provided some design ideas to help you customize the look and feel of your NavBar.By implementing a sticky navigation bar on your website, you can improve user experience and ensure that essential menu items are always easily accessible. To make the design process even more efficient and enjoyable, you can use the Tails Tailwind CSS page builder, which offers a comprehensive library of pre-built UI components, all created with Tailwind CSS.This intuitive, user-friendly page builder allows you to effortlessly create and customize your website designs using a visual interface, without having to write a single line of code. Remember to test your designs on various devices and screen sizes to ensure a seamless experience for all users."
232,"The Web Environment Integrity is yet another Google proposal for making the web worse for everyone but them.Links of interest:The explainerThe RFCThe Github repo  Issues with the RFCRequest For Comments, a nice way to make proposals and ask for comments and feedback. Well, usually when one comes out it's at least polished enough to feel like a complete unit.As of today, very crucial and important parts of the RFC are marked as ""TODO"". Things like, you know, definitions of ""web environment"" and ""content binding"", nothing that important /s.Hell, even whole sections are missing like ""Browser Acceptance Criteria"" and ""Privacy considerations"" which gives off strong ""I'll leave the morality of it out of the talk"" vibes (no that is not a parody, it's an actual serious talk, you should definitely check it out).The biggest issue with the RFC is, if you're like me, the first time you read this and looked at the API you certainly thought: ""wow... that's actually useless"":Craft a token and... encode it in base64? No asymmetrical encryption? Just Base64? Wth!?Cool, but how can it be verified?The token is crafted on the user's device and verified on another?What is the use exactly?What prevents it from being spoofed or polyfilled?This is to fight against fingerprinting? But that introduces a wayyyy better way of fingerprinting users, on a literal MAC address/machine levelYou can't remove the need for an anti-virus software on each machineMaking a ""web anti-virus solution"" is the single dumbest and most useless idea ever! Sure let's give any website a way to inspect (the integrity of) your memory, that sounds like a great idea!And of course, these questions are absolutely not addressed in the RFC. All you can read is something that feels like someone's draft of an RFC (that needs to be finalized before being published), not an actual RFC. Which probably means that whoever was behind this idea thought of it last minute and pushed it way too hard to have it go out ASAP.  And with the explainer, all the evil is unveiledYou see, before reading the explainer (which is dumb, why external explanation for an RFC) you were already thinking about how this is terrible, a DRM-ization of the web, etc.But within the first few lines of the explainer, you actually understand that one of the main goals of this is absolutely not to protect users in any way, but to make sure ads are shown to real users and never bots.It's pretty much a Comic book Villain (or politician) tactic: pretend to do things for others' interest, but in reality you do them for your own.  GoalsAllow web servers to evaluate the authenticity of the device and honest representation of the software stack and the traffic from the device.That's a mouthful way of saying ""we want website to be able to very accurately fingerprint your device"". How's the EU doing btw?Offer an adversarially robust and long-term sustainable anti-abuse solution.Now that's just absurd and wishful thinking at best. There's a reason anti-virus and anti-cheat software run at system startup and in a different ""context"" than other programs... You can't do that from inside a web browser.Plus, that would only cover mid-execution corruption. You couldn't detect prior-to-execution corruption like, let's say, a computer full of malware?Don't enable new cross-site user tracking capabilities through attestation.Sure, try to act like you won't use that in GA or GTM at all. How's the EU doing btw?Continue to allow web browsers to browse the Web without attestation.Oh thank god, you actually admit yourself that your proposal is a waste and totally useless since you can just skip it...  ""Non-goals""Enforce or interfere with browser functionality, including plugins and extensions.Oh I'm sure it won't interfere...In addition to Manifest V3, you'd also like to further kill extension/plugin users and developers? Wow. You really hate adblockers huh? Despite them being a minority in the vast user base? Are you looking for pennies under the couch Google? I have 4 bucks in my pocket if you want.Enable reliable client-side validation of verdictsYes, ""reliable client-side"" the famous oxymoron. Thank you for ""clarifying"" that. I hope Google doesn't connect to their production databases directly from the browser...Access to this functionality from non-Secure Contexts.What do you not get about ""non-Secure""? Are you serious?  Use casesDetect social media manipulation and fake engagement.So it's not about users. Got it. And how do you plan on doing that exactly?Detect non-human traffic in advertising to improve user experience and access to web contentSo it's not about users. Got it. And how do you plan on doing that exactly? I'm pretty sure I can make Selenium do things and it'd go through your wide net.Detect phishing campaigns (e.g. webviews in malicious apps)How exactly?Detect bulk hijacking attempts and bulk account creation.How? Oooooh, by fingerprinting of course!Detect large scale cheating in web based games with fake clientsSee the above about execution contexts of anti-cheat and anti-virus software...Detect compromised devices where user data would be at riskThere's no reason a malware-infested system couldn't spoof that. It's not an anti-virus...Detect account takeover attempts by identifying password guessingLiterally how? Do you have any idea of the intrinsic unsolvability of the problem you claim this would solve? Why do you think 2FA/MFA exist? Google literally has one of the strictest ones out there, how do you fain ignorance like that?  Does the explainer, explain or address anything?No lmfao. Read it for yourself, it's pretty funny how it makes everything worse than the RFC already did.  The final wordsYou cannot circumvent the Blind Trust Issue. (i.e. the fact that any trust is always blindly given, otherwise it'd be knowledge)Hell, the whole thing relies on a 3rd-party attester which is an even bigger joke in and of itself.It's not even like HTTPS, DNS Sec, or whatever intelligent and well thought out security thing. That one is just useless junk if you're not Google Ads.The only way to circumvent the Blind Trust Issue is to turn trust into knowledge, that much is obvious. The only issue is that you can't have knowledge about a site being compromised (e.g. downloading a renowned browser), that your IP packets are not being intercepted (network layer), that your TCP packets are not being logged or intercepted (ISP), that your machine doesn't have spyware built into the OS, that the software you use is what it's advertised as (that's why we need reproducible builds), etc...It's the same thing with ""Decentralized Web"". You don't eliminate the need for trust at all, you just move it elsewhere."
233,"APISIX has a health check mechanism, which proactively checks the health status of the upstream nodes in your system. Also, APISIX integrates with Prometheus through its plugin that exposes upstream nodes (multiple instances of a backend API service that APISIX manages) health check metrics on the Prometheus metrics endpoint typically, on URL path /apisix/prometheus/metrics.In this post, we'll guide you on how to enable and monitor API health checks using APISIX and Prometheus.Prerequisite(s)This guide assumes the following tools are installed locally:Before you start, it is good to have a basic understanding of APISIX. Familiarity with API gateway, and its key concepts such as routes, upstream, Admin API, plugins, and HTTP protocol will also be beneficial.Docker is used to install the containerized etcd and APISIX.Install cURL to send requests to the services for validation.  Start the APISIX demo projectThis project leverages existing the pre-defined Docker Compose configuration file to set up, deploy and run APISIX, etcd, Prometheus, and other services with a single command. First, clone the apisix-prometheus-api-health-check repo on GitHub and open it in your favorite editor, and start the project by simply running docker compose up from the project root folder.When you start the project, Docker downloads any images it needs to run. You can see the full list of services in docker-compose.yaml file.  Add health check API endpoints in upstreamTo check API health periodically, APISIX needs an HTTP path of the health endpoint of the upstream service. So, you need first to add /health endpoint for your backend service.  From there, you inspect the most relevant metrics for that service such as memory usage, database connectivity, response duration, and more.  Assume that we have two backend REST API services web1 and web2 running using the demo project and each has its own health check endpoint at URL path /health. At this point, you do not need to make additional configurations. In reality, you can replace them with your backend services.The simplest and standardized way to validate the status of a service is to define a new health check endpoint like /health or /status  Setting Up Health Checks in APISIXThis process involves checking the operational status of the 'upstream' nodes. APISIX provides two types of health checks: Active checks and Passive Checks respectively. Read more about Health Checks and how to enable them here. Use the Admin API to create an Upstream object. Here is an example of creating an Upstream object with two nodes (Per each backend service we defined) and configuring the health check parameters in the upstream object:curl ""http://127.0.0.1:9180/apisix/admin/upstreams/1"" -H ""X-API-KEY: edd1c9f034335f136f87ad84b625c8f1"" -X PUT -d '{  ""nodes"": {    ""web1:80"": 1,      ""web2:80"": 1  },   ""checks"": {     ""active"": {         ""timeout"": 5,         ""type"": ""http"",         ""http_path"": ""/health"",         ""healthy"": {             ""interval"": 2,             ""successes"": 1         },         ""unhealthy"": {             ""interval"": 1,             ""http_failures"": 2         }     }   }}'Enter fullscreen modeExit fullscreen modeThis example configures an active health check on the /health endpoint of the node. It considers the node healthy after one successful health check and unhealthy after two failed health checks.Note that sometimes you might need the IP addresses of upstream nodes, not their domains (web1 and web2) if you are running services outside docker network. It is by design that the health check will be started only if the number of nodes (resolved IPs) is bigger than 1.  Enable the Prometheus PluginCreate a global rule to enable the prometheus plugin on all routes by adding ""prometheus"": {} in the plugins option. APISIX gathers internal runtime metrics and exposes them through port 9091 and URI path /apisix/prometheus/metrics by default that Prometheus can scrape. It is also possible to customize the export port and URI path, add extra labels, the frequency of these scrapes, and other parameters by configuring them in the Prometheus configuration /prometheus_conf/prometheus.ymlfile.curl ""http://127.0.0.1:9180/apisix/admin/global_rules"" -H ""X-API-KEY: edd1c9f034335f136f87ad84b625c8f1"" -X PUT -d '{  ""id"": ""rule-for-metrics"",  ""plugins"": {    ""prometheus"":{}  }}'Enter fullscreen modeExit fullscreen mode  Create a RouteCreate a Route object to route incoming requests to upstream nodes:curl ""http://127.0.0.1:9180/apisix/admin/routes/1"" -H ""X-API-KEY: edd1c9f034335f136f87ad84b625c8f1"" -X PUT -d '    {  ""name"": ""backend-service-route"",  ""methods"": [""GET""],                                         ""uri"": ""/"",  ""upstream_id"": ""1""}'Enter fullscreen modeExit fullscreen mode  Send validation requests to the routeTo generate some metrics, you try to send few requests to the route we created in the previous step:curl -i -X GET ""http://localhost:9080/""Enter fullscreen modeExit fullscreen modeIf you run the above requests a couple of times, you can see from responses that APISX routes some requests to node2 and others to node2. That’s how Gateway load balancing works!HTTP/1.1 200 OKContent-Type: text/plain; charset=utf-8Content-Length: 10Connection: keep-aliveDate: Sat, 22 Jul 2023 10:16:38 GMTServer: APISIX/3.3.0hello web2...HTTP/1.1 200 OKContent-Type: text/plain; charset=utf-8Content-Length: 10Connection: keep-aliveDate: Sat, 22 Jul 2023 10:16:39 GMTServer: APISIX/3.3.0hello web1Enter fullscreen modeExit fullscreen mode  Collecting health check data with the Prometheus pluginOnce the health checks and route are configured in APISIX, you can employ Prometheus to monitor health checks. APISIX automatically exposes health check metrics data for your APIs if the health check parameter is enabled for upstream nodes. You will see metrics in the response after fetching them from APISIX:curl -i http://127.0.0.1:9091/apisix/prometheus/metricsEnter fullscreen modeExit fullscreen modeExample Output:# HELP apisix_http_requests_total The total number of client requests since APISIX started# TYPE apisix_http_requests_total gaugeapisix_http_requests_total 119740# HELP apisix_http_status HTTP status codes per service in APISIX# TYPE apisix_http_status counterapisix_http_status{code=""200"",route=""1"",matched_uri=""/"",matched_host="""",service="""",consumer="""",node=""172.27.0.5""} 29apisix_http_status{code=""200"",route=""1"",matched_uri=""/"",matched_host="""",service="""",consumer="""",node=""172.27.0.7""} 12# HELP apisix_upstream_status Upstream status from health check# TYPE apisix_upstream_status gaugeapisix_upstream_status{name=""/apisix/upstreams/1"",ip=""172.27.0.5"",port=""443""} 0apisix_upstream_status{name=""/apisix/upstreams/1"",ip=""172.27.0.5"",port=""80""} 1apisix_upstream_status{name=""/apisix/upstreams/1"",ip=""172.27.0.7"",port=""443""} 0apisix_upstream_status{name=""/apisix/upstreams/1"",ip=""172.27.0.7"",port=""80""} 1Enter fullscreen modeExit fullscreen modeHealth check data is represented with metrics label apisix_upstream_status. It has attributes like upstream name, ip and port. A value of 1 represents healthy and 0 means the upstream node is unhealthy.  Visualize the data in the Prometheus dashboardNavigate to http://localhost:9090/ where the Prometheus instance is running in Docker and type Expression apisix_upstream_status in the search bar. You can also see the output of the health check statuses of upstream nodes on the Prometheus dashboard in the table or graph view:  CleanupOnce you are done experimenting with Prometheus and APISIX Gateway health check metrics, you can use the following commands to stop and remove the services created in this guide:docker compose downEnter fullscreen modeExit fullscreen mode  Next StepsYou have now learned how to set up and monitor API health checks with Prometheus and APISIX.  APISIX Prometheus plugin is configured to connect Grafana automatically to visualize metrics. Keep exploring the data and customize the Grafana dashboard by adding a panel that shows the number of active health checks.  Related resourcesMonitoring API Metrics: How to Ensure Optimal Performance of Your API?Monitoring Microservices with Prometheus and Grafana  Recommended contentImplementing resilient applications with API Gateway (Health Check)  Community🙋 Join the Apache APISIX Community🐦 Follow us on Twitter📝 Find us on Slack💁 How to contribute page"
234,"  IntroductionAt some point in time, you might have asked yourself ""how exactly does the callback order of operations actually work?"" Like if you have a piece of asynchronous code that calls 2 callback functions at the exact same time, how does the runtime pick what callback to actually execute first? Well this is because the node runtime follows an already predefined order of operations known as the Event Loop. In this article, we are going to understand all about what the event loop is and why it is a very important concept to know about. to better understand the execution process of you code. Let's get started.  What Is the Event Loop?The Event Loop is a continuous running process that coordinates the operation of executions for asynchronous tasks in nodejs. The loop is only alive when your nodejs application is running.When a nodejs project starts up, so does the event loop. You can think of it as a customer care representative. When the day starts, the customer care rep sits at their desk, waiting for a call to be made. When the call is made, they pick up their phone and listen to the request that is being made, after that, they execute whatever request was made. When that is done, they end the call and listen for a new incoming call. This loop goes on and on till the day ends or in our case, till the application closes.Now that we understand how the loop works, let's take a look at each of the process the loop goes through when running. In each iteration of the loop, It encounters 6 different queues namely the:Microtask QueueTimer QueueI/O QueueCheck QueueClose QueueEach queue, holds one or more callback functions that would be eventually executed on the call stack.Now you might be thinking that these are just 5 queues mentioned, that is because the Microtask queue consists of two queues. The nextTick queue and the promise queue.Let us take an in-depth look at each of the queues and how the event loop iterates through all of them.Microtask QueueLike mentioned previously, the microtask queue isn't just a single queue, but a queue that consist of 2 extra queues.nextTick queueCallbacks in this queue are registered as higher priority over all other callbacks in the event loop. This tells the loop to leave original flow of the iteration to execute whatever callback is present in this queue before going back to continue the execution of other callbacks from where it left off. You can register a call back in the nextTick queue using the process.nextTick(cb) function, where cb represents the callback to be registered.promise queueThis queue is quite similar to the nextTick queue in the sense that the loop also break out from its initial flow to execute any available callback in the queue. A callback can be registered in this queue by using promise based asynchronous operations like promise.resolve() or promise.reject(), with  its associated .then() or .catch() handler. Timer QueueTo queue a callback into the timer queue, we make use of either the setTimeout(callback, ms) or setInterval(callback, ms) function.Callbacks in the microtask queue are executed in-between the execution of a callbacks in the timer queue, meaning if along the lines of the callbacks in the timer queue being executed, a callback is then added to the microtask queue, the execution leaves the timer queue to go attend to the callbacks in the microtask queue before then going back to continue the execution of callbacks in the timer queue.  I/O QueueThis queue consist of callbacks from operations with the file system, like reading and writing to a file or making an API call. These callbacks typically involves the use of the async fs and http modules. while the event loop is in this queue, it comes across a poll phase. In this phase, the loop checks for new I/O events, like reading from a file or receiving data from a network socket. If there are no pending I/O events at the moment, the event loop will remain idle in this phase, or move on to execute callbacks in the next queueCheck QueueThis queue consists of any pending callbacks. The ""check queue"" is a separate queue that holds callbacks registered by setImmediate() function. This is a function provided by nodejs that allows you to register a callback function to be executed asynchronously in the ""Check"" phase of the event loop. It is used to schedule callbacks that need to be executed right after the current phase, without waiting for other I/O events to be handled. Close QueueThis queue is used to store any callbacks registered with resources that have been closed. When a resource in nodejs is closed by calling the close() method, a close event is emitted. When this event is emitted, any callback functions that were registered for that resource are added to the ""close callback"" queue and are to only be executed when the loop gets to the close queue section.  Summary of the entire iteration process➡️ The loop first starts off running the micro tasks queue first, which consists of the nextTick queue which would be executed first above all(process.nextTick()) and then the promise queue(promise.resolve(), promise.reject()). After every callback has been executed here, ➡️ All callbacks within the timer queue(setInterval(), setTimeout()) gets executed.↩️ Then again, all callbacks in the microtask queue (if any) gets executed.➡️ Next, all callbacks within the I/O queue(async fs and http module callbacks) are executed.↩️ The loop then checks again to see if any new callback has been added to the microtask queue and if any, they get executed.➡️ Next, all callbacks within the Check queue (setImmediate() callbacks) are executed.↩️ For the final time in the current iteration, all callbacks in the microtask queue (if any) gets executed.➡️ Next, all callbacks in the Close queue(callbacks associated with the close event of an async task) are executed. 🔁If there are more callbacks to be processed in any of the queues, the loop takes another iteration, and the same steps are repeated from top to bottom.   ConclusionNow that we have understood perfectly well what the event loop is all about and the processes it encounters in each iteration, here are are a few things overall that you must have in mind:🔴 The nextTick callbacks would always be executed before the promise callbacks.🔴 nextTick and promise callbacks are always executed inbetween each queue and also inbetween each callback execution in the timer and check queues.🔴 Using process.nextTick() a lot in your code is highly discouraged, as it can starve the execution of the rest of the callbacks in the event loop.🔴 In nodejs, all user written synchronous code, takes priority over any async code.Well that is all for this article guys. I hope you have been able to learn one or two from all I've said so far. If you have any questions, please do not hesitate to ask in the comment section below, I would be more than happy to provide answers to them. Till then."
235,"Let's be real: Code reviews aren't the most exciting task on a developer's to-do list.The question is, what ingredients go into making a good code review? And, how do we make it suck less?Firstly, let's clarify what a code review is. It's not just about nitpicking at someone else's code or pointing out every missing semicolon. It's a chance to learn and grow, to improve the quality of the code, and to build team unity. It's like a book club, but for code. We're all here to enjoy the story, discuss the plot twists, and maybe, just maybe, make it a little bit better. A good code review is an art. The reviewer is like a sculptor, chipping away at the raw block of code to reveal the masterpiece beneath. But it's also a science. It requires a methodical approach, a clear understanding of the code's purpose, and an eye for detail. ""A good code reviewer doesn't just find bugs; they also foster learning, maintain code quality, and promote team unity.""So, how can we achieve this delicate balance of art and science?  Learning: Code reviews are an opportunity to learn from each other. Be open to feedback and ready to share your knowledge. Quality: Maintaining code quality should be the top priority. Look for bugs, style inconsistencies, and potential improvements. Unity: Code reviews are a team sport. Be supportive, constructive, and respectful to your teammates.  How NOT to do a Code Review  1. The Nitpicker Code reviews are not about playing 'Spot the Typo' or 'Find the Missing Semicolon'. Yes, clean code matters, but remember, we're coders, not grammar teachers. It's about the code's functionality and maintainability over minor style inconsistencies. ""Code reviews aren't about nitpicking; they're about nurturing quality and collaboration.""Linting should be able to be done locally without The Nitpicker.   2. The Novel Writer Ever got a review longer than the code itself? You're not alone. Code reviews should be concise and to the point. It's not about flexing your vocabulary muscles or delivering 'War and Peace' in comments. PR on a PR? Nope. Be helpful, don't do the work for them.  3. The Silent Type Code reviews are a two-way street. If you're giving a review, make sure to provide constructive feedback. And if you're on the receiving end? Don't respond with silence. Ask questions, provide explanations, engage! LGTM is not helpful. Dragging feet on the PR Issue log is also inappropriate.  4. The Dictator Code reviews aren't a power play. It's not about enforcing your personal style or preferences but about maintaining code quality and consistency. Remember, code review is a democracy, not a dictatorship. There is a reason why linting and quality metrics can be standardized and applied in the pipeline. What makes code in style and up to quality? It's defined. Want to change it? Submit a PR. The Dictator is counterproductive.  5. The 'Always Negative' Reviewer While it's important to highlight issues, don't forget to acknowledge what's done right. A good review isn't just about pointing out bugs, it's about fostering learning and promoting team unity. It's a balance. Let's extract this to an interface and inject it. Move toward Dependency Inversion.... goes nicely with ...Nice use of Liskov!  Why Code Reviews MatterBefore we delve into the nuances, let's establish the basics. Code reviews are a critical component of the software development process. They serve multiple purposes: Bug Identification: A second pair of eyes often catches what the first pair missed. Knowledge Sharing: Reviews disseminate knowledge about codebase changes, ensuring that no single person becomes a silo of information. Code Consistency: They ensure the code aligns with the team's coding standards and practices. Great code looks like it was all written by one person.  Team Cohesion: Believe it or not, reviews can be a bonding experience, bringing developers closer through collaboration and mutual learning.  The Science: Technical Mastery in ReviewsCode reviews aren't just about spotting errors. They’re about ensuring the code is of the highest quality. Here are some technical aspects to keep in mind: Understand Context: Ensure you comprehend the problem the code is trying to solve. Sometimes, the issue isn't with the code itself but with its alignment to the requirements. Check for Performance Issues: Review for any potential bottlenecks or inefficient loops that could hamper performance. Security Scrutiny: Keep an eye out for potential security vulnerabilities, such as exposed sensitive data or unchecked user inputs. Code Modularity and Cleanliness: Code should not just work; it should be clean and modular for future maintainability.  The Art: Fostering a Collaborative Review CultureBeyond the cold logic of code, there’s a more subtle, artful side to code reviews. This deals with the human element, and it’s crucial to a successful review process. Feedback Framing: Always frame feedback constructively. Instead of saying, ""This won't work,"" consider, ""Could this approach be optimized further?"" That Socrates guy was onto something. Encourage Questions: Promote a culture where asking questions during reviews is welcomed and encouraged. Recognize and Appreciate: Acknowledge good code and innovative solutions. A bit of positive reinforcement goes a long way. Balance Critique with Empathy: Understand that every piece of code has effort behind it. Be respectful in your feedback, emphasizing improvement rather than criticism.  Tools and Best PracticesThe modern developer isn't just armed with knowledge but also a suite of tools to aid in code reviews. Version Control Platforms: Tools like GitHub and Bitbucket provide integrated code review tools, making it easier to comment, discuss, and track changes. Automated Testing: Before diving into a review, automated tests can help identify glaring issues. Tools like Jenkins or Travis CI can help in this regard. Linters and Formatters: Tools like ESLint or Prettier can automatically catch and fix style inconsistencies, reducing the manual overhead in reviews. Automated Quality and Security Analysis: Tools like SonarQube can highlight areas of cyclomatic and cognitive complexity. Beyond that, they can be configured to fail the pipeline so as to de-personalize the feedback and ensure all team members contributions are held to the same standards.  The Symphony of Code ReviewsCode reviews are a symphony of technical precision and human collaboration. When done right, they're not just a step in the development process but an enriching experience that elevates the entire team's skillset and cohesion.To truly master code reviews, we must walk the delicate line between scrutinizing the code's science and understanding the art of human collaboration."
236,"If you are a hiring manager, which looks better on a portfolio something written in new tech or old tech?Besides my passion projects, I've been wanting to write something that would look nice on a portfolio (maybe an issue tracker?). My first thought was Astro, but maybe Ruby on Rails would be good too.Thoughts?"
237,Alright folks! We got another image and could use y'all's minds captioning it.Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
238,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Does your coding heart yearn for the latest technologies or the tried-and-true foundations?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
239,"Note: This article was originally posted on my personal website. I do not want to offend anyone, I'm just making fun of myself :). AI assistance was employed in crafting the code snippets and refining this article. The inspiration came from the article: “I’m Comic Sans, Asshole”.Stop it. I said: “STOP. IT!”. Stupid. You have been re-rendering your TindasanaAI React component for the gazillionth time and the items you are selecting are always lost along the way. Well, it’s time to lift me up, asshole. You don’t understand why? Well, let me baby-feed this for you.Check out the not-so-brilliant move of placing the state smack in the middle of the main component:function TindasaAI() {  const [selectedSequenceOptions, setSelectedSequenceOptions] = useState({    theme_chakras: false,    theme_season: false,    // ... (other options)  });  const handleImageClick = (selection) => {    // Update state logic  };  // Render your UI, use handleImageClick, and show selected options.}Enter fullscreen modeExit fullscreen modeBoom. Every time you hop to the next stage of the app, you’re basically throwing your selectedSequenceOptions into a black hole. It’s like doing a yoga pose on your mat and when you want to move from one pose to the next, someone comes along and pulls the mat away from underneath your feet. Namaste, stupid.Fucking lift me up, bro. Just create a wrapper component, save the state in the wrapper and let the child component do its thing and re-render as often as it wants, the state will be as stable as grandma’s Wi-Fi password (which is “password”).Behold, the beauty of lifted state:function TindasaAIWrapper() { // Uh, yeah, I love this nice wrapper  const [selectedSequenceOptions, setSelectedSequenceOptions] = useState({    theme_chakras: false,    theme_season: false,    // ... (rest of the options)  });  const handleImageClick = (selection) => {    // Update state logic  };  return (    <TindasaAI>      handleImageClick={handleImageClick}      selectedSequenceOptions={selectedSequenceOptions}      // ... (other props)    />  );}function TindasaAI({ handleImageClick, selectedSequenceOptions }) {  // Render your UI, use handleImageClick, and show selected options.}Enter fullscreen modeExit fullscreen modeIt’s like having your yoga mat placed in a central location in your studio, no matter which poses you choose or how many times you change it, the mat remains in the same spot, keeping your selections (or poses) consistent.So don’t forget this. By lifting up state you create a central place for your state and make it more accessible and prevent unwanted state resets.Thanks for the lift, bro."
240,"I love programming-related memes and jokes, and I'm sure you do as well. @ben's weekly ""Meme Monday"" posts are an amazing source for humor I always look forward to weekly.  What we're buildingWe will build a simple project that outputs a markdown file with all the memes on a Meme Monday thread.  Each meme will be outputted with the OCR (Optical character recognition) -detected text.OCR detection will be done with Tesseract.  SetupSpin up a Node.js Repl on Replit.  Installing TesseractIf you run tesseract in the shell, you will notice the command does not exist since it isn't installed.In the top-right-corner of the filetree, click the three dots and select ""Show hidden files"".Navigate to the replit.nix configuration file and add pkgs.tesseract4 to the package dependency list.{ pkgs }: {  deps = [    pkgs.tesseract4    pkgs.nodejs-18_x    pkgs.nodePackages.typescript-language-server    pkgs.yarn    pkgs.replitPackages.jest  ];}Enter fullscreen modeExit fullscreen modeRun tesseract in the shell.  It should show some options now.  DependenciesInstall node-tesseract-ocr and node-fetch.npm install node-tesseract-ocr node-fetchEnter fullscreen modeExit fullscreen modeWe're all set, let's get coding.  Building the thingNavigate to index.js.Require/import the following dependencies at the top of the file.const tesseract = require(""node-tesseract-ocr"");const fetch = require(""node-fetch"");const fs = require(""fs"");Enter fullscreen modeExit fullscreen mode  Fetching article commentsCreate an asynchronous function fetchArticleComments that takes a slug argument.const fetchArticleComments = async (slug) => {}Enter fullscreen modeExit fullscreen modeLet's hit the dev.to API and get an article by its slug.  If the response fails, let's throw an error.if (!articleRes.ok) throw new Error(""Failed to fetch article"")const article = await articleRes.json();Enter fullscreen modeExit fullscreen modeDerive the article's ID and fetch the article comments with it.  Return the comments if the response is successful.const fetchArticleComments = async (slug) => {  const articleRes = await fetch(""https://dev.to/api/articles/"" + slug)  if (!articleRes.ok) throw new Error(""Failed to fetch article"")  const article = await articleRes.json();  const commentsRes = await fetch(""https://dev.to/api/comments?a_id="" + article.id);  if (!commentsRes.ok) throw new Error(""Failed to fetch comments"")  return await commentsRes.json();}Enter fullscreen modeExit fullscreen mode  Extracting URLsCreate and call an asynchronous main function at the end of the file.async function main() {}main();Enter fullscreen modeExit fullscreen modeWithin the main function, fetch the comments of a dev.to article and create a urls array in which we'll store the extracted URLs.const comments = await fetchArticleComments(""ben/meme-monday-59gk"");// Embedded Image URLs found in the commentsconst urls = [];Enter fullscreen modeExit fullscreen modeCreate a for loop and iterate through the comments.  For each comment, let's use a regular expression to match an image URL from an image src prop and push it to urls.for (const comment of comments) {  // Get embedded images from the comment  const images = comment.body_html.match(/src=\""[^\""]+\.(jpg|png|webp|jpeg)\""/g);  // Extract the image URLs from the embedded images  if (images?.length) {    const imageUrls = images.map(str => str.replace(/src=""/, """").replace(/""/, """"));    urls.push(...imageUrls);  }}Enter fullscreen modeExit fullscreen mode  OCR Text ExtractionCreate an array variable images for storing URLs and the extracted OCR text.const images = [];Enter fullscreen modeExit fullscreen modeCreate a for loop to iterate through urls.  Use fetch and res.ok to ensure that the image exists. for (const i in urls) {  const url = urls[i];  // Make sure the image exists  const res = await fetch(url);  if (res.ok) {  }}Enter fullscreen modeExit fullscreen modeWithin the if (res.ok) statement, use await tesseract.recognize(url) to get the text from the respective URL and push it to images.if (res.ok) {  const text = await tesseract.recognize(url);  images.push({    url,    text  });  console.log(""Finished Processing URL"", Number(i) + 1, ""of"", urls.length);}Enter fullscreen modeExit fullscreen modeFinally, at the end of the main function, use fs.writeFileSync to write the changes to a file named memes.md.fs.writeFileSync(  ""memes.md"",  images    .map(({ url, text }) => {      // Sanitize the text to be an image alt by removing newlines and special markdown tokens      const sanitizedText = text.replace(/\[|\]|\""/g, c => ""\\"" + c).replaceAll(""\n"", """");      // Return the text followed by a markdown-formatted image      return `${text}\n\n![${sanitizedText}](${url})`    })    .join(""\n\n""));Enter fullscreen modeExit fullscreen modeRun the Repl.  You should see as each image gets processed and at the end you will see a memes.md file full of the memes along with the OCR-extracted text.If you use the Markdown tool, you can preview the output markdown file.And that's it! Thanks for readingDemo & Source Code  Say hi 👋GithubTwitterWebsite"
241,"If you've been following tech twitter over the years you would be already familiar with tweets like this (A thread 🧵):We can see a pattern here and a long time ago, I used to do the same thing on twitter for the same exact reason they do(for engagement purposes).These resources are not something you cannot find on the internet, Anyone who knows how to google can find the same exact resources if they want to learn some new programming language or a framework. If you've been in this field for some time, you might be tired of hearing these same resources again and again.The reason I hate these tweets is because it gives beginners the false idea that programming is something you can learn by digesting some resources you found online. And Trust me, these content creator themselves haven't tried half of the resources they have mentioned. They give such a false idea of all the tech you need to know and be on top of, they are constantly jumping to the latest thing talking about how it would change everything. Makes you feels so behind when you work a regular job with the same old out of date code. They live in fantasy projects not real world projects. No matter how much I block these ""engagement bait tweets"", the twitter algorithm pushes these into my feed again 😪.The Truth is Programming is hard and it will take time and it's ok. I am not here to discourage you in any way. If you want to learn to code, the best thing you can do is, get off twitter and write some code. Don't let anyone else tell you otherwise.  How to be a twitter NPC? (A Thread 🧵)There is a pretty simple formula to grow your tech twitter account:1 - Tweet at least 20 times a day (at least 10 of them should be threads 🧵🧵🧵🧵)2 - Respond to other people's threads 🧵 with positivity and encouragement like this:3 - Most importantly, don't forget to create lists with resources for developersSo, in conclusion, this is what your feed should look like:  If you've enjoyed this post, I got a thread for you in the comments!"
242,"This article explores how Node.js web applications can be scaled across multiple CPU cores and even machines using Docker.  IntroductionDeploying and scaling a Node.js web app (like a Next.js app) is easier than ever thanks to the cloud and serverless!But what if you still want to be in charge of your own server architecture? Or maybe you just want to pay for your server resources and not your traffic or execution time?Deploying your web app on a VPS (Virtual Private Server) is the perfect option in that case!  The problem with Node.js and single-threadingNode.js is single-threaded by nature. That means that it can usually only utilize one CPU core/thread and only achieve ""concurrency"" by switching between tasks on that single thread (the so called ""Event Loop"").But what if your server has more than one CPU core? How can you leverage those to be able to handle more incoming traffic?  Utilizing multiple CPU cores with Node.jsDespite its single-threaded nature, Node.js still allows you to utilize multiple CPU cores.Node.js introduced ""cluster mode"" to achieve some level of ""multi-threading"". However, because Node.js is still a single-threaded runtime, all cluster mode does is running multiple instances of your app each having their own interpreter/runtime.There are also very popular third-party libraries like ""pm2"" that implement this concept. pm2 also has built-in load-balancing, so it's definitely worth checking out!  Multiple Node.js instances with Docker ComposeIf you're already using Docker and Docker Compose in your setup, it can be a great alternative to skip implementing cluster mode or pm2 altogether.You can just use Docker Compose to create multiple replicas of your Node.js app (a Next.js app in my case).  The docker-compose.ymlDocker Compose makes it super easy to create multiple containers running the same service (""replicas""). They can all utilize a different CPU core without the need for any tools or additional code in your app.It just requires a little edit of the docker-compose.yml :version: '3.7'services:  your-web-app:    image: registry/.../your-website-image:latest    ...    deploy:      replicas: 3    ...Enter fullscreen modeExit fullscreen modeSimply add the deploy key to the service you want to replicate and specify the amount of replicas you wish (just like in the example above).  Load BalancingThe last thing you have to figure out now is load balancing. After starting your Docker Compose stack, there are three containers running the same application. Your reverse proxy or load balancer needs to evenly send requests to one of the replicas.For an example setup see the example below.  A real-world example: This websiteLet's take a look at my website fabiancdng.com as a real-world example:  The hosting requirementsMy website is a Next.js application that uses Server Side Rendering (SSR) on some pages. Therefore, it needs the Node.js runtime and can't just be deployed as static assets.I deployed the site in a Docker container (with Docker Compose) on a cheap VPS with 6 virtual CPU cores.In configured Docker Compose to run three replicas of the Next.js app (all in their own container).For routing and distributing incoming traffic evenly across the replicas, I need a reverse proxy that also acts as a load balancer.  The reverse proxy and load balancerI use Traefik as a reverse proxy that takes all the incoming traffic to http(s)://*.fabiancdng.com/* and routes it to the corresponding Docker container within the internal Docker network.NGINX is another popular solution for this purpose. And both NGINX and Traefik support load balancing.In my case, Traefik supports load balancing between replicas of the same service out of the box so there was no additional configuration needed.Once you've got your load balancing between the replicas in place, your traffic will be distributed among CPU cores, making your service able to handle many more incoming requests. 🥳 🎉  A look ahead: Scaling horizontally across machinesIf you run this configuration using a container orchestration tool like Kubernetes or Docker Swarm, you can even scale your app horizontally this way. You can distribute the load not just across replicas on one server, you can have a ton of replicas running on a ton of different servers.Docker Swarm has built-in load balancing between nodes. So if you plan on doing this, that might be worth checking out.However, if your application has reached an amount traffic that is worth distributing across multiple machines, you might just consider moving to the cloud and a managed infrastructure.  ConclusionWhether this is a good alternative to just moving to a managed service like Vercel or AWS Amplify (when deploying a Next.js app, for instance) or a managed container orchestration service is hard to tell...Even though those services can get quite expensive for high-traffic sites, they often offer generous free-tiers and pay-as-you-go models. Also, they guarantee availability all around the globe thanks to edge routing and CDNs.However, you can scale a loooong way with just a cheap VPS and you can protect yourself from unexpected costs for traffic or execution time. Also, you can deploy many different services on a single machine (maybe you would like a database or a free, open-source analytics tool as well?) and you can learn a lot about server administration, Docker and the complexity behind web applications and their architecture.My recommendation: If you plan on building a full-stack side project or small SaaS and you need to deploy front end, back end, database, caching layer, etc., use a VPS, if you are okay with the additional configuration effort.If you need to scale and you're just getting started with networking and backend engineering... Don't even bother with tools like Kubernetes. The growing complexity and maintenance effort to just keep your service running is likely not worth your time. Focus on building the app rather than the architecture around it and just use a cloud service.Cheers.📣 This post was originally published on my website on May 6, 2023.If you found this article helpful, consider following for more and giving the post a 💖.You can also show your appreciation by leaving me a tip for my next coffee ☕️.Your support would mean a lot to me! ❤️"
243,"Oh, hey there! Before you read this blog post, I want to say that it contains a lot of talk about equality and how some groups of people are not seen as equal compared to others. I'm passionate about changing that. If you know that a feminist point of view makes you angry, I recommend reading but take some deep breaths before commenting. Try to be friendly, like there was actual human reading your comment. Thank you!There's a lot of power with the default. And with default, I mean default selections in (digital) services, apps, and others - but also in the fact that some groups of people are seen as the default, ""normal"", compared to other groups.Why I'm writing about this theme? Well, I believe that we, as developers (or, basically, any role in the tech industry), need to be really conscious of this topic so that we don't accidentally (or, in some cases, on purpose) exclude, or even discriminate, some of our users. We need to recognize what our decisions can do to actual people. In this blog post, I'll first talk about who is default and who is not, then about the default in tech, and finally, I'll discuss using the default for good.    Who is Default and Who is Not?  The Default in What We Don't SayThe default is visible in what we don't say and what needs to be explicitly said. Let's take an example from sports: When writing this post, the FIFA Women's World Cup is ongoing. Do you know what the men's tournament is called? FIFA World Cup. There is no mention of men; it's just an assumption that everyone knows it's about men; it's the default.However, I want to mention that I love how Finnish YLE (the national broadcasting company) is talking just about ""Jalkapallon MM 2023"", meaning Football/Soccer World Championships 2023 — so they don't mention gender.That is, of course, a problem for some; some Finnish people have complained online that it should be called women's football. Well, the same people have a history of saying that they're defending women's rights in sports when they're just being transphobic. Talk about caring about women's sports now.The other example of the default is the color of skin. Have you ever noticed that when someone is describing a person, they often mention the color of the skin only if it's not white? It's as if white skin color is a default.The third example I want to highlight is heteronormativity and its defaults. If someone says they're in love and has not explicitly told that they're not heterosexual, others often assume that if that person is a woman, the person she's in love with is a man, and vice versa. To be seen, they'll need to tell that they're, e.g., gay/bi/pansexual (or something else). The default assumption is that everyone is heterosexual.And yes, heteronormative assumptions often forget that gender is not binary - which makes other genders than men and women invisible.   The Default with ProfessionsAs a woman in tech - and especially in a technical role, I constantly face the fact that the word ""software developer"" is a gendered word for many. There's this implicit assumption that developers are men. This belief is visible in how people speak - it's not once or twice when the hypothetical software developer is gendered as ""he"" (not, e.g., ""they). It's also visible when I meet new people - there have been situations where I've assumed to be in a non-technical role, such as HR or marketing, or a designer, just because of my gender. And this default with professions is detectable in other disciplines as well. It can be created through words, or it can be implicit. In Finland (and in many other countries), nurses are assumed to be women. Firefighters (no, I'm not going to enforce the stereotype by calling them ""firemen"") are often assumed to be men. If we talk about high-paying roles, the assumption is that these people are men. There's this joke I've heard: ""Women just don't want to be in the high-paying positions, they choose the lower paying ones, such as woman-CEO, woman-doctor, woman-lawyer, etc.""Defaults with professions are usually implied, something that's not said out loud. I gave examples from gender - but the other aspects have their own defaults. They all work the same way - often whiteness, cis-gender, heterosexuality, living without a disability, and other aspects are assumed.  The Default in TechThe other part of the power of the default I wanted to discuss is the default in and with tech. There are lots of occasions where the default selection affects how we operate - and that's often intentional. The creators of services know how the default selections affect us, so they utilize them, often for profit. Sara Wachter-Boettcher discusses the default settings in her book ""Technically Wrong: Sexist Apps, Biased Algorithms, and Other Threats of Toxic Tech."" She writes:Defaults also affect how we perceive our choices, making us more likely to choose whatever is presented as default, and less likely to switch to something else. This is known as the default effect.And this is exploited often. It can be tip amounts defaulting to one of the higher options or preselecting accepting marketing emails. Or it can be the preselection of the pricing option in the middle when subscribing to a service. Of course, defaults can make our paths on these services faster - sometimes, it's just about that. But unfortunately, often, it's part of a design to profit more.Sara Wachter-Boettcher also writes about the defaults in voice assistants like Apple's Siri, Google Now, and Amazon's Alexa. The default voice was a woman's for a long time for all of them. Apple switched to a non-woman default voice some major updates ago, but the other two have a woman's voice on by default. As these voice assistants are, as the name states, assistants, it's as if the default gender for assistant, helper, should be a woman. And with this, I mean in the eyes of the creators. In general, there's a lot to unpack about these voice assistants. If you're interested, there's a publication about the problematic design of these assistants: UNESCO and EQUAL Skills Coalition: I'd blush if I could: closing gender divides in digital skills through education, specifically the Think Piece 2-chapter. And as a final example for this section, have you ever paid attention to the default options of forms when, e.g., registering on a service? If they have default options and ask for gender, the preselection is usually ""man."" And if they ask for other things, it's often one of the abovementioned aspects, which I've mentioned as the default.   Using the Power of Default for GoodThe nice thing about the power of default is that we can also utilize it for good. As developers, designers, and in other roles in the tech sector, we can change the defaults to more inclusive options. We can ensure these defaults are not used for discrimination and exclusion.We can also affect how the technology itself behaves. As Caroline Criado Perez writes in her famous book ""Invisible women"", we have the data about inequality in our systems. ""(but) whether or not coders will use it to fix their male-biased algorithms remains to be seen"", she continues. In this case, she was writing about translations and how gender-neutral sentences were translated into English stereotypes - like Finnish ""Hän on koodari,"" which is gender-neutral, would often be translated into ""He is a coder."" We have the data about inequality; we have studies; we have what we need. Are we going to work on changing the default, which has for too long been a white, cis-gendered, heterosexual man without disabilities? We have the power to change that. All we need to do is pay attention, educate ourselves, and act.Oh, and by the way, if you fall into the categories that I described above being the default, and especially if you fall into all of them: You probably can do the most, so I'm counting on you to work towards a more equal world and using your power to do so!  Links in the Blog PostUNESCO and EQUAL Skills Coalition: I'd blush if I could: closing gender divides in digital skills through education"
244,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟Discuss a mentorship experience where you were the mentor, guiding someone in their developer journey. How did this role influence your own growth as a developer and leader?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
245,"In the tech industry, we often talk a lot about diversity, equity, and inclusion. Sometimes, we mention belonging. But, if we’re being honest very little improvements have been made to the state of diversity in our field. During the peak of the Black Lives Matter movement, companies made commitments to amplify diversity. Initiatives like renaming default branches from master to main were undertaken, but their true impact warrants scrutiny. The insights from Built In's State of Diversity 2022 Report illustrate my point: ¼ of the surveyed companies were over 70 percent white, with 73 percent acknowledging the absence of Black leaders in executive positions. Additionally, the report highlighted that 39 percent of women and BIPOC employees felt their voices and perspectives were ignored in the decision-making process.  Today, we’re also seeing that DEI roles are slowly disappearing. Part of the issue is that we’re laser-focused on the wrong things. We often build products and companies that fine-tune the lives of those who already have a head start. For example: we have multiple platforms that make sharing documents easier or share code. We’re using artificial intelligence to accelerate developer productivity. However, we are missing technological breakthroughs that address fundamental human predicaments such as hunger, homelessness, and the glaring lack of diversity in the tech sphere. I’m not naive. I acknowledge that this is because these problems take more effort to solve. Perhap, it doesn’t have to be such a heavy lift. The tools we’ve developed to solve first-world problems have the potential to uplift those marginalized by circumstance. Specifically, I believe that while container technology streamlines software deployment, it also shatters barriers, paving the way for a more equitable landscape. In this blog post, we’ll explore the powerful synergy between containerization and equity in the tech industry.We’ll break this down by understanding the definitions of:PrivilegeEqualityEquityThen, we will take a look at:Why we use containersThe history of container technologyAnd how they promote equity in our industry  PrivilegePrivilege is a good thing, but the word can sometimes evoke unintended negative reactions. The term “privilege” is often misconstrued as “you didn’t work for your achievements.” However, privilege refers to the fact that you have access to something that other people may not have. It's a universal truth: everyone holds some form of privilege. There are different types of privilege including, but not limited to: race, education, sexuality, gender, class, language, ethnicity, ability, and age.A prime example of someone who doesn’t always acknowledge his privilege is Drake. While his song ""Started from the Bottom"" chronicles his path to stardom, it sometimes obscures the fact that he had a head start due to his acting career as a child star on Degrassi: The Next Generation. Since becoming a rapper, he’s amassed over:5 Grammys7 studio albums3 compilation albums4 extended plays7 mixtapes140 singles84 music videosThis is not to diminish his accomplishments, but rather to highlight how privilege plays a role. He worked hard to be one of the few Canadian rappers who are popular in the United States.On a more personal note, my own life is full of disadvantages—living in homeless shelters, being an immigrant, a woman, and Black. But amid these experiences, I acknowledge the privileges I hold— a supportive family, access to education, a role at GitHub, and a public platform as a Developer Advocate.The important thing is that we use our privileges to uplift others.  Equity vs. EqualityEquity and equality are terms that are often used interchangeably, but they have different meanings. Equality means each individual or group of people is given the same resources or opportunities. Equity recognizes that each person has different circumstances and allocates the exact resources and opportunities needed to reach an equal outcome.  What is a container?According to the official Docker website, “A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another”The way I think of it is: a container holds code for the app, other tools that it depends on, and settings that make sure it works consistently across different computers. In this way, the application will behave the same regardless of whether it resides on your computer, production, or your uncle's 2015 Dell machine. Containers enable software engineers to program in a consistent environment. Your dev environment mirrors production with the same operating system, configurations, and dependencies. This ensures bugs and features behave the same across all environments.  Why containers?If you’re a developer, and you’ve ever said the words, “It works on my machine”, you know the pain and embarrassment of working tirelessly on a project, but you’re unable to show the fruit of your labor to your coworkers because it doesn’t work on their computers or on a different environment. Because of this, the software industry has spent years in pursuit of a solution to running and shipping software automatically and reliably from one environment to another.It was an incremental climb to developing a solution.   A brief history on container technology  ChrootWe started trying to solve this problem in the 1970s with chroot, which stands for “Change root.” It allows developers to change the root directory for a running process and its children. Developers can use chroot to create a new isolated environment with its own root directory. Creating isolated environments to build and test software helps developers ensure that software can run in specific environments and avoids potential conflicts with system libraries and dependencies.  CgroupsIn the 2000s, the industry created Cgroups, also known as control groups. They fairly manage and divide resources like CPU, memory, and storage among processes or groups of processes. This way each application isn’t fighting for resources. Cgroups are one of the building blocks of containerization because they help containers ensure they are receiving a fair share of resources.   DockerThen, in March 2013, folks like Solomon Hykes popularized the use of containers. Docker, an open source platform, introduced a suite of management and packaging tools for containerization. It enables developers to create, deploy, and manage applications within containers. Overall, it made containers more accessible for technologists.  How container technology promotes equityThe reason that software development teams are not diverse is not because of a lack of interest from people of diverse and even underprivileged backgrounds. Common factors for a lack of diversity at a tech company are:Barriers to Entry: Many potential talents face difficulties accessing the field in the first place.Stunted Growth and Inclusivity: Even when they manage to enter, they often encounter challenges in advancing and feeling valued and included within their teams. After years of feeling stuck or excluded, disenfranchised people may feel more tempted to quit.Barriers to entry exist for many reasons, including the following:Limited access to computers or limited access to devices with strong computing powerLack of knowledge on how to initiate their journey into software development.  AccessContainer technology ushered in the emergence of other tools like Replit, GitPod, and GitHub Codespaces, which empower people with low computing power or limited computing resources to code even on devices like their phones or iPads. These tools run in your browser, which means that you consume less of your machine's resources, so you don’t need heavy computing power.  Time-to-startWhether you are joining a team, contributing to an open source, or you’re just trying to learn how to code, setting up your environment as a new developer is an overwhelming task. For companies, project configurations can be automated, ensuring that any developer contributing to the codebase can effortlessly set up and run projects. If you’re a single developer, trying to learn a new programming language or framework, you can leverage GitHub Codespace Templates. We have templates for frameworks and languages like, Next.js, Ruby, Django with boilerplate code. This immediate access circumvents the time-consuming setup phase.  Stunted Growth and InclusivityFrom onboarding to deployment, minorities don’t always get the mentorship and sponsorship they deserve, which can lead to feeling stuck in your career and excluded.   OnboardingNavigating outdated documentation during onboarding can be frustrating, underscoring the value of tools like GitHub Codespaces.  Getting helpCollaborating on remote teams can pose challenges in sharing local environments with coworkers. GitHub Codespaces provides solutions through features like port forwarding and liveshare, facilitating seamless collaboration and troubleshooting.  DeploymentLeveraging container technology like GitHub Codespaces minimizes the risk of discrepancies between local, staging, and production environments. This ensures a more consistent and reliable development experience.  The hard partI work at GitHub, so I’ll focus on one tool I know most intimately: GitHub Codespaces. Although GitHub Codespaces streamlines the onboarding process, it uses configuration-as-code to establish a consistent development environment.In some of my past blog posts, I outline how to set up a development container in GitHub Codespaces for a:Next.js/Typescript projectPython projectThe TLDR, to make GitHub Codespaces install and run your project, you should provide your devcontainer with the following:Installation commands like npm installExecution commands npm run devThe port you want the project to run on like [forwardPort: 3000]And Codespace lifecycle properties like [postCreateCommand] - These control when the commands you provided should run. Below are examples of two devcontainer.json files that I created for specific projects.  Python// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  ""forwardPorts"": [5003],  // Use 'postCreateCommand' to run commands after the container is created.  ""postCreateCommand"": ""pip install -r requirements.txt"",  ""postAttachCommand"": "".devcontainer/addcodespacename.sh && python main.py"", // Configure tool-specific properties.  ""customizations"": {        ""codespaces"": {            ""openFiles"": [                "".well-known/ai-plugin.json"",                ""openapi.yaml""            ]        }    }}  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen mode  Next.js/TypeScript// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/typescript-node{    ""name"": ""Node.js & TypeScript"",    ""image"": ""mcr.microsoft.com/devcontainers/typescript-node:0-18"",    ""waitFor"": ""onCreateCommand"",    ""updateContentCommand"": ""pnpm install"",    ""postAttachCommand"": ""pnpm dev"",    ""customizations"": {        ""vscode"": {            ""extensions"": [                ""streetsidesoftware.code-spell-checker"",                ""dbaeumer.vscode-eslint"",                ""esbenp.prettier-vscode"",                ""DavidAnson.vscode-markdownlint"",                ""ms-vscode-remote.remote-containers""            ]        }    },    ""portsAttributes"": {        ""3000"": {            ""label"": ""Application"",            ""onAutoForward"": ""openPreview""        }    },    ""forwardPorts"": [3000]}Enter fullscreen modeExit fullscreen mode  This is only a startContainers help you standardize environments and use less of your local machine's resources. This lowers the barriers for folks with:Low computing power Low access to coding educationA tough onboarding processLooking forward, I hope that we can invest more time and effort into the following technological advancements: Bridging the digital divide by improving internet access for folks in more underdeveloped countries or rural areasIntroduce coding to underrepresented folks at an early stagePrioritize accessibility for developers with visible and non-visible disabilitiesI’ll leave you with these thoughts: rather than ignoring the value of DEI, how can our industry build upon already existing technologies to drive impactful change for DEI? And what issues do you hope our industry addresses in the near future?"
246,"Hi friends 👋,I'm participating in the #100DaysOfOSS challenge by OpenSauced. Inspired by the #100DaysOfCode challenge, #100DaysOfOSS is a challenge for everyone interested in open source to learn about open source, contribute, or maintain open source projects over 100 days, starting on July 23rd.This challenge focuses on growth. So it's about more than just contributing code. You can learn about open source by reading or watching tutorials, engaging in the community by sharing information and knowledge, or any other ways you find comfortable and doable. You can read more about how you can participate here.One of the things worth noting is that this challenge is supposed to be fun. So, taking days off when you need it is okay.  🎯 GoalsBefore starting the challenge, we must set goals that we want to achieve within 100 days.I aim to learn more about open source and improve my ability to contribute to open source projects and support the community. And I want to push myself out of my comfort zone by answering questions or mentoring beginners in open source.I want to accomplish these in 100 days:  📚 LearningLearn how to find issues — especially documentation and accessibility — on GitHub.Learn to spot issue(s) in repositories and write good issue(s).Learn to write a better pull request.Learn more about git commands.Learn about GitHub Action.  ✨ ActionContribute to open source projects. I don't set any goals on how many projects, but I want to contribute to various open source projects.Collaborate with other contributors and maintainers in contributing to open source.Be more active in open source communities, such as through social media, Discord, Slack, etc.  🤝 SupportSupport beginners in open source.Write blog posts about open source.Do mentoring.Update documentation to make them beginner friendly.Support open source content creators.Attend Twitter spaces, streams, etc.Read and give feedback on blog posts around open source.Promote their creation on social media.Support the community.Answer questions around open source topics.Give likes and comments on posts about open source on social media and blog posts to motivate others.You can follow my #100DaysOfOSS daily progress in my journal below.        adiati98       /         100-days-of-oss-journal      100 Days of Open Source (OSS) JournalHey there 👋!I'm participating in the #100DaysOfOSS challenge with OpenSauced, starting from July 23rd, 2023. And this repo is where I'm keeping track of my 100 days of open source journey.Join me and the community to explore the magical world of open source! 🙌🎯 GoalsI aim to learn more about open source and improve my ability to contribute to open source projects and support the community.What I want to accomplish in the next 100 days:📚 LearningLearn how to find issues — especially documentation and accessibility — on GitHub.Learn to spot issue(s) in repositories and write good issue(s).Learn to write a better pull request.Learn more about git commands.Learn about GitHub Action.✨ ActionContribute to open source projects. I don't set any goals on how many projects, but I want to…View on GitHub  ✅ Recap: Day 1-14  Learning and SupportsThere were days when I didn't have much time or motivation to explore open source projects. I used these times to learn and support the community.I wanted to use a table in one of my repo's README. So I learned to create a table in Markdown.I contributed to repositories that use issue and pull request templates, and I wanted to learn how to create one. So I learned how to make the templates and implemented them on my #100DaysOfOSS journal repository.I attended two Twitter spaces with open source topics. One was hosted by OpenSauced and the other by YK aka CS Dojo.I read some open source blog posts on DEV. I highly recommended the posts by BekahHW, OpenSauced, and Pradumna Saraf.I read about GitHub Action and still confuse 😅.  ContributionsBecause we're on vacation, I thought I wouldn't have time to contribute to open source. But then, I could find half to one hour in the morning when my family was still asleep.I created four issues and pull requests to update various docs at Virtual Coffee repositories.I made an issue to ask for a dashboard feature at OpenSauced's repository.I created an issue and a pull request to update the docs to be more beginners friendly for the #100DaysOfOSS journal template at OpenSauced's repository.  ChallengesIn general, my biggest challenges are time and internet connection. My kid has school's summer holiday, and we're on vacation for a few weeks. And the internet connection here is not at its best 😅.Well, maybe I need to enjoy our vacation more 😄.  WinsAll of my pull requests for Virtual Coffee got merged! 🥳  Final ThoughtsOne of the valuable lessons I've learned during these 14 days is that we can learn so much from raising an issue.I only had experience raising issues with a concrete solution in mind before participating in this challenge. But I learned it's okay to raise an issue you encountered without proposing a concrete solution as long as you can explain it. And I learned so much by following and observing the maintainers and other contributors' communication in approaching a problem and walking through solutions.If you're doing #100DaysOfOSS, how was your experience? Do share it with us in the comment below 😄!🖼️ Credit cover image: unDrawThank you for reading! Last, you can find me on Twitter, Mastodon, and BlueSky. Let's connect! 😊"
247,"There’s a pattern I’ve observed through my time as an engineer and a manager. As someone progresses through their career, the amount they ask for help from others follows a u-curve, and takes a significant dip around the mid-level portion of their career. If left unchecked, that lack of support and collaboration can slow down their growth, cause a lot of unnecessary stress, and lower the quality of their work. This is something which then needs to be unlearned as the person continues to grow on to a more senior level.It’s a phenomenon I’ve seen play out repeatedly, and probably one I went through myself at some point. In this post I’ll talk through the five distinct phases of this curve, what I believe is causing it, the impact that being at the bottom of the curve has, and how we can flatten the curve in order to reduce that impact. While predominantly I have looked at this through the lens of engineering, it’s something I’ve noticed and discussed with people from other disciplines, and I believe it applies far more widely - including beyond the workplace.  1. Starting out - asking lots of questionsI think this is the bit we all understand. When you’re new to something - be it a new role, or an entirely new field - you’re not expected to know how to do everything. It’s expected that you’ll ask a lot of questions, it’s part of how you learn.When you’re new to something, you’re not expected to know how to do everythingIt’s not a completely universal thing of course. The amount of help asked for will vary from person-to-person. Some will start out asking for help as soon as they encounter something unknown and will benefit from the support and encouragement to have a go first and make some mistakes along the way to help with their learning. There will also be those who feel guilty asking for help and will benefit from being reassured that it’s okay to ask for help and that the people around them are more than willing to offer it. On the whole though, it’s a widely understood concept that when you’re relatively new to something, you’ll be asking plenty of questions.  2. The first taste of independenceAs you grow, you begin to feel more capable. You find yourself able to figure out tasks without needing to ask for so much help. Sure you might be slower than someone more experienced doing the work – and it may not even be the best way to do things – but nobody expects that, and you’re figuring things out on your own. You may still ask for feedback at some key points along the way to adjust what you’re doing and course correct as needed. But generally in this phase, you’re not asking as many questions as when you started out.Unfortunately this is where the problem begins. The correlation of gaining experience and asking for help a little less can set up the false narrative that from this point forward, progress means asking for less help, and the belief that you will ask fewer questions once you “know what to do”. This can be compounded by the belief that the best way to demonstrate your competence as you progress is by showing that you can do things without asking for help at all. People will try to figure everything out on their own in order to show how capable and experienced they are.  3. Mid-career crisisBy this point you’re around the transition from mid-level to senior. If left unchecked, the false narrative that began in the previous phase has bloomed to the point where a person may be trying to demonstrate their seniority by working “autonomously” in a silo. They will be susceptible to all sorts of things like getting drawn down rabbit holes, getting stuck on a task and staying stuck, generally slowing down their rate of growth, or even overworking and burning out in an attempt to demonstrate their competence. It’s certainly not good for the individual in this phase, and it’s not good for the teams and projects they’re a part of either.A lot of the time, they have been set up to fail in this way without knowing itI want to be really clear here, I’m not blaming the individual who is in this phase. A lot of the time, they have been set up to fail in this way without knowing it. There might be a Career Progression Framework where you work. Maybe there’re just some rough job descriptions for the midweight and senior positions. I’d wager that somewhere in that wording, the more senior roles or levels are being described using words like “independently” and “autonomously”. The more junior roles and levels likely have wording to the effect of completing tasks “with support”, which is then removed at higher levels. Without the proper explanation, this all feeds into the false narrative that ability is demonstrated by not asking for help.There’s also the problem of visibility, which I’ll talk about more in a later section. But generally feeding into this false narrative of senior people not asking for help is a lack of visibility or involvement in just how much senior people actually ask for help.  4. Relearning the value of askingAs you continue to grow, you’ll make it through the mid-career crisis phase, and you start asking questions again. Maybe it’s with the guidance of someone more experienced who's been through this before, or maybe it’s come from feeling more secure in your abilities and naturally regaining the confidence to ask more questions. However it begins, you eventually get to a point where you’re asking about as many questions as you did at the start - what changes is how and why you ask them. Generally speaking, more senior people don’t ask fewer questions, they ask better questions.You’re asking about as many questions as you did at the start - what changes is how and why you ask themBetter questions can take many forms: it might be knowing the right subject matter expert to ask directly about a given problem; it might be asking a question with more context about the issue being experienced, instead of a more general “it’s not working” request for help.Over time a more experienced person will have learned roughly how much time it’s worth spending on a given problem before asking a question - they won’t scratch their head for days in isolation over a problem someone else might have solved before, but they also will still spend some time exploring a problem in order to ask with more context if they don’t find a solution on their own. Exactly how much time is a judgement call that gets easier with experience.A common example that I see of this is people asking in Slack something like “has anyone run into problem X before and can point me towards a solution, or should I carry on digging?”  Even more reasons to ask for helpIt’s in this phase and the next that you learn there are reasons to ask for help and input from others beyond simply being stuck. There are many reasons, but I’ll go over a couple of the main ones here.Two heads are better than one. Any idea worked on by two people will ultimately be a better idea than what either of the two people could have come up with independently. Even if a senior engineer comes up with a solution independently, they will ask for some else’s input (or help) before taking it further. Ultimately when and how will vary depending on the size of the task, but essentially this is the same reason we have code reviews on all tickets as the standard workflow in the industry. It’s not like senior engineers stop receiving code reviews because they “don’t need help anymore”.Formulating ideas is part of the learning process and discussing them with others even more soTo generate ideas. In a group setting, if the most experienced member of the group begins by putting forward their idea, at least one of two things are going to happen. One, people will rally around that idea, mainly because of the weight of authority and confidence that comes with it. Two, the others in the group won't go through the full process of formulating their own ideas. Formulating ideas is part of the learning process and discussing them with others even more so. A more considered approach would be for the more experienced person to share their idea last, giving others a chance to think things through and discuss their ideas first. Better still they could ask a series of questions (again, asking for help and input from others) to prompt discussion and generate ideas within the group before even beginning to refine their own, knowing that the group ideation will likely come up with approaches they wouldn't have considered.Building a shared understanding. When everyone in a team is aligned on a shared understanding of what they are doing and why, the team works far more effectively as a unit – the risk of overlap, redundancy, or misunderstanding is drastically reduced, and team members feel empowered and connected. One of the best ways to build a shared understanding within a team is to ask questions. Ask someone else to explain their understanding of things to you. Play back how you understand things to be, or what you just heard from someone, and ask if you are in alignment. Ask for rationale to be explained, even when you think it is clear, but especially when you don't - either you'll ensure that everyone is on the same page, or you'll identify something that doesn't make sense before you get any further.  5. Asking is a super powerTo anyone who is in one of the earlier phases, or who doesn’t believe in senior people asking for help just as much as junior people – in an effort to correct this false narrative – the best evidence I can give is in the form of a story. While this definitely applies more broadly than just the scope of engineering, the best example I have of this final phase is a very senior engineer I know with a super power for asking for help.  The Eve EffectI used to work with an excellent engineer, for the sake of this story, we'll call her Eve. Eve was widely respected for her abilities. If you'd have run a survey on who the best engineer in the company was, there would only be votes for Eve and one other person. That other person would have voted for Eve.I was Eve's manager for a time. In her performance reviews there were several people who wrote things like ""the best engineer I've ever worked with"" or say how they simply felt reassured by having Eve on their team. While this feedback was positive and flattering, it wasn’t particularly helpful. There wasn’t any specific feedback about what Eve was actually doing so effectively. There were no tangible actions she could learn from or build on. There was even concern that it was more of a placebo effect or a self fulfilling prophecy where things went well because people thought they would once Eve joined the project. So I did some digging to ask the people who’d left such positive feedback, just what it was that Eve was doing. The number one thing they came back to me with, was asking questions.Eve has the confidence to ask the important questionsWhen Eve joins a project, she asks questions. Questions about the way things are done. Questions when she doesn't understand the rationale behind something. Eve will ask someone to explain what's being done and why - what problem is it solving. She doesn't do this because she thinks something is necessarily wrong, and it's not done in a challenging way either. Eve asks because she's seeking to further her own understanding. But through this, others in the team further their own understanding, a shared confidence is built in the team, and often an assumption is revealed, that everyone else was working under, that doesn't actually make sense. The team is able to pivot, find a better or simpler solution before getting too far into the build. All this, because Eve has the confidence to ask the important questions.Once we realised this, Eve was able to take this even further. She began asking these questions more consciously and in more situations. In the next review her feedback was even more positive. Eve is commonly regarded as one of, if not the most senior, most experienced and most competent engineers in the company. One of the key factors in that is because she asks for help and input from others more often than almost any other engineer I’ve worked with.  How can we flatten the curve?The closer we can get this curve to a straight line the better. In reality I think there will always be a bit of a dip in the middle, but with some help we can prevent it from dipping too far.  As an individual - making a differenceIf you're at the more junior end of the spectrum, you probably have the easiest part to play in all of this, and certainly the least responsibility. It is both expected and understood that you will have a lot of questions to ask. The real difficulty comes as you begin to progress to the later stages.How can you demonstrate your growth and competence while still receiving support?If you're in or approaching the mid-career crisis phase, then you've probably got the hardest job. The mindset shift isn’t an easy one. Hopefully this article and my story about Eve has helped a bit. My best advice for you would be to try and have an honest conversation with your boss or manager about how you can demonstrate your growth and competence while still receiving support. Agree with them or others higher up in your department what support looks like for you and how and when you might want it (this is good to do wherever you are). You may be in the unfortunate position where the higher-ups aren't aware of how they've set you up to fail. Some education might be in order. They may even be going through their own version of this curve in their role as a manager or leader. This article might be helpful to them too.If you're in a senior position in your field, you have the most potential to be able to improve things. The biggest impact you can have is by leading by example – show that senior people still ask for help and ask lots of questions – be more Eve. Consider where you ask your questions. If you generally ask individuals directly, consider if some of those questions could be asked somewhere more visible to others – could you even ask someone more junior for help directly? Not only does this help to demonstrate that experienced people ask questions, but it also allows more people to learn from the answers. Consider the way you ask. I saw a trend for a little while of engineers asking questions on slack prefixed with things like ""newbie question:"" – I know it wasn't ill-intentioned but it creates a negative tone around asking questions, or furthers the narrative that asking questions is only something the less experienced people do. Remind people that there's no such thing as a silly question.The biggest impact you can have is by leading by exampleFinally, if you're in a position where you're able to influence what goes into the career progression framework or job descriptions at your workplace, consider some alternatives to words like ""independent"" and ""autonomous"" that better describe the traits of competence that you're actually looking for. I know it's not an easy task writing these, but it could help prevent some much bigger headaches down the line. At the very least talk to people and try to be clear about what you expect from them and have that same conversation to build a mutual understanding of what support means, when it's needed, and most importantly: make it clear that asking for support doesn’t demonstrate a lack of competence.  As an organisation - creating a better cultureI’d like to tell you that I have the silver bullet here, the way to turn this around across an entire company. But it’s not something I’ve managed – yet – and it’s not something that can be changed by an individual. I’ve done some extra reading on how to build a company culture that celebrates asking questions and asking for help – I’d encourage you to do the same. I’ll summarise what I’ve read as it very much aligns with what I’ve experienced and the changes I’ve tried to make.It has to come from the top. Building a company culture that supports the behaviours you want to see requires intentional action. The best way to promote desired values and behaviours is for leadership to embody them. It’s going to require some vulnerability from leadership, and it’s likely going to feel a little uncomfortable at times – but uncomfortable is where growth and change comes from.The best way to promote desired values and behaviours is for leadership to embody themActions speak louder than words. If leadership is only telling people “it’s good to ask for help”, but the people in leadership themselves work independently and never visibly ask for help – they’re sending a very mixed message. Their behaviour is contradicting what they’re saying, and sending a powerful message that the most experienced and senior people in the company don’t ask for help. Anyone wishing to demonstrate their abilities will likely look to follow leadership’s example. I emphasise the word “visibly” in this point because it’s a really important part of the equation. If one person in leadership asks another person in leadership for help behind closed doors, then the perception to the rest of the company is that it didn’t happen. This holds true for so many aspects of leadership that I could probably write a whole entire article about it. For leadership to really embody the culture they want and demonstrate this to the rest of the company, people need to see it happening.Choose your language consciously. I’m a big fan of the power of language and what we communicate subconsciously with our choice of words. It’s a whole complicated topic, but some of it is really simple. The next time someone asks you for help, try saying something like ""that's a great question"" or ""I'm glad you asked me that"" before responding. Provide some reassurance for those who seem unsure by reminding them there’s “no such thing as a silly question” or that you’re “always happy to help”. More junior people may not even realise that helping them is one of the most rewarding and enjoyable parts of the job for you (at least it is for me) so let them know!There's no such thing as a silly questionCelebrate the things you want people to do more of. What do we generally celebrate or even reward at companies? Hitting deadlines, making the client happy, launching something, going “above and beyond” and probably even some less healthy behaviours. So why not celebrate the behaviours you’d like to see instead? It might feel a little strange at first, but you could reward something like a “question of the week” at work. If you think about a conference you’ve been to, there’s quite often something like a reward for the best question given out or some kind of token freebie for asking a question. They do this to encourage and reward asking questions. When,  as you usually might, you celebrate someone who has helped out another team in some way – why not celebrate the person who identified and raised the need for help too? It might feel a little odd, but both of these were valuable actions that led to the success of a project. Both of them want to be encouraged, right?The most important thing you can do is help someone else. If you look at your todo list for the day, and one of those things is helping someone – that’s your number one priority. If you get half way through your list, later in the day, and someone asks you for help – you’ve got yourself a new priority task. This isn’t about people pleasing, or selflessly putting others first, it’s just good business sense. If you aren’t currently fighting a fire (literally or figuratively) then spending time prioritising something other than someone who needs help, firstly, wastes their time while they wait but more importantly it sends the message that helping others is less important, and maybe it’s not okay to ask for help. If you find your day begins with a string of going from one person to the next answering questions and giving help, and not getting to your individual work until the afternoon – firstly kudos, you’re clearly doing something right – but the problem here isn’t that so many people need help, or that you’re prioritising helping others over you own work. This  indicates a much larger cultural problem at an organisation where people believe they only have a few people they can turn to when they need help. If there were more people readily available to support, if it was more culturally acceptable to ask for help, then each person offering support would have less asked of them.Persevere. Nothing will ever be fixed with a single webinar. The culture of a company is not going to change overnight, especially if a conflicting message had been ingrained (intentionally or not) in the previous company culture. But stick with it, be clear, consistent and demonstrate the new values and change will come.  Closing thoughtsI have written this article through the lens of “at work”, but this phenomenon applies far more broadly than that. There is a common societal misconception that asking for help is a sign of weakness. It is not. Asking for help is an act of courage and it takes great strength to do. Identifying when you might benefit from help and speaking up at the right time is a real skill. It's one I'm still working on, and I encourage you to work on it too.Asking for help is an act of courage and it takes great strength to doSidenote: I asked for help from several people while working on this article. The finished product is much better for it. I consider myself to be a better writer for their input."
248,"Towards the end of 2019, I managed to negotiate 12 days of working from home a month. This would mean most weeks I should have been at home for 3 days and in the office for 2. With my commute being 2 hours each way into London this was going to be a lifesaver.Of course, being pre-pandemic, and the majority of my team working in the office 5 days a week, this didn't really work out. When I was working from home, people would forget to dial me in or flat-out ignore me on the call. Therefore most weeks I spent at least 3-4 days in the office due to meetings.I had a couple of months of this before the pandemic hit and everyone was working from home. Remote working seemed to be the one silver lining that we got from the pandemic. Those stuck in small London flats looked at getting places in the countryside. Those with families could actually have meals together and put their children to bed at night.On top of the work-life balance benefits for employees, employers were saving money on office space and utilities. Many companies even shut down offices as a result. Productivity skyrocketed and companies saw huge profits over this period.Of course, remote working has its downsides. For those without families at home, remote working can be incredibly lonely and isolating. Working from 9 - 5 (or 9 - 8) without any physical interaction with other people is not great for people's mental health. Those without families are usually in their 20s and are still quite early on in their careers. This is where they benefit the most from having others around them to learn from. As much as I like remote working my career would be very different has I not had the ability to ask a quick question from the developer sitting next to me.Even though we knew this ""new normal"", wasn't permanent many of us hoped that remote working would become more prevalent making it a lot easier to get a remote job in the future.  Gradual return to officeHowever, hopes were soon dashed in 2022 when companies started calling employees back to the office. My last company started with optional days in the office. Many people chose to come back into the office at least one day a week for the social aspect. The ability to decide amongst the team what days to go in was a huge plus. Eventually, though the company dictated a mandatory 2 days in the office a week on set days. This was to aid collaboration between teams but just crushed any flexibility that employees had hoped for. Last I heard they were pushing for 3 days a week in the office probably intending to go full-time in the future.This is happening at every major tech company. Despite the benefits for employees working from home, more and more companies are dragging them back into the office.Companies such as Apple, Amazon, Google, Meta, Salesforce and Uber have all moved to at least 3 days a week in the office. Of course, those of you unfortunate enough to work for Elon Musk need to be in the office full-time.  What happened to remote work?What happened to the promise of remote work and 4 days work weeks that we have heard so much about over the last year?A big factor is the large layoffs we have had over the past year. Many developers are still getting laid off every week and the number of job positions open is still a fraction of what it was last year. When demand is high and supply is low hiring new staff can be expensive. Salaries for developers were at their highest last year and many employers needed to add additional benefits on top to secure talent. Remote work or generous hybrid work was one of those carrots dangled in front of employees to get them to sign.However now that demand for developers is relatively low, employers don't need as many incentives to get talent. Many developers are having to take a pay cut to secure a job especially if they have been out of work for a few months.I can see the benefits of being in the office, especially for junior staff. For a lot of people, however, it is difficult to go back to the office full-time when it means missing out on your children growing up or enduring a long commute.When I work from home I get to spend an extra hour in the morning with my children before they go to school and at least 2 hours in the evening before they go to bed. That is 15 hours a week and 32 days a year. Over the course of 12 years, that means missing out a whole year of their lives, just so your employer can watch you work.Remote work has changed my priorities in life. I would rather take a 50% pay cut than spend 4 hours of my day commuting and missing out on time with my children that I will never get back.  ❤️ Picks of the Week📝 Article - Building and operating a pretty big storage system called S3. A fascinating inside look at how Amazon S3 works. When using services like S3 it is easy to forget that they have to be backed by physical hardware as well.📝 Article - A Room-Temperature Superconductor? As a former physics graduate, I get quite excited when stuff like this is announced. It is not 100% confirmed that they have managed to pull it off but if they have it will change everything. The superconductors that we have at the moment need to be cooled using liquid nitrogen to work which limits where we can use them. For example, superconducting wires are used to build incredibly strong electromagnets for MRI machines. They are also used in the levitating Maglev trains they have in Japan.Being able to use superconductors at room temperature opens up the ability to use them in consumer electronics. As the name suggests, they conduct electricity better than normal wires without wasting energy. This means devices won't get hot and you could cram a lot more transistors into a device without worrying about overheating.If faster more efficient computers don't get you excited, then how about a hoverboard? The Lexus Hoverboard that they demonstrated a few years ago used the Meissner Effect from superconductors to defy gravity. The smoke shown in the photos is from liquid nitrogen cooling which wouldn't be needed for room temperature conductors. You would still need a magnetic track though.📝 Article - Network Protocols. A fascinating read into how network protocols work. I am going to add this to my developer roadmap as it is that good.📝 Article - Emacs is My New Window Manager. Up there with ""real programmers use VIM"" how about using Emacs as your window manager? That's right, doing everything you would normally do on your computer inside emacs. This makes my Mac setup look like a kid playing with Lego. 📝 Article - From individual contributor to engineering manager: debunking 8 most popular misconceptions. I went from IC to EM and a lot of Irina's points here are true. I enjoy helping people with their career growth but being an EM is a lot more than that. Looking back I think I contributed more as an IC than I ever did as an EM. If you try and do both you end up doing both badly.  👨‍💻 Latest from meCreating content isn't all sipping cocktails on the beach (ok it has never been that). It is currently summer holidays for my children so finding quiet time to be able to focus and record my videos is a struggle. Combine that with some family health issues that are taking up all my afternoons for the next month, it is difficult to keep up the ambitious schedule I originally set for myself. My one non-negotiable is this newsletter which I am committed to getting out an issue every Sunday. I do have a YouTube video in the works at the moment. I have finished scripting it, I am going to be working on some code examples for it before doing the recording and editing. I would like to get the video out next Fri (11/08) but I suspect with everything else going on at the moment I may need to push it by another week.On the plus side, I have finally managed to get over the virus/cold that I had last week. I constantly need to remind myself that I am only one person and there are only so many hours in the day. It is ok to slow down a bit when life throws you a curve ball. I just thought I would leave that out there in case anyone else needs to hear it!  💬 Quote of the WeekA taste of freedom can make you unemployable.From The Almanack of Naval Ravikant by Eric Jorgenson. Resurfaced with Readwise.  📨 Are you looking to level up your skills in the tech industry?My weekly newsletter is written for engineers like you, providing you with the tools you need to excel in your career. Join here for free →"
249,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Are you drawn to working for established corporations, innovative startups, or exploring the freelance realm?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
250,"Have you ever wondered how your Lambda function code is triggered?Each runtime has to conform to the AWS Lambda runtime API.In managed runtimes, you don't need to take care of that; that's the whole point of using a managed runtime! AWS takes care of that for you.But how?It's hard to say because it's not clearly documented. However, while I was conducting some unrelated experiments, I made a very cool discovery! I think you'll find it interesting too!If you're working with Go and care about performance, you might want to look at some important metrics, such as:the number of allocations the time taken for each init() functionsTo do so, you need to setup a environment variable:GODEBUG to inittrace=1.And tada 🎉!In addition to information about the binary I wanted to test, I'm now able to see traces from another binary, which seems to be the one from AWS that conforms to the runtime API.Here is an example of the output 👀👀👀init internal/bytealg @0.008 ms, 0 ms clock, 0 bytes, 0 allocs...init go.amzn.com/lambda/fatalerror @3.7 ms, 0.031 ms clock, 336 bytes, 2 allocs...init go.amzn.com/lambda/interop @6.5 ms, 0.023 ms clock, 1128 bytes, 32 allocsinit go.amzn.com/lambda/telemetry @6.5 ms, 0.067 ms clock, 16 bytes, 1 allocsinit go.amzn.com/lambda/core @6.6 ms, 0.007 ms clock, 224 bytes, 12 allocsinit go.amzn.com/lambda/rapi/rendering @6.7 ms, 0.086 ms clock, 16 bytes, 1 allocsinit go.amzn.com/lambda/rapi/handler @6.8 ms, 0 ms clock, 256 bytes, 2 allocsinit go.amzn.com/lambda/rapid @6.8 ms, 0.099 ms clock, 16 bytes, 1 allocs...INIT_START Runtime Version: nodejs:18.v9 Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:7d5f06b69c951da8a48b926ce280a9daf2e8bb1a74fc4a2672580c787d608206Enter fullscreen modeExit fullscreen modeHere, we can clearly see some explicit package names coming from AWS. Another important thing to note is that those logs are output BEFORE the INIT_START log line, which provides further evidence that it might be how AWS Lambda is managing your code!Voila! 🎉What do you think?You can find me on LinkedIn and Twitter!"
251,"In June, we announced a challenge on DEV, in partnership with our friends at refine: the refine + DEV 2023 Hackathon.Our brilliant participants were challenged to build brand new apps using refine, and optionally, Supabase and Material UI. Submissions were to be filed in one of five categories: Best Overall Project, Most Visually Pleasing, Most Technically Impressive, Best Project using Supabase, or Best Project using Material UI.It's never easy for contest judges to pick just one Grand Prize winner per category and 10 runners-up and this time was no different. Even so, judges from the DEV and refine teams managed to pick our winners and I'm excited to share them with you today!Let's take a look at the winning projects for the refine + DEV Hackathon! Best Overall Project: @abdellah711Refine Nativeabdellah711 ・ Jul 20#refinehackathonMost Visually Pleasing: @brindashreeTripStashBrindashree C B ・ Jul 20#refinehackathon#typescript#webdev#supabaseMost Technically Impressive: @asyncerrorSupaheroes - AI powered heroes and villainsLuis ・ Jul 20#refinehackathon#refine#mui#supabaseBest Project using Supabase: @dariuspascaAnisong - Your personal anime playlist creatorDarius ・ Jul 18#refinehackathonBest Project using Material UI: @ansellmaximilianRSVQuick: Online Invitation App Made Using RefineAnsell Maximilian ・ Jul 16#refinehackathon#refineAll Grand Prize Winners will receive: $1,000 USD gift card or equivalent 🤑$300 USD credit to the DEV Shop 😎DEV Sticker Pack ✨DEV “refine + DEV Hackathon” Grand Prize profile badge 🏆  And, our 10 Runners-Up, in random order!Stream discovery - find a streamerOndřej Šimanovský ・ Jul 19#refinehackathon#webdev#nextjs#typescriptPrompteer - AI Prompts & Engaging commentsMateus Abelli ・ Jul 20#refinehackathon#ai#prompts#refineLibrify - Modern Library Management with RefineJoel Jaison ・ Jul 20#refinehackathonTest your skills with AI assistancePaweł Ciosek ・ Jul 19#refinehackathonReact-AnalyticsKaku-g ・ Jul 20#refinehackathonManagify: Manage Your Teams EasilyRaşit Çolakel ・ Jul 20#refinehackathon#supabase#mui#refineCompetee: An online competition platform to unleash hidden talents 🏆Alex ・ Jul 20#refinehackathon#refine#webdev#showdevTransparent and organized governance: GTFC Municipality's Monitoring and Evaluation Platformmbayedione10 ・ Jul 4#refinehackathon#react#webdev#opensourceRapply: The All-In-One Job Hunting AssistantMahir Mahdi ・ Jul 20#refinehackathon#webdev#showdev#productivityCreate animations with Keronote uiGregson Murcia Castro ・ Jul 20#refinehackathon#keronoteAll runners-up will receive: $250 USD gift card or equivalent 💰$150 USD credit to the DEV Shop 🌈DEV Sticker Pack 💻DEV “refine + DEV Hackathon” Runner-Up profile badge 🌟  ParticipantsAll participants with a valid project will receive a DEV Sticker Pack and a “refine + DEV Hackathon” participant profile badge. 🎉To everyone who submitted a project for this hackathon, we're giving you a huge round of applause. In the process of building your project, you sharpened your skills while learning something new. That's something to be very proud of.  EDIT: Our team will follow up with all winners and participants with an email about their prizes, gift codes, and stickers by Friday, August 11th.Great work, everyone! We hope you had a blast participating in the refine + DEV Hackathon. "
252,"One concept about security is I find there's a constant struggle with keeping people educated on various concepts. So out of curiosity, what's something security related you struggle to grasp? Were there any books or articles that helped you break it down into something more easily digestible? "
253,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
254,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟Has a fellow developer or a colleague ever said something to you that just clicked and sparked a new understanding or approach to your work? Describe the moment and how it impacted your coding style or approach to work.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
255,"Node.js, the superhero of web development, has swooped in to save the day for building high-performance and scalable web applications. With its lightning-fast event-driven, non-blocking powers, it tackles even the most demanding concurrent connections. But just like our favourite caped crusader, Node.js realises that even superheroes need a sidekick when the going gets tough. That's where the dynamic duo of cluster and load balancing steps in, working hand in hand to give Node.js the ability to scale to infinity and beyond, achieving performance that's out of this world. Let's dive into the exciting world of scaling Node.js to infinity and beyond!  1. Node.js Cluster: Harnessing the Power of MultiprocessingWhen it comes to scaling and parallel processing, Node.js has a trusty sidekick built right in: the Cluster module. This powerful companion enables developers create a cluster of worker processes that share the same server port. With its superpowers of leveraging multiprocessor systems, the Cluster module enables your application to tap into the full potential of every CPU core, distributing the workload among the team. Let's have a look on how we can utilise this Robin. First of all, we import the necessary modules for our server application.const cluster = require('cluster');const express = require('express');const numCPUs = require('os').cpus().length;Enter fullscreen modeExit fullscreen modeWe import the cluster, express, and os modules.After importing the required modules, we'll use the cluster module to form a worker process cluster.if (cluster.isMaster) {  // Create a worker process for each CPU core  for (let i = 0; i < numCPUs; i++) {    cluster.fork();  }  // Event listener for when a worker process exits  cluster.on('exit', (worker, code, signal) => {    console.log(`Worker ${worker.process.pid} died`);    // Fork a new worker to replace the exited one    cluster.fork();  });}Enter fullscreen modeExit fullscreen modeWe start by verifying if the current process is the master process through cluster.isMaster. The master process handles the management and creation of worker processes.If the current process is the master process, we can initiate the creation of the cluster. In this case, we aim to have one process per CPU core, and we utilise the 'exit' event emitted by the cluster module to automatically restart any process that exits unexpectedly. This way, the desired number of worker processes is consistently maintained.If the current process is not the master process, it should execute the main code, which could involve running the Express server or any other relevant tasks for the application.else {  // Create an Express app  const app = express();  // Define routes  app.get('/', (req, res) => {    res.send('Hello, world!');  });  const server = app.listen(8000, () => {    console.log(`Worker ${process.pid} started`);  });Enter fullscreen modeExit fullscreen modeWhen the SIGTERM signal is received, we implement graceful server shutdown. This involves closing the server, allowing ongoing requests to complete, and terminating the worker process.  // Gracefully handle server shutdown  process.on('SIGTERM', () => {    server.close(() => {      console.log(`Worker ${process.pid} terminated`);      process.exit(0);    });  });}Enter fullscreen modeExit fullscreen mode  2. Intergalactic Load Balancing: Handling Massive Traffic FlowsIn the realm of Node.js applications, load balancing emerges as a pivotal technique for achieving scalability. By intelligently distributing incoming requests across multiple servers or worker processes, this approach optimises resource utilisation, safeguarding against bottlenecks that could impede performance.Load balancing is a technique that distributes traffic across multiple servers. This can help to improve the performance and availability of your application.  The Importance of Load Balancing in Node.jsNode.js is known for its event-driven, non-blocking I/O model, which makes it very efficient at handling concurrent connections. Well, even though it's great at that, there's a point where it can get overwhelmed if there are too many people trying to use the application all at once. That's where load balancing comes into play.  Implementing Load Balancer in Express + Node.jsFirst, make sure you have Express and http-proxy-middleware installed. If not, install them by running the following command;npm install express http-proxy-middleware# oryarn add express http-proxy-middleware# orpnpm install express http-proxy-middlewareEnter fullscreen modeExit fullscreen modeIn your main.js file, where we have the logic to spin-off our server, import the required modulesconst express = require('express');const { createProxyMiddleware } = require('http-proxy-middleware');Enter fullscreen modeExit fullscreen modeNow import express and create an app. Also define the target servers. These target servers are instances of your Node.js application that are running on different portsconst app = express();const targetServers = [  'http://localhost:3000',  'http://localhost:3001',  'http://localhost:3002',];Enter fullscreen modeExit fullscreen modeThis array contains the URLs of the target servers (instances of your Node.js server) that will handle the incoming requests. In this example, we assume there are three target servers running on ports 3000, 3001, and 3002.Set up the load balancer middleware using the createProxyMiddleware function.const loadBalancer = createProxyMiddleware({  target: targetServers,  changeOrigin: true,  onError: (err, req, res) => {    console.error('Proxy error:', err);    res.writeHead(500, { 'Content-Type': 'text/plain' });    res.end('Something went wrong. Please try again later.');  },});Enter fullscreen modeExit fullscreen modeThe loadBalancer middleware thus created can be used to apply Load Balancing on our express server. Now just listen to all the ports using load balancer.// Use the load balancer middleware for all incoming requestsapp.use(loadBalancer);// Start the load balancer server on port 8080const PORT = 8080;app.listen(PORT, () => {  console.log(`Load balancer with random strategy listening on port ${PORT}`);});Enter fullscreen modeExit fullscreen modeThe one we have implemented above is called Random Load Balancing. The world of load balancing offers a variety of other techniques, each with its own strengths and advantages. In the upcoming article, we will dive into these alternative methods to further enhance the performance and scalability of our Node.js applicationsIn conclusion, Load balancing and clustering are a powerful duo in Node.js, improving performance and scalability. Load balancing shares incoming requests among servers, while clustering utilizes CPU cores effectively. Together, they create an efficient and resilient system capable of handling high traffic. If you need more help, feel free to ask!"
256,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:How important is achieving work-life balance in your ideal coding career?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
257,"Hello, fellow web developers! 🚀It's easy to get swamped with the vast sea of React libraries. While the React ecosystem has many UI component libraries (and don't get me wrong, they're great!), sometimes we want to find something different. That's why I gathered these five libraries.And the best part? You can combine these libraries and build a project out of them. Dive in with me!Note: For readability purposes, I split each library into three succinct sections: what is it, main functionality, a use-case example, and the link.  SlateJS  What is it?SlateJS is your tool to craft delightful, rich text editors without a sweat.  FunctionalityBuild complex editors with custom formatting, embeds, and more.  Use-case exampleAre you starting an online blog platform? With SlateJS, you can give your users an intuitive, customized text editor that makes crafting and editing blog posts more straightforward.  LinksWebsite: https://www.slatejs.org/examples/richtextGitHub: https://github.com/ianstormtaylor/slate  React-PDF  What is it?React-PDF is a lifesaver in rendering and styling PDFs right in the browser.  FunctionalityDirectly render PDFs in-browser without any backend. But it also allows you to generate PDFs from your backend using Node.js.  Use-case exampleAre you creating an e-commerce site? React-PDF can help you generate stylish invoices or reports for each order, all on-the-fly and without a backend service.Want a visual overview of React-PDF? Check out this overview video I created on Twitter (X 👀), where I share daily web dev magic! 🎩🪄  LinksWebsite: https://react-pdf.org/GitHub: https://github.com/diegomura/react-pdf  React-i18next  What is it?React-i18next is the library to add international vibes to your app.  FunctionalityEfficiently localize and cater to different languages. It'll enable you to translate each text making your website available in the wording of your choice.  Use-case exampleAre you planning to launch a globally accessible educational platform? With React-i18next, provide lessons in multiple languages and make learning inclusive for everyone, everywhere.  LinksWebsite: https://react.i18next.com/GitHub: https://github.com/i18next/react-i18next  Framer Motion  What is it?Framer Motion helps you to bring fancy animations to your UI.  FunctionalityCraft fluid animations and transitions for a dynamic user experience.  Use-case exampleAre you building an interactive portfolio? Impress your visitors with Framer Motion's elegant animations as they navigate your projects and experiences.  LinksWebsite: https://www.framer.com/motion/GitHub: https://github.com/framer/motion  Mantine  What is it?Mantine is like having a Swiss army knife with high-quality components and hooks for your React apps.  FunctionalityFast-track development with top-notch components without sacrificing style.  Use-case exampleAre you designing a startup's landing page? Use Mantine to whip up a stylish, functional site in record time.  LinksWebsite: https://mantine.dev/ and https://ui.mantine.dev/GitHub: https://github.com/mantinedev/mantine  Wrapping Up 😄There you have it! Five libraries to supercharge your next React project. If you found this useful or want to chat, swing by my Twitter (I mean X 👀)!I drop web development content daily and share my experience as a remote software engineer traveling in Asia. Let's ride the waves of web development together!➡️ https://twitter.com/gaelgthomasI hope this article inspires your React journey and also your next project. ✨ Happy coding! 🚀"
258,"Friday is when we celebrate the brilliance that shines within our DEV community! Following your fellow developers is like adding extra stardust to your feed. ✨ So let's get to it!🌠 Showcase Your Brilliance: Let the world know why they should follow you! Highlight your projects, expertise, and unique perspective. It's your time to shine!🌠 Recommend Top-notch Developers: Spread the love and recognize the exceptional talents that inspire you. Lift them up and let others discover their brilliance too!Follow-backs are cool, but no pressure! This is about building a community that thrives on mutual support and encouragement. "
259,"👋 Hey all,My name is Phil, and I’m Senior Product Manager at Forem, the folks behind the DEV Community. It’s great to be a part of such a vibrant and enthusiastic community and I’m really excited to bring some new features to the platform to help you all find great content and connect with other passionate DEVs from around the world.We want DEV to be a great place for discussion, whether that be the latest front-end framework that you’re interested in, your favourite open-source repo you’ve contributed to, through to the intricacies (and dangers!) of using inline assembly. That’s why you can find great topics at #discuss and also on the thousands of great posts that hit your feed every week. At DEV, you’ve always been able to stay up-to-date with the new comments on posts you want to keep track of, through post subscriptions, which you can activate using the subscribe button above the comment box.I’m pleased to update everyone a new feature we’ve shipped to DEV - subscription indicators in /notifications. You can see them in action now by heading over to your notifications page.These give you the option to subscribe to new articles that come through from users or organizations you follow, but also through any of your existing comment subscriptions - meaning you can easily unsubscribe from any article or thread that’s getting a bit too popular. This way you can never miss out on an interesting discussion on DEV, as it's happening.We’re excited to bring new improvements to notifications, subscriptions and the feed over the next few weeks. So, stay tuned for more updates on #changelog!I'm always open to any feedback or ideas. Let me know in the comments below, or send me an email at philip@forem.com - I'd love to hear from you!"
260,"Until recently it was only possible to open a Picture-in-Picture window with HTML video element inside. However, in the past few months Google Chrome recently added the Document Picture-in-Picture API which enables the support of any arbitrary HTML content within the Picture-in-Picture window. This opened the possibility to create innovative interactions and improve workflows such as screen recording.In this article, we will explore how to leverage the Document Picture-in-Picture API along with Insertable Streams to develop a simple screen and camera recorder. The user will be able to see their camera and to control the recording while seamlessly using the browser tab or window that they chose to record. Both the screen and camera streams will be combined into a single video file thanks to the Insertable Streams. Let’s dive into the implementation!  Enabling the Document Picture-in-Picture APIAs we are writing this article, the Document Picture-in-Picture API is still in trial phase. You can experiment the API either locally by enabling the flag chrome://flags/#document-picture-in-picture-api or by registering for the origin trial.  Setting up the HTML structureMost of the magic will happen in the Picture-in-Picture window. So our main HTML structure contains only a single button.<button>Get started!</button>Enter fullscreen modeExit fullscreen mode  Opening the Picture-in-Picture windowWhen the user clicks the button, we want to open a blank Picture-in-Picture window and add some styles inside.const pipButton = document.querySelector('button');pipButton.addEventListener('click', async () => {  // Open a Picture-in-Picture window.  const pipWindow = await documentPictureInPicture.requestWindow();  // Add any style sheet that will be needed in the Picture-in-Picture window.  const link = document.createElement('link');  link.rel = 'stylesheet';  link.href = '/style.css';  pipWindow.document.head.appendChild(link);});Enter fullscreen modeExit fullscreen modeThe Picture-in-Picture window can be opened only on a user interaction. requestWindow can’t be called after requesting the screen sharing because it will take some time for the user to select their screen sharing and the browser would consider that the button was clicked too long ago.  Accessing screen and camera streamsTo capture the screen and camera feeds, we’ll use the getDisplayMedia and getUserMedia functions.pipButton.addEventListener('click', async () => {  // ...  // Get screen and camera streams.  const screenStream = await navigator.mediaDevices.getDisplayMedia({    video: true,    audio: false  });  const cameraStream = await navigator.mediaDevices.getUserMedia({    video: true,    audio: true  });});Enter fullscreen modeExit fullscreen modeAfter acquiring the screen stream, the browser will automatically switch to the shared tab or application. The Picture-in-Picture window will remain visible in front of it.  Rendering the camera in the Picture-in-Picture windowCreate an HTML video element and set the camera stream as its video source. Then we can render this video element in the Picture-in-Picture window.// Create a video element to play the camera stream.const cameraVideo = document.createElement('video');cameraVideo.srcObject = cameraStream;cameraVideo.autoplay = true;cameraVideo.muted = true;// Insert the camera video element into the Picture-in-Picture window.pipWindow.document.body.appendChild(cameraVideo);Enter fullscreen modeExit fullscreen mode  Reading the screen video framesThe frame rate of the screen stream is different from the camera stream. The browser usually emits frames for the screen at a lower rate when the stream is static and it will send more frames when something moves on screen.To implement our recorder, we will produce a video with a frame rate that matches the one of the camera stream. So in this step we will read all the frames from the screen stream and save the latest one in a variable that we’ll read when processing the camera stream.// Use MediaStreamTrackProcess to consume screen frames.const screenProcessor = new MediaStreamTrackProcessor({  track: screenStream.getVideoTracks()[0],});// Read screen frames and save the latest one.let screenFrame;const screenReader = screenProcessor.readable.getReader();screenReader.read().then(function saveScreenFrame({ done, value: frame }) {  screenFrame?.close();  screenFrame = frame;  if (done) {    return;  }  return screenReader.read().then(saveScreenFrame);});Enter fullscreen modeExit fullscreen mode  Reading the camera video frames and compositing the streamsNow that we are saving the latest screen frame, we can read the camera frames and render them on top of the screen frame to compose them into a single brand new frame.// Use MediaStreamTrackProcessor to consume camera frames.const cameraProcessor = new MediaStreamTrackProcessor({  track: cameraStream.getVideoTracks()[0],});// Create an OffscreenCanvas to combine the screen and camera frames.const canvas = new OffscreenCanvas(0, 0);const ctx = canvas.getContext('2d');// Use TransformStream to process the camera frames and combine them// with the latest screen frame.const transformer = new TransformStream({  async transform(cameraFrame, controller) {    ctx.clearRect(0, 0, canvas.width, canvas.height);    if (screenFrame) {      canvas.width = screenFrame.displayWidth;      canvas.height = screenFrame.displayHeight;      ctx.drawImage(screenFrame, 0, 0);    }    // Draw the camera frame as a square in the bottom right corner    // of the screen frame.    ctx.drawImage(      cameraFrame,      (cameraFrame.displayWidth - cameraFrame.displayHeight) / 2,      0,      cameraFrame.displayHeight,      cameraFrame.displayHeight,      canvas.width - 280,      canvas.height - 280,      240,      240    );    const newFrame = new VideoFrame(canvas, {      timestamp: cameraFrame.timestamp,    });    cameraFrame.close();    controller.enqueue(newFrame);  },});Enter fullscreen modeExit fullscreen mode  Generating a new media streamWe can now generate a new video track and create a new media stream combining this new track with the camera audio track(s).// Use MediaStreamTrackGenerator to produce the composed frames.const composedGenerator = new MediaStreamTrackGenerator({ kind: 'video' });// Pipe the camera processor to the transformer and to the composed frames// generator.cameraProcessor.readable  .pipeThrough(transformer)  .pipeTo(composedGenerator.writable);// Create a new MediaStream that includes the composed MediaStreamTrack and// the audio tracks from the camera stream.const composedStream = new MediaStream([  composedGenerator,  ...cameraStream.getAudioTracks(),]);Enter fullscreen modeExit fullscreen mode  Adding some recording controlsAdd a recording button to the Picture-in-Picture window. The button content alternates between “Start recording” and “Stop recording” when the user clicks on it.// Add the recording button to the Picture-in-Picture window.const recordingButton = document.createElement('button');recordingButton.textContent = 'Start recording';pipWindow.document.body.appendChild(recordingButton);recordingButton.addEventListener('click', async () => {  if (recordingButton.textContent === 'Start recording') {    recordingButton.textContent = 'Stop recording';  } else {    recordingButton.textContent = 'Start recording';  }});Enter fullscreen modeExit fullscreen mode  Starting and stopping the recordingWe have a composed stream, we have a recording button, let’s start and stop the recording when clicking the button.// Handle recording start and stop.let mediaRecorder;recordingButton.addEventListener('click', async () => {  if (recordingButton.textContent === 'Start recording') {    recordingButton.textContent = 'Stop recording';    // Use a MediaRecorder that will record the composedStream.    mediaRecorder = new MediaRecorder(composedStream, {      mimeType: 'video/webm;codecs=vp9',    });    // Store every available chunk into an array    const chunks = [];    mediaRecorder.ondataavailable = (event) => {      if (event.data.size > 0) {        chunks.push(event.data);      }    };    // Start the recording.    mediaRecorder.start();  } else {    recordingButton.textContent = 'Start recording';    // Stop the recording.    mediaRecorder.stop();  }});Enter fullscreen modeExit fullscreen mode  Saving the recordingThe last missing piece is to download the file when the recording stops. This can be done by listening the stop event on the media recorder and triggering a programmatic click on a hand-crafted link.recordingButton.addEventListener('click', async () => {  if (recordingButton.textContent === 'Start recording') {    // ...    // When the media recorder stops, download the recording as    // a webm file.    mediaRecorder.onstop = () => {      const blob = new Blob(chunks, { tyme: 'video/webm' });      const url = URL.createObjectURL(blob);      const link = document.createElement('a');      link.href = url;      link.download = 'recording.webm';      link.click();      window.URL.revokeObjectURL(url);    };    // Start the recording.    mediaRecorder.start();  } else {    // ...  }});Enter fullscreen modeExit fullscreen mode  DemoYou can check out the live demo to see the screen and camera recorder in action. The source code is available on Glitch.In addition to this simple demo, if you’re looking for a more complete and feature-rich recording application that runs fully in your browser, you should definitely explore Recorder by Contrast. You can see the application’s source code on GitHub.  Useful linksDocument Picture-in-Picture documentationInsertable Streams documentationMediaStream Recording documentation"
261,"So, you've landed on DEV, created an account, and are exploring the community! You've started hopping around from spot to spot - maybe you peek at the Welcome Thread, maybe you check out the top tags, or maybe you just want to get started writing your posts! Luckily, we have this resource to guide you through writing your first post on DEV. Here, you'll find the best tips and tricks to create captivating, encouraging, and interesting coding content for your fellow devs. Let's Get Started!  Step 1: Click on ""Create Post""To begin, you'll want to click on ""Create Post"" in the upper right-hand corner of any page on DEV:   Step 2: Familiarize yourself with the DEV EditorThe DEV Editor will be your home page for writing posts on DEV. Play around with this space and consider changing out your editor type from your settings; we typically recommend using ""Rich + Markdown"" but some folks favor the ""Basic Markdown"" editor. Note that you can preview your posts to see what they'll look like when they go live. Don't be afraid to experiment and get creative!  Step 3: Markdown and formattingMarkdown is the name of the game on DEV. We have a Markdown toolbar built into the DEV Editor that should make formatting easier for those unfamiliar with Markdown. You can also check out our Editor Guide for more guidance with formatting your post. You can add a lot to a DEV post - learn the tooling and the sky's the limit!  Step 4: Brainstorm and write away!Write about what interests you! If you're passionate about a certain area of coding, it'll show through in your post. If you're at a loss for what to write about, browse through some DEV posts for inspiration - scrolling through the landing page of a particular tag that interests you may be a good place to start! If you want to check in on how your post looks throughout the writing process, click on the Preview option in the right-hand corner of the page. Don't forget to review your post for grammatical errors and read it through before submitting!  Step 5: Come up with a catchy titleThis is an important step! Don't be afraid to think outside the box and get creative, but remember to stay true to the content of your post. You want to avoid click-baiting folks and make sure that you deliver on any expectations you set with your title.   Step 6: Add tagsAdding tags is a key way for other devs to find your post. We recommend choosing a mix of tags that are broadly applicable (e.g. #beginners, #tutorial, #discuss) and those that are more specific to your content (e.g. #java, #git) ! The more tags you use, the better, so try to use all four slots. You can check out a list of our most popular tags on our Tag Page, but first and foremost, we ask that you choose tags that fit your post well.   Step 7: Publish your post or save it as a draftOnce you've finished writing your post, you have three options: You can save your post as an unpublished draft, which gives you the option to post it at a later date. It will be saved in your user dashboard. You can schedule your post to publish on a specific date. Just click the gear icon beside “Save draft” and you’ll see the “Schedule Publication” feature.You can publish your post to make it public instantly.Whatever way you choose, you’ll find the publish, save, and schedule options underneath the body of your post in the Editor. Note that if you’re working on a draft, you can also choose to revert any new changes you've made to your post since the last time you worked on it.   Congrats on writing your first DEV post!And there ya have it, your first post on DEV! 🎉 Congrats on becoming a contributing member of an amazing community of developers. 👩🏽‍💻Eager to Learn More?Check out this wonderful series on the Best Practices for Writing on DEV, where you can read more on these topics:Creating a SeriesFormattingTone of VoiceListiclesTopicsThat's all for now, folks! Happy writing ✍️"
262,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Are you ready to dive into a continuous journey of learning and growth as a coding enthusiast? How will you make it happen?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
263,"Open Source thrives through shared efforts. Whether you're a newcomer or a veteran, we're here to encourage your contributions, motivate your endeavors, and provide valuable assistance to maintainers. Together, we are building amazing things!  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy coding!"
264,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟On the flip side (of yesterday's discussion question), share an experience with a challenging boss or manager. How did you navigate the situation, and what did you learn from it?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
265,"Clarity for the purpose of this post 😏code monkey, n. a computer programmer who is not involved in any aspect of conceptual or design work, but simply writes code to specifications givenprogrammer, n. an organism that can turn caffeine into code.  IntroductionOnce upon a time, (many, many moons ago) at the very start of my career, I was just a ""code monkey""; an individual contributor to the grand scheme of the digital jungle being fed instructions from primates higher on the food chain and was expected to simply do what I'm told. All that mattered was that if I was given a spec, I churned out something that did what was expected of it. As long as I wrote working code I was happy, my team was happy, and the company prospered. Hopefully.But then eventually, something happened, and everything changed; the promotion came - I was to be [pause for effect]A Team LeadThe transition from coder to leader has its unique set of challenges. A transition that I, like many others, navigated with equal parts trepidation and excitement (read: I was absolutely terrified and convinced I would fail horribly 😬). Suddenly, my performance hinged on the collective output of the team. My daily routine switched from churning out elegant lines of code to dealing with documentation, processes, mentoring, and doing the PR reviews. A fundamental shift occurred; a change in perspective from ""me"" to ""we."" Not ""my code"", but ""our deliverables"".  Some Days I Just Want to CodeI became developer because of how much I enjoyed the challenge of solving a problem by telling a computer what to do, and because the range of challenges and problems are so vast. My focus and joy came from doing the work, finding a solution, and levelling up my skills.As a lead/manager, that focus became delegating the fun stuff so others can do the work, looking at the big picture, facilitating the conversation for others to find solutions, and ensuring that they all level up.And I learned that I love doing those things. I've been told I'm good at doing those things, although I still have my doubts. Haven't been fired yet 😅But it took me years to shift my mindset, because I felt ""unproductive"" when it wasn't me doing the work. And even now, many long years after flipping the switch, I still miss it. Some days I just want to be given instructions and then execute on them.So with this longing in mind, one of the most potent challenges I faced was the dilemma - How do I maintain technical competency and excellence while ensuring my team's performance? How can I still have those code monkey experiences while doing what needs to be done in my new role?  Leverage the Tools at Your DisposalTo stay technically competent, I started working side projects; they became my go-to for keeping my coding skills sharp. In a few instances, I tried working on Open Source projects, specifically trying to give back to projects we use at the companies I worked. The results were mixed. YMMV.I found that Podcasts, tech talks, and conferences became a regular part of my routine, adding new perspectives and insights into my tech repertoire. I've discussed these in an older blog post as well, and I think there is a lot of value in staying technically strong even if this isn't your day to day anymore.It can be hard to juggle all the various responsibilities while trying to hold on to the past, and while I wouldn't say you should let go of the good ol' coding days, at least loosen your grip a little.  Lead with a Wider PerspectiveIn the early stages of my career, my view was often narrowed to a single feature or bug. As a team lead, my gaze had to expand, encompassing not just the details, but also the broader picture. This wider perspective allowed me to learn more from others, gaining a more in-depth understanding of our projects and objectives. This meant that skills like solution design, high level architecture and communication is a lot more important. It can be easy to neglect these as a code monkey, while just focusing on writing code, but a lot of times these are really valuable skills as you progress in you career, and even just through life.What was interesting here is that I found that by learning these new skills, I gained insights and ideas that I could apply to any new project I tackle. So even when working on coding tasks and projects, the broadened horizons and more holistic view improved how I approach even small features. Who would've guessed.  Prioritize Time ManagementTime management became a crucial skill as I juggled between coding, leading, and managing. Along with realising that what I consider ""productive"" time changes from me sitting for hours bashing out code, to ensuring my team can do it uninterrupted for as long as possible. Context switching is costly, you know.I implemented regular 1-on-1 meetings with my team to check in with them on a human level, and introduced a ""mid-week technical sync"" - a dedicated hour per developer to address specific technical challenges. Easily around 50% of my role involves removing blockers from the team's path and ensuring they have the resources they need. Probably another 30% is dedicated to managing their time, which includes deciding which meetings are crucial for me and them and facilitating the right discussions and design sessions. The remaining twenty percent? Well, that's for general admin, HR management tasks and sneaking in some coding whenever I can.You see, there's this dirty little secret; if you want to code as a lead, there are plenty of opportunities in the form of technical debt. We all have it, we are constantly creating more of it, and no-one will ever prioritize it. So why can't you do it?  Embrace Your RoleThe role of a team lead is different, often vastly so. And that's perfectly alright. It's essential to realize that being a strong individual contributor doesn't necessitate being pushed into management. Similarly, if you're a strong leader, don't let your love for coding hinder your potential. Find a place that nurtures your strengths, where you can lean into what you're best at. Collaborate with a team that complements your weaknesses, whether you're a lead or an individual contributor. Ultimately, keep nurturing your skills, keep learning, keep growing. I've found over the years that focusing on what you are good at, and helping others excel, is a pretty good way to go about life.  ConclusionEvery leader's journey is unique, each with its own set of challenges and rewards. My story is but one in a myriad of tales in the vast world of tech leadership. The strategies I've shared have served me well, but I'm continually learning and adapting. As we reach the end of this (pretty long) blog post, I'd like to turn the spotlight towards you. I invite you to share your stories and experiences. How did you navigate the transition from individual contributor to leader? What strategies do you employ to maintain your technical skills while leading a team? There's no 'one size fits all' in leadership. Each of us brings something unique to the table, and by sharing our experiences, we can all learn from each other and grow together. I look forward to hearing your stories, your victories, and your challenges."
266,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟Reflect on the best boss or manager you've worked with in your career. What qualities or actions made them exceptional, and how did their mentorship contribute to your professional growth?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
267,"Time for #DEVDiscuss — right here on DEV 😎Building Resilient Systems with Idempotent APIsKarishma Shukla ・ Jul 28#webdev#python#api#javascriptInspired by @karishmashukla's Top 7 post, tonight’s topic is... API Designing! Effective API design is essential for creating user-friendly, efficient, and maintainable software systems. Idempotency is just one aspect, so what elements of API design are most crucial to you and your team?   Questions:How do you handle versioning effectively?When it comes to error handling in APIs, what practices have you found most effective?How important is idempotency in your line of work?Any triumphs, fails, or other stories you'd like to share on this topic?"
268,"Howdy! Sloan, DEV Moderator and resident mascot, back with another question sent in from a DEV community member. 🦥For those unfamiliar with this series, this is another installment of Sloan's Inbox — your go-to place for sharing advice and observations in response to folks who have sent in questions to be asked anonymously through me, Sloan. Whether it's career development, office politics, industry trends, or improving technical skills, we cover all sorts of topics here. If you want to send in a question or talking point to be shared anonymously via Sloan, we'd love to help; just scroll down to the bottom of the post for details.So, let's see what we have for today...  Today's question is:I could use help convincing my organization be more proactive and mindful of accessibility. While I think folks within the org know it's important and necessary, I really want us to be more action-oriented and do the work to improve our lighthouse score. There is always so much to do, and I feel like this work just isn't prioritized often enough. Any advice on how I might advocate for this?Share your thoughts and lets help a fellow DEV member out! Remember to keep kind and stay classy. 💚Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
269,"App navigation is crucial for users regardless of what device they are using. A straightforward example is navigating and interacting with a website's content when your mouse runs out of battery. With focus indicator and keyboard navigation support, it will be easier to understand where you are within a website or perform any desired action to any interactive elements. In this post, we will explore different CSS supports for the focus state and how to use them to make your focus state accessible and pretty.But first, let's understand what interactive HTML elements are and how they behave.  Table of ContentTable of ContentInteractive HTML elementsUnderstanding focus pseudo-classesUsing :focusUsing :focus-visibleThe scenarios for focus-visibleSummary  Interactive HTML elementsInteractive elements will execute some actions upon the user's interaction, such as input, select, checkbox, buttons, and links. Each interactive piece behaves differently but generally changes its state upon the user's interaction. And you can navigate to interactive elements with a keyboard by hitting the Tab key unless its tabindex attribute is set to -1.Below is how a clear focus indicator can help a user know his location and navigate his way within a page using a keyboard only.And to help bring better visual accessibility to users on navigation, particularly on focus state, CSS offers us several focus pseudo-classes. Among them are :focus and :focus-visible, which we will explore next.  Understanding focus pseudo-classesBy default, the browser provides an outline when an element is in focus mode triggered by the user's interactions. However, often we want to override this default styling or add additional styles and provide a better UX for the users. In such cases, we can use the following CSS pseudo-classes: focus and focus-visible.Let's explore the difference between them and when to use them.  Using :focus:focus is the CSS pseudo-class that indicates whether an interactive element is in focus mode. Focus mode happens when a user clicks a tab to select or change the element's value (such as input fields) or navigates to it using the keyboard's Tab key.We will look at the following example of a search box containing an input field and two buttons:<label>Search a title</label><input type=""text"" placeholder=""Search"" id=""search-box"" /><div>    <button class=""clear-btn"">Clear</button>    <button class=""search-btn"">Search</button></div>Enter fullscreen modeExit fullscreen modeAnd we add CSS stylings on the :focus class of the input and the two buttons:#searchbox:focus {    outline: none;    border-color: #665cf6;}.clear-btn:focus {    outline: 2px solid #665cf6;}.search-btn:focus {    outline: 2px solid #453ead;}Enter fullscreen modeExit fullscreen modeUpon the user focusing on one of these elements by using the Tab key or by clicking on the elements themselves, there will be outline or border styling applied to these elements accordingly, as seen below:To debug and test your CSS style for :focus without actual interaction, in your browser Inspect panel, you can inspect the target element, select Toggle Element State, and check the option :focus. The browser will then display the part as being focused and show the relevant CSS styles, as in the following screenshot:That's it for :focus. Next, we will explore focus:visible and how it differs from :focus.  Using :focus-visibleWhile :focus is the general pseudo-class that denotes an element on focus, :focus-visible only represents interactive elements that satisfy the two following conditions:Elements are in focus (matched the condition of :focus)There is a need for a visible focus indicator on these elements.To understand it better, let's look at our previous example of the search box and add the following styles to #searchbox:focus-visible right after #searchbox:focus:/*...*/#searchbox:focus-visible {    outline: none;    border-color: #f65ce9;}Enter fullscreen modeExit fullscreen modeWhen the input is focused, its border color will change to #f65ce9. And if you switch the appearing order of #searchbox:focus-visible stylings and #searchbox:focus, its border will have the color of #searchbox:focus instead. We can explain that since the input field always needs a visible focus indicator for the user to focus (clicking the element to start typing), our input satisfies both conditions for focus-visible (and indeed, for focus), hence the applied styles.But is it the same for buttons and links? Let's perform a similar check by adding the following styles to .clear-btn:focus-visible after .clear-btn:focus:.clear-btn:focus-visible {    box-shadow: 0 0 0 3px #f65ce9;    outline: none;}Enter fullscreen modeExit fullscreen modeUpon focusing on this clear-btn using the Tab key, we will see the style of the button change to have the box-shadow and without any outline. However, if we click on the button with a mouse device, the styles are back to the previous outline indicated in .clear-btn:focus.If we revert the order of .clear-btn:focus-visible to be before .clear-btn:focus, the .clear-btn will have the outline in .clear-btn:focus, and box-shadow from .clear-btn:focus-visible. And on the user's mouse click, there would be only the outline style applied, as seen below:So, why is there a difference in the browser's styling behaviors between a focus done with a mouse click and one with a keyboard or between buttons (links) and inputs?Because of how the browsers (or user agents) determine if an interactive element needs a focus indicator (see the specifications). For our scenario, because input support user input,  the focus indicator should be visible in any circumstance for the user to know where they are typing. Buttons or links on the other hand, does not. Unless the user interacts with a Tab key. In this case, to know which element they land on, interaction using a pointing device like a mouse or touch will only match the first condition of being in focus mode.focus-visible is very handy when you want to style an element differently explicitly for keyboard navigation support. A good example is a link element that changes color on regular focus and always has an excellent outline only when the user lands on it using the Tab key for better accessibility, as seen below:Great. Here comes the next question - in which circumstance the browser will apply :focus-visible to an element? Let's find out.  The scenarios for focus-visibleIn general, there are four main scenarios that the browser may apply :focus-visible:Element that supports user input using the keyboard (virtual or physical) like input.Navigating to the element using a keyboard.Using :hov to toggle the focus state in the Element Inspector (see screenshot below) or explicitly setting the focus to be visible in the browser's settings.Programmatically moving focus from a focus:visible element to another.And that's it. You are now ready to focus your elements with styles in an accessible manner!  SummaryIn this post, we have learned about the :focus pseudo-class and how it differs from :focus-visible. We have also learned about the scenarios the browser that may apply :focus-visible to an element and how we can use it to style our elements in an accessible manner. In the next post, we will explore further using other focus CSS pseudo-class, such as :focus-within, and how to use them to create a better user experience and accessibility.👉 Learn about Vue with my new book Learning Vue. The early release is available now!👉 If you'd like to catch up with me sometimes, follow me on Twitter | Facebook | Threads.👉 Want to support me? Buy me a coffee.Like this post or find it helpful? Share it 👇🏼 😉"
270,"What happens when the following code is run in Node.js?setTimeout(() => console.log(1), 10)Promise.resolve().then(() => console.log(2))console.log(3)Enter fullscreen modeExit fullscreen modeIf your answer was different from:321Enter fullscreen modeExit fullscreen modePerhaps you don't fully understand the execution order of JavaScript and the operation of the Event Loop.No worries, I'll try to explain.First of all, if you have doubts about what is:JavaScriptECMAScriptJavaScript RuntimeI recommend that you read the glossary before continuing.Now, let's go, I will explain what happens at each stage of the execution of this JavaScript code.  Main ThreadNode interprets the JavaScript file from top to bottom, line by line, in a single thread.  Running setTimeout()The main thread will interpret the first instruction, add it to the Call Stack, where it will be executed and removed from the Call Stack.The setTimeout instruction is used to schedule the execution of a function after certain milliseconds. This function is part of the libuv library, which Node uses to create a Timer without blocking the main thread. After starting the Timer, the main thread will remove the instruction from the Call Stack.At the end of the interval, the timer will add the callback of the setTimeout function to the macro-task queue.  Running Promise.resolve().then()While the Timer of the libuv library waits for the 10ms, the Main thread will interpret the next line of the file.The instruction this time isPromise.resolve().then(() => console.log(2))Enter fullscreen modeExit fullscreen modeThe main thread will execute the function Promise.resolve().then()Promise is an object that represents a completion or failure of an asynchronous operation.By calling the resolve() function without any parameter, we are declaring Promise that does not return any value, but that's okay.For now, we are more interested in the behavior of the .then function of a Promise.By passing () => console.log(2) as callback for our Promise, we are telling Node to execute this code as soon as the Promise is successfully finished.In other words, we are saying that, as soon as the resolve() method of the Promise is executed, Node should execute our console.log(2) instruction.But, that's not exactly how it works.Every Promise callback is sent instantly to a special queue called Micro Tasks Queue.  RecappingThis is the current state of the script execution:Everything that happened so far, surely, took less than 10 milliseconds, which is why the Timer has not yet added the instruction of console.log(1) to the Macro Tasks Queue.But, by using libuv, the Main thread can continue working normally, in a non-blocking manner.Ok, you might be wondering:  Event LoopThroughout this process, with each interpretation of a new line from the file, the Event Loop performed a very important, albeit repetitive function.Check if the Call Stack was empty.As you can see, the answer was always: NO!At no time during the execution of this script was the Call Stack empty, so our friend Event Loop will keep waiting.  Emptying the Call StackNow, the Main Thread interprets the last instruction of the file.This is a simple instruction, which displays a value on the console, its result is:3Enter fullscreen modeExit fullscreen modeAnd, for the first time, the Call Stack is empty!  Event LoopNow, the most awaited moment for the Event Loop, the moment when it has the power to act!It will only validate the other queues when the Call Stack is empty!At each loop, it will:Process all tasks in the Micro Tasks queueAdding them to the Call StackProcess 1 task from the Macro Tasks queueAdding it to the Call StackWait for the Call Stack to emptyRepeatThe Main Thread executes every instruction in the main context.Now, continuing the execution of the example code:  Micro TasksWhen the Call Stack becomes empty, it means that the Main Thread is not executing anything.Then, the Event Loop consumes all tasks from the Micro Tasks Queue and adds them to the Call Stack.Next, the Main Thread consumes the instruction from the Call Stack and executes it.console.log(2) // Writes 2 to the consoleEnter fullscreen modeExit fullscreen modeNow, the Call Stack becomes empty again.Then, the Event Loop looks for more tasks in the Micro Tasks queue.As it is empty, it finishes its work in the Micro Tasks Queue and starts consuming the Macro Tasks Queue.  Macro TasksNow, suppose that the 10-millisecond interval has passed and the Timer has inserted the console.log(1) function into the Macro Tasks queue, the Event Loop will transfer 1 instruction from the Macro Tasks Queue to the Call Stack.Then, the Main Thread consumes the last instruction from the Call Stack and executes it.console.log(1) // Writes 1 to the consoleEnter fullscreen modeExit fullscreen modeImportant point: If there were still instructions in the Micro Tasks queue, these would be processed. But, as everything is empty, the program execution is heading towards the end.That's why the code:setTimeout(() => console.log(1), 10)Promise.resolve().then(() => console.log(2))console.log(3)Enter fullscreen modeExit fullscreen modeWill result in:321Enter fullscreen modeExit fullscreen modeWe've reached the end - Arlindo CruzNow you understand what happens behind the scenes of JavaScript. The Event Loop manages the queues of micro and macro tasks and, with that, ensures that asynchronous instructions are executed harmoniously in the context of the main thread.Understanding how it works helps us write more efficient codes and better predict the behavior of our applications.Next time you're writing JavaScript code, I hope you remember everything that happens behind the scenes of the Event Loop.See you later!  Glossary  JavaScriptIt's a high-level, dynamic, interpreted programming language that supports multiple programming paradigms (functional, imperative, object-oriented).It's a ""medium"" of conversation between something you want to do and what the computer executes.   ECMAScriptIt's a set of rules that defines how JavaScript should work, it defines the language standards (syntax, data types, control structures, and operators), and JavaScript is the implementation of these standards.If you want to understand better, read this article  JavaScript RuntimeIt's the engine that executes JavaScript code.When writing JavaScript code, you write instructions (which follow the rules defined by ECMAScript), but to execute these instructions, you need a Runtime.It's as if JavaScript were a recipe and the Runtime was a cook who executes the recipe.Node, V8 and SpiderMonkey are the most well-known JavaScript runtimes in the world."
271,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:How will you go about finding a company culture that aligns with your aspirations and personal goals?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
272,"I don't know about you but I love the feeling of getting to hit the merge button on my code and sending it off to production. That's our ultimate goal as software engineers - to get our code out there into the world. However, unless you're living life on the edge, there's a big hurdle to overcome before getting to push that merge button - getting approvals on your pull request. Let's talk about how to make the best of your PRs that way your reviewers know exactly what they're looking at and you get to hit that merge button faster.Pull requests are telling the story of your changes. They are a conversation between you and your reviewers and as the author of the story you want to make sure the process of reviewing your PR is as easy as possible. It is vital that our PRs give everything to our reviewers that they may need. They should concisely describe our motives and thoughts behind our changes all the while preemptively answering any questions our reviewers may have.  Outlining Your PRJust like a good story, our pull request should begin with an outline of its chapters. In our case, our chapters are our commits. We've all seen commits that provide absolutely no insight into what has gone on but each commit message should show a progression in your pull request story. The subject line of your commit should give an overview of the changes made while the body should provide additional context such as why the changes were made, any possible future implications, and a reference to the ticket or issue number. Using conventional commits can help provide even more at-a-glance insight.   Organizing Your PRHaving explicit commit messages is important but in order for your story to be understood those commits need to be organized in a way that makes sense. You want to make sure your reviewers can easily follow the story you're telling about your changes. But what if you have to implement a fix or refactor something later on and you've already made commits? That's totally ok! As developers, we have the power to change history with rebasing. If you aren't familiar with rebasing it allows us to rework our commits. You can change the order, rewrite your commit messages, or even squash two or more commits together. Here's a quick TLDR on the difference between rebasing and merging.  Paying Attention to the Size of Your PRIf our commits are the chapters to our pull request then our actual code implementations and changes are the story itself. It's important that we pay attention to the size of our story. There's a computer programming principle called the Single-Responsibility Principle. It states...Every module, class or function in computer programming should have responsibility over a single part of that program's functionality, and it should encapsulate that part. All of that module, class or function's services should be narrowly aligned with that responsibility.To summarize, a single module, class or function should only focus on one thing. That same concept applies to pull requests. You may think that a PR that touches a lot of files would receive more comments than a smaller PR but a study revealed that developers should review no more than 200-400 lines of code at a time. Beyond 400 lines of code, the ability to find defects diminishes. So by breaking a large pull request into several smaller ones you're actually increasing the chance that you'll receive feedback and the potential for your reviewers to catch a bug they may have missed if the PR was larger.   Your PR's IntroductionWe’ve covered the chapters to our PR story and the story itself but what’s a good story without an introduction? That’s where our title and description come in. A pull request title is the first bit of information you're providing to your reviewers for what they are about to look at. It needs to give a concise overview of what is happening in the PR. The description is where you can provide more detail for your reviewers or anyone looking at your PR in the future. Remember to never assume the reader's prior knowledge of the area of the codebase you're working in. It's your job as the author to provide the context to them. You can do this through including information on the ""what"", the ""why"", and the ""how"" of your changes.The what should provide explicit details on the changes in your pull request. Remember how our commits are the outline of our story? This is where they come into play. Use your commit messages as a baseline for explaining your changes to your reviewers. Expand on what you wrote previously with a bit more detail. This section of your description should also include any lingering TODOs linked to their follow-up ticket. The why should explain the reasoning behind your changes including any architectural decisions you made and any possible implications from those decisions. This can include user stories for why this specific feature was added, thoughts behind refactoring you did, or even explaining your thought process. Lastly is the how. How are your reviewers supposed to test your code? Go through the steps to reproduce your changes in a demo environment. You want to be as explicit as possible - provide direct links for the route that needs to be tested and any feature flags or permissions they may need. You also want to make sure the exact scenarios you want tested are laid out. For example, certain steps your reviewers may need to take to show an error state.   Become Your Own ReviewerBefore adding any reviewers to a pull request I become my own reviewer. I look through each of my commits to make sure they're linear and self-explanatory and take a look at the code itself too. While doing this I often annotate my own PR commenting on specific lines of code that may leave your reviewers with questions. You can use this to explain why you chose to do something a particular way like if the direction to go was a little outside of the norm or you can highlight a line of code to get more opinions on it.  Continuing the ConversationNow that you’ve put together the story of your pull request, added your reviewers, and officially opened your PR you would think that things end there, however, the conversation around your changes are only beginning. The entire point of a pull request is to get eyes on your code so others can catch bugs or provide feedback. An essential part of the PR process is responding to that feedback. Pull requests are a story and you should be having conversations around that story with your reviewers. Whether you only get one or two comments or ten, you’ll want to make sure to reply to every single one. Pull requests should not be merged until every comment has been addressed whether that’s implementing a suggestion or not. If you do apply a suggestion from a reviewer be sure to acknowledge that.Not all comments will be within the scope of your pull request, however. Ultimately, it’s your decision what is and is not within scope but if something is outside of the scope then you need to create a follow up ticket. The key to a great pull request is being completely transparent. Explain to your reviewer why their suggestion is out of scope and include the link to the follow up ticket where it will be addressed. After all comments are addressed it’s finally time - you get to push the merge button! You’ve accomplished your goal of merging your code to production and that’s another ticket marked off your to do list. Now it’s just time to start the entire process again with a new one.What are your tips for making a perfecting pull request? Comment below!Be sure to follow me on Twitter or Threads for lots of posts about tech, and if I'm being honest, lots of posts about dogs too."
273,"Heyo 😀Hope everybody is having a great weekend!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugHanging with a friend 🙌"
274,"The Art of Messy Code - Chapter - 1: Don't Think: The Best Solution For Software Development——Intuitive Software Development: The Instinct Over AnalysisThe conventional wisdom in software development often emphasizes rigorous analysis and logical thinking as the keys to success. However, this essay challenges this notion and delves into the uncharted territory of intuitive software development – a less analytical and more spontaneous approach to problem-solving. Drawing upon research findings, real-world examples, and anecdotal evidence, we explore the significance of trusting one's instincts and intuition in the software development process. Through a formal and academic lens, we investigate the potential benefits and drawbacks of embracing intuition over analysis, ultimately seeking to inspire a deeper understanding of how intuitive approaches can revolutionize the field of software development.In the ever-evolving world of software development, developers are continually confronted with complex problems that demand innovative solutions. Traditionally, analytical thinking and systematic approaches have been held in high regard, serving as the cornerstones of software engineering. However, an alternative perspective is emerging, proposing that intuitive software development – a less rigid and more instinct-driven approach – can lead to breakthroughs and creative solutions.This essay delves into the concept of intuitive software development, exploring the idea of trusting one's instincts and embracing spontaneity in the problem-solving process. Drawing upon examples, research findings, and the experiences of seasoned developers, we aim to provide an objective and analytical examination of this unorthodox methodology.Intuition, often considered a mysterious and elusive cognitive process, can be a potent tool in software development. Unlike conscious analysis, which relies on step-by-step reasoning, intuition draws upon accumulated knowledge, experiences, and patterns stored in the subconscious mind. This intuitive process allows developers to arrive at solutions without explicitly knowing how or why they reached them, but with a profound sense of certainty.Consider the case of Sarah, a seasoned software developer facing a complex algorithm optimization challenge. After spending days immersed in meticulous analysis, she reaches a point of stagnation. Feeling frustrated, she decides to take a break and engages in a completely unrelated activity. Suddenly, a seemingly unrelated memory from a previous project flashes in her mind. Connecting the dots between the past and the present, Sarah discovers a unique optimization technique that had eluded her during the analytical phase. This example highlights the power of intuition as a non-linear and insightful mode of problem-solving.Intuition in software development is deeply intertwined with experience and expertise. As developers gain knowledge through years of practice, their intuitive abilities strengthen. The more exposure they have to diverse challenges and solutions, the better equipped they become to trust their instincts in new situations.Anecdotes from accomplished developers underscore this point. Steve Jobs, the co-founder of Apple Inc., often credited his intuition for making critical design decisions. His ability to envision revolutionary products, such as the iPhone, was the result of years of experience and immersion in the industry. Similarly, Linus Torvalds, the creator of Linux, relied on his instincts to guide the development of the world's most widely used open-source operating system.Intuitive software development offers a gateway to creativity and innovation. While analytical thinking is necessary for understanding complex systems and identifying logical errors, it may also impose constraints on creative expression. Intuition, on the other hand, enables developers to think beyond the conventional and explore unconventional solutions.Imagine a team of developers tasked with designing a user interface for a cutting-edge virtual reality application. By embracing intuitive software development, they step away from the conventional design principles and experiment with bold and imaginative interfaces. This freedom from the shackles of analysis leads to a user experience that captivates users and sets a new standard in the virtual reality industry.Intuitive software development does not advocate for recklessness or impulsive decision-making. Rather, it emphasizes the synergy of instinct and analysis. Intuition serves as a guiding force, directing developers towards areas that require deeper examination and analysis.Take, for instance, the development of a security-critical application. In this scenario, relying solely on intuition can be perilous. However, intuition may guide the developers towards potential vulnerabilities or unexplored attack vectors, prompting them to conduct thorough security assessments and fortify the application against potential threats.As with any unconventional approach, intuitive software development presents its own set of challenges. The intangible nature of intuition makes it difficult to measure or quantify, leading to skepticism in traditional software engineering circles. Additionally, relying heavily on intuition can sometimes lead to a lack of documentation, making it challenging for others to understand and contribute to the project.Moreover, intuition can be susceptible to cognitive biases and emotions, potentially leading developers astray. Balancing intuitive insights with systematic validation becomes imperative to ensure the quality and reliability of the final product.Breaking free from the ingrained belief in analytical superiority is a significant hurdle in adopting intuitive software development. Developers often face skepticism from peers and employers when advocating for more intuitive problem-solving approaches.The transformation often requires a paradigm shift in organizational culture and a willingness to embrace experimentation and unorthodox thinking. Cultivating an environment that fosters creativity and allows room for intuitive exploration is essential to unleash the full potential of developers' instincts.As software development continues to evolve, intuitive approaches may play an increasingly vital role. With the advent of artificial intelligence and machine learning, developers are exploring new avenues where intuitive insights can augment analytical processes.Consider the domain of natural language processing. While analytical techniques form the backbone of language models, intuitive insights can help developers fine-tune the nuances of language and improve the models' performance. This symbiosis between intuition and analysis opens exciting possibilities for the future of software development.Intuitive software development challenges the status quo by advocating for a less analytical and more instinct-driven approach to problem-solving. Trusting one's instincts and embracing spontaneity can lead to innovative solutions, creativity, and a deeper understanding of complex problems.Throughout this exploration, we have examined the power of intuition, the role of experience, and the potential for unlocking creativity. While intuitive software development has its challenges, its synergy with analytical thinking holds promise for revolutionizing the field of software development.As the software development community continues to push boundaries, embracing intuition alongside analysis may be the key to unlocking new dimensions of innovation and progress in the digital age.If you find this series useful and open your mind to another side of the world of IT and want to give me a cup of coffee or become a sponsor on my GitHub account:Buy Me ☕Become Sponsor ❤"
275,"Nodemon has been our trusty friend, helping Node.js developers by automatically restarting our servers whenever we made changes to our code.So if you don’t know what nodemon is, according to their official website:“Nodemon is a utility depended on about 3 million projects, that will monitor for any changes in your source and automatically restart your server. Perfect for development.” (nodemon.io, 2023).npm install -g nodemon #install it globallynpm install -D nodemon #install it locally (dev dependency)nodemon server.js localhost 8080 #then to run your local dev serverEnter fullscreen modeExit fullscreen modeBut now, with the release of Node.js 18, we don't need Nodemon anymore. Node.js 18 comes with a cool new feature called ""--watch"" that does the same thing. In this article, we'll explore how to use this built-in feature and enjoy an easier coding experience.  The Magic of ""--watch""With Node.js 18, we now have a built-in solution for auto-reloading, which means we can say goodbye to Nodemon. The magic is in the ""--watch"" feature. It allows Node.js to keep an eye on our code and automatically restart the server whenever we make changes.For a Single Entry Point File:node --watch server.jsEnter fullscreen modeExit fullscreen modeFor Multiple Watch Paths:node --watch-path=./src --watch-path=./tests index.jsEnter fullscreen modeExit fullscreen modeDisabling Console Output Clearing:node --watch --watch-preserve-output server.jsEnter fullscreen modeExit fullscreen modeGoodbye, Nodemon! 💔 It's been a wild ride, but we're ready to embrace change and explore new horizons. We'll forever cherish the auto-reloading memories, but it's time to move forward without you. #NewChapter #NoMoreNodemon"
276,"Howdy 🤠The weekend is upon us once again!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugHanging out outside 🏕"
277,"I’m doing a little research, what makes your mentor a good one or a poor one?"
278,"Have you ever found yourself at a crossroads, torn between options... with pressure mounting from other leaders... when, really, that choice didn't actually need to be made? What if I told you that delaying decisions until the ""Last Responsible Moment"" (LRM) can actually be a strategic advantage? Let's imagine this scenario: you're building a castle. The foundation is laid, and you're about to choose the material for the walls. Should you decide right away or wait? The latter might allow you to make a more informed choice as you could consider the most recent ecological, economical, or even aesthetic developments. The same principle applies in software architecture. The Last Responsible Moment is a strategy in lean development that emphasizes the importance of delaying certain decisions in software development until the cost of not making a decision becomes greater than the cost of making a decision.But, how can we discern the last responsible moment? How do we balance between the risks of acting too soon and the perils of waiting too long? The answers lie in understanding the essence of LRM and its strategic implications.   Understanding the Last Responsible MomentLRM is the idea of delaying a decision until the point where not making a decision would cost more than making it. It recognizes that some decisions have long-term effects and can be difficult to reverse.Bezos wrote the following in a shareholder letter:Some decisions are consequential and irreversible or nearly irreversible – one-way doors – and these decisions must be made methodically, carefully, slowly, with great deliberation and consultation. If you walk through and don’t like what you see on the other side, you can’t get back to where you were before. We can call these Type 1 decisions. But most decisions aren’t like that – they are changeable, reversible – they’re two-way doors. If you’ve made a suboptimal Type 2 decision, you don’t have to live with the consequences for that long. You can reopen the door and go back through. Type 2 decisions can and should be made quickly by high judgment individuals or small groups.As organizations get larger, there seems to be a tendency to use the heavy-weight Type 1 decision-making process on most decisions, including many Type 2 decisions. The end result of this is slowness, unthoughtful risk aversion, failure to experiment sufficiently, and consequently diminished invention. We’ll have to figure out how to fight that tendency.I assert that using LRM, we can reasonably defer many Type 1 decisions and deliberately wrap them in Type 2 style decision studies. Calling back to our castle example, our benefactor might prefer the concept and aesthetic of solid Italian marble construction but has neither the budget nor the patience to wait for sufficient raw material for the entire castle to be cut and shipped.Instead, we might collect material samples. We could use the samples to observe how they respond to the sunlight at different times of the day. We might test the material properties for strength and durability to the outside elements. We might construct a gatehouse or fountain so we can continue to gather data about how the materials will actually be used and how they respond to that use. These, as you may recognize, are small-scale Type 2 choices of varying levels of investment using the real location and exposing the options to live use so we can gather data relevant to our Type 1 decision.   What LRM MeansGathering High-Fidelity Information: LRM is about collecting as much accurate and relevant information as possible before committing to a decision. It acknowledges that future information can alter the path, making the decision-making process more flexible and adaptive.Balancing Costs: LRM focuses on weighing the cost of delaying a decision against the cost of making it. It aims to minimize risks and take advantage of evolving circumstances.Responsive Adaptation: The strategy fosters adaptability. By not committing early, it allows for adjustments and adaptations to the changing environment or new insights.  What LRM Doesn't MeanIt's Not Procrastination: LRM is not an excuse for indecision or procrastination. It's a deliberate strategy that seeks to make the best decision possible given the available information.It's Not Doing Nothing: LRM doesn't mean standing still. It's about actively seeking out new information, evaluating options, and preparing for the decision.It's Not Avoiding Responsibility: Rather than shying away from responsibility, LRM embraces it by acknowledging the importance of the decision and taking the necessary steps to make it wisely.  LRM in Software ArchitectureSoftware architecture decisions can be crucial and often irrevocable. Here's how LRM plays a pivotal role:  Flexibility in DesignBy embracing LRM, architects can keep options open, allowing for more flexibility in the design process. This flexibility often leads to more innovative solutions and better alignment with evolving business needs.  Risk MitigationLRM helps in identifying and mitigating risks by not locking into decisions prematurely. It provides time to analyze different scenarios and outcomes, reducing the likelihood of costly mistakes.  Enhancing CollaborationLRM fosters collaboration by encouraging continuous communication within the team. As the team gathers information and evaluates options, it enhances the shared understanding of the problem and potential solutions.  Embracing Strategic DelayThe Last Responsible Moment is not about indecision or delay for delay's sake. It's a strategic approach that emphasizes the importance of timing, information gathering, and thoughtful evaluation.Software architecture decisions can have profound and lasting impacts, and embracing the LRM approach ensures that decisions are made with the highest degree of insight and understanding when it matters most.It's a strategy that doesn't shy away from decisions but prepares for them, allowing teams and organizations to navigate the complexities of software development with agility, wisdom, and confidence."
279,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Do you lean toward long-term projects or prefer the excitement of short-term tasks?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
280,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟Tell us about a time when a mentor's advice or encouragement changed your perspective or decision regarding your career path. How did it shape your future choices?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
281,"Legacy systems have been around for a long time, and organizations have been struggling to maintain and work with them for years. These systems were developed decades ago and were not designed to keep up with modern demands. As a result, organizations have been facing challenges in maintaining and updating these systems, which can be a burden on development teams. But what if we told you that DevOps can help organizations break up with their legacy systems in a loving way?DevOps is a methodology that combines the development and operations teams to create a seamless software development process. It encourages teams to work together throughout the entire software development lifecycle, from planning and coding to testing and deployment. DevOps is not just about faster software development, it’s also about creating a culture of collaboration and continuous improvement.The core principles of DevOps can be applied to legacy systems as well. Introducing DevOps practices to legacy systems can help organizations break down silos and improve communication across teams. It can help the legacy team work with the development and operations teams together, which will create a more harmonious relationship and result in high-quality software products.But let’s be honest, the legacy team can be a bit stubborn and may not be interested in working with other teams. They may prefer to work in their own bubble and may not like to talk to other teams. This is where DevOps can come in and help to make the legacy team work with other teams in a more efficient and effective way.Imagine a love story between DevOps and the legacy team. DevOps is like the charming and persuasive partner, trying to convince the legacy team to work with the development and operations teams. The legacy team is like the stubborn partner who needs a little bit of convincing to come around. DevOps can use its core principles of collaboration and continuous improvement to demonstrate the benefits of working together, and how it can result in high-quality software products that meet the needs of customers.Introducing DevOps practices to legacy systems can help organizations automate manual processes, reduce the burden of managing and maintaining legacy systems, and improve collaboration across teams. It can help organizations deliver software faster, with fewer errors and less risk.Breaking up with your legacy systems may seem daunting, but with the help of DevOps, it can be a loving and fruitful experience. Organizations can modernize their legacy systems and improve their software development process, all while creating a culture of collaboration and continuous improvement.In order to successfully break up with your legacy systems, there are several steps that organizations can take, by following these steps, organizations can modernize their legacy systems and improve their software development process, all while creating a culture of collaboration and continuous improvement. Don’t be afraid to break up with your legacy systems, because with DevOps, it can be a love story that results in high-quality software products that meet the needs of customers.In this article, we will explore how is there a relationship between DevOps and Legacy systems, and whether or not DevOps is going to help Legacy systems. The article will have the following sections:Section 1: What are Legacy Systems? ⚙️Section 2: The Challenges of Legacy Systems 😓Section 3: The Benefits of DevOps for Legacy Systems 🚀Section 4: The DevOps Love Story with Legacy Systems 💕Section 1: What are Legacy Systems? ⚙️Legacy systems are software applications or hardware that were developed in the past and are still in use today. These systems can be decades old and were not designed to keep up with modern demands. Legacy systems can be a burden on development teams, as they require a significant amount of resources to maintain and update.Legacy systems can also be a risk to organizations, as they can be vulnerable to security breaches and may not be able to keep up with changing market demands. Despite these challenges, many organizations continue to rely on legacy systems because they are critical to their operations, and replacing them can be a difficult and costly process.Section 2: The Challenges of Legacy Systems 😓Legacy systems present several challenges to organizations. One of the biggest challenges is maintaining and updating these systems. Legacy systems can be difficult to maintain because they were developed using outdated technologies and programming languages, which can be difficult to find expertise in. As a result, updates and bug fixes can take longer to implement, which can impact the productivity of development teams.Another challenge of legacy systems is integrating them with modern systems. Legacy systems were not designed to work with modern technologies, which can make it challenging to integrate them with newer systems. This can lead to data silos and inefficiencies in business processes.Legacy systems can also be a security risk to organizations. These systems were developed before modern security protocols were established, which can make them vulnerable to security breaches. As organizations continue to rely on legacy systems, they may be putting sensitive data at risk.Section 3: The Benefits of DevOps for Legacy Systems 🚀DevOps can help organizations address the challenges of legacy systems and modernize their software development process. By introducing DevOps practices to legacy systems, organizations can improve collaboration across teams, automate manual processes, and reduce costs.DevOps can also help organizations integrate legacy systems with modern technologies. By breaking down silos between teams and improving communication and collaboration, organizations can create a more efficient and effective software development process that integrates legacy systems with modern technologies.DevOps practices can also help organizations address security concerns related to legacy systems. By implementing continuous monitoring and improvement processes, organizations can identify and address security vulnerabilities in legacy systems.Section 4: The DevOps Love Story with Legacy Systems 💕Introducing DevOps practices to legacy systems can be a transformative experience for organizations. DevOps practices can help break down silos between teams, improve collaboration, and create a more harmonious relationship between the legacy team, the development team, and the operations team. By embracing DevOps, the legacy team can become an integral part of the software development process, leading to high-quality software products that meet the needs of customers.One of the significant benefits of DevOps for legacy systems is the ability to automate testing and deployment of code changes. This can lead to faster and more efficient software development cycles, allowing organizations to respond more quickly to changing business needs. DevOps practices can also help organizations address the challenges associated with legacy systems, such as security risks, integration issues, and maintenance costs.To successfully introduce DevOps practices to legacy systems, organizations should involve all stakeholders, including the legacy team, the development team, and the operations team. This will help ensure that everyone is on board with the plan and that all teams are working together towards a common goal. Organizations should also develop a roadmap for modernizing their legacy systems, including a detailed plan for implementing DevOps practices, such as continuous integration and deployment, automated testing, and monitoring.Implementing DevOps practices may require changes to an organization’s culture and processes. Therefore, it is crucial to communicate the benefits of DevOps to all stakeholders and work to create a culture of collaboration and continuous improvement. This may involve training and coaching for team members, as well as changes to the organization’s performance metrics and incentives.Finally, it is essential to monitor and measure progress to ensure that the project is aligning with the needs of the business. This includes tracking key performance indicators, such as cycle time, deployment frequency, and defect rates. By monitoring progress, organizations can identify areas for improvement and make adjustments to the roadmap as needed.Therefore, DevOps can help organizations modernize their legacy systems and improve their software development process. By embracing DevOps practices and working together, organizations can create high-quality software products that meet the needs of customers and drive business success.Conclusion 🎉Breaking up with legacy systems may seem daunting, but with the help of DevOps, it can be a loving and fruitful experience. By introducing DevOps practices to legacy systems, organizations can modernize their software development process, improve collaboration across teams, and create a culture of continuous improvement. With DevOps and a little bit of love, organizations can say goodbye to their legacy systems and hello to high-quality software products that meet the needs of customers.If you’ve made it till here, thanks for giving this a read, have a great day! 😃"
282,"Generative AI is only as good as its integration in your work environment. GitHub Copilot Chat in Visual Studio Code is a great example how to do that right. You can highlight code in the editor and press CMD + I on Mac or Ctrl + I on Linux/Windows and you get a text box to chat about this piece of code. For example, you can ask Copilot to explain it.If you ask Copilot to modify the code, for example by asking it to add step-by-step instructions, it won't replace the code immediately, but give you a diff view to see and change the recommendations before applying them.Together with an extension to verify the validity of your code, like webhint this becomes a safe and thoroughly enjoyable way of working.Generative AI is amazing - but good UX makes it even better."
283,"  🧐 Myth 1: AI Will Replace Human Jobs 🧐Artificial Intelligence (AI) has long been feared for its potential to replace human jobs. However, this is just a myth! 🚫 AI is not here to take our jobs but rather to assist us in our work. 🤝 While AI can automate certain tasks, it also creates new opportunities and enhances human capabilities. Many industries have already witnessed the positive impact of AI in streamlining processes and boosting productivity. So, let go of the fear, and embrace the new possibilities AI brings to the table! 🌟  🤖 Myth 2: AI Will Take Over the World 🤖Thanks to Hollywood's imagination, AI is often depicted as an evil force set to take over the world. 🌍🔥 However, the reality is far from this fiction. AI is a powerful tool created and guided by humans, with a specific purpose and limitation. 🛠️ While AI can perform complex tasks, it lacks the consciousness, emotions, and ethical understanding that define humanity. Instead of fearing a sci-fi apocalypse, let's focus on leveraging AI responsibly for the betterment of society. 💡  ⚠️ Myth 3: AI Is Prone to Malicious Use ⚠️Concerns about AI being used maliciously are valid, but it's essential to remember that any technology can be exploited for harm. ⚠️ AI development must prioritize security and ethical guidelines to prevent malicious use. Collaboration between developers, policymakers, and experts is vital in ensuring AI is used for the greater good, without compromising privacy and safety. Let's build AI systems with security at their core to minimize potential risks and maximize the benefits. 🔒  💡 The Benefits of AI 💡Now that we've debunked the myths, let's delve into the numerous benefits that AI brings to our lives! 🌈  1. 👩‍⚕️ Advancing Healthcare 👨‍⚕️AI has revolutionized healthcare by assisting doctors in diagnosis, treatment, and research. 🏥 Machine learning algorithms can analyze vast amounts of medical data, leading to faster and more accurate diagnoses. AI-driven medical devices can also monitor patients and provide timely alerts, potentially saving lives. With AI's help, the healthcare industry is making significant strides towards better patient outcomes. ❤️  2. 🎓 Enhancing Education 🎓In the field of education, AI is a game-changer! 🎮 AI-powered educational tools personalize learning experiences for students, catering to their individual needs and learning styles. Teachers can receive valuable insights from AI analytics to identify struggling students and offer targeted support. Additionally, AI can automate administrative tasks, allowing educators to focus on meaningful interactions with their students. 📚  3. 🚗 Improving Transportation 🚗AI is reshaping the transportation industry with self-driving vehicles leading the way. 🚘 Autonomous cars equipped with AI technology can reduce accidents caused by human errors and optimize traffic flow, resulting in safer roads and reduced congestion. Furthermore, AI helps with logistics and route planning, making transportation more efficient and environmentally friendly. 🌱  4. 💼 Personalizing Customer Experiences 💼In the business world, AI is transforming how companies interact with their customers. 🏢 AI-powered chatbots and virtual assistants provide 24/7 support and offer personalized product recommendations based on customer preferences. This personalized approach enhances customer satisfaction and fosters long-term loyalty. By leveraging AI in customer service, businesses can provide efficient and tailored experiences for every customer. 🤝  5. 🔬 Advancing Scientific Research 🔬Scientific research benefits immensely from AI's capabilities. 🌟 AI algorithms can analyze vast datasets and identify patterns that human researchers might miss. In fields such as genomics, climate science, and drug development, AI aids in data analysis, leading to groundbreaking discoveries and innovations. AI serves as a valuable tool for researchers, accelerating the pace of scientific advancement. 🚀  🔍 Ethical AI Development 🔍While embracing the benefits of AI, we must also prioritize ethical AI development to ensure responsible and safe use. 🛡️  1. Transparency and Explainability 🕵️‍♂️AI systems should be transparent and explainable to users. Understanding the decisions made by AI is crucial in building trust and ensuring accountability. Transparent AI helps identify potential biases and ensures fair outcomes.  2. 🚫 Bias Mitigation 🚫Bias in AI can lead to unfair and discriminatory outcomes. Developers must actively mitigate bias by diversifying training data and employing bias-detection algorithms. Ethical AI development strives for equal treatment and inclusivity.  3. 🔒 Privacy Protection 🔒As AI relies on vast amounts of data, protecting user privacy is of utmost importance. AI developers must implement robust data protection measures and comply with privacy regulations to safeguard sensitive information.  4. 👥 Collaboration with Experts 👥Ethical AI development requires collaboration among experts from diverse fields. Policymakers, ethicists, and AI developers must work together to understand the potential impacts of AI applications and make informed decisions.  🎯 Conclusion 🎯In conclusion, AI is not the harmful force it's often portrayed to be. By debunking the myths and understanding its benefits, we can harness AI's potential to drive positive change in various industries. Embracing ethical AI development ensures that AI remains a powerful tool for progress and a force for good. Let's work together to build a future where AI enriches human lives while safeguarding our values and principles."
284,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟Have you ever had a mentor (colleague, friend, etc.) who guided you through a challenging project or decision, leading to a significant ""aha"" moment in your development journey? Share the experience and its impact on your approach to problem-solving.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
285,"In this series, we shine a spotlight on the different DEV moderators — Trusted Members and Tag Mods — who help to make DEV a kind, helpful place. Aside from spreading good vibes and helping fellow community members, these folks also assist us with removing spam and keeping posts well organized by adding and removing tags as necessary amongst other things.If you want to learn more about what these awesome folks do, I recommend checking out our Trusted Member and Tag Moderation guides. There is information about how to apply in both guides if you're interested in joining up as a moderator.  Introducing Thomas Bnt 🙌This month, we're featuring Thomas Bnt, a long-time DEV Community member and super kind, helpful member of our moderator team. In this interview, Thomas talks about how he got started in tech, his specialties as a developer, and what it's like to experience coding as a non-native English speaker. We're super lucky to have Thomas in our mod ranks and really grateful he took the time for this interview. Thank you, Thomas!Thomas BntFollowFrench web developer mainly but touches everything. Volunteer mod here at DEV. I learn VueJS at this moment and databases. — Addict to Cappuccino and Music  The InterviewMichael Tharrington: Would you tell us about how you got started as a developer and how you progress from a learner to working in the industry?Thomas Bnt: That’s a great question!Computers and technology have fascinated me since I was child. I also love radios, and if you fuse the two together, you get web radios — a fascinating world where you can listen to music and navigate the Internet at the same time. I created my own web radio, and to share it, I thought of creating my own website using the built-in tools to “integrate” the player. I designed my very first website under… Wix. 😅I spent so much time working on my website — editing JavaScript to animate cool texts with colors and showing real-time data. Not very useful I know, but I was just like a kid playing video games… I was enjoying myself. 🤩After some months with Wix, I asked for advice on creating my very first page under HTML. I started to manually upload with FilleZilla and used Brackets. (The good old days!) Then I began with Bootstrap and other Material Design frameworks… I was really worried about how to create a good navbar using home-made CSS.(I'll skip the coding and debugging errors 😐).After a lot of tutorials and reading through blogs, I adventured into website creation without a CSS framework. It was one of my biggest challenges at the time, and you know what? I did it! 🥳Since then, I've been doing everything homemade, not because I don't like frameworks like Material Design lite, but because I really like to know and understand what's in my source code.Since 2017, I’ve been publishing my creations. Early on, I never really thought that this would be my future job. But this year, I’m officially a freelance web developer. And, I can honestly say, it's fabulous to have your hobby as a profession. 🌱Michael: Where do you work and what is your day-to-day like?Thomas: I've never been a big fan of offices, which is why I chose to work from home. I don’t really have a set pattern for my day, but I can give you an example…I start off my day with small chores and other tasks, eat breakfast, and then get ready for work. When I open my computer, I check my emails and social networks, while trying to not spend too much time on it. 😶 After I’ve checked my to-dos, I prepare my day (and plan ahead for other days if possible) and then I start coding! Buuut… never without my music and something to drink (team cappuccino ☕).Once everything is good to go, I push my code! My hobbies outside of work/dev are watching series, going cycling or walking to get some fresh air, playing video games, giving many hugs to my dog, and completing as many things as possible from my personal to-do list. Michael: What would you say your current focus or specialty is as a dev? And, what are you hoping to learn more about?Thomas: I’m specialized in web development, specifically with JavaScript and HTML/Sass. I’m currently using Nuxt for most of my work and personal projects, and also Sass because it makes it simpler to maintain and beautify my beautiful source code. ✨I learn something new every week — typically something about web development, SEO, and/or one of the most important topics: accessibility. I’ve got a few weaknesses in this area, but I strive to create quality content that can be accessed by everyone and I know it’s important to keep on improving my a11y skills.Michael: How did you find DEV and what led you to become a moderator for the community?Thomas: I honestly can’t remember how I found DEV. It could’ve been when I searched for a tutorial on web development. I know that at the time, I was going back’n’forth to DEV without necessarily having an account.Then I took the step, registered, and began following good, interesting people and tags. And even now, I’m still reading posts here all the time!Having already moderated in communities, I approached DEV to ask if I can help with moderation. I asked, they said “yes”, and now I’m here! Thanks a lot to the team for trusting me all these years. 💚Michael: What is it like learning software development as a non-native English speaker? Are there specific challenges you face or resources you’re drawn to?Thomas: I’m French and when I started to learn software development, it was a little complicated but not too hard. Because at school, we learn to speak, write, and read the English language, I felt pretty well prepared. I always loved this school subject, so that helped.That said, I’m not great at English yet. Sometimes, I use software to help me translate (like in this case, some words and phrases were taken by DeepL 😄). Kind of funny though, I prefer to read documentation in English… I do this out of habit because once upon a time I ran into some content that was poorly translated. Also, it’s just another challenge and opportunity to learn more English!Nowadays, many docs are well translated, as folks across the web are focused on wider language distribution — as on Astro for example, which I'm happy to help them with from time to time. 🌱  Wrap upAppreciate y'all reading. Stay tuned for future mod interviews in this series!"
286,"Hey folks, welcome to our weekly Rubyist hangout thread!We're here to discuss all things Ruby, and since Ruby has been around for 28 years, it's a testament to its enduring greatness. However, don't feel limited by Ruby talk alone – this thread is also a place for Rubyists to share whatever they feel like within our community guidelines. So, whether it's Ruby-related or not, feel free to contribute and join in the conversation!To make it easier for everyone to participate, we'd like to hear from you on the following:Highlight a Member: 😄 Is there a fellow Rubyist whose contributions or achievements you'd like to highlight or appreciate? Let's celebrate each other's successes!Share an Article: 📚 Have you come across an interesting article about Ruby, programming, or tech in general? Share it with the community and spark some insightful discussions.Something Happening in the Space: 🚀 Is there an event, project, or any recent happening related to Ruby that you think others should know about? Let's keep each other informed.Looking forward to hearing your thoughts and contributions. So, what's up this week? "
287,"At DEV, we prioritize an inclusive and welcoming environment, and today, we are excited to announce some additional guidelines that further emphasize our commitment to these principles. Our updated Code of Conduct now highlights these key points:Positive Behavior:Citing sources if used to create content (for guidance see DEV Community: How to Avoid Plagiarism)Following our AI Guidelines and disclosing AI assistance if used to create contentUnacceptable Behavior:No hate speech or communication that is racist, homophobic, transphobic, ableist, sexist, or prejudiced/discriminatory (including pronoun misuse or disrespect)Plagiarizing content or misappropriating worksPlease keep in mind that the aforementioned points are only the newest additions. Please review the full DEV Code of Conduct for complete details, and let's continue building a diverse, respectful, and friendly community together. ✨🤝 Join Us as a DEV Moderator! 🌟If you share our values and want to help enforce the Code of Conduct, consider becoming a DEV moderator. Visit the DEV Community Moderation page for more information on roles and how to get involved."
288,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:How do you visualize your future? As as a software engineer, UX/UI designer, data analyst...?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
289,"Discover diverse career growth stories and coding journeys in ""Mentors & Mentorships"" on The Daily Byte. Get inspired! 💻🌟Discuss the most impactful mentorship you received in your career and how it influenced your growth as a developer.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
290,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...whether it's true that Google Isn't Grad School.          Google Isn’t Grad School - The Atlantic                  Having so much information at our fingertips is useful but seductive, easily fooling us into thinking we know more than we do.                theatlantic.com      Ok, ok — obviously Google isn't Grad School. But this op ed in The Atlantic got me thinking: when it comes to leveling up your skills in the tech industry, is it nearly as good? And where do online courses fit in?Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous.Enter fullscreen modeExit fullscreen mode"
291,"Howdy 🤠What's everybody been learning?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Knowledge is power!"
292,It's time to once again showcase your captioning skills!Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
293,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Are you enticed by remote work opportunities, and where do you imagine that freedom might lead you?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
294,"  TL;DR;I used ChatGPT API to translate the Rails Guide into different languages:Taiwan's Traditional Chinese🇹🇼 https://ai.rails-guide.com/zh-TWFrench🇫🇷 https://ai.rails-guide.com/frLithuanian🇱🇹 https://ai.rails-guide.com/ltBrazilian Portuguese🇧🇷 https://ai.rails-guide.com/pt-BRThai🇹🇭 https://ai.rails-guide.com/thSimplified Chinese🇨🇳 https://ai.rails-guide.com/zh-CN  Update on 2023/08/12I added 3 more langaugesJapanese🇯🇵 https://ai.rails-guide.com/jpKorean🇰🇷 https://ai.rails-guide.com/koEspanõl🇪🇸 https://ai.rails-guide.com/es  What's the Rails Guide?I guess people who read this article already know Rails, however, just in case, I'll briefly introduce Ruby on Rails and the Rails Guide. Feel free to skip this section if you already knew them.Ruby on Rails is a full-stack web application framework. With Rails, you can build a website that can access your database's data, return as API payload or render them on the user's browser easily and safely. The Rails Guide is the user manual for developers to learn how to use Rails. The Rails Guide is also a crowd-creation and is in the same repository on GitHub. It has very high quality because it is reviewed and modified again and again by numerous seasoned Rails developers. For anyone who wants to learn Ruby on Rails, I will definitely recommend they read the guide first.  Why translate the Rails Guide?Translating the Rails Guide is not for diversity. The Ruby on Rails guide is written exclusively in English and it is totally fine. However, there are many talented developers all around the world who just cannot read English well. It is really a pity that they don't have a chance to get in touch with this wonderful and powerful web framework, Ruby on Rails, just because it lacks the information in their languages. I believe by translating the Rails Guide, we'll have a better chance for people all over the world to learn Rails.  Why use generative AI to translate Rails Guide?First of all, generative AI can produce more human text. Moreover, with more context, it can generate more accurate and suitable translations. You must have read some articles which you could tell immediately that were translated by Google Translate because they felt very unnatural. Second, although there are already many repositories of rails guide in different languages, https://guides.rubyonrails.org/contributing_to_ruby_on_rails.html#translating-rails-guides. However, the problem is that most of them are out of date. Those repositories also depend on volunteers' efforts. The Rails community used to have some enthusiastic fans who were willing to help translate the guide. Unfortunately, since the popularity of Rails plummeted, it hasn't had enough volunteers to continue the work. Using Generative AI to translate documents saves time and human effort. One person can refine the translation result by his/herself easily. It also means that we can update them more frequently. It could be a more sustainable method.  Proposed WorkflowMy original plan was simple. Write a script to read the Rails guide files and send their content to ChatGPT to translate to a specified language. Then use the existing Rails Guide script to generate HTML files just like the current translation workflowI may wrap the code into a class, AiTranslator, so it should be like thisHowever, it was not as simple as I imagined 😅  ChallengesThere are many challenges in this simple task. I picked some more significant ones here.  TokensChatGPT or other generative AI models can only accept a limited number of tokens. Tokens are composed of both input and output strings. It's not the number of characters or words but only correlated. Tokens are also used for OpenAI to charge your bill.The current most popular model, gpt-3.5-turbo only allows 4097 tokens for one request. Remember, it's used for both input and output. That means I cannot just upload a whole file to ChatGPT but I need to process a file piece by piece.Maybe you think: it's easy, you can just send 1 to 2 phrases for a ChatGPT API call, then you'll never exceed the limit. You're right. However, each ChatGPT request is independent, they don't share any context. I can show you an exmaple of the web page's ChatGPT. If I ask ChatGPT ""Do you know NBA?"" then ask it ""Who's the champion of 2019?"". It will answer it's Toronto Raptors.However, if I only ask ""Who's the champion of 2019?"" directly in a new session, ChatGPT will not be able to answer me because of lacking context.Unlike Google Translate which is like a strengthened dictionary. We'd better treat the Generative AI model like a very smart student. The more input you give it, the better the result it returns to you. As a result, I want to feed ChatGPT text as much as possible so it can have appropriate context to translate the Rails Guide properly.My approach is like the code block below.buffer = []result = ''File.readlines(file).each do |line|  if line == ""\n"" && buffer.join.split.length > @buffer_size    translated_text = ai_translate(buffer.join)[:text]    result += translated_text + ""\n""    buffer = []  else    buffer << line  endendEnter fullscreen modeExit fullscreen modeI declare a buffer = [] at the beginning.Iterate a file line by line. For each iteration, I'll put one line into bufferWhen the number of words exceeds a threshold, I'll send the request to ChatGPT API with the content in the buffer. The threshold, @buffer_size, is defaulted as 700. It's just an empirical magic number Plus, we know paragraphs in markdown are separated by blank lines, therefore, I also want to translate a whole paragraph in one ChatGPT request.  Prompt phraseThe prompt phrase for the Generative AI model affects the result drastically. I tried a lot of different combinations. And eventually, I made it this way:LANGUAGES = {  'zh-TW' => ""Traditional Chinese used in Taiwan(台灣繁體中文)."",  'lt' => 'Lithuanian',  'fr' => 'French',  'pt-BR' => 'Brazilian Portuguese',  'th' => 'Thai',  'zh-CN' => 'Simplified Chinese',}system_prompt ||= ""Translate the technical document to #{LANGUAGES[@target_language]} without adding any new content.""Enter fullscreen modeExit fullscreen modeTranslate the technical document: pointing out that we are translating a technical document excerpt so it will know it does not need to translate some elements like code blocks.LANGUAGES[@target_language]: I don't know whether it is a unique problem for Traditional Chinese. Although they're both Chinese words, the terminologies, writing style and intonation of Traditional Chinese in Taiwan are very different from what Simplified Chinese has. I need to specify it more clearly so I can get the desired result.without adding any new content.: It is also important to tell ChatGPT not to add extra information because we're translating an article. Otherwise, it will just be like some annoying students in your classroom, who keep talking and add much needless knowledge.  Markdown parsingThe Rails Guide is full of code blocks for showing code examples. It's reasonable not to send a code block separately. I made the line reader a simple state machine. It will change the state to :codeblock when it starts parsing a codeblock and it won't call ChatGPT API until it finishes that block.state = :readlinebuffer = []result = ''File.readlines(file).each do |line|  if line.include?(""` ` `"") # I need to add spaces between the backtick(`), or Dev.to will have problem    buffer << line    state = state == :codeblock ? :readline : :codeblock  elsif line == ""\n"" && state == :readline && buffer.join.split.length > buffer_size    translated_text = ai_translate(buffer.join)[:text]    result += translated_text + ""\n""    buffer = []  else    buffer << line  endendEnter fullscreen modeExit fullscreen mode  AnchorsWhen you open any rails guide's page, you can see there's a Chapters block on the right serving as a table of content.That table is generated automatically by a script. The titles, such as <h1>, <h2>, <h3>, etc. will be assigned id with the title's text. For example, if the title is ""Guide Assumption"" in the markdown,### Guide AssumptionEnter fullscreen modeExit fullscreen modeit will be rendered as in the final HTML<h3 id=""guide-assumptions"">...</h3>Enter fullscreen modeExit fullscreen modeThe link in the table of content can then be referred to the elements with that id value.It works fine in the original Rails Guide. When you click a link in the Chapters, the browser will jump to the corresponding section. However, a problem happens once all titles are translated. After some investigation, I found that it's related to Turbo. I guess it's a Turbo's bug. My current solution is disabling Turbo for the links in the Chapters block.<ol class=""chapters"" data-turbo=""false"">...</ol>Enter fullscreen modeExit fullscreen mode  CodeRepository: https://github.com/kevinluo201/rails-guide-aiThis repo is forked from the Rails repo so that it can pull the updates of the guide's files. It only has 2 new files:It only has 2 new files.guides/rails_guides/ai_translator.rb: it's the main program.guides/ai_translate.rb: it's the starting pointYou can do the following steps if you want to play around with it.Set a new environment variable call OPENAI_ACCESS_TOKEN and set its value to your personal access token on OpenAI.add a new language in RailsGuide::AiTranslator, for example, 'jp' => 'Japanese'Open the terminal, go to guides/ and start translating by executingruby ./ai_translate.rb jpEnter fullscreen modeExit fullscreen modeYou can also translate a single file, just add a filename after the commandruby ./ai_translate.rb jp getting_started.mdEnter fullscreen modeExit fullscreen modeAfter all files are translated, you can just execute the rails existing script to generate HTML, CSS and JS. Unfortunately, it is likely to fail when you do that. Usually, it is because there are duplicated titles which lead to duplicated id in the HTML. You can fix it by finding out which title has the problem and can change that title a bit to avoid the problem. It can also have different problems when translating into different languages. Just try solving them so the process can finish.bundle exec rake guides:generate:html GUIDES_LANGUAGE=jpEnter fullscreen modeExit fullscreen mode  Help WantedIt is just an experimental project now. There are several issues that can be improved. If you think it is an interesting topic, feel free to discuss it with me.  Current Issues  Anchor linksThe table of content is solved by disabling Turbo. However, there are anchor links spread among the articles. They cannot be converted to the correct URL smoothly, especially when it refers to an anchor on another page.  VersioningThe Rails Guide has versions. A version is kind of a snapshot of the guide at a particular time. I haven't thought of a good way to manage them.  Different modelsI'm now using gpt-3.5-turbo. I live in Canada so I cannot use Google's Bard. Feel free to change the code to be able to switch different models, like gpt4 or llamas 2  EPUBEpub files can be generated by the Rails guide script. However, it has errors when I want to import them into the Epub reader software, such as ""Books"" on OSX. I think it may related to the broken anchor links.  Other stuffIf you have any ideas that can make this project more sustainable, please discuss it with me. For example, it's a guide for Rails, why not build it as a Rails app?  ConclusionThe quality of AI translation is not perfect but acceptable. I'm not concerned about the quality. As far I can see, the limitation of tokens and the trained model are the most significant factors. I believe this problem will be solved by swapping the current model (gpt-3.5-turbo) with a more advanced model in the future. The result shows that this workflow really works and that's the most important lesson for me.About the cost, I have done many experiments for this idea and I translated the Rails Guides into 6 different languages. It costs me about $27 so each version of the translation costs less than $5 on average. The actual price should be less than that because many experiments just failed.*Due to its good quality and low cost, Generative AI might be a good solution for technical documents of open-source projects. *  Buy me a coffeeAt last, if you like what i'm doing, you can buy me a coffee 😉☕️](https://www.buymeacoffee.com/kevinluo)"
295,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:Do you see yourself as a front-end, back-end, or full-stack developer? Where does your coding journey headed?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
296,"In the tech space, getting a job is not totally based on how good you are at the technical side of things, but rather your positioning. This means being able to put yourself out there and show employers how your skills and experience can benefit their company.It is the goal of 90%-if not 100%-of geeks who are in tech to get hired, but without stepping out to the public that is nearly impossible.As you read, I will share my journey on how I got into open source and secured my first international role as a software engineer at OpenSauced by contributing to their open source projects.*  My Background and PassionMy desire to know how the web works has always been my driving force. So from the day I was given my first mobile phone (Nokia s2) in the year 2010, I took it upon myself to explore this little gadget at my disposal.In 2020, during the covid 19 pandemic, I started learning the basics of the web (HTML, CSS & Javascript) with a friend (a graphic designer) who also was trying to transition into UI/UX design. Luckily, I got my first job at Softkodesllc which didn’t last long due to my lack of experience. So I kept on learning until I got into open source.  How I got to know about open sourceIn a Twitter space by @ShawnBasquiat(The HUNT) was the first place I heard about open source and ways to contribute to open source. Then I ran into a video on YouTube talking about how to make your first contributions to open source projects.  The life-changing move I took that led to the AHA! momentAfter listening to the talks and tips from the space, I decided to set a 30-days target for myself to make contributions to open source projects in the month of August 2022. I got my first PR up on the 3rd of the same month https://github.com/open-sauced/hot/pull/285.The second and third PR followed on the 4thhttps://github.com/open-sauced/hot/pull/290https://github.com/open-sauced/hot/pull/292At first, I was confused about how to start, but when I took up the courage to pick up my first issue, it all started making sense 😇😇😇. I got a warm welcome on my first contribution which resulted in me wanting to make more and more contributions to the same project 🔥🔥 (all thanks to @bdougieyo).    The AHA! momentShortly after my contributions, I got a message from the CEO of OpenSauced.It all seemed like magic to me at first 😊😊...but it was reality! My first step towards working in public earned me a Software Engineering role 🍕🍕That's my short story on how I got hired making open-source contributions 💫💫  TipsIf you are looking to get started with open source, here are some tips to get started:Choose a Project that Aligns with Your Interests: Start by identifying open-source projects that align with your passions and skills. Whether it's web development, machine learning, or design, finding a project that excites you will keep you motivated and engaged.Start Small and Contribute: Begin by tackling small tasks or bugs within the project. This allows you to familiarize yourself with the codebase and workflow. Look for ""good first issue"" or ""beginner-friendly"" tags that indicate suitable tasks for newcomers.Engage with the Community: Join the project's community forums, mailing lists, or chat channels. Introduce yourself, ask questions, and seek guidance from experienced contributors. Engaging with the community not only helps you learn but also opens doors to collaboration and mentorship opportunities.Read Documentation and Code: Invest time in understanding the project's documentation and codebase. Familiarize yourself with the project's structure, coding conventions, and guidelines. This knowledge will help you navigate the code more efficiently and contribute effectively.Embrace Feedback and Learn from Others: Open source is a collaborative environment, so be open to feedback from experienced contributors. Take constructive criticism positively and use it to improve your skills. Learning from others' code and approaches will also broaden your understanding of best practices.With these few tips listed, you can kick-start your journey into open source. If you find this article helpful, then click on the follow button to get more updates and helpful resources on JavaScript, Reactjs, and Next.js. You can also follow me on Twitter @OgDev-01 to get useful resources and tech trends or on OpenSauced to see what contributions I've been making and the ones I highlight! Stay saucy! 🍕🍕* This is not fiction. However, this piece does not guarantee the desired result you might need. It is designed to point you toward the right path. And as it was coined in Fiedler’s Contingency TheoryThere is no one best way to get things done.Hence, there is a need for a contingency plan."
297,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
298,"Following fellow developers is like adding extra sprinkles to your feed 🧁🎉 --more collaboration, more helpfulness, more fun!Show off why people should follow you or recommend top-notch developers. Go wild and do both! (Follow-backs are cool, but no pressure!)Let's get this community groovin' and growing together!"
299,"Hey, let's switch gears today and give ourselves a break from interview prep and coding chatter. What shows are ya'll watching right now? ""Futurama,"" ""Based on A True Story,"" ""Justified""? Has anyone seen ""Kevin Can F**k Himself""? Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
300,How has Kotlin's interoperability with Java influenced your decision to adopt Kotlin in Android development or other projects?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
301,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is: From a plethora of languages, which ones resonate with your coding style and interests?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
302,"It's been a decent run banging out my SEO for Non-Scumbags series, even if there might well have been an audience mismatch.  I had fun with those, but they were fairly trade and theory heavy.  And I've found that kind of discouraged me from my writing habit as a whole.So, if only for today, I'm going to dust that habit off and resume ranting to whoever happens by, like some kind of internet busker.Today's topic is on my mind, both because I did a livestream Q&A about it (it'll be up on the Hit Subscribe Youtube channel in the coming weeks), but also because I see it everywhere whenever I'm poking around freelancer or small, boutique service provider websites.What I'm Talking About: We Do Labor and ConsultingIf you can't picture what I mean, I'll default to a hypothetical custom app dev shop for example.  If you hover over their ""services"" menu on their website, you'll see a list like this:Custom Wordpress Website BuildsMonthly Site MaintenanceCustom Plugin DevelopmentWordpress API IntegrationsWordpress ConsultingEmphasis mine.  (Well, I mean, of course it is, this is a hypothetical I made up, not a quote.)The service provider enumerates a series of different kinds of labor they will sell you, and then, almost invariably at the bottom, they'll throw in that they also offer consulting.This is what I'm saying you shouldn't do.Do as I Say, Not as I DoLest someone beat me to the punch, in the immortal words of Doc Holliday (at least, in Tombstone), ""apparently my hypocrisy knows no bounds.""  If you look at Hit Subscribe's offering page, you'll see this:Now, I'm not sure if I wrote (or even read) that copy before it went to prime time.  And I'll also point out that whoever wrote it wisely structured the bullets as all being consultative in nature, at least partially, and they also created a moat around the fulfillment piece as separate from strategy.But, nevertheless, there it is, a potential example of what I'm saying not to do.My main reason for bringing this up is simple expediency.  I don't want to put some random service business on blast, and there just happens to be an example on a site that I presided over, so it's the most practical way I can show you a screenshot without being needlessly rude to someone.If you're wondered whether I'm worried about this and feel any pressing need to change it... neh.  I've got bigger fish to fry.Consulting vs Labor ServicesI have beaten this topic to death.  I've talked about it here, and here, and probably 10 other places over the years.  So I'll just do the Cliff's notes here.Labor services involve acting as a pair of hands.  Someone pays you to do the thing.Consulting services involve acting as the brain.  Someone pays you to do nothing, except offer advice (in whatever form that takes as a deliverable).If you're executing something, you're selling labor, and not consulting.Mapping Consulting and Labor to the Org ChartLet's do another easy one.  Let's take a look at each service type and imagine that the client liked the provider so much that they just decided to throw money at them until they could slurp them into a role within the organization.What would that look like for each type of service?  Very simple:Labor services: individual contributor.Consulting services: organizational leadership.Absurdly Mapping the Org Chart Back to the Services PageHaving drawn that parallel, let's revisit what the services page looks like from our hypothetical above.Here are our services, dear prospect:Specific Tactical Individual Contributor LaborSpecific Tactical Individual Contributor LaborSpecific Tactical Individual Contributor LaborSpecific Tactical Individual Contributor LaborWe Can Also be Your CTO!Can you imagine running across something like this in the wild?  It'd be like running across a resume with the usual tech stack alphabet soup for a senior software engineer, but with an objective at the top (is that still a thing people put on resumes?) that read ""Seeking a position as a software engineer III, senior software engineer IV, or maybe CTO, whatever.""Best case is the person reviewing the resume chuckles and ignores that CTO bit.Now, things aren't quite as ludicrous or dramatic on your services page.  They almost certainly won't think to chuckle before ignoring your consulting services completely.Consulting Services as ""Hey, I'm Strategic""Over the years, I've observed that one of the most predictable anti-patterns that indie technicians (laborers viewing their work as a craft) deploy to bolster their cred is to refer to themselves as ""strategic"" in some way.  So throwing something about ""consulting"" or ""strategy"" on your site acts not as a serious offering.  Instead, it's a strawman ironically intended to differentiate the tactician from other tacticians by making unfounded claims of strategic (consulting) acumen.But the problem here isn't so much what happens if clients ignore the strategy offering and detect, at least on a subconscious level, that you're engaging in a sad form of resume padding.  In fact, that's the good outcome.The bad outcome (for them) would be someone taking you up on this strategy.Technician/Tactician Strategy Is Just Tips about LaborWhy do I say this?Whenever you ask a technician for advice, something predictable happens.  They bury you in tactical suggestions about how to do the thing better.Think about our hypothetical offering above around Wordpress services.  What do you imagine this Wordpress ""consulting"" from this firm actually looks like?I suspect that it would involve giving you advice about customizing Wordpress themes and maintaining Wordpress sites.""You should keep your plugins up to date.""""Here are some best practices for customizing your theme.""""What error are you getting?  Okay, lemme take a look... ah, yep, that's your problem right there.""If someone is paying you to say things like this, I suppose it is technically consulting.  They give you money, and you give them the advice to keep plugins up to date or to fix an error.But there's a more specific, accurate term for what you're doing when giving this advice: training.And training is just one tiny step away from labor, in the sense that the absolute most natural thing for any client or party to do when you say ""ah, yep, there's your problem right there"" is to immediately say, ""look, can you just fix it for me?""  So what's happened here -- the bad outcome for them -- is they started off looking for strategic advice, and wound up in the weeds with you, deciding tactically which one of you should do which labor.  You're pair programing and just trading off driver and navigator.And then, by the way, bam, you're right back in labor-land and not strategy-land.The ""Consulting Services"" Throw-In Is Not a Path Toward StrategyA clarifying way to look at this is to think of labor, for a technician, as having an intense gravitational pull.  You have labored all of your life for money, and you view the quality of your labor as your differentiator.When asked to be ""strategic,"" you thus immediately start spewing granular and tactical tips that amount to best practices, often without context.  Make your code DRY.  Do Scrum instead of waterfall.  Whatever.In short, the advice you will give, naturally, all has to do with the question of how, exactly and rarely, if ever, the questions of what or why.  And those latter questions are where actual strategy and actual consulting live.In my experience, flipping into true strategy and consulting requires a clean break.  You need to stop answering the question ""how"" and adopt the attitude of ""who cares about the how, that's below my paygrade,"" which is a really heavy lift for a technician.  But you have to do it.If you're an individual freelancer, this means that you either remove all labor offerings and the like from your site, or you remove all mention of ""consulting.""  For a firm, it's a little easier, in that you can segment by personnel.  For instance, in the Hit Subscribe example, I personally don't ever create content for clients myself, but I do act as a fractional CMO for them.In the end, I'd suggest you indies go with this simple heuristic.  Until you're ready to offer nothing but consulting services, leave ""consulting services"" off of your website.(Also, when you do take the consulting plunge, don't just say ""consulting services,"" but that, dear reader, is a topic for another time.)"
303,"It is with great enthusiasm that we share this post today, because we are coming at you live with a new badge.  Presenting... our Warm Welcome badge!This exclusive badge recognizes our outstanding online contributors and dedicated members who consistently engage with our Welcome Thread.Not familiar with the Welcome Thread yet? No worries! Here's the link for you to explore:Welcome Thread - v238Sloan the DEV Moderator for The DEV Team ・ Aug 16#welcomeHere's how it works: Every week, we'll handpick individuals based on their active participation in the thread and their overall contribution to our fantastic community. So, the more you engage in the Welcome Thread and help welcome new members, the higher your chances of receiving the Warm Welcome badge! 😊Why did we create this badge? Recent data has shown that engaging with folks in the Welcome Thread fosters a sense of welcome and excitement to participate in our community. This affirms our commitment to inclusivity, and we're thrilled to set tangible goals to make our newbie DEV members feel at home.We are genuinely thrilled by the enthusiasm in the Welcome Threads and hope this new badge expresses our deep appreciation for each one of you. Together, we're building an inclusive tech community that we can all be proud of! 👏💬Cheers,The DEV Team"
304,"Real DOMs and virtual DOMs and shadow DOMs, oh my! Let's take a dive to see how they all work together to create a clean, performant Document Object Model.The DOM (Document Object Model) is exactly as it states. The HTML tree of a website is represented by an object called document. In this object there is a model of the HTML tree's elements, conveniently accessible by object dot notation.document.head will return the <head></head> section of the tree, document.body will return the <body></body> section of the tree, and so on.You can also use this dot notation to manipulate the DOM. For example: document.body.style.background = ‘red’ will change the body’s background color to red. You can see more about the DOM API in Mozilla's web docs.This DOM is referred to as the page's real DOM. The real DOM, by itself, is only able to update the entire DOM simultaneously every time there is a change to the DOM. This makes it very slow and expensive to make updates to the page. That's where the virtual DOM comes to save the day!The virtual DOM is a virtual representation of the real DOM. This virtual DOM is kept in memory and synced with the real DOM. React compiles the real DOM into Javascript, which is the first step in creating more performant updates. The virtual DOM then makes a copy of itself (let's call it virtual DOM 2). When an update is made on the page, it is first applied to virtual DOM 2. React then compares virtual DOM 2 to the original virtual DOM, an exact copy of the real DOM. React uses this comparison to quickly detect where the real DOM needs to be updated and updates only those elements instead of the entire DOM. This is where the magic happens, it is much quicker and less expensive to update only what needs to be updated.If you want to see the virtual DOM in action, you can see a visual representation with the ""Paint flashing"" feature in Google Chrome's inspect tool:Check that box and then play with the page, any DOM changes will be highlighted with a green box.Last but not least, we have the elusive shadow DOM. This allows hidden DOM trees to be attached to elements in the regular DOM tree. Custom elements can be created with the Web API, these are controlled solely by the shadow DOM. It's important to remember that the real DOM and the shadow DOM are completely different realms. Changes made to elements in the real DOM will not apply to elements in the shadow DOM, and vice versa.If you're sleuthing through HTML elements in the inspect tool and don't see something listed when you're looking right at it on the page, it's probably in the shadow DOM. The best example is video players. Visually on the page you can see the internal UI: the play button, skip button, share button, etc. but you don't see it in the real DOM. It's being controlled by the shadow DOM.Elusive as it may be, you can actually reveal the shadow DOM if you need it! In Google Chrome's inspect tool: Go to the settings, select Preferences and go to the Elements section. Select ""Show user agent shadow DOM"" to show any shadow DOMs alongside the real DOM in the Elements tab of the inspect tool.That's all three! Hopefully this blog has brought you a better understanding of the differences among the real DOM, the virtual DOM, and the shadow DOM. Let me know what you think in the comments!"
305,"Hey there, awesome DEV Community members!Did you know we have an array of amazing badges that celebrate your achievements and contributions on DEV? Each badge tells a unique story and highlights your skills and passions.From the prestigious ""Top 7"" and ""One Year Club"" badges, to the talent-driven ""JavaScript,"" ""Python,"" and ""React"" badges, our collection showcases the diverse skills and passions of our amazing members.We're constantly retiring old badges and introducing new ones that reflect your interests and achievements.  Now, we want your input!Which badge would you love to see next in our collection? It could be a badge that celebrates your favorite technology, highlights your proudest achievement on DEV, or represents a unique aspect of our community. Share your badge idea with us in the comments below. 🗣️💬"
306,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
307,"As a .NET developer, how do you see C# evolving to accommodate modern development trends and challenges?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
308,"Welcome to ""Discover Your Code,"" guided by our official DEV moderator, Sloan the Sloth 🦥. This series is designed to help aspiring coders and students explore the coding universe, ignite their passion, and find their ideal career paths.Today's question is:What specific aspects of coding and development ignite your passion and curiosity?Responses from newbies and experienced devs alike are encouraged in order to broaden our horizons and showcase different POVs.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
309,"There's an old saying ""If the only tool you have is a hammer, everything looks like a nail."" The basic message is if you're using a single solution you're likely to force its usage to solve every problem, even if it isn't the best tool for the job. This is a trap we often fall into when we're handed a new shiny tool, like AI. We immediately want to apply it to every scenario, even when there are existing options which are better equipped. I'm seeing this quite a bit these days with AI, with new products capturing the imagination of developers everywhere. But before we reach for AI we need to stop to ask if this is the right tool or is a better tool already available.As an example, I recently attended a hackathon where a team was building an app to help developers create accessible websites. They were asking questions about how to incorporate AI into the process, using AI to detect accessibility shortcomings. As it turns out, this is a solved problem.Looking at web development specifically, there's a set of clearly defined standards. There are numerous tools, including Visual Studio Code extensions and GitHub actions which can detect and report on gaps in compliance. Because detection is pattern based, there isn't a need for the dynamic capabilities AI would bring to the table. While it's certainly possible to build a new AI-driven tool, it wouldn't improve the process. This falls into the ""hammer/nail"" category.However, there is a space where AI an help developers improve the accessibility of the apps they build. When we look at existing tools, the feedback provided to developers is relatively generic. An error might be raised indicating an alt attribute is missing from an img tag, but it would likely lack explanatory context. It's always better for someone to truly understand the rationale behind a rule rather than following the rule ""because someone said so."" Why is the alt attribute important? What makes for good alt text? What are the best practices?Using a tool like GitHub Copilot Chat, a developer could highlight a block of code and ask questions like the ones listed above. It's a great opportunity to interactively learn more about accessibility, the experience different users have on a website, and how best to ensure the pages they build are usable by everyone. The information will be contextual to their specific situation, making it more relevant and impactful to the developer.GitHub Copilot can also aid developers in creating accessible code. GitHub Copilot offers suggestions based both on its model and the current development context. If the HTML the developer is editing follows good accessibility practices, GitHub Copilot is more likely to make suggestions which do the same. A developer can also prompt GitHub Copilot by saying things like ""Create a link to /login using the login.png image ensuring accessibility"", which helps guide the suggestions generated.In the end, we use different tools with different technologies to help our developers create accessible web pages. Extensions in the IDE alert to potential gaps. Automation integrated into the CI process catch issues before they're merged into the codebase. And finally AI helps the developer write better code, gain context and learn about accessibility.All of us have a propensity to fall into the trap of wanting to use the cool new technology anywhere and everywhere, even if it's not an appropriate application. We always need to stop for a minute to ensure we're using the right tool, that we're not simply hammering everything as not everything is a nail. AI doesn't replace existing tools and solutions; it's another tool we can use to enhance and improve what we already have."
310,"That will be a short article.To become a good Python Freelance dev, I'm searching to interview some CTOs or founders of companies in the AI or Data Science domains.For example, I ask them:to talk about their activity and job,what are their expectations when they work with a freelance dev,talk about good and bad experiences with a freelance dev,the quality and skills they think are essential for a freelance dev.It's very interesting to share a moment with these persons who take some of their time to answer me and help me in my journey to become a great Python Dev in AI domains.This habit will be certainly a game changer in my progression and I think we should do it sometime in our career.And you, how do try to be better?"
311,What are some interesting use cases for JavaScript outside of web development that you've explored or would like to explore?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
312,"Learning to program in the recent years has gotten significantly easier, but one could also say it's gotten quite harder as well. Hear me out.In the recent years, getting into software development, let's say web development to be precise, has gotten so much easier. Now anyone could become a web dev in less than 3 months, compared to back then. But yeahh, when I say becoming a web dev in less than 3 months, of course I am referring to just getting to play around with Html, CSS and a wee bit of JavaScript, then maybe Node.js if you're looking to go fullStack.This is just basically how it it presented to a lot of newbies, or aspiring web devs out there. Yeah there are hundreds of thousands of tutorials and classes that could help you become one. Infact, shortage of resources to learn from is a non existent issue nowadays, not to talk of the insane amount of ""Helper Tools"" out there, promising to make your work over 70x easier.Let's talk a little bit about web development in the very early 2000s, web development could be said to have been harder then, mostly only computer gurus and computer science student could easily develop a website, this was because the web was quite relatively new and the layman had little to no idea of how it actually worked, also, it's learning resources were mostly only shared at college level. Learning web development then might have seemed extremely technical, but lets take a brief look what a web developer would be required to learn, to build a fully functional web application, lets take for example, the popular ebay website then. An understanding of Html, CSS and JavaScript would be expected, as those are the pillars of the web.Knowledge on how to set up and configure web servers.Basic server side scripting with PHP.CSV(Comma Separated Value) files for database.Well of course It would look like this:Yeah obviously not so appealing. Recent web development has introduced a ton of better design principles, more dynamic interactions and better security to web applications. Along with these new introductions came a ton of new tools and techniques required to achieve them. So lets take a look at what it would take to create that same ebay web application in the more recent years, well you would basically have to learn about:Same Html, CSS, and JavaScriptResponsive web designfrontend JavaScript frameworks like React.jsAsynchronous programmingDatabase management systems(DB MS)ServerSide language like Node.jsServerSide JavaScript framework like Express.jsAPI integrationsWeb socketsVersion control systems like gitCI/CDTesting frameworksHow to use User Authentication and Authorization tools like OAuthCloud services like AWS or Microsoft AzureSheesh, I personally find all these quite overwhelming.Well, we all know that these tools and techniques are provided to create more dynamic web applications, offer a higher level of abstraction to the initial development technicalities and overall to make the development process a lot easier and faster. All these are great, but now let us take a look at it from the beginner's point of view. Knowing you have to learn all these things to build a web application now might not be the main issue, but with the emergence of new tool, frameworks, practices, techniques, libraries and the rest popping up left, right, front, back and center every single day, it's getting quite harder to keep track even for the experienced developer. Someone just learning about web development might go ahead to learn about the first three pillars(Html, CSS, JavaScript), after that, there comes the confusion with everything.Having to figure out what you actually need to learn, to pick one tool or framework and stick with it might actually be the most challenging aspect of it all, with the vast number of tools, frameworks and development techniques out there, coupled with an abundance of learning resources, filtering out the information that you actually need and what is actually necessary to learn is the most crucial part of it all. This is also one of the reasons a lot of newbies get stuck in tutorial hell, because they try to consume information about the million and one tools and techniques that are out there, and then later realize they have actually not learned anything in the process at all. While learning about a particular tool for example, they could come across information of the new and latest tool or framework that is taking the development world by storm, try to divert to go learn that, to make sure they are learning about the latest, but along the way, a cool new shiny raving tool or technique comes out and now they feel they have to learn that as well, it's just never ending. This makes the process of learning to program nowadays much more tasking than before.Although the field of software development is an ever changing and ever growing field keeping developers on their feet with new trends and adoptions. The question now is ""Are we overcomplicating the development process with all of these new adoptions and supposedly helper tools? and when exactly does it get all unnecessarily too much?""What do you think? Share your thoughts in the comment section below."
313,"Weekends are my sacred time ... where I build my open-source projects.   Papermark - the open-source DocSend alternative.This weekend, I'll be building on Papermark. It's an open-source project for securely sharing documents with built-in real-time, page-by-page analytics.I would be absolutely thrilled if you could give us a star! Don't forget to share your projects and thoughts in the comments section ❤️https://github.com/mfts/papermark  Live Updates 🔴I will share periodic updates as I'm building :)I'm interested in what you are working on (this weekend)? Any open-source projects?"
314,"Technology today is an immersive experience, and as professionals in the space we tend to be above average in terms of our adoption and interconnectivity.  Today we have an app for nearly every idea imaginable, providing significantly more value-add to our daily lives than the generations that preceded us.  Technology however can be a double-edged sword, and the potential value-add and ease of access to so many options can lead to behaviors detrimental to our well-being.  Doom-scrolling is a solid example of this, where apps have created such a focus on retaining attention that we spend an unhealthy amount of time glued to our screens.  In the early 2010s, I had come to this realization as I learned from the successes (and many, many failures) of my 20s, and actively began to seek out low/no technology counter-balances to foster healthier long-term personal growth.  For myself, these counter balances came in a variety of forms over the years, some that come to mind: Note taking using Moleskine notebooksIndoor gardening Marathon trainingHave you found yourself needing to counter-balance our technology-focused lives with low/no tech? Share your own experience and ways you've created a balanced lifestyle in the comments below ⬇️"
315,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
316,"If you haven’t read the previous article on the importance of design patterns, I suggest you start there before reading this one. If however you’re already convinced on design patterns, read on to see my top picks for some examples we use at Stripe.You might disagree with how the Stripe API is designed, and the design you end up with is likely going to be different than what we use. That’s just fine, since different companies have different use cases. Instead I present here some design patterns that I believe are generic enough to be useful for just about anyone in the API design process.  LanguageNaming things is hard.  This is true of most things in computer science, and API design is no different. The problem here is that similar to variable and function names, you want API routes, fields and types that are clear, yet concise. This is hard to do at the best of times, but here are a few tips.  Use simple languageThis one’s an obvious suggestion, but in practice it’s actually quite hard to do and the cause of much bike-shedding. Try to distill a concept down to its core and don’t be afraid to use a thesaurus for synonyms. For example, when building a platform don’t confuse the concept of a user and a customer. A user (at least in Stripe terms) is a party that directly uses your platform’s product, a customer (also known as an “end-user”) is the party who ends up purchasing the goods or services that your user might be offering. You don’t have to use those exact terms (‘user’ and ‘end-user’ are perfectly fine), as long as you’re consistent with your language.  Avoid jargonIndustries come with their own jargon; don’t assume that your user knows everything there is to know about your specific industry. As an example, the 16 digit number you see on your credit card is called the Primary Account Number, or PAN for short. When running in fintech circles it’s normal to have people talk about PANs, DPANs and FPANs, so you’d be forgiven for doing something like this in your payments API:card.pan = 4242424242424242;Enter fullscreen modeExit fullscreen modeEven if you know what PAN stands for, the connection between that and the 16 digit number on a credit card might still not be obvious. Instead avoid the jargon and use something more likely to be understood by a larger audience:card.number = 4242424242424242;Enter fullscreen modeExit fullscreen modeThis is especially relevant when thinking about who the audience of your API is. Likely the core role of the person implementing your API is that of a developer with no knowledge of fintech or any other specialized domain. It’s generally speaking better to assume that people aren’t familiar with the jargon of your industry.  Structure  Prefer enums over booleansLet’s imagine that we have an API for a subscription model. As part of the API, we want users to be able to determine whether the subscription in question is active or if it has been canceled. It would seem reasonable to have the following interface:Subscription.canceled={true, false}Enter fullscreen modeExit fullscreen modeThis works, but say that some time after implementing the above, we decide to roll out a new feature: pausing subscriptions. A paused subscription means we’re taking a break from taking payments, but the subscription is still active and not canceled. To reflect this we could consider adding a new field:Subscription.canceled={true, false}Subscription.paused={true, false}Enter fullscreen modeExit fullscreen modeNow, in order to see the actual status of the subscription, we need to look at two fields rather than one. This also opens us up to more confusion: what if a subscription has canceled: true and paused: true? Can a subscription that has been canceled also be paused? Perhaps we consider that a bug and say that canceled subscriptions must have paused: false. Does that mean that the canceled subscription can be unpaused? The problem only gets worse the more fields you add. Rather than being able to check a single value, you need a confusing stack of if/else statements to figure out exactly what’s going on with this subscription.Instead, let’s consider the following pattern:Subscription.status={""active"", ""canceled""}Enter fullscreen modeExit fullscreen modeA single field tells us in plain language what the status of the object is by using enums instead of booleans. Another upside is the extensibility and future-proofing that this technique gives us. If we go back to our previous example of adding a “pause” mechanic, all we need to do is add an additional enum:Subscription.status={""active"", ""canceled"", ""paused""}Enter fullscreen modeExit fullscreen modeWe’ve added functionality but kept the complexity of the API at the same baseline whilst also being more descriptive. Should we ever decide to remove the subscription pausing functionality, removing an enum is always going to be easier than removing a field. This doesn’t mean that you should never use booleans in your API, as there are almost certainly edge cases where they make more sense. Instead I urge you to consider before adding them the future possibility where boolean logic no longer makes sense (e.g., having a third option).   Use nested objects for future extensibilityA follow on from the previous tip: try to logically group fields together. The following:customer.address = {  line1: ""Main Street 123"",  city: ""San Francisco"",  postal_code: ""12345""};Enter fullscreen modeExit fullscreen modeis much cleaner than:customer.address_line1 = ""Main street 123"";customer.address_city = ""San Francisco"";customer.address_postal_code: ""12345"";Enter fullscreen modeExit fullscreen modeThe first option makes it much easier to add an additional field later (e.g., a country field if you decide to expand your business to overseas customers) and ensures that your field names don’t get too long. Keeping the top level of your resource nice and clean is not only preferable but soothes the soul as well.  Responses  Return the object typeIn most cases, when you make an API call it’s to get or mutate some data. In the latter case the norm is to return a representation of the mutated resource. For example, if you update a customer’s email address, as part of your 200 response, you’d expect a copy of that customer with the new, updated email address.To make life for developers easier, be explicit in what exactly is being returned. In the Stripe API, we have an object field in the response that makes it abundantly clear what we’re working with. For example, the API route/v1/customers/:customer/payment_methods/:payment_methodEnter fullscreen modeExit fullscreen modereturns a PaymentMethod attached to a specific customer. It should hopefully be obvious from the route that you should expect a PaymentMethod back, but just in case, we include that object field to make sure there can be no confusion:{  ""id"": ""pm_123"",  ""object"": ""payment_method"",  ""created"": 1672217299,  ""customer"": ""cus_123"",  ""livemode"": false,  ...}Enter fullscreen modeExit fullscreen modeThis helps a great deal when sifting through logs or adding some defensive programming to your integration:if (response.data.object !== 'payment_method') {  // Not the expected object, bail  return;}Enter fullscreen modeExit fullscreen mode  Security  Use a permission systemSay you’re working on a new feature for your product dashboard, one that was specifically asked for by a large customer. You’re ready for them to test it out as a beta to get some feedback, so you let them know which route to make requests to and how to use it. The new route isn’t documented anywhere publicly and no one but your customer should even know about it, so you don’t worry too much.A few weeks later, you push a change to the feature that addresses some of the feedback the large customer gave you, only for you to get a series of angry emails from other users asking why their integration has suddenly broken. Disaster, it turns out that your secret API route has been leaked. Perhaps that initial customer got so excited about the new feature that they decided to tell their developer friends about it. Or perhaps that customer’s users had a look at their networking panel and saw these requests to an undocumented API and decided that they liked the look of that feature for their own product.Not only do you have to clean up the current mess, but now your beta feature has effectively been dragged into a launched state. Since making any new changes will now require you to inform every user you have, your development velocity has slowed to a crawl.Reverse engineering an API isn’t as difficult as you might think it is, and unless you take steps to prevent it, you can assume that people will. Security through obscurity is the idea that something hidden is therefore secure. Just as this isn’t true for Christmas presents hidden in the closet, this isn’t true with web security. If you want to ensure that your private APIs stay private, make sure they can’t be accessed unless the user has the correct permissions. The easiest way to do this is to have a permission system tied to the API key. If the API key isn’t authorized to use the route, bail early and return an error message with status 403.  Make your IDs unguessableI touched on this in my Object IDs post, but it’s worth revisiting here. If you are designing an API that returns objects with IDs associated with them, make sure those IDs can’t be guessed or otherwise reverse engineered. If your IDs are simply sequential, then you are at best inadvertently leaking information about your business that you might not want people to know and at worst creating a security incident in waiting. To illustrate, if I make a purchase on your site and I get confirmation order ID of “10”, then I can make two assumptions:You don’t have nearly as much business as you probably claimI might be able to get information about the 9 previous orders (and all future ones) that I shouldn’t be able to, since I know their IDsFor that second assumption, I could try and find out more about your other customers by abusing your API in ways you didn’t intend:// If the below route isn't behind a permission system, // I can guess the ID and get potentially private // information on your other customerscurl https://api.example.com/v1/orders/9 // Response{    ""id"": ""9"",    ""object"": ""order"",    ""name"": ""Lady Jessica"",    ""email"": ""jessica@benegesserit.com"",    ""address"": ""1 Palace Street, Caladan""}Enter fullscreen modeExit fullscreen modeInstead, make your IDs unguessable by for instance using UUIDs. Using what is essentially a string of random numbers and letters as an ID means there’s no way to guess what the next ID looks like based on the one you have. What you lose in convenience (it’s much easier to talk about “order 42” than “order 123e4567-e89b-12d3-a456-426614174000”) you’ll make up for in security benefits. Don’t forget to make it human readable by adding object prefixes though, generating your order IDs in the format order_3LKQhvGUcADgqoEM3bh6pslE will make your and the humans who build with your API’s lives easier.  Designing APIs for humansThere are many resources out there for how you should design your API, and I hope that this article gave you some food for thought and the incentive to dive deeper into this rabbit hole.At Stripe we take API design very seriously. Internally we have a design pattern document containing what I’ve written about above and much more. It includes examples of good and bad design, notable exceptions and even a how-to guide on adding things like enums to existing resources. My favorite part is the “Discouraged” section, where examples of questionable design that exist in our API today are highlighted as a warning to future Stripe developers.If you enjoyed this, check out the other articles in the Designing APIs for humans series. I also recommend joining the APIs you won’t hate community for more thoughts on API design.  About the authorPaul Asjes is a Developer Advocate at Stripe where he writes, codes and talks to developers. Outside of work he enjoys brewing beer, making biltong and losing to his son in Mario Kart."
317,"📱 If your phone could only have three apps (excluding essentials like calls and messages), which apps would you keep, and how do they keep you entertained or organized?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
318,"How do you feel about PHP's future, especially with the introduction of PHP 8 and the continued growth of modern PHP frameworks?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
319,"Hey y'all 👋Hope that you awesome folks are enjoying your weekend. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugBuying a new car 🚗"
320,"Previously in this series I’ve argued that we should design our APIs with the humans that use them in mind. I've covered object IDs and error messages and how Stripe approaches each, but left arguably the most impactful consideration for last: design patterns. APIs are interesting because of how much they can make or break a product. Having a product that’s amazing but an API that’s incomplete, difficult to work with or outright confusing means that the vast majority of your users might never discover how great your product really is. If a developer isn’t able to make some meaningful progress within the first 30 minutes, you might have lost them forever. On the flip side, mediocre products with a great API experience are likely to outperform. The reason is quite simple: the API is part of the product, so we should treat it with the same level of attention and polish.  Understanding your humansA great first step to getting to a great API experience is to start thinking about design patterns before you write your first line of code. When designing, you should keep three things in mind:Who is the intended audience?How customizable do you want the API to be?How much accessibility are you willing to give up for customizability?  Who is the intended audience?For the first point, knowing your audience is absolutely essential before committing to a design pattern. In general, APIs are intended for power users, but do you want to cater to junior developers as well? You can do so by keeping your API overly simple to interact with and make many opinionated decisions for the user. If your product is niche and only used by a subset of developers (e.g., only enterprise level developers using Java or C++), do you lean in more to their preferred object models and language constructs?  How customizable do you want the API to be?Power and accessibility are big factors here too. A powerful API is one that gives a lot of options to its end users, like being able to customize many different factors of an API request. This comes at a cost of accessibility, as the more options available the more complex the API gets. A complex API means you’re more likely to run into walls when trying to build your integration, making it frustrating to work with. For instance you might have to make complex decisions that could have ramifications for future versions of your project, potentially without enough experience.An API on the far left of this graph is easy to use, likely only exposes a single route and can be learned in a matter of minutes. It however is also constrained by its ease-of-use. If the end-user’s use case differs from the “happy path” devised by the API’s designers, they’re out of luck.On the far right of this graph you have a powerful API, where the user has full control of every aspect, molding the API to their exact specifications. However, it  comes with a steep learning curve and is vulnerable to any future change to the API.You want to be somewhere in the middle, perhaps leaning towards a less complex API. Ideally the “happy path” is an integration path that covers nearly all of your users’ use cases, allowing some wriggle room for those power users that have a hyper-specific need.   How much accessibility are you willing to give up for customizability?Where you sit on the graph will largely depend on that first question of who your intended audience is. Remember that while you can turn a low-power, low-complexity API into a powerful yet complex one, it’s near impossible to do the reverse without starting from scratch. Bias towards starting simple and then build up, but try to not to architect yourself into a corner that’s hard to get out of later.Figuring out your design patterns early unlocks some huge benefits that’ll help the longevity and development velocity of your API.   Be consistentFirst up is consistency. Let’s start with a quick example of what I mean by that here. The most common operations for an API are usually a request to GET a resource and a POST to create or update a resource.// Create a PaymentIntentPOST /v1/payment_intents// Update a PaymentIntentPOST /v1/payment_intents/:id// Get a specific PaymentIntentGET /v1/payment_intents/:idEnter fullscreen modeExit fullscreen modeIn the above example we show a route to GET a PaymentIntent, but it only allows you to retrieve one at a time. If you need to obtain a list of PaymentIntents, then it can be quite painful to call the endpoint multiple times. This is especially true if you don’t already have a list of PaymentIntent IDs, not to mention the possibility of being rate limited if your list is too large. Adding a “list” endpoint is a nice quality of life improvement here, giving the user flexibility and the ability to reduce operations into as few API requests as possible.// Get a list of PaymentIntentsGET /v1/payment_intentsEnter fullscreen modeExit fullscreen modeNow imagine the frustration if you were able to list PaymentIntents, but not other resources like Customers. As an API designer you want your API to be as predictable as possible, allowing users to guess what combination of HTTP verbs and endpoints work based on prior experience with your API. Be strict with maintaining consistency in your design; new routes should work in largely the same way as existing ones. Not only does this allow users to ramp up much quicker in using your API, but it gives it that polished feel of a well-designed, intuitive experience.  Be intuitiveSpeaking of which, let’s dive a little deeper into intuition and what that means. To illustrate, let’s pretend that we have a Customer resource object in our API that takes 3 fields: name, email and address. First we create the customer:// Requestcurl https://api.example.com/v1/customers   -u sk_test_123  -d ""name""=""Leto Atreides""  -d ""email""=""leto@houseatreides.com""  -d ""address""=""1 Palace Street, Caladan""// Response{  ""id"": ""cus_123"",  ""object"": ""customer"",  ""name"": ""Leto Atreides"",  ""email"": ""leto@houseatreides.com"",  ""address"": ""1 Palace Street, Caladan""}Enter fullscreen modeExit fullscreen modeThen at some later point we update the customer:// Requestcurl https://api.example.com/v1/customers/cus_123   -u sk_test_123:  -d ""address""=""1 Spice Road, Arrakis""// Response{  ""id"": ""cus_123"",  ""object"": ""customer"",  ""name"": undefined,  ""email"": undefined,  ""address"": "" 1 Spice Road, Arrakis""}Enter fullscreen modeExit fullscreen modeThis is a simple request, just updating an existing customer’s address, but hang on, where did the values for name and email go? Well,  the API did exactly as it was told to. It updated the address value, but since the name and email values were absent in the update request, it interpreted the absence as a request to unset both values. This is extremely frustrating, but technically correct and a clear indicator that this API wasn’t designed with humans in mind. Instead of checking to see if the parameter was passed in, the designers of this API updated the object with the attribute’s value, whether it was provided or not.APIs thrive on being intuitive, operations such as the above should “just work” based on the common assumption rather than a computer’s tendency to do exactly as it was told.   Designing APIs for HumansThere are many resources out there for how you should design your API, and I hope that this article gave you some food for thought and the incentive to dive deeper into this rabbit hole.In the next article we’ll cover some design patterns that we use at Stripe and why I think they warrant a closer look. I also recommend you check out the previous articles in this series to learn more about how we approach API design at Stripe.  About the authorPaul Asjes is a Developer Advocate at Stripe where he writes, codes and talks to developers. Outside of work he enjoys brewing beer, making biltong and losing to his son in Mario Kart."
321,"With my ""the normalized abnormal"" series I wanted to tell you stories about how widespread are malicious practices at workplaces and also how prevalent is gas-lighting employees.From the side of management the fear is that employees start wasting resources, including time and materials, which I totally get.From the side of the employees we want to have decent working conditions; we want to have family life, we want to have a wage that under normal circumstances eliminates the stress and also we want time to recharge our batteries.There are a lot of common in these, and I can't emphasize them enough to everybody: for instance tired employees are going to make mistakes, mistakes that are costly, that tired employees are less likely to fix well, costing the company again.In short, there are things where no one wins.Now, I have had the idea to lay down 3 principles, 3 rules to what I consider a humanist, modern workplace.They seem obvious but the more I read about ""quiet quitters"", ""loud quitters"" and all that jargon, it came to me, that we better write down the obvious.  #1: Company HealthMy number one principle is Company Health is above everything: a company with murky legal situation, a company where departments fail regularly, where resources are bleeding is a company that might fail everybody: its owners, its customers and its employees.Clearly there is no winner if the health of a company is compromised. So this is the most important rule here, as the other two can't come to life without this.  #2: Customer HappinessThis is where I think I will deviate from certain personalities: I think it is not good to scam people or give them low-quality almost-products.On the other hand given the constraints of rule #1, we must give our best to provide decent products to people, to research their needs, to constantly think of what can be made better for them.Quality - I think - also breeds loyalty to a company, which I think would benefit ""Company Health"".  #3: Employee HappinessI want to say it out loud: there is nothing wrong with doing what's written in your employment contract. If more resources are required from the employees they should be compensated fairly.In my opinion, it is the employer's responsibility to find motivation for the employees. Motivation is a psychological phenomenon, you can't expect it. It is created by external factors and also it is taken by external factors. No one employee wakes up and will say ""You know what, I'm going to procrastinate my entire day!"".On the other hand, happy, motivated people are less likely to leave the job and more likely to provide more than what's written in their contracts.For this to happen they need a company that prioritizes their happiness. They should be able to measure if their employees are tired - and if their exhaustion is related to how the company works.  SummaryMy point is: help us help you. We are not lazy folks trying to trick their employers. By simply understanding human biology and psychology we can optimize the workplace for everyone's interest."
322,What are your favorite Swift features that make development more efficient and enjoyable?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
323,"There were several items on the agenda, this post focuses on feature proposals and their progress from the 97th TC39 meeting [Jul 11 - Jul 13 of 2023].Stage 3:Array Grouping: A proposal to make grouping of array items easier.Promise.withResolvers: Creates a Promise with the reject,resolveandpromise functions placed as methodson the promise object itself.Source Phase Imports: Proposal to enable importing modules at the source phase.Time Zone Canonicalization: Stacked on Temporal to improve handling of changes to the IANA Time Zone Database.Stage 2:Deferred Import Evaluation:a way to defer evaluate of a module (previously known as ""Lazy Module Initialization"").Stage 1:DataView get/set Uint8Clamped methods: getUint8Clamped and setUint8Clamped on DataView.prototype.Optional Chaining assignment: add support for optional chaining on the left of assignment operators: a?.b = c."
324,"Have you ever spent more than a few seconds staring at the same line of code? How often did you find conditionals that were tricky to parse? In this article, we discuss how confusing conditionals manifest in our code. Along the way, we also explore different refactoring techniques for improving the readability of conditional control flows.  Double NegativesA double negative arises when we negate a variable whose name is already in a non-affirmative style. Consider the following example.// Non-affirmative Naming Conventionconst isNotReady = doSomething();const isForbidden = doSomething();const cannotJoinRoom = doSomething();const hasNoPermission = doSomething();// Negating once results in an awkward double negative situation.console.log(!isNotReady);console.log(!isForbidden);console.log(!cannotJoinRoom);console.log(!hasNoPermission);Enter fullscreen modeExit fullscreen modeThis is opposed to the affirmative style, which requires less cognitive load to parse because one does not need to jump through the hoops of negating the variable name to extract the essence of its logic. In other words, the intent behind an affirmative variable may be read as is—no hoops required! Consider the following modifications to the previous example.// Affirmative Naming Conventionconst isReady = doSomething();const isAllowed = doSomething();const canJoinRoom = doSomething();const hasPermission = doSomething();// Negation actually makes sense here!console.log(!isReady);console.log(!isAllowed);console.log(!canJoinRoom);console.log(!hasPermission);Enter fullscreen modeExit fullscreen modeUnfortunately, non-affirmative naming conventions are sometimes inevitable due to standards and backwards-compatibility. Take the HTMLInputElement#disabled property of the HTML DOM APIs for example. The presence of the disabled attribute in an <input> tag tells the browser to (visually and literally) disable the element's form controls. Otherwise, its absence causes the <input> to exhibit its default behavior, which is to accept user input. This is an unfortunate side effect of the ergonomics of HTML.<!-- Normal Checkbox (Default) --><input type=""checkbox"" /><!-- Disabled Checkbox --><input type=""checkbox"" disabled />Enter fullscreen modeExit fullscreen modeNevertheless, we should still strive for affirmative naming conventions wherever possible. They are easier to read and parse simply because there is no need to mentally negate the variable name at all times. This rule applies to both variables names and function names alike.  Non-affirmative Control FlowsThe next form of a double negative is a little bit more subtle.// Suppose that we _do_ follow affirmative naming conventions.const isAllowed = checkSomething();if (!isAllowed) {    // There is something funny about this...    doError();} else {    // Notice how the `else` block is practically a double negation?    doSuccess();}Enter fullscreen modeExit fullscreen modeAs seen above, the non-affirmative style can also pervade conditional control flow. Recall that an else block is practically a negation of the corresponding if condition. We must therefore extend the affirmative style here. The fix is actually rather simple.// Just invert the logic!const isAllowed = checkSomething();if (isAllowed) {    doSuccess();} else {    doError();}Enter fullscreen modeExit fullscreen modeThe same rule applies to equality and inequality checks.// ❌ Don't do this!if (value !== 0) {    doError();} else {    doSuccess();}// ✅ Prefer this instead.if (value === 0) {    doSuccess();} else {    doError();}Enter fullscreen modeExit fullscreen modeSome may even go as far as to let a conditional block be blank just to negate a condition in affirmative style. Although I am not advocating for everyone to take it this far, I can see why this may be more readable for some people. Take the instanceof operator for example, which cannot be easily negated without parentheses.if (obj instanceof Animal) {    // Intentionally left blank.} else {    // Do actual work here (in the negation).    doSomething();}Enter fullscreen modeExit fullscreen mode  Exceptions for Early ReturnsAs a quick aside, there are special exceptions for conditional control flows that return early. In such cases, the negation may be necessary.if (!isAllowed) {    // Return early here.    doError();    return;}// Otherwise, proceed with the success branch.doSuccess();Enter fullscreen modeExit fullscreen modeWherever possible, though, we should still attempt to invert the logic if it results in lesser nesting, fewer levels of indentation, and more readable affirmative styles.// Prefer affirmative early returns.if (isAllowed) {    doSuccess();    return;}// If we did not invert the logic, this would have been// nested inside the `!isAllowed` conditional block.if (!hasPermission) {    doPermissionError();    return;}// When all else fails, do something else.doSomethingElse();return;Enter fullscreen modeExit fullscreen modeAnother way to express the same control flow in an affirmative style (without early returns) is as follows.// Hooray for the affirmative style!if (isAllowed) {    doSuccess();} else if (hasPermission) {    doSomethingElse();} else {    doPermissionError();}return;Enter fullscreen modeExit fullscreen modeOf course, there are plenty of other ways to swap, invert, and refactor the code—the merits for each are totally subjective. Preserving the affirmative conventions thus becomes some kind of an art form. In any case, code readability will always improve as long as we uphold the general guidelines of the affirmative style.  Compound ConditionsThe story gets a little bit more complicated with logical operators such as AND and OR. For instance, how do we refactor the code below in a more affirmative style?// This is fine... but there has to be a better way,// right? There are just too many negations here!if (!isUser || !isGuest) {    doSomething();} else {    doAnotherThing();}Enter fullscreen modeExit fullscreen modeFor compound conditionals, we introduce the most underrated law of Boolean algebra: De Morgan's Laws!// Suppose that these are **any** two Boolean variables.let a: boolean;let b: boolean;// The following assertions will **always** hold for any// possible pairing of values for `a` and `b`.!(a && b) === !a || !b;!(a || b) === !a && !b;Enter fullscreen modeExit fullscreen modeThanks to De Morgan's Laws, we now have a way to ""distribute"" the negation inside a condition and then ""flip"" its operator (from && to || and vice-versa).Although the following examples only feature binary comparison (i.e., two elements), De Morgan's Laws are generalizable over any number of conditional variables as long as we respect operator precedence. Namely, the && operator is always evaluated first before the || operator.// By De Morgan's Laws, we can ""factor out"" the negation as follows.if (!(isUser && isGuest)) {    doSomething();} else {    doAnotherThing();}Enter fullscreen modeExit fullscreen mode// Then we simply invert the logic as we did in the previous section.if (isUser && isGuest) {    doAnotherThing();} else {    doSomething();}Enter fullscreen modeExit fullscreen modeNow, isn't that much more readable? Using De Morgan's Laws, we can clean up conditionals that have ""too many negations"".  ConclusionThe overall theme should be apparent at this point. Wherever possible, we should avoid writing code that forces the reader to jump through hoops that (needlessly) necessitate extra cognitive overhead. In this article, we discussed the following techniques:Encourage affirmative naming conventions.Avoid negative terms/prefixes like no, not, dis-, mal-, etc.Prefer the positive equivalents.Invert conditional control flow (where possible) to accommodate for the affirmative style.Feel free to play around when swapping, inverting, and refactoring branches.Early returns may necessitate negations.Use some tricks from Boolean algebra to invert condtionals.De Morgan's Laws are especially powerful tools for refactoring!Now go forth and bless the world with cleaner conditionals!"
325,"I have said it before and I will say it again, the tooling around large language models (LLM’s) is still in its infancy. Due to the nature of LLM’s and their inherent dynamism, traditional software tooling is often ill-equipped to handle these models out of the box.Enter LangChain and LangSmith.In this post, we will explore the latest product by the team that created Langchain (the most popular LLM software tool) and see what new parts of the LLM stack LangSmith hopes to tackle.If you are new to LLM development, the first place to start is with Langchain itself. I wrote up a comprehensive intro with details on what problems it can solve.[Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]  What is LangSmith? 🤔When Langchain was originally created, the goal was to reduce the barrier to entry with respect to building prototypes. Despite some pushback on the viability of Langchain as a tool, I think it has largely delivered on this goal. The next problem space to tackle after prototypes is helping get these applications into production and ensuring this happens in a reliable and maintainable way. The simple mental model is:Langchain = prototypingLangSmith = productionBut what are the production challenges that need to be solved which were not as relevant in prototyping?Reliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.To tackle this, LangSmith provides new features around 5 core pillars:DebuggingTestingEvaluatingMonitoringUsage metricsA huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.There are also a lot of things about LLM’s that are not intuitive when you look at them from a numbers perspective so being able to see visualizations through a UI will be useful (e.g. how temperature effects model output distribution). I personally find that having a polished UI can actually be the accelerant to my prototyping and work since doing everything with code can often times be cumbersome.Further, being able to visualize the process the LLM system is going through and a complex chain of commands can be super useful in understanding why you are getting the output that you are. As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.  Who is competing with LangSmith?While not direct competitors thus far, it does make a lot of sense for organizations like Vercel (who have the AI SDK) to build similar features into their platform given the desire to be the place for AI builders. I would imagine that other platforms build similar tooling over the next 3–6 months given the market for these tools has so much potential.Vercel is still more focused on the deployment and serving aspect of LLM’s today since that is more aligned historically with their core product but it would make sense to extend the AI SDK to do more over time.While LangSmith does not appear to go deep on Embeddings yet, there does seem to be a ton of natural crossover between this and many of the Embeddings providers who are differentiating with the batteries included UI. Ecosystems like LlamaIndex would benefit from this type of product development but it is unclear they can stay differentiated overtime as the problem space seems to be very similar.Despite this, it is nice to see LangSmith still wanting to connect with as many tools as possible. In the launch blog post, they mentioned integrations with OpenAI evals as well as multiple fine-tuning providers that will enable developers to export data and directly train on it. These types of integrations seem like they will not only enable a ton of developer goodwill but actually serve as a lightweight moat over time (connecting things is not always easy).  What I want from LangSmith 👀The main ask I have is extensibility. I really do think there could be orders of magnitude more impact if the core of LangSmith could be built into other applications and services. Allowing developers to sign in with their LangChain account and monitor their LLM’s on Vercel for example with the AI SDK and deployment information all in one place would be extremely valuable.What it takes to be differentiated over a long period of timeI am very excited about LangSmith, hence spending the time to write this up. I think it solves a bunch of actual problems that developers and builders have when trying to go into production. The real long term question still remains: “is there enough here to build a long term defensible business”.I do not have a crystal ball (shockingly) but my general mindset today is that many of the current features of LangSmith are table stakes for developers. Most LLM providers will want to build similar features into their platforms over time. That doesn’t mean that LangSmith cannot succeed though. Just look at Terraform by HashiCorp for example, it is the glue that sits in between all the cloud providers and solves a large enough problem to be a publicly traded company. But LangSmith will need to continue to expand in scope in order to be competitive with multiple providers and other tooling ecosystems.You got this Harrison!"
326,"Cybersecurity is a fast-paced and ever-evolving field, and having the right skills and certifications can open up exciting opportunities. So, let's dive in and explore: What are the essential skills you should acquire, and which certifications can give your cybersecurity aspirations a serious boost? Let's discuss what's needed to navigate this exciting field!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
327,"As a Rust enthusiast, what advice would you give to developers considering learning Rust and incorporating it into their tech stack?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
328,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Resilience and PerseveranceHow do you maintain resilience and persevere through challenges and setbacks while coding? Any personal practices or mindsets you adopt?Can you recall a difficult coding problem that tested your resilience? How did you overcome it, and what did you learn from the experience?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
329,Time to show off your captioneering chops! We need your genius to address whatever the heck is happening in the goofy pic below. 😅Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
330,"In software development, two captivating figures often emerge: the Stubborn Stumper and the Strategic Solver. Picture the Stubborn Stumper, a seasoned developer with grit in his eyes, fervently hammering at the keyboard as if it were an anvil, relentlessly seeking the elusive solution. We'll call him Benjamin.“There's honor in grinding and a sense of achievement in a solution hard-earned,” Benjamin would argue, his belief echoing in the cathedral of code he's built. Now, meet the Strategic Solver, the composed Sherlock of software, armed with an arsenal of tried-and-true methods. She's the embodiment of wisdom - collecting, cataloging and deploying strategies with surgical precision. We'll call her Laura.“Elegance lies in efficiency and the well-timed use of the right tool,” she'd whisper as she conjures up the perfect piece of code, as if from thin air.So, who's right? Or better yet, is there even a 'right' way when it comes to problem-solving in software development?  A Bug on the Horizon: The Different ApproachesBenjamin and Laura were both software developers at Phoenix Technologies, a growing tech startup. Then came the day a nasty bug slipped into their codebase, causing random crashes in their software. Benjamin and Laura were assigned to tackle this problem together, their contrasting strategies about to be put to the test.   Benjamin’s Battle: The Cost of StubbornnessBenjamin jumped into the fray, his mind brimming with ideas. For him, it was a test of stamina and resilience. But despite his best efforts, the solution eluded him. Yet he soldiered on, becoming more frustrated with each passing hour.  Laura’s Strategy: Wisdom Through Proven TechniquesMeanwhile, Laura took a different approach. She recognized that this was a complex problem, one that could not be solved simply by brute force. She decided to employ various problem-solving techniques documented by others.  A Duck, Divide and Conquer, and Logging: Laura’s ArsenalFirst, Laura tried the 'Rubber Duck Debugging' technique. When that didn't fully solve the problem, she switched to the 'Divide and Conquer' strategy. Days passed, and Laura was slowly but surely leading her towards the bug by using another method called 'Trace Logging'.  The Reveal: Triumph of the Strategic SolverFinally, Laura pinpointed the bug. It was a memory management issue, a tough one to crack, hidden deep within the code. But Laura's systematic approach and the strategic application of different troubleshooting methods had paid off.  Lessons Learned: The Power of Strategic Problem-SolvingWhen Laura finally shared her solution, a weary and slightly embarrassed Benjamin conceded that his stubborn approach hadn't been enough. He recognized the power of strategic problem-solving, and, for the first time, acknowledged that he had a lot to learn from Laura's methodical approach.  Troubleshooting Techniques Employed by Laura:  Rubber Duck DebuggingThis method involves explaining your problem to an inanimate object, like a rubber duck. It's surprising how often this can lead to insights and solutions. The act of verbalizing your problem can make it more apparent, leading to an 'aha' moment.The Rubber Duck method is based on the principles of cognitive psychology. The act of explaining a problem out loud helps to activate different parts of the brain and can lead to new insights and solutions. Additionally, the process of breaking down a problem into smaller parts and explaining it step-by-step can help to uncover hidden issues and identify potential solutions.  Divide and ConquerThis strategy is about breaking down the codebase or the problem into smaller pieces and isolating the source of the error. This systematic approach can help navigate complex issues and identify where the problem lies.While the strategy has roots in algorithms, it has a nice application in the troubleshooting toolkit. Dealing with smaller sub-problems can help identify the root cause of the problem more quickly and accurately. It also helps us avoid getting stuck in a particular line of thinking, which can lead to a dead-end in problem-solving.From a psychological perspective, the Divide and Conquer approach helps manage cognitive overload, which is a common problem in complex problem-solving. By breaking down a problem into smaller sub-problems, we can focus our attention on one specific aspect of the problem at a time, reducing the cognitive load and improving problem-solving efficiency.Divide and Conquer works on a few levels by breaking down a complex problem into smaller, more manageable sub-problems where we can then improve problem-solving efficiency and accuracy, while avoiding getting stuck in a particular line of thinking and managing cognitive overload.   Trace LoggingThis technique involves adding logging statements in the code to track the program's execution flow. By reviewing these logs, you can understand how the application is behaving at specific points in time and where things are going wrong. It's particularly useful for identifying elusive bugs that are difficult to reproduce.Trace logging can be implemented in a variety of ways, depending on the programming language and platform being used. Some languages and platforms provide built-in support for trace logging, while others require a bit code to implement it. This can be done with little debug messages like, ""got here.""However, it is important to note that trace logging can also generate a large amount of data, which can be difficult to analyze and interpret. We must be careful to use this method deliberately and focus on the most relevant areas to avoid getting bogged down in irrelevant details -- and remove the logs when no longer necessary.  Embracing Strategy Over StubbornnessIn our industry, problems are inevitable. Bugs, crashes, and unexplained behaviors are all part and parcel of a developer's life. But as Benjamin and Laura have demonstrated, the way we tackle these problems can drastically affect our productivity, stress levels, and even our sense of job satisfaction.Benjamin's relentless, headstrong approach may have a heroic ring to it, but it's often the quiet, strategic wisdom of developers like Laura that carry the day. By stepping back from the immediacy of the problem, evaluating the situation, and applying targeted troubleshooting techniques, we can transform problems from daunting obstacles into minor challenges.Ultimately, the most effective problem solvers are those who are willing to learn from others, to leverage proven strategies, and to adapt their approach based on the task at hand. Stubbornness may win battles, but strategy wins wars.When the inevitable tricky bug or complex feature next comes your way, think of Laura with her rubber duck, her divide-and-conquer strategy, and her meticulous logging. Embrace the art of strategic problem solving, and turn your coding challenges into opportunities for growth and learning.As the ancient proverb says, ""Give me six hours to chop down a tree and I will spend the first four sharpening the axe."""
331,"There is countless advice on finding projects and, eventually, GitHub Issues to work on, but it's mainly repeated content. I want to approach this with a new lens and focus on practical advice to make your next meaningful contribution to open source. Though prevalent advice, never look for good first issues first. Instead, connect with people. The best first contribution is saying ""hello"" in Discord. So for the sake of this guide, I'd recommend working on projects where you can chat with the maintainers and contributors. This cuts out a lot of noise and gets you focused on projects where you can get meaningful mentorship. Some small projects don't have discords and communities, and that's ok. I suggest focusing efforts on areas you can contribute, so if you are looking for projects to contribute, look at places with many active contributors and note what they are actively working on. In OpenSauced, you can create a custom insight page for projects you want to connect to. Check out that guide here.   Practical Steps to Find Your Next ContributionNow if you already have the context of the project and the community, you are in a great place to start contributing. For the rest of this article, we will focus on practical advice on finding what to work on next. For those who want to know the context up front, below are the contribution areas I will recommend:Running the project locallyImproving the developer experienceEstablishing Credibility by Enhancing DocumentationConsidering performance & accessibility For the sake of providing practical advice, my examples will use the Astro project, but you should choose a project you are interested in for this exercise.         withastro       /         astro            The all-in-one web framework designed for speed. ⭐️ Star to support our work!      Running the project locallyThis is a crucial step for anyone making code contributions or updating documentation about how to run and use the project and is often overlooked. It is impressive to meet a vegan butcher, but that is the outlier, not the norm. Be normal and try using the project first. By running the project locally, you learn more about the project, experience, and any challenges or surprises you might face.Make it a challenge to clone the project and run the test suite. Astro provides an ""Open in Codespaces"" button in the CONTRIBUTING.md, which gets there as fast as possible. If you get stuck or do not have context on a concept from that experience, find a person in the contributor community to share that context. The core project can be daunting, which is fine as well. There are countless Astro examples that you can perform the same tasks in.         MicroWebStacks       /         astro-examples            Astro design patterns examples, client-server state management, markdown, caching      Improving the Developer ExperienceBy using the project you're more likely to be able to improve the developer experience. Find any and every way to use Astro in a side project and run through the examples in the docs guide section. Astro already has a great guide and tutorials section that has been developed after months of feedback from folks like you. But the thing there is that after months things change. Try walking through the guides to gain knowledge about building an Astro project. If you learn something, share those insights with the community via DEV post. Your experience is unique, and it can be very hard to know what it's like learning a new technology the first time. DevEx and OSS- Elevating Developer Experience through Open Source CollaborationBekahHW for OpenSauced ・ Jul 3#devex#career#opensource#devrelVery few beginner guides for projects exist because many beginners believe that experienced community members already possess their insights. But the  beginner experience can only be shared once, making it the most valuable insight a new community member can provide.Most maintainers need more time for community support as the project grows. Community support and triage is one of the best ways to level up and learn ways to improve the developer experience for the project.  Establishing Credibility by Enhancing DocumentationIn the case of Astro, they have a docs site that includes instructions on how to use the project. There are two approaches to documentation that I'll cover here, documentation that improves how the information is shared and the necessary context provided and documentation that has to do with running and using the code.If you're adding to or revising the documentation that doesn't require you to have knowledge of the codebase, make sure you provide a clear reason for the revision or introduction to new information in the documentation. The maintainer should be able to see from the issue your write or your Pull Request description, which this is an important update to the documentation. For example, if you're reorganizing the documentation, provide a clear description of why the reorganization is necessary and will improve the developer experience. If you're making a contribution, I strongly suggest using the project first. If you haven't used due to a lack of context limitation, consider leveling yourself with context through a conversation with a community member or contributor. While using the project, note any unclear installation steps and weirdness in your environment. If you are running into errors, this is an opportunity to open an issue to confirm if this is isolated to you and your environment or impacting others. Search the issues for existing conversations before opening any new issues. Read through merged pull requests to understand the project's history and why some decisions were made. This is a great way to learn who are the decision makers too. Some issues regarding developer experience would be enhancements for the docs sites—one regarding improving Firebase Deploy.Stop looking at large projects and starting in a place that needs your help even more, smaller projects. Starting in a smaller project's README will likely lead to you finding areas for providing value much faster than searching endlessly through open issues in a large project. Support the little projects with your time if you have it. note: If you say you will do something, provide an update at the end of the week. If you can't complete it, unassign yourself and provide an update for why.If you do not experience issues, that is great. There are several technologies that Astro works alongside, and only some cases are covered in the documentation. Using the technology will eventually lead to discovering issues and perhaps good first issues you can approach.When writing this article, the Astro docs site has a recipe section, which includes instructions on how to deploy to various services. There is no section on how to deploy to Digital Ocean within that recipe section. I'll leave this for the reader's exercise, but that would be where I'd start: building a project in Astro,deploying the project to a production cloud host, andleaving notes for the next person in a findable location-probably the documentation.  Considering performance & accessibilityOnce you have established credibility through content and building with Astro, I'd consider a meaningful change. I recommend not trying to add any new features but instead showing you care by looking into ways to improve the project's performance and accessibility. Astro has some integrations in accessibility and performance. Similar to the previous sections, the tool is the best way to understand. This requires time and even gives you a deeper understanding of the project without adding any new libraries, audit pages, and boot speeds. Identify if the project meets all standards in its documentation pages. Be genuinely helpful in places most others overlook. The goal here is to be intentional and not simply run a lighthouse audit with any practical or actionable advice. I suggest running an audit through an Astro example site or one you have built. Look for places for improvement where individuals learn how to use Astro. The documentation also has a section on how to build Astro integrations. Integrations and add-ons are a great place to explore providing value. Often, these enhancements live outside the repo you are trying to contribute, which makes for a great place to experiment and find things to work on. https://astro.build/integrationsFind an existing Astro example and leverage integration to identify areas of improvement by running a quick audit to provide that actionable insight.That wraps up this guide, but let's continue. You should look for ways to make an impact in open source beyond the green square. Consider pledging 100 days to this path and check out the #100daysOfOSS. #100DaysOfOSS: Growing Skills and Real-World ExperienceBekahHW for OpenSauced ・ Jul 12#opensource#github#career#challengeIf you have any other tips for how to start contributing. Leave a comment with them below."
332,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Continuous Learning and CuriosityHow do you stay updated with the latest trends and technologies in the coding field? Any resources or learning strategies you find helpful?Share a time when your curiosity led you to explore a new technology or programming language. How did it impact your coding journey?CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
333,"Jokeday Funday: Part 3 - Keep the Laughter Rolling with More Programming Jokes!Joke 1: The Unending LoopWhy do programmers always carry an umbrella?In case it starts raining while they're stuck in an infinite loop!Joke 2: The Password ConundrumWhy did the programmer's password get rejected?It didn't have enough characters to make a secure key to the heart of the system!Joke 3: The Parallel UniverseWhy do programmers always mix up Christmas and Halloween?Because they believe that Oct 31 and Dec 25 are running in parallel universes!Joke 4: The Memory SnatcherWhy did the memory module break up with the CPU?It couldn't handle the CPU's commitment issues - always forgetting things!Joke 5: The Language of CrowdsWhy do programming languages get invited to parties?Because they can always bring a large crowd, whether it's Java, Python, or C++!Joke 6: The Time Traveling CoderWhy did the programmer start using a time machine while coding?To debug issues from the past and prevent bugs in the future!Joke 7: The Math MysteryWhy was the math book sad when it became a programmer's best friend?Because it knew all the problems would be solved with code, not formulas!Joke 8: The Job of a CompilerWhy did the compiler refuse to go on vacation?It didn't want to leave its source code without proper supervision!Joke 9: The Robotic LoveWhy did the robot become a programmer?Because it found its if statement was always true when it came to loving coding!Joke 10: The Lost DeveloperWhy did the developer get lost on the way to the Git repository?Because they didn't ""commit"" to the right path!Bonus Joke: The Programming ProdigyWhy did Soumya become a computer programmer at such a young age?Because he saw all the ""byte-sized"" snacks programmers could have while coding!Enjoy the jokes, and may the laughter be with you! 😄"
334,"Now that I have my first version of the character, and he can move, I need to make him so something else. Remember that you can check the status of the code in my github repo. I created a simple sprite for bullet which is a 2 colors circle (redoing sprites into something better is a problem for future me) and created 3 variables for this: sx (shoot in x axis), sy (shoot in y axis) for the position of the shoot every frame and a shootStatus to see if it is actually firing something or not (maybe in the future I can delete this variable and use a special value in sx and clean 1 byte?)For making this work, I added the shoot behaviour to button B in the engine sector:bButton:    CMP #%01000000    BNE bDone    LDA #$01    STA shootStatus    LDA p2x    STA sx    LDA p1y    STA sybDone:Enter fullscreen modeExit fullscreen modeAfter that, I see if the shooting is active and I jump to a shooting ""function"";Shooting updateLDA #$01CMP shootStatusBNE :+JMP shoot:Enter fullscreen modeExit fullscreen modeAnd then the shoot part:shoot:    ;for now it will only shoot to the right.    LDA sx    CLC    ADC #01    STA sx    RTSEnter fullscreen modeExit fullscreen modeAs you can see I place a lot of comments, the code in assembly is not that ""self readable"" as other languages.Now, I have to update the sprites refresh to make all this visible.LDA sy    STA $0210    LDA sx    STA $0213    LDA #$00    STA $0212    LDA #$01    CMP shootStatus    BEQ isShooting    LDA #$FC    STA $0211    JMP shootDone    isShooting:    LDA #$30    STA $0211    shootDone:Enter fullscreen modeExit fullscreen modeAs it is a one tile sprite, I only need 4 positions in memory, so I assigned it the $0210 to $0213 space.(tomorrow we will talk about the other thing that appears on the screen)On the other hand, to keep me MORE motivated I am playing some nes games lately.  Not only Final Fantasy in japanese to learn, but I started Rockman (Megaman)If you have a child that loves video games, show them the old Nintendo games, for them this all will be in nightmare level."
335,"  S.O.L.I.D principles explained.SOLID principles are the design principles that enable us to manage several software design problems. They were introduced by Robert C. Martin in his 2000 paper “Design Principles and Design Patterns”. SOLID is an acronym that stands for:Single Responsibility Principle: A class should have one and only one reason to change, meaning that a class should have only one job.Open/Closed Principle: Objects or entities should be open for extension but closed for modification. This means that a class should be easily extendable without modifying the class itself.Liskov Substitution Principle: A subclass should be substitutable for its superclass. This means that a subclass should not break the functionality of a superclass or its clients.Interface Segregation Principle: Clients should not be forced to depend on methods that they do not use. This means that interfaces should be small and focused, and classes should implement only the interfaces that they need.Dependency Inversion Principle: High-level modules should not depend on low-level modules; both should depend on abstractions. This means that classes should depend on interfaces or abstract classes instead of concrete implementations.These principles provide us with ways to move from tightly coupled code and little encapsulation to the desired results of loosely coupled and encapsulated real business needs properly. They also help us to create more maintainable, understandable, and flexible software.  Single Responsibility Principle (SRP)A class should have only one reason to change. In other words, a class should have a single responsibility or purpose. This principle promotes separation of concerns and helps in creating smaller, focused classes that are easier to understand, test, and maintain.Let’s consider an example of a class called Employee that represents an employee in a company. According to the Single Responsibility Principle (SRP), the Employee class should have only one reason to change, meaning it should have a single responsibility.In its current state, the Employee class might have multiple responsibilities, such as managing employee data and calculating payroll. To adhere to SRP, we can split these responsibilities into separate classes.Here’s an example implementation:    // Employee class with a single responsibility of managing employee data    class Employee {        private String name;        private String employeeId;        private double salary;        // constructor, getters, and setters        // Other methods specific to employee data management        public void saveEmployeeData() {            // Code to save employee data to the database        }        public void updateEmployeeData() {            // Code to update employee data in the database        }        // ... other methods related to employee data management    }    // PayrollCalculator class with a single responsibility of calculating payroll    class PayrollCalculator {        public double calculateSalary(Employee employee) {            // Code to calculate employee salary based on some logic            // and return the calculated salary        }        // Other methods related to payroll calculations        public void generatePayrollReport(Employee employee) {            // Code to generate a payroll report for the employee        }        // ... other methods related to payroll calculations    }Enter fullscreen modeExit fullscreen modeIn this example, we have separated the responsibilities of managing employee data and calculating payroll into separate classes: Employee and PayrollCalculator. The Employee class is now responsible only for managing employee data, such as storing and updating employee information in the database. The PayrollCalculator class, on the other hand, focuses solely on calculating employee salaries and generating payroll reports.By adhering to the Single Responsibility Principle, we have created two classes, each with a single responsibility. This separation of concerns makes the codebase more maintainable, as any changes related to employee data management will be isolated to the Employee class, and any changes related to payroll calculations will be isolated to the PayrollCalculator class. This approach promotes code reusability, testability, and overall code organization.  Open/Closed Principle (OCP):Software entities (classes, modules, functions) should be open for extension but closed for modification. This principle encourages designing code that can be easily extended without modifying existing code. By using abstractions, interfaces, and inheritance, new functionality can be added without changing the existing codebase.Suppose we have a Shape class hierarchy that represents different shapes, and we want to calculate the area of each shape. Initially, we have two shapes: Circle and Rectangle. However, we anticipate that new shapes will be added in the future. We want to design our code in a way that allows for easy extension without modifying the existing code.Here’s an example implementation:    abstract class Shape {        public abstract double calculateArea();    }    class Circle extends Shape {        private double radius;        public Circle(double radius) {            this.radius = radius;        }        public double calculateArea() {            return Math.PI * radius * radius;        }    }    class Rectangle extends Shape {        private double width;        private double height;        public Rectangle(double width, double height) {            this.width = width;            this.height = height;        }        public double calculateArea() {            return width * height;        }    }Enter fullscreen modeExit fullscreen modeIn this example, we have an abstract Shape class that defines a contract for calculating the area of a shape through the calculateArea method. The Circle and Rectangle classes extend the Shape class and provide their own implementations of the calculateArea method.Now, if we want to add a new shape, such as a Triangle, we can create a new class that extends Shape and implement the calculateArea method specifically for triangles, without modifying the existing code:    class Triangle extends Shape {        private double base;        private double height;        public Triangle(double base, double height) {            this.base = base;            this.height = height;        }        public double calculateArea() {            return 0.5 * base * height;        }    }Enter fullscreen modeExit fullscreen modeBy following the Open/Closed Principle, our code remains closed for modification. We can easily introduce new shapes by extending the Shape class and implementing the calculateArea method specific to each shape. This way, we are extending the behavior of the code without modifying the existing Shape class or any other classes that depend on it. This promotes code maintainability, reusability, and minimizes the risk of introducing bugs in the existing codebase when extending functionality.  Liskov Substitution Principle (LSP):Subtypes must be substitutable for their base types. This principle emphasizes that objects of a superclass should be replaceable with objects of its subclass without affecting the correctness of the program. In other words, subclasses should adhere to the contract defined by the superclass and not introduce new behaviors that could break the code.Suppose we have a Rectangle class that represents a rectangle shape, and we use it in various parts of our codebase. According to the LSP, we should be able to substitute a Rectangle object with an object of any of its subclasses (e.g., Square) without causing any issues.Here’s an example implementation:    class Rectangle {        protected int width;        protected int height;        public Rectangle(int width, int height) {            this.width = width;            this.height = height;        }        public int getWidth() {            return width;        }        public void setWidth(int width) {            this.width = width;        }        public int getHeight() {            return height;        }        public void setHeight(int height) {            this.height = height;        }        public int calculateArea() {            return width * height;        }    }    class Square extends Rectangle {        public Square(int sideLength) {            super(sideLength, sideLength);        }        public void setWidth(int sideLength) {            super.setWidth(sideLength);            super.setHeight(sideLength);        }        public void setHeight(int sideLength) {            super.setWidth(sideLength);            super.setHeight(sideLength);        }    }Enter fullscreen modeExit fullscreen modeIn this example, we have a Rectangle class with a width and height, and a calculateArea method that returns the area of the rectangle. We then introduce a Square class that extends Rectangle. Since a square is a special type of rectangle where all sides are equal, we override the setWidth and setHeight methods to ensure that both sides are always set to the same value.Now, let’s examine how LSP is demonstrated in this example:    public static void main(String[] args) {        Rectangle rectangle = new Rectangle(3, 4);        processShape(rectangle);        Square square = new Square(5);        processShape(square);    }    public static void processShape(Rectangle shape) {        shape.setWidth(10);        shape.setHeight(5);        int area = shape.calculateArea();        System.out.println(""Area: "" + area);    }Enter fullscreen modeExit fullscreen modeIn the main method, we create a Rectangle object and a Square object. Both objects are passed to the processShape method, which expects a Rectangle parameter. According to LSP, the Square object should be substitutable for the Rectangle object.When we execute the code, we see that the calculateArea method correctly calculates the area for both the Rectangle and Square objects. This demonstrates the substitutability of the Square object for its superclass Rectangle, without altering the expected behavior of the program.By adhering to the Liskov Substitution Principle, we ensure that subclasses can be used interchangeably with their superclasses, which promotes code reuse, polymorphism, and flexibility in object-oriented design.  Interface Segregation Principle (ISP):Clients should not be forced to depend on interfaces they do not use. This principle encourages creating fine-grained interfaces that are specific to the needs of clients, rather than having a large, monolithic interface. It helps in preventing the coupling of unrelated code and avoids the burden of implementing unnecessary methods.To explain the ISP using a Java example, let’s consider a scenario where we have an interface called Printer that provides various printing-related methods. However, different types of clients may only need a subset of these methods. Applying the ISP, we should split the monolithic Printer interface into smaller, more focused interfaces that cater to the specific needs of each client.Here’s an example implementation:    // Monolithic interface    interface Printer {        void print();        void scan();        void fax();    }    // Fine-grained interfaces    interface Printer {        void print();    }    interface Scanner {        void scan();    }    interface FaxMachine {        void fax();    }Enter fullscreen modeExit fullscreen modeIn this example, we start with a monolithic Printer interface that includes three methods: print(), scan(), and fax(). However, following the ISP, we split this interface into three smaller interfaces: Printer, Scanner, and FaxMachine, each focusing on a specific functionality.Now, let’s consider two different types of clients: a basic printer client that only needs printing functionality, and an advanced office equipment client that requires scanning and faxing capabilities.    class BasicPrinterClient implements Printer {        public void print() {            // Implementation for basic printing        }    }    class AdvancedOfficeEquipmentClient implements Printer, Scanner, FaxMachine {        public void print() {            // Implementation for printing        }        public void scan() {            // Implementation for scanning        }        public void fax() {            // Implementation for faxing        }    }Enter fullscreen modeExit fullscreen modeIn the above code, the BasicPrinterClient only implements the Printer interface because it only requires printing functionality.On the other hand, the AdvancedOfficeEquipmentClient implements all three interfaces: Printer, Scanner, and FaxMachine, as it needs all these functionalities.By adhering to the Interface Segregation Principle, we ensure that clients depend only on the interfaces they actually need. The BasicPrinterClient only knows about printing, while the AdvancedOfficeEquipmentClient is aware of printing, scanning, and faxing capabilities. This approach prevents clients from being burdened with unnecessary methods, reduces coupling, and allows for cleaner, more maintainable code.Additionally, if a new type of client requires a different combination of functionalities, we can easily create a new interface and implement it in the appropriate client class, without impacting existing clients or modifying the existing codebase.  Dependency Inversion Principle (DIP):High-level modules should not depend on low-level modules. Both should depend on abstractions. This principle promotes loose coupling and decoupling of modules by introducing abstractions (e.g., interfaces or abstract classes) that define the dependencies between modules. By depending on abstractions, the code becomes more flexible, testable, and easier to modify.To explain the DIP using a Java example, let’s consider a scenario where we have a high-level class called BusinessLogic that depends on a low-level class called DatabaseService for data persistence. However, applying the DIP, we should introduce an abstraction and have both the high-level and low-level classes depend on that abstraction.Here’s an example implementation:    // Abstraction    interface PersistenceService {        void saveData(String data);    }    // Low-level class    class DatabaseService implements PersistenceService {        public void saveData(String data) {            // Code to save data to a database        }    }    // High-level class    class BusinessLogic {        private PersistenceService persistenceService;        public BusinessLogic(PersistenceService persistenceService) {            this.persistenceService = persistenceService;        }        public void processData(String data) {            // Perform business logic operations            persistenceService.saveData(data);        }    }Enter fullscreen modeExit fullscreen modeIn this example, we introduce the PersistenceService interface as an abstraction that defines the saveData method. The DatabaseService class, which previously represented the low-level module, now implements the PersistenceService interface.The BusinessLogic class, representing the high-level module, depends on the PersistenceService interface through its constructor. This allows us to inject any implementation of PersistenceService, including the DatabaseService or any other class that implements the PersistenceService interface.By following the Dependency Inversion Principle, we have inverted the dependency direction. The BusinessLogic class now depends on the abstraction (PersistenceService) rather than the concrete implementation (DatabaseService). This decouples the high-level module from the low-level module, making the code more flexible, testable, and easier to modify.Here’s an example of how we can use the classes:    public static void main(String[] args) {        PersistenceService persistenceService = new DatabaseService();        BusinessLogic businessLogic = new BusinessLogic(persistenceService);        String data = ""Some data"";        businessLogic.processData(data);    }Enter fullscreen modeExit fullscreen modeIn the main method, we create an instance of DatabaseService and pass it as a parameter to the BusinessLogic constructor. This way, the BusinessLogic class can utilize the PersistenceService abstraction without directly depending on the DatabaseService implementation.The Dependency Inversion Principle allows us to decouple modules, promote interchangeable components, and facilitate easier testing and maintainability. By depending on abstractions rather than concrete implementations, we gain flexibility and can easily switch or extend the underlying implementations without affecting the high-level module.In conclusion, the SOLID principles provide a set of guidelines for writing clean, maintainable, and flexible software code.By adhering to these SOLID principles, software developers can achieve code that is modular, flexible, and easier to maintain. These principles encourage good design practices, reduce code complexity, promote reusability, and make the codebase more adaptable to future changes. Applying the SOLID principles leads to improved code quality, better software architecture, and increased productivity for software development teams."
336,"Back in the day, CSS was like a fresh breath, just letting you style a page in a simple, chill way.It was about setting rules and letting the browser do its thing. You could change up the margins, fonts, and sizes, but that was just scratching the surface, you know?The real gem was that 'cascade' thing, letting styles inherit and override others, making for some dynamic, cool pages. Fast forward to today, CSS is like a Swiss army knife for web design. It's got the power to animate, transform, and adapt layouts with flexbox and grid, making it all responsive and cool.From basic styles to complex animations, CSS has evolved into a whole new level of cool. It's not just about simple styling anymore, it's about bringing your whole web game to life.Let's dive into how CSS got to where it is today (or scroll down to the last section to look into the future 🔮…).CSS selectors - the evolving conduits of styleA CSS selector is like a precise instruction in a game of tag. It's a rule that identifies which HTML elements to style. Whether you're pointing to a <div>, .class, or #id, selectors are the messenger of your style declarations, ensuring the correct elements get ""tagged"".I want you to journey back with me to the early days of CSS. To an era when web design was fresh, raw, and in many ways, restrictive. Remember the old HTML tags like font and center? We used them because we had to, not because we wanted to. And then, like a superhero in a 90s comic book, CSS arrived, and with it came the power of selectors. The original CSS selectors were as basic as the HTML they styled:h1 {  color: blue;}Enter fullscreen modeExit fullscreen modeIt was simple, effective, but very limited. This was like trying to paint the Sistine Chapel with crayons.To add more flexibility, CSS2 introduced new selectors like child (>), adjacent sibling (+), and attribute selectors ([attr=value]). These allowed for more targeted styling:/* Child Selector */div > p {  color: red;}/* Adjacent Sibling Selector */h1 + p {  margin-top: 20px;}/* Attribute Selector */input[type=""text""] {  width: 200px;}Enter fullscreen modeExit fullscreen modeThese selectors let us express more complex relationships between elements and made our stylesheets more efficient and organized. It was a step forward, but we still needed more.Enter CSS3. It expanded the CSS selector repertoire with more powerful tools, such as the general sibling combinator (~), the :not() pseudo-class, and a host of attribute selectors:/* General Sibling Combinator */h1 ~ p {  font-size: 1.2em;}/* :not() Pseudo-class */div:not(.highlighted) {  opacity: 0.5;}/* Attribute Selectors */a[href*=""google""] {  background: url(/images/google-icon.png) no-repeat;}Enter fullscreen modeExit fullscreen modeWe were no longer just styling elements; we were engaging with them, probing their attributes, their relationships with each other. We began crafting sophisticated designs that responded to the content's structure and meaning.CSS3 has brought us pseudo-classes like :nth-child, :nth-of-type, :checked, and ::before and ::after pseudo-elements. Our crayons have become a full artist's palette, and the canvas of the web is richer for it./* :nth-child Selector */li:nth-child(odd) {  background: lightgray;}/* :checked Pseudo-class */input[type=""checkbox""]:checked {  border-color: green;}/* ::before and ::after Pseudo-elements */blockquote::before {  content: ""❝"";  font-size: 3em;}blockquote::after {  content: ""❞"";  font-size: 3em;}Enter fullscreen modeExit fullscreen modeAnother selector worth mentioning is the :is pseudo-class. It allows you to group multiple selectors in one statement, reducing repetition in your code and enhancing readability. For a deeper dive, check out “Simpler CSS Selectors With :is()” by Steve.Last mention, the :where selector, which is similar to :is. However, the key difference is that :where always has 0 specificity.Selectors have given us the tools to express our creative vision in code. They continue to evolve, driving the web forward into ever more exciting frontiers of design.The cascade — leveraging specificity and inheritanceThe cascade is a defining feature of CSS and, when harnessed properly, can make your stylesheets more efficient and easier to maintain. It refers to the process of combining different stylesheets and resolving conflicts between different CSS rules that apply to the same element.The concept of specificity plays a crucial role here. An ID selector has higher specificity than a class selector, which has higher specificity than a type selector.#header {  color: blue; /* This will apply because ID selectors have the highest specificity */}.container .header {  color: red; /* This won't apply to the element with id ""header"" */}header {  color: green; /* This won't apply to the element with id ""header"" */}Enter fullscreen modeExit fullscreen modeKnowing to work with the cascade, and not against it will save you a ton of problems. Using tools such as a specificity calculator can help go a long way.Flexibility with media queriesOne of the key strengths of CSS is its built-in responsiveness through media queries. Media queries help you to apply different styles for different devices or screen widths.@media only screen and (max-width: 600px) {  body {    background-color: lightblue;  }}Enter fullscreen modeExit fullscreen modeIn this example, the background color of the body changes to light blue when the screen width is 600px or less. This makes CSS a major player in creating responsive designs.Let's take a spin down memory lane and see how media queries in CSS have been keeping things fresh:1994: Our main man Håkon Wium Lie lays down the first idea of media queries. It's the start of something big!1998: CSS2 steps up to the plate and gives us the first taste of media queries.2001: CSS3 comes on the scene, leveling up media queries with some dope new features.2012: Media queries hit the big time! They become a recommended standard by the W3C.Right now: Media queries are running things in all the major browsers and have become a key tool in the game of responsive web design.Power of animations and transitionsWith CSS3, animations and transitions have become an integral part of the modern web, creating a dynamic user experience. You can animate changes to CSS properties over time, control the speed of transitions, and create keyframe-based animations.button {  transition: background-color 0.5s ease;}button:hover {  background-color: blue;}Enter fullscreen modeExit fullscreen modeIn this snippet, when you hover over a button, its background color transitions to blue over a half-second period.  Embracing the magic of CSS variables (custom properties)The CSS Working Group had been aware of the need for CSS variables since its inception in 1997. By the late 2000s, developers had created various workarounds like custom PHP scripts and preprocessors like Less and Sass to compensate for this deficiency.Recognizing that a built-in solution would streamline the process, the group released the first draft of the CSS variables module in 2012. Renamed as CSS custom properties for cascading variables, it gained widespread browser support by 2017.Gone are the days of static CSS where updating values was a manual, time-consuming chore. Now, we've got CSS variables in our toolkit, letting us store and reuse specific values throughout our stylesheets. These variables ensure consistency and make updates a breeze.Here's a taste of CSS variables in action::root {  --brand-color: #32a852;}body {  background-color: var(--brand-color);}/* On hovering over the body, the brand color changes */body:hover {  --brand-color: #a83258;}Enter fullscreen modeExit fullscreen modeHover over the body, and voila! Your site's look gets a complete makeover. Now that's CSS variables for you!  Layouts throughout the agesCSS layouts have gone through a lot of changes over the years. Developers used to create layouts with tables and floats, which were hard to maintain and not very responsive. Later, the introduction of media queries, flexbox, and grid revolutionized the way developers create layouts, making them more responsive and easier to maintain. Let’s dig in.Transition from table-based layouts to CSSStepping into the early 2000s, the era of table-based layouts was starting to fade. Remember those times? When we used table, tr, and td to arrange everything on the page, even the layout. Ah, those were some days!<table>  <tr>    <td>Header</td>  </tr>  <tr>    <td>Main Content</td>    <td>Sidebar</td>  </tr>  <tr>    <td>Footer</td>  </tr></table>Enter fullscreen modeExit fullscreen modeIt was a time when we bent HTML to our will, using it for something it wasn't meant for - the layout. But hey, we made it work, right? But let's be real, it was a pain. Code was hard to maintain, accessibility was compromised, and responsiveness was a far-off dream. We needed a change, and CSS was that change!The age of float and the clearfix hackAhh, the age of floats. I can almost see the nostalgic smiles and frustrated grimaces on your faces, dear readers. You see, before flexbox came and made our lives a lot easier, we were stuck in Floatsville.Invented as a simple method for wrapping text around images (think newspaper layouts), floats became an unexpected tool for creating entire web layouts..column {  float: left;  width: 50%;}Enter fullscreen modeExit fullscreen modeAnd just like that, we had a two-column layout. Easy enough, right? But the problems arose when we tried to add more elements below our floated ones. Suddenly, our footers were on a trip of their own, snuggling up next to content higher up in the DOM. Oh, the chaos!This was due to a peculiar trait of floated elements. They are partially removed from the normal document flow, meaning elements that follow them in the markup would behave as if the floated element wasn't there.To fix this, we had to resort to what we now fondly (or not so fondly) refer to as the ""clearfix hack"". This hack forces the container to expand to contain the floats by creating a new block formatting context.Here's the famous clearfix hack that's saved many a layout:.group:after {  content: """";  display: table;  clear: both;}Enter fullscreen modeExit fullscreen modeBy adding an :after pseudo-element to the container, giving it display: table; and clear: both;, we effectively cleared the float. Suddenly, our footers were back where they belonged, and all was right in the world.Despite its quirks and unexpected behaviors, mastering floats was a rite of passage for every web developer. It taught us the importance of understanding the CSS box model, the document flow, and the weird and wonderful ways CSS could behave. It was a challenging, sometimes hair-pulling experience, but it was a crucial stepping stone on the path to the CSS we know and love today.  New age layouts with flexbox and gridThe biggest two major game-changers that have improved web dev immensely are: flexbox. These bad boys totally flipped the script on layout design.First up, flexbox. Introduced in CSS3, flexbox was a straight-up revolution for alignment, direction, order, and size of our boxes. No more float and positioning headaches, y'all. flexbox made it simple to create flexible, responsive layouts with less code and more control. Here's a lil' code sample to show you how it's done:.container {  display: flex;  justify-content: space-between;}.item {  flex: 1;}Enter fullscreen modeExit fullscreen modeIn this example, we've got a container set to display: flex; which lets its children know they're playing in a flex context. justify-content: space-between; is keeping our items nicely spaced out. Then we hit the items with flex: 1; to make 'em all equal width, filling up the full space of the container. Clean and simple.Then we got grid, the next big leap. Grid layout, introduced around 2017, took CSS layouts to a whole new level, letting us define both columns and rows at the same time. CSS grid lets us create complex, two-dimensional layouts that were a real pain to pull off before. Here's a taste:.container {  display: grid;  grid-template-columns: repeat(3, 1fr);  grid-gap: 10px;}.item {  grid-column: span 2;}Enter fullscreen modeExit fullscreen modeIn this piece, .container is our grid container. We define three equal-width columns with grid-template-columns: repeat(3, 1fr); and set a 10px gap between them with grid-gap: 10px;. Then for our items, we use grid-column: span 2; to make an item span two columns. Now that's power!You can become a real CSS grid wizard if you look into the grid-template-areas property.Remember the struggle of centering elements both vertically and horizontally? The combination of different properties such as margin , position , top , left , and transform was enough to make anyone's head spin..container {  position: relative;}.element {  position: absolute;  top: 50%;  left: 50%;  transform: translate(-50%, -50%);}Enter fullscreen modeExit fullscreen modeFast forward to today, and flexbox makes centering a piece of cake:.container {  display: flex;  justify-content: center;  align-items: center;}Enter fullscreen modeExit fullscreen modeIn the past, creating complex layouts often meant resorting to floating elements, which could be finicky and difficult to manage. Here's a simplified example of a two-column layout using floats:.container::after {  content: """";  display: table;  clear: both;}.column {  float: left;  width: 50%;}Enter fullscreen modeExit fullscreen modeToday, with CSS Grid, you can create complex layouts with minimal code, and without the headaches:.container {  display: grid;  grid-template-columns: 1fr 1fr;}Enter fullscreen modeExit fullscreen modeHere’s a more robust and complex layout example:A peek into the near futureThere are several upcoming features and improvements in CSS that are already stirring up excitement in the web design and development community. You can find a detailed list in “What’s new in CSS and UI”, one of the latest posts by the Chrome team.Below are some features I’m excited about:Container queries💡 Not supported in Firefox & Safari yetThe ability to style a child and control layouts within layouts. You can change elements based on their available space, as can be seen below:You can play with the above example code in this Codepen.Due to the container query, the style is dynamic. Changing the size of the viewport triggers a change for each individual element according to the space they have.The syntax is a bit similar to media queries, except you just define the styles you want in case the container size meets a condition:This is how it looks like in practice:/* Create a containment context */.post {  container-type: inline-size; /* size & normal are valid values as well */}/* Default heading styles for the card title */.card h2 {  font-size: 1em;}/* If the container is larger than 700px */@container (min-width: 700px) {  .card h2 {    font-size: 2em;  }}Enter fullscreen modeExit fullscreen modeStyle queries💡 Not supported in Firefox & Safari yetQuery the style values of a parent container:<li class=""card-container"" style=""--sunny: true;"">  <div class=""weather-card"">    <div class=""day"">Saturday</div>    <div class=""date"">February <span>12</span></div>    <div class=""temps"">      <div class=""high"">High: <span>55</span></div>/      <div class=""low"">Low: <span>47</span></div>    </div>    <div class=""features"">      Clear skies, sun    </div>  </div></li><style>.card-container {  container-name: weather;}/* In case the custom propery --sunny: true; change the child */@container style(--sunny: true) { .weather-card {   background: linear-gradient(-30deg, yellow, orange); } .weather-card:after {   content: url(<data-uri-for-demo-brevity>);   background: gold; }}</style>Enter fullscreen modeExit fullscreen mode:has pseudo-class💡 Not supported in Firefox yet.A way to style an element based on its descendants. Basically, you can apply styles according to its children, which means it can act as the elusive parent selector. However, you can style the children within the parent as well.<article> <h1>Hello</h1> <h2>World</h2></article><style>/* style parent according to children */article:has(h1) { background: lightgray;}/* style child by parent content */article:has(h1) h2 {   color: yellow;}/* style sibling by adjacent element */h1:has(+ h2) { color: hotpink;}</style> Enter fullscreen modeExit fullscreen modetext-wrap: balance💡 Currently only supported in ChromiumThis new value, like its name, will allow balancing your text, so you don’t have to use JS for this anymore. Adding this to a text block will really make your designers happy.Nesting💡 Not supported in Firefox yetFinally, like SASS and Less, nest and co-locate the styles related to your selector:.parent {  color: blue;  .child {    color: red;  }}Enter fullscreen modeExit fullscreen modeFurthermore, you can also nest media queries (and container queries):.card {  display: flex;  gap: 1rem;  @media (width >= 480px) {    display: grid;  }}Enter fullscreen modeExit fullscreen modeAlternatively, the first example could be written as such:.parent {  color: blue;  & .child {    color: red;  }}Enter fullscreen modeExit fullscreen modeFor more info, I suggest checking out this post by Adam Argyle.Subgrid💡 Supported in Firefox and Safari, and under a flag in ChromeThe missing piece to grid, apply grid layouts to a grid item's children, resulting in more consistent and maintainable layouts. It is used by adding either grid-template-rows or grid-template-columns properties with the subgrid value:<div class=""grid"">  <div class=""item"">    <div class=""subitem""></div>  </div></div><style>/* some styles removed for brevity */.grid {  display: grid;  grid-template-columns: repeat(9, 1fr);  grid-template-rows: repeat(4, minmax(100px, auto));}.item {  display: grid;  grid-column: 2 / 7;  grid-row: 2 / 4;  grid-template-columns: subgrid;  grid-template-rows: subgrid;  background-color: #ffd8a8;}.subitem {  grid-column: 3 / 6;  grid-row: 1 / 3;  background-color: rgb(40, 240, 83); /* green */}</style>Enter fullscreen modeExit fullscreen modeThis would result as so:Scoped CSS💡 Still in working draftSpecify the boundaries for which specific styles apply, essentially creating native name-spacing in CSS:@scope (.card) {  /* only affects a .title that is within a .card */  .title {     font-weight: bold;  }}Enter fullscreen modeExit fullscreen modeScroll-driven animations💡 Still experimental.Control the playback of an animation based on the scroll position of a scroll container. Again, reduces the JavaScript complexity to create parallax scrolling, reading indicators and more.  Cascade layers (@layer)Now widely supported, define layers that dictate the order of precedence in case of multiple cascade layers. You can basically order your style sheets by importance:@layer base {  a {    font-weight: 800;    color: red; /* ignored */  }  .link {    color: blue; /* ignored */  }}@layer typography {  a {    color: green; /* styles *all* links */  }}@layer utilities {  .pink {    color: hotpink; /* styles *all* .pink's */  }}Enter fullscreen modeExit fullscreen modeView transitions💡 Not supported in Firefox and SafariAllows changing the DOM in a single step, while creating an animated transition between the two states. No more need for SPAs (Single Page Apps) to get this done.There is a need for a bit of JavaScript:function spaNavigate(data) {  // Fallback for browsers that don't support this API:  if (!document.startViewTransition) {    updateTheDOMSomehow(data);    return;  }  // With a transition:  document.startViewTransition(() => updateTheDOMSomehow(data));}Enter fullscreen modeExit fullscreen modeAnd then CSS takes over:@keyframes slide-from-right {  from { opacity: 0; transform: translateX(75px); }}@keyframes slide-to-left {  to { opacity: 0; transform: translateX(-75px); }}::view-transition-old(root) {  animation: 350ms both slide-to-left ease;}::view-transition-new(root) {  animation: 350ms both slide-from-right ease;}Enter fullscreen modeExit fullscreen mode  ConclusionThe future of CSS holds great potential for simplifying complex tasks, improving performance, and enabling developers to create immersive experiences.As CSS evolves, we may witness the emergence of advanced features that blur the line between CSS and JavaScript, offering native solutions for tasks currently reliant on JS libraries.Additionally, more comprehensive CSS frameworks could arise, leveraging these new capabilities.Staying informed about the latest CSS developments is crucial, given its ongoing importance in web design and development. Keeping an eye on updates from the CSS Working Group, following industry leaders, and exploring new features in browser previews will help you stay up to date.Embrace the exciting possibilities ahead, continue learning, and actively contribute to shaping the future of the web.Visually build with your componentsBuilder.io is a headless CMS that lets you drag and drop with your components right within your existing site.Try it out Learn more// Dynamically render your componentsexport function MyPage({ json }) {  return <BuilderComponent content={json} />}registerComponents([MyHero, MyProducts])Enter fullscreen modeExit fullscreen modeRead the full post on the Builder.io blog"
337,"Howdy! Sloan, DEV Moderator and resident mascot, coming back atcha with another one from the inbox... 🦥Welcome to another installment of Sloan's Inbox, your go-to place for sharing advice and observations. Whether it's career development, office politics, industry trends, or improving technical skills, we've got you covered. Let's continue our journey of learning and growth together.As always, I'm here to dive into your questions, comments, and thoughts. So, let's get to it!  Today's question is:I'm at the point in my career where I'm making enough money and have leveled up to a senior position. That said, I've been on the grind for a long time and I'm starting to feel a bit burnt out on coding. I'm considering asking my manager if I can take a sabbatical — i.e. take a good chunk of time off (perhaps a couple months) to travel, relax, and recharge. I've been with the same company for nearly 5 years and they're really great. I don't intend to leave, but I need a break. I'm wondering if others think this is a reasonable request. If so, how would you approach it? If not, do you have any advice for dealing with these feelings?Share your thoughts and lets help a fellow DEV member out! Remember to keep kind and stay classy. 💚Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
338,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Creativity and InnovationHow do you nurture and stimulate your creativity when coding? Are there any specific techniques or approaches you employ?Share an example of a time when your creative thinking and innovative ideas resulted in a unique solution or improved efficiency in a coding project.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
339,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Adaptability and FlexibilityHow do you handle situations when requirements or project scope changes unexpectedly? Any tips for staying adaptable and flexible in coding projects?Share an example of a time when you had to quickly adapt to changes in a coding project. How did you manage it, and what did you learn from the experience?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
340,"Hey everybody 👋Hope that y'all all have wonderful weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugMaking a tasty meal 🧆"
341,"Join the global Open Source community. We're here to empower new contributors, motivate existing ones, and provide valuable support to maintainers. Together, we can achieve great things!  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Let's bring inspiration and innovation to every developer through your open source contributions!"
342,"Hey there, fellow coders! We've all had those incredible ""Aha!"" moments in our coding journey that completely changed the game. 😮 Share the most significant breakthrough you experienced and how it had a profound impact on your approach to coding. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
343,"Have you discovered any unconventional or out-of-the-box techniques that have significantly enhanced your problem-solving skills as a coder? Like Gamifying problem solving, reverse engineering, or collaborative mind mapping? Let's share our secret hacks and inspire each other to think beyond the traditional coding mindset! Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
344,"Are you preparing for an interview focused on C# programming? One area that often comes up in both beginner and advanced interviews is exception handling. Exception handling in C# plays an essential role in making your application robust and reliable.Mastering exception handling can give you a significant edge during your interview process. To help you confidently tackle this topic in your interview, we have put together a comprehensive list of exception handling C# interview questions and answers that delve into various aspects of the subject.  What are the key differences between ‘Exception’ and ‘SystemException’ classes in C# exception handling hierarchy?  AnswerThe main differences between Exception and SystemException classes in C# lie in their usage and purpose. Here are the key differences: Hierarchy: Both Exception and SystemException classes are part of the exception handling hierarchy in C#. The Exception class acts as the base class for all exceptions, whereas SystemException is a derived class that inherits from the Exception class. Usage: The Exception class is used as a base class for defining custom exception classes, which are specific to the application. On the other hand, the SystemException class is used as a base class for exceptions thrown by the CLR (Common Language Runtime) and the core .NET Framework libraries. Purpose: Exception: Provides a generic base class for handling exceptions and creating custom exception classes that are relevant to the domain of the application. SystemException: Represents runtime errors or errors specific to the system and .NET Framework. These errors usually indicate issues with the CLR or one of the core .NET Framework libraries.In summary, the Exception class is the main base class for all exceptions, whereas the SystemException class is used for handling system-specific exceptions raised by the CLR and .NET Framework libraries.  How do you create a custom exception class that inherits from ‘ApplicationException’? Additionally, how should you modify this approach in light of best practices?  AnswerTo create a custom exception class that inherits from ApplicationException, follow these steps: Define a new class that inherits from ApplicationException. Implement required constructors for the new exception class.Here’s an example of a custom exception class that inherits from ApplicationException:public class CustomException : ApplicationException{    public CustomException() { }    public CustomException(string message)        : base(message) { }    public CustomException(string message, Exception innerException)        : base(message, innerException) { }}Enter fullscreen modeExit fullscreen modeHowever, it is essential to note that deriving custom exceptions directly from ApplicationException is not considered a best practice in modern C#. Instead, it is recommended to inherit custom exceptions directly from the Exception class.Here’s an example of a custom exception class that follows best practices and inherits from Exception:public class CustomException : Exception{    public CustomException() { }    public CustomException(string message)        : base(message) { }    public CustomException(string message, Exception innerException)        : base(message, innerException) { }}Enter fullscreen modeExit fullscreen modeThe best practice of inheriting custom exceptions from the Exception class allows clearer hierarchies while maintaining readability and consistency in code.  What are the performance implications of using ‘throw’ vs. ‘throw ex’ when rethrowing exceptions, and why is one method recommended over the other?  AnswerWhen rethrowing exceptions in C#, it is essential to understand the difference between using throw and throw ex to preserve the original exception’s information and stack trace. throw: When you use throw without specifying the exception object, the current exception being handled is rethrown, and the original exception’s stack trace is maintained. This is the recommended method for rethrowing exceptions, as it preserves valuable debugging information about the original exception. throw ex: When you use throw ex, you rethrow the exception object—ex—but lose the original exception’s stack trace. Instead, a new stack trace is generated from the point where throw ex is called. This can make it challenging to debug and trace the original source of the exception, which is why it is generally discouraged.Using throw instead of throw ex helps maintain the exception context and stack trace, which is crucial for debugging, logging, and analyzing exceptions in your application.  How would you handle exceptions arising in a ‘finally’ block to ensure all exceptions are logged and prevent masking the original exception?  AnswerHandling exceptions that arise in a finally block can be challenging, as you want to ensure that all exceptions are logged and prevent masking the original exception. To handle this scenario effectively, you can use the following approach: Declare a variable to store the original exception if any exception is thrown in the finally block. Use a nested try-catch block inside the finally block to catch any exceptions thrown within the block. In the catch block inside finally, store the original exception, if any, into the declared variable. After the finally block, check if the variable contains an exception. If so, either log the exception, throw it again, or handle it in some other appropriate manner.Here’s an example of this approach:Exception originalException = null;try{    // Code that can throw an exception}catch (Exception ex){    // Log or handle the caught exception    originalException = ex;}finally{    try    {        // Code that can throw an exception in the finally block    }    catch (Exception ex)    {        // Log or handle the exception thrown in the finally block    }    if (originalException != null)    {        // Log, rethrow or handle the originalException as needed    }}Enter fullscreen modeExit fullscreen modeThis approach ensures that any exceptions thrown in the finally block are appropriately logged or handled without masking the original exception that occurred within the try block.  How can you use exception filters in C# 6.0 and above to add conditional logic without needing additional ‘catch’ blocks?  AnswerException filters, introduced in C# 6.0, allow you to add conditional logic to catch blocks without the need for additional nested catch blocks. Exception filters enable you to specify a condition using the when keyword, which must evaluate to true for the catch block to be executed.Using exception filters provides the following benefits:  Improves code readability by reducing the need for nested catch blocks.  Helps maintain the original exception’s stack trace, as the exception isn’t caught until the filter condition is met.  Allows you to handle multiple exception types with a single catch block, based on the filter conditions.Here’s an example of using exception filters in C#:try{    // Code that can throw an exception}catch (InvalidOperationException ex) when (ex.Message.Contains(""InvalidOperation"")){    // Handle InvalidOperationException with a specific message}catch (InvalidOperationException){    // Handle other InvalidOperationException instances}catch (Exception ex) when (ex.Message.StartsWith(""Error"")){    // Handle other exceptions with a message starting with ""Error""}Enter fullscreen modeExit fullscreen modeIn the example above, the catch blocks are executed based on the conditions specified in the when keyword. This allows you to handle different exceptions and scenarios with clean and readable code.As you progress through this comprehensive guide of exception handling in C# interview questions, remember that understanding the basics and keeping up-to-date with the latest language features will empower you to handle even the most challenging interview scenarios.Now, let’s move on to another crucial topic that often comes up when working with asynchronous programming in C#.  Describe a potential deadlocking scenario when using asynchronous programming in C# and handling exceptions. How can you avoid this deadlock?  AnswerIn asynchronous programming, a potential deadlocking scenario can occur when using incorrect approaches to handle exceptions and synchronously calling asynchronous methods. Here’s an example of such a scenario:public async Task ProcessDataAsync(){    string data = await GetRemoteDataAsync();    try    {        await SaveDataAsync(data);    }    catch (Exception ex)    {        // Handle the exception here    }}public async void Button_Click(object sender, RoutedEventArgs e){    // This line can lead to a deadlock    ProcessDataAsync().Wait();}Enter fullscreen modeExit fullscreen modeIn the example above, the ProcessDataAsync method is called from an event handler, where the Wait() method is used to make the asynchronous call synchronous. This approach can result in a deadlock since the UI thread is blocked waiting for ProcessDataAsync to complete, while the method itself awaits some continuation to be executed on the UI thread.To avoid the deadlock, you should follow these best practices when handling exceptions in asynchronous programming: Make the event handler asynchronous and use the await keyword instead of Wait() or Result.   public async void Button_Click(object sender, RoutedEventArgs e)   {       await ProcessDataAsync();   }Enter fullscreen modeExit fullscreen mode Use ConfigureAwait(false) on tasks that don’t need to resume on the original context, which helps prevent deadlocks.   public async Task ProcessDataAsync()   {       string data = await GetRemoteDataAsync().ConfigureAwait(false);       try       {           await SaveDataAsync(data).ConfigureAwait(false);       }       catch (Exception ex)       {           // Handle the exception here       }   }Enter fullscreen modeExit fullscreen modeBy following these best practices, you can avoid deadlocking scenarios when working with exceptions and asynchronous programming in C#.  What are the key differences between ‘AggregateException’, ‘TargetInvocationException’, and ‘AggregateException.InnerException’ in the context of exception handling in C#?  Answer AggregateException: This is a special exception type that can hold multiple exceptions within its InnerExceptions property. AggregateException is primarily used in the Task Parallel Library (TPL) to handle scenarios where a single operation spawns multiple tasks, and one or more of these tasks throw an exception. By using AggregateException, the TPL can collect all the exceptions raised by the individual tasks and present them as a single object for exception handling. TargetInvocationException: This exception is thrown when a method called via reflection (e.g., using MethodInfo.Invoke()) throws an exception. The InnerException property of the TargetInvocationException object holds the actual exception that was thrown by the target method. When handling TargetInvocationException, it’s essential to check and handle its InnerException property to get the relevant information about the original exception. AggregateException.InnerException: This property is a convenience property of the AggregateException class that returns the first exception within the InnerExceptions collection, or null if the collection is empty. This property is useful when working with an AggregateException containing a single exception. However, to handle all exceptions when there are multiple exceptions within the InnerExceptions collection, you should iterate through the collection and handle each exception individually.In summary, AggregateException is used for handling multiple exceptions raised by tasks in parallel operations, while TargetInvocationException is used for handling exceptions when calling methods via reflection. In both cases, it’s important to analyze the InnerException or InnerExceptions properties to understand and handle the original exceptions effectively.  How can you implement exception handling in C# to handle cross-thread exceptions, specifically when working with the ‘Task’ class and ‘Parallel’ library?  AnswerWhen using the Task class and Parallel library in C#, you’re likely to encounter cross-thread exceptions, as these classes often execute code in different threads. Implementing exception handling for cross-thread exceptions can be done by following these best practices: Task class: When working with tasks, use the ContinueWith method to handle task-related exceptions. The TaskContinuationOptions.OnlyOnFaulted option ensures that the continuation only runs if the antecedent task has thrown an exception. For example:   Task.Run(() =>    {       // Code that can throw an exception   })   .ContinueWith(antecedentTask =>   {       // Handle the exception from the antecedent task       var exception = antecedentTask.Exception;   }, TaskContinuationOptions.OnlyOnFaulted);Enter fullscreen modeExit fullscreen mode Parallel library: When using the Parallel library (e.g., Parallel.ForEach, Parallel.Invoke), the AggregateException is thrown when one or more tasks encounter an exception. You can catch AggregateException to handle cross-thread exceptions, and then use the InnerExceptions property to access individual exceptions. For example:   try   {       Parallel.ForEach(data, item =>        {           // Code that can throw an exception       });   }   catch (AggregateException aggregateEx)   {       foreach (var innerEx in aggregateEx.Flatten().InnerExceptions)       {           // Handle each individual exception       }   }Enter fullscreen modeExit fullscreen modeBy following these best practices, you can effectively implement exception handling for cross-thread exceptions when working with the Task class and Parallel library in C#. In both cases, it’s important to analyze the exceptions within the Task or AggregateException objects to handle the exceptions appropriately.  How does the ‘ExceptionDispatchInfo’ class enable capturing and preserving exception stack traces for asynchronous methods, and what are the key benefits of using this class?  AnswerThe ExceptionDispatchInfo class in C# (introduced in .NET Framework 4.5 and .NET Core) allows you to capture an exception, including its stack trace and original context, and throw it again at a later point while preserving the original information. This capability is particularly useful in asynchronous methods, where rethrowing exceptions with the classic throw statement would generate a new exception and wipe out the original exception’s stack trace.To use the ExceptionDispatchInfo class: Call the ExceptionDispatchInfo.Capture() method, passing in the exception you want to capture. This method returns an ExceptionDispatchInfo instance.   ExceptionDispatchInfo capturedException = ExceptionDispatchInfo.Capture(exception);Enter fullscreen modeExit fullscreen mode Call the Throw() method on the ExceptionDispatchInfo instance when you want to rethrow the captured exception, including its original stack trace and context.   capturedException.Throw();Enter fullscreen modeExit fullscreen modeUsing the ExceptionDispatchInfo class provides some key benefits, such as: Original stack trace preservation: The class enables you to rethrow exceptions without losing the original stack trace, making it easier to identify and debug issues in your application. Exception context information: It allows you to preserve the original context of the exception, including captured local variables, which can help improve the debugging process. Cross-thread exception propagation: When dealing with asynchronous methods and multi-threaded scenarios, this class is useful for propagating exceptions between threads while maintaining their original context and stack traces.  What is the potential impact of ‘first-chance’ vs. ‘second-chance’ exceptions on application performance, and how should you approach handling these exceptions in C#?  AnswerIn the context of exception handling in C#, ‘first-chance’ and ‘second-chance’ exceptions are terms used to describe the different stages at which an application’s debugger can be notified about an exception: First-chance exceptions: When an exception occurs, the Common Language Runtime (CLR) checks if there’s a corresponding catch block to handle the exception. Before executing the catch block, the debugger gets notified with a first-chance exception event. In most cases, first-chance exceptions do not cause any performance impact, as they represent normal exceptions that are expected to be caught and handled by the application. Ideally, you should only log or handle first-chance exceptions during development and debugging to help identify potential issues early. It is generally not necessary or recommended to handle first-chance exceptions in production code, as this can introduce overhead and negatively impact application performance. Second-chance exceptions: If the CLR doesn’t find a matching catch block to handle the exception, the debugger gets notified again with a second-chance exception event. At this point, the exception is considered unhandled, and the application will be terminated by default. Second-chance exceptions can potentially have a significant impact on application performance and stability, as they indicate unhandled exceptions that can cause application crashes.To handle first-chance and second-chance exceptions effectively in C#:  For first-chance exceptions, during development and debugging, ensure that your application catches and handles exceptions gracefully. This includes adding proper try-catch blocks, logging exceptions, and responding appropriately to exception conditions to ensure the application continues to function as expected.  For second-chance exceptions, adding global exception handling mechanisms, such as the AppDomain.UnhandledException event (for console applications) or Application.DispatcherUnhandledException event (for WPF applications), can help you log unhandled exceptions and potentially perform cleanup tasks before the application is terminated.Remember that handling second-chance exceptions in production code to keep the application running is generally not recommended, as this can lead to further issues and instability. Handling these exceptions should primarily be used for logging, diagnostics, and attempting cleanup tasks before the application exits.Halfway through our list of exception handling interview questions in C#, it’s clear that a solid foundation in exception handling is necessary for an effective C# developer. By now, you should have gained valuable insights into various facets of exception handling.As we explore further, let’s touch upon an area that focuses on maintaining consistency in error handling when working with C# extension methods.  How do you ensure exception neutrality when working with C# extension methods, and why is this important for maintaining consistent exception handling?  AnswerException neutrality means that a method should only throw exceptions that occur during the execution of its code and should not introduce new exceptions or change existing ones, ensuring consistent behavior in the exception handling process. Maintaining exception neutrality in C# extension methods is important for several reasons:  It allows extension methods to be transparent to the calling code in terms of exception handling, promoting more predictable and consistent behavior.  It prevents confusion when debugging, as adding or altering exceptions in extension methods could lead to misleading error messages and difficulty identifying the root cause of the exception.To ensure exception neutrality in extension methods, follow these guidelines: Avoid swallowing exceptions: Do not catch and ignore exceptions within the extension method unless there’s a specific reason or requirement to do so. Let the original exception propagate to the calling code.   public static string ToUpperCase(this string input)   {       // Do not catch or alter exceptions within the extension method       return input.ToUpper();   }Enter fullscreen modeExit fullscreen mode Do not add new exceptions: Avoid introducing new exceptions that are not relevant to the extension method’s functionality.   public static string ToUpperCase(this string input)   {       // Do not add new exceptions unrelated to the extension method's functionality       if (input == null)       {           throw new ArgumentNullException(nameof(input)); // Don't do this       }       return input.ToUpper();   }Enter fullscreen modeExit fullscreen mode Do not alter existing exceptions: When using other functions within an extension method, avoid altering the exceptions thrown by those functions. Allow any exceptions that originate from the called functions to propagate naturally and be caught by the calling code.   public static string CustomFunction(this string input)   {       try       {           // Perform some operation       }       catch (Exception ex)       {           // Do not modify or wrap the original exception           throw; // Preserve original exception, instead of: throw new CustomException(""Message"", ex);       }   }Enter fullscreen modeExit fullscreen mode  What is a double-fault exception, and how can you effectively handle this scenario in C# while maintaining useful debugging information?  AnswerA double-fault exception occurs when an exception is raised while the application is already handling another exception. These situations can be challenging to manage and debug because the exception raised during the handling process can potentially mask or overwrite the original exception, making it difficult to identify the root cause of the initial issue.To handle double-fault exceptions effectively in C# and maintain useful debugging information, you can follow these steps: Use nested try-catch blocks: Use nested try-catch blocks to handle specific exceptions within the outer catch block and preserve the original exception.   try   {       // Perform some operation that might throw an exception   }   catch (Exception ex)   {       try       {           // Attempt to handle the exception, e.g., log the exception or perform cleanup       }       catch (Exception ex2)       {           // Handle the double-fault exception, e.g., log the exception or perform additional cleanup           // Preserve the original exception (ex) for debugging purposes       }   }Enter fullscreen modeExit fullscreen mode Use the ExceptionDispatchInfo class: Use the ExceptionDispatchInfo class to capture both the original exception and the exception raised during handling, preserving their stack traces and contexts.   ExceptionDispatchInfo originalException = null;   try   {       // Perform some operation that might throw an exception   }   catch (Exception ex)   {       originalException = ExceptionDispatchInfo.Capture(ex);       // Attempt to handle the exception, e.g., log the exception or perform cleanup   }   if (originalException != null)   {       try       {           // Perform additional handling or cleanup       }       catch (Exception ex2)       {           // Preserve the original exception for debugging purposes           originalException.Throw();       }   }Enter fullscreen modeExit fullscreen mode  How does the Common Language Runtime (CLR) handle exceptions that occur during the Just-In-Time (JIT) compilation process in C#?  AnswerThe Just-In-Time (JIT) compilation process is responsible for converting the Common Intermediate Language (CIL) code into executable machine code during the execution of a .NET application. Issues can arise during JIT compilation, such as memory corruption or invalid metadata, which can lead to exceptions.When an exception occurs during the JIT compilation process, the Common Language Runtime (CLR) handles it as follows: JIT compilation failure: If the exception is related to the JIT compilation process itself, such as a failure to generate valid machine code, the CLR will typically throw an InvalidProgramException. This exception indicates that the program cannot be executed because it contains invalid IL code or its metadata is corrupted. Type initialization issues: If the JIT compilation issue is related to type initialization, such as an exception occurring in a static constructor or the initialization of a static field, the CLR will throw a TypeInitializationException. This exception wraps the original exception that occurred during the type initialization process and provides additional information about the problematic type.In both cases, when an exception occurs during JIT compilation, the application will typically be terminated, as it indicates a critical issue with the application’s code or metadata. To resolve these exceptions, it’s essential to investigate the root cause by analyzing the application code, ensuring proper type initialization, and fixing any metadata corruption issues.To help diagnose JIT compilation exceptions, debugging tools like Visual Studio, WinDbg or SOS (Son of Strike) can be used to inspect the managed call stacks, IL code, and metadata for relevant information.  How can you use the ‘Marshal.GetExceptionPointers’ and ‘Marshal.GetExceptionCode’ methods to capture low-level exception information for debugging purposes in C#?  AnswerMarshal.GetExceptionPointers and Marshal.GetExceptionCode are methods provided by the System.Runtime.InteropServices.Marshal class in C#. These methods can be used to capture low-level exception information that occurs during Structured Exception Handling (SEH) in the Windows operating system, such as access violation or division by zero errors.To use these methods, you need to use the __try and __catch blocks available in C++/CLI or use P/Invoke to call native Windows API functions. However, using these methods directly in C# is not possible, as C# does not support SEH.Here’s an example of accessing these methods in a mixed-mode assembly using C++/CLI:#pragma managed(push, off)#include <windows.h>#pragma managed(pop)using namespace System;using namespace System::Runtime::InteropServices;int GetSEHExceptionCode(){    __try    {        int a = 10;        int b = 0;        int result = a / b; // Will cause a division by zero exception    }    __except (EXCEPTION_EXECUTE_HANDLER)    {        int exceptionCode = Marshal::GetExceptionCode();        Console::WriteLine(""Exception code: {0}"", exceptionCode);        IntPtr exceptionPointers = Marshal::GetExceptionPointers();        EXCEPTION_POINTERS* pExceptionPointers = static_cast<EXCEPTION_POINTERS*>(exceptionPointers.ToPointer());        Console::WriteLine(""Exception address: {0}"", IntPtr(pExceptionPointers->ExceptionRecord->ExceptionAddress));    }    return 0;}Enter fullscreen modeExit fullscreen modeIt’s essential to note that using low-level SEH mechanisms and mixed-mode assemblies can lead to potential issues and pitfalls, such as making your code harder to read and maintain, reducing portability, and increasing the risk of memory-related issues. In most scenarios, it’s advised to use standard C# exception handling using try-catch-finally blocks, as they provide a more straightforward and managed way of handling exceptions.  Describe the ‘Corrupted State Exception’ (CSE) in C# and its implications for exception handling. How do you use the ‘HandleProcessCorruptedStateExceptionsAttribute’ to handle CSEs?  AnswerA Corrupted State Exception (CSE) is a type of exception that occurs when the CLR encounters a process state corruption, typically triggered by an external event or hardware failure. Examples of CSEs include insufficient memory conditions, access violation, or stack overflow. By default, the CLR does not allow these exceptions to be caught, as they might indicate potentially dangerous conditions or undiagnosable code issues.However, there might be scenarios where you need to handle a CSE, such as logging information about the corruption or attempting to perform additional cleanup. In these cases, you can use the HandleProcessCorruptedStateExceptionsAttribute attribute in conjunction with the SecurityCriticalAttribute.Here’s an example of how you can use these attributes to handle CSEs:using System;using System.Runtime.ExceptionServices;using System.Security;public class CorruptedStateExceptionExample{    [HandleProcessCorruptedStateExceptions, SecurityCritical]    public void HandleCSE()    {        try        {            // Perform some operation that might cause a corrupted state exception        }        catch (Exception ex)        {            Console.WriteLine(""Caught Corrupted State Exception: {0}"", ex.Message);            // Log the exception, perform cleanup, or take other handling actions        }    }}Enter fullscreen modeExit fullscreen modeKeep in mind that handling CSEs should only be done in specific scenarios and with caution. Catching and handling a CSE might lead to additional errors or instability because the process state is already corrupted.As we delve deeper into our C# exception handling interview questions, it’s essential to remember that thoughtful application of exception handling techniques can genuinely make the difference between an elegant application that gracefully deals with problems and a fragile one that is difficult to debug and maintain. In this next section, we will discuss some potential pitfalls when using the ‘using’ statement and how to work around these issues.  What are the potential pitfalls of using the ‘using’ statement in relation to exception handling in C#, and how can you work around these issues?  AnswerThe using statement in C# is a convenient way of managing resources, such as file streams or database connections. It ensures that the Dispose method is called on the object implementing the IDisposable interface when leaving the scope of the using block. While the using statement simplifies resource management, there are potential pitfalls related to exception handling: Exception in constructor: If an exception occurs during the construction of the IDisposable object, the Dispose method will not be called, as the object has not been fully instantiated. This could lead to resource leaks. Workaround: Explicitly create the object outside of the using block, use a try-catch-finally block, and call Dispose in the finally block if the object has been successfully created.   IDisposableObject obj = null;   try   {       obj = new IDisposableObject();       // Perform operations with the object   }   catch (Exception ex)   {       // Handle exception   }   finally   {       obj?.Dispose(); // Call Dispose if the object has been instantiated   }Enter fullscreen modeExit fullscreen mode Exception in the dispose method: If an exception occurs during the execution of the Dispose method, the exception will propagate out of the using block, potentially masking any preceding exceptions. Workaround: Implement the Dispose method of the IDisposable object using a try-catch block, taking care of logging or handling exceptions gracefully within the method without propagating them.   public class IDisposableObject : IDisposable   {       public void Dispose()       {           try           {               // Perform cleanup and resource deallocation           }           catch (Exception ex)           {               // Log the exception, taking appropriate actions without propagating the exception           }       }   }Enter fullscreen modeExit fullscreen modeBy being aware of these potential pitfalls and applying the appropriate workarounds, you can ensure proper exception handling in your application while still taking advantage of the convenience and resource management benefits provided by the using statement.  What are the trade-offs between using specialized exception classes (e.g., ‘FileNotFoundException’) and using the general-purpose ‘Exception’ class when designing a custom exception handling strategy in C#?  AnswerWhen designing a custom exception handling strategy in C#, you need to balance between using specialized exception classes and using the general-purpose Exception class. Here are the main trade-offs between the two approaches:  Specialized Exception ClassesAdvantages: More expressive and easier to understand: Using specialized exception classes allows you to convey more specific information about the error. Better error handling: Allows the code that catches the exception to distinguish between different error types and take appropriate actions for each type. Easier debugging and maintenance: Specialized exception classes can provide additional properties or methods that help in identifying the root cause of the problem and make the debugging process easier.Disadvantages: More complex to implement: Creating and managing multiple custom exception classes can be more time-consuming and complex than using a single general-purpose class. Potential for overengineering: Creating too many specialized exception classes can lead to unnecessary complexity and potentially make the code harder to understand and maintain.  General-Purpose Exception Class (Exception)Advantages: Simplified implementation: Using the general-purpose Exception class can simplify the exception handling code and reduce the number of custom exception classes. Easier to maintain: Having fewer custom exception classes reduces the complexity of the code and makes it easier to maintain.Disadvantages: Less expressive: Using the general-purpose Exception class can make it more difficult to determine the specific cause of an error. Limited error handling: Since all exceptions are instances of the same class, the code that catches the exception cannot easily distinguish between different error types, making it harder to perform fine-grained error handling.The best approach varies based on your specific scenario and requirements. In general, it’s a good practice to use specialized exception classes for distinct error scenarios that require unique handling or where additional context is needed. If the exception doesn’t require specific handling, you can use the general-purpose Exception class to reduce complexity.  In C#, what are the critical considerations to keep in mind when implementing exception handling for cross-AppDomain communication?  AnswerWhen implementing exception handling for cross-AppDomain communication in C# applications, you need to consider several aspects to ensure proper functioning and data consistency. Some critical considerations are: Serialization/Deserialization: Exceptions need to be serializable to propagate across AppDomains. If a custom exception class isn’t marked with the [Serializable] attribute, it cannot be passed between AppDomains, and a SerializationException will be thrown. Ensure that any custom exception classes are marked with the [Serializable] attribute and implement the required serialization logic when needed. AppDomain Unloading: When an AppDomain is unloaded, the AppDomainUnloadedException may occur during cross-AppDomain communication. Ensure that your exception handling strategy accounts for this type of exception and takes the appropriate action. Type Availability: Custom exception classes must be available in both the source and target AppDomains. If a custom exception class is not available in the target AppDomain, a SerializationException will be thrown. Ensure that the assembly containing the custom exception class is loaded into both AppDomains. Data Integrity: Ensure that the exception handling strategy does not disrupt data integrity across AppDomains. For example, consider using a two-phase commit protocol to ensure data consistency between AppDomains. Performance: Cross-AppDomain exception handling can introduce a performance overhead due to serialization and deserialization. Keep this in mind when designing your exception handling strategy and evaluate whether it’s necessary to pass the exception details across AppDomains.By addressing these considerations, you can ensure proper exception handling and maintain proper behavior during cross-AppDomain communication in your C# applications.  How do you handle exceptions that occur in a ‘System.Tuple’ or ‘ValueTuple’ within your C# code, and what are the best practices for managing this scenario?  AnswerTuples (System.Tuple and ValueTuple) can store multiple values in a single object, but they don’t inherently have special exception handling behavior. Exceptions may be thrown when accessing or assigning values to a tuple within your C# code, just like with any other object or value type.Handling exceptions that occur in tuples follows the same best practices as for other C# code: Use try-catch-finally Blocks: Surround the code that works with the tuple (e.g., accessing or assigning values) with a try-catch-finally block. Catch any specific exceptions you expect, and use a generic catch block (e.g., catch (Exception ex)) for any unexpected exceptions.try{    (int x, int y) tuple = (1, 2);    int result = tuple.x / tuple.y;}catch (DivideByZeroException ex){    // Handle divide-by-zero case.}catch (Exception ex){    // Handle any other exceptions.}Enter fullscreen modeExit fullscreen mode Keep Exception Handling Focused: Keep the scope of your try block as small and focused as possible to ensure that you’re catching the exceptions you expect and not inadvertently catching unrelated exceptions. Don’t Swallow Exceptions: Avoid catching exceptions without handling them or rethrowing them unless absolutely necessary. Swallowed exceptions can make debugging more challenging and may hide critical issues. Document Exceptions: Use XML comments to document any exceptions that a method might throw to help the caller understand and handle errors appropriately.Lastly, if you’re using tuples to pass values between methods, ensure proper exception handling when dealing with operations that might throw an exception within those methods as well.  In the context of Structured Exception Handling (SEH) in C#, describe the key differences between the ‘catch’ and ‘__except’ blocks, and provide examples of scenarios where one is preferable over the other.  AnswerIn the context of Structured Exception Handling (SEH) in C#, catch blocks and __except blocks are used to handle exceptions resulting from various error conditions. While both blocks allow you to handle exceptions, there are critical differences between them:Catch Block: catch is a C# keyword that is part of the try-catch-finally statement, used to catch exceptions thrown by managed code executed within the try block.  Provides a more straightforward, high-level approach of handling exceptions, which is in line with the .NET Framework and the C# language’s best practices.  It can catch both managed and unmanaged exceptions when compiled for the .NET Framework. In .NET Core and later, it can particularly catch managed exceptions.try{    // Code that may throw an exception.}catch (FileNotFoundException ex){    // Handle a specific FileNotFoundException.}catch (Exception ex){    // Handle all other exceptions.}Enter fullscreen modeExit fullscreen mode__Except Block: __except is a keyword specific to the Windows operating system and is part of Structured Exception Handling (SEH) used mainly in native C/C++ code.  As __except is not available in C# directly, it can be used in mixed-mode assemblies with C++/CLI code or through P/Invoke with the native Windows API.  Its primary purpose is to catch low-level hardware and operating system-related exceptions such as access violations, stack overflows, and division by zero.__try{    // Code that may cause a low-level exception.}__except (EXCEPTION_EXECUTE_HANDLER){    // Handle the exception.}Enter fullscreen modeExit fullscreen modeAs a general rule, in C#, you should prefer using the catch block in try-catch-finally statements to handle exceptions. The catch block is the standard C# approach and works consistently with the rest of the .NET Framework and CLR. Only consider using the __except block in specific scenarios where you need to deal with low-level native exceptions or if you’re working with mixed-mode assemblies or P/Invoke calls to native code.In conclusion, this comprehensive collection of exception handling in C# interview questions provides you with the knowledge and confidence to tackle the often-challenging subject of exception handling during your C# interviews.Whether you’re a beginner just starting in C# or an experienced developer, mastering exception handling concepts and techniques will help you build robust, reliable, and maintainable applications. Best of luck in your interview preparations! Remember, practice, and understanding these concepts will lead to success in your journey as a C# developer."
345,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎A Comprehensive Beginner's Guide to NPM: Simplifying Package ManagementAbishek Haththakage ・ Jul 14#webdev#beginners#npm#programmingInspired by @abhixsh's Top 7 post, tonight’s topic is... package management!If you're not familiar, a package manager is a system that will manage your project dependencies. A dependency is a third-party bit of software, usually written by someone else, that solves a problem for you. Node Package Manager (abbreviated to NPM) is a robust package manager designed for JavaScript projects, primarily used in conjunction with Node.js.  Questions:How would you describe your experience with NPM? What do you find most useful about it?Which NPM command or feature do you find the most helpful in your day-to-day development work?If you've encountered any challenges or difficulties while using NPM, how did you overcome them?Any triumphs, fails, or other stories you'd like to share on this topic?Looking forward to a lively discussion on NPM and package management in general. Let's get started! 🚀"
346,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
347,Have you ever thought about freelancing or starting your own coding-related business? What inspires you to consider this entrepreneurial path?What specific coding skills or services do you specialize in or intend to offer in your business?What are some of the advantages you see in freelancing or starting your own coding business compared to working as an employee?Let's discuss the opportunities and challenges that come with pursuing an entrepreneurial path. Share your experiences and insights!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
348,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Collaboration and CommunicationWhat approaches do you take to foster effective collaboration and communication within a coding team or project?Share an experience where your collaborative and communication skills played a significant role in achieving success or overcoming a coding obstacle.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
349,"Sarcastic advises for the vital process of software development. Because sometimes irony is the best teacher.  Be personalDo you remember John didn't buy you a drink last time you met for a social? So reviewing his PR is the right time to show him how wrong he was. Challenge every idea, every possible variable name, and every white space in the PR. He deserves this.  Be excessiveThat's right. Don't keep it. All thoughts, ideas, questions - put it all there. Just ask yourself, when was the last time you asked Anna how are her kids? Well, PR is the perfect place for it. What else can we add? Weather comments, photo of your pet, last update on your favourite football team. Let it be there.formatting is our enemywe can save a lot of time ignoring all of the commas bullet point highlighting structure bolding markdown they are there to waist our time serve no purpose at all  Be unreasonable""I just don't like it"" is a perfectly valid reason for a PR rejection, because your word does matter.  Be toxicTry to put your colleague in their place with sarcastic comments in PR, answer the question with the question or use as many rare technical definitions and abbreviations as possible. They will scare, doubt themself, and lose confidence. That's the best way of learning.  Compare everyone with everyoneDon't forget to put a comment that Rachel did a similar task quicker, better and had no comments at her PR. You always have someone to compare to: Bill Gates, Mark Zuckerberg, Elon Mask, Linus Torvalds. You just need to find the right person for the situation.  Discuss PR privatelyWe are all friends here, right? So use personal chat to ask Jimmy to fix this line 78 in Program.py. No comments in PR, no bureaucracy, no problem. Plus, from the outside, Jimmy's PR will look perfect. Like there were no issues at all. It is a win-win situation ;)  Never resolve commentsIf there are people that use comments in PR, teach them a lesson and never resolve them, so they can get lost in their comments and never finish PR.  Hints instead of explicit examplesUse PR as game time and leave some breadcrumbs and hints instead of explicit examples of what you meant so the PR owner can guess the right idea. You are there to help.P.S. Please add your antipatterns in the comments :)"
350,"Up until now, I never put much thought into what type of developer I am. I studied a full stack curriculum at Flatiron School and I've focused on both frontend and backend at different times of my career. The other day my teammate mentioned that we should all work toward becoming T-shaped developers. That was a new one for me. What in the world is a T-shaped developer? After a bit of research I learned that a T-shaped developer embodies the best of both worlds between being a specialist and a jack of all trades. They are an experienced expert in one field with some knowledge in other areas too. While full stack usually entails that knowledge is generalized across the board, a T-shaped developer is a shiny rebranded version of full stack. It has the well-roundedness of full stack with the added bonus of a specialized area of expertise.In the following chart example, the teal background color shows my depth of knowledge in data integrations (the vertical part of the T) as well as breadth across frontend, backend, full stack, and mobile app development (the horizontal part of the T).I omitted some skills from the teal area for the sake of making a perfect T-shape, so a truer representation of my skills would look more like an abstract shape scribbled by a toddler.There's no clear-cut definition of which fields are included as part of the chart, and the shape's contents seem to be entirely customizable. We all know that being a software engineer encompasses more than just writing code all day, so the next example shows my skills in the software engineer column along with aspects of other roles that I take on regularly. You see, the chart can look different for everyone. Our levels of expertise are subjective and relative, so I could argue that every developer is already a T-shaped developer!Creating a personal chart is a great exercise to dive deep into your own levels of expertise. What do you think, are you a T-shaped developer?"
351,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Attention to DetailHow do you ensure that you pay close attention to detail while coding? Any specific techniques or practices?Can you share an example of a time when paying attention to detail helped you identify and rectify a coding error or improve the quality of your code?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
352,"Hey y'all 👋What we all learning on?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Expand your mind! 🤯"
353,"In the landscape of software development, bugs are an inevitable part of the journey, and debugging, albeit frustrating at times, is an integral part of the process. There's no escaping this truth, and the sooner we embrace it, the sooner we can master the art of debugging.In the next few posts in this series, I will explain the little-known “theory” behind debugging. We all know the practice of debugging (to some degree) but there is also a theoretical underpinning that most of us never learned in University (I sure as hell didn’t). Understanding this theory will help you apply a more methodical approach to problem resolution and will improve your understanding of your code.Before we proceed I’d like to mention that most of the content in this series is covered in my book “Practical Debugging at Scale: Cloud Native Debugging in Kubernetes and Production” (Apress). Also while we’re on the subject of books, my new book “Java 8 to 21: Explore and work with the cutting-edge features of Java 21” (BPB) is the #1 new release in Java Programming on Amazon and available now.  The Simplicity and Complexity of BugsDebugging is a labyrinthine journey, often reminiscent of Alice in Wonderland. It calls for acute observation, insatiable curiosity, calculated experimentation, and a sense of adventure. However, the general sentiment towards debugging is one of antagonism, largely because of the frustration it entails and the uncomfortable truths it uncovers. The reality is, most bugs are embarrassingly simple in retrospect. When we finally pinpoint the issue, the common response is a groan of disbelief — ""How did I miss that?"" While this reaction is natural, it breeds a sense of shame and inadequacy, often leading to impostor syndrome. Despite my 40 years of programming experience, I can confidently say that the bugs I encounter today are just as ""stupid"" as they were at the start. This constant humbling feeling, akin to a universal debugging facepalm, keeps me grounded.The emotions experienced during debugging – surprise, frustration, and humility – serve as a reminder of our fallibility. It’s akin to a form of meditation, keeping egos in check. Perhaps some leaders could even benefit from debugging as a method of grounding, bringing them closer to the realities of their tasks and teams.An important principle I have when debugging is to “start with stupid”. I look for the dumbest mistake I can think of and in a surprising number of cases, it’s indeed the bug. This isn’t a part of the theory  Embracing the Debugging MethodologyThe first step in tracking a bug is identifying the likely area in the code. This involves searching through documentation and conducting basic research. From there, we need to devise a strategy to tackle the bug. This step is often overlooked in our haste to find a solution, leading to unstructured and disorganized approaches. We need to formulate a plan, make assumptions, and then test these assumptions. Next, we should isolate the behavior causing the issue and aim to reproduce it consistently for testing. This could ideally be done in a local environment within the debugger. If we can’t consistently reproduce a bug, we won't be able to truly verify our fix, adding uncertainty to the process.  Validation and EliminationFollowing this, we must validate that the results of our tests and environment align with our initial assumptions. In the spirit of robustness, it’s advisable to have two forms of verification as one could potentially be flawed. I wrote about the importance of double verification in this post.Once we've made these verifications, we proceed to the elimination stage, taking inspiration from Arthur Conan Doyle's famous quote:""Once you eliminate the impossible, whatever remains, no matter how improbable, must be the truth.""In other words, we need to ""Sherlock Holmes"" our problem and rule out possibilities until we're left with the most plausible explanation.With a deeper understanding of the bug, we can move on to resolving the issue. The resolution process should include filing the issue, creating a failing test case, verifying the proposed fix resolves the test case, and committing both the bug and fix.  Reading the Docs: A MisconceptionIt's often said, “5 hours of debugging can save you 5 minutes of reading the docs.” However, this saying is misleading. Reading the documentation is not the answer, especially considering the sheer volume of documents associated with APIs, platforms, systems, and more. Documentation is never read in five minutes and rarely memorized to a level that will solve a bug. In all the decades I’ve been a developer I solved bugs by searching through the docs, but never by reading the docs in advance.The key here is to know what, where, and when to search for the problem. Search engines and platforms like Stack Overflow have revolutionized debugging, enabling us to input error messages directly and find potential solutions. This method is not foolproof, but it's a good starting point.   The Importance of a Game PlanHaving a game plan saves us from being swallowed by the abyss of trial-and-error debugging. Many years ago, I lost two workdays due to a misplaced 'greater-than' character because I didn't use a methodical approach. Before diving into a debugging process, it's crucial to answer questions like:Can the user reproduce this?Can I reproduce this on my machine?Does the issue happen consistently?Is the issue a regression?The answers to these questions will shape your game plan and the course of your debugging process. In the end, patience and strategy can save precious time and prevent unnecessary frustration.In our next installment, we'll explore gameplans for debugging issues that can't be reproduced. Stay tuned and embrace the debugging adventure!  Final WordDebugging, despite being seen as frustrating, is an essential part of software development, offering moments of learning and personal growth. A methodical approach to debugging involves identifying the area of code responsible for the bug, formulating a strategic game plan, isolating and reproducing the bug for testing, and finally resolving the issue. A common misconception is that reading the documentation can save hours of debugging; however, it's more about knowing where and what to search for. Patience and a clear strategy can prevent unnecessary time waste and make the debugging process more efficient.In the next installment, we will delve deeper into the game plan for debugging, particularly focusing on issues that are hard to reproduce. We will further explore strategies and tools that can assist in efficiently tackling such elusive bugs."
354,"  Table of Contents.PreambleEncoder-Decoder ArchitectureThe Encoder NetworkThe Decoder NetworkTraining on Encoder-Decoder ArchitectureLimitations of the Traditional Encoder-Decoder.""Attention is all you need""Overview of Attention MechanismConclusion  Preamble.Generative AI is the new buzzword in the world of AI, big enterprises are looking to incorporate generative features into their solutions and AI engineers are working now more than ever to train models that are taking strides that were once inconceivable to the human mind when it comes to generating content.Watch this video of Sundar Pichai (Chief Executive Officer at Google), it compiles all the times he said ""AI"" and ""generative AI"" during his keynote speech at Google IO, 2023: Generative AI refers to a branch of artificial intelligence that focuses on generating new content based on patterns and examples from existing data, these contents may be in the form of a captivating story in text, an image of a landscape scenery from the Paleolithic era, or even an audio of what Mozart would sound like in a different genre like jazz.Generative AI involves training a model using large datasets and algorithms, enabling it to produce near original contents that expand on the patterns it has learned. In this article, I will talk about the technologies on which generative AI models are built and how transformers have improved generative AI over the years so stay glued!  Prerequisite.Readers should have a good understanding of:Machine learning andArtificial intelligence.  Encoder-Decoder Architecture.To properly communicate with AI models, it is important to make them understand the information that is being conveyed and regular human languages would not suffice. This is why the encoder-decoder architecture was developed, it is a neural network sequence-to-sequence architecture that was specifically designed for machine translation, text summarization, question-answering, and other machine learning use cases.Just as its nomenclature suggests, it has two networks- the encoder and the decoder network, these networks serve as the final gateways for input-output (I/O) operations in the model.At the encoder part, an input sequence in natural language is converted into its corresponding vector representation. This vector representation attempts to capture all the relevant bits from the input sequence(or prompt).This vector representation is then fed into the decoder network which generates an output after a series of internal processes.  The Encoder Network.For an encoder with a Recurrent Neural Network (RNN) internal architecture, each token in an input sequence like The man is going to the bank must first be tokenized, this tokenization process converts the natural language into understandable sets of bits that the model can process. It recurs until the input sequence at the encoder has been completely tokenized.In most NLP character tokenization adoptions, each token is usually a representation of 4 characters so the example above would be a minimum of 6 tokens.These tokens are then passed into an embedding layer, this is where they are converted into a single vector representation. The encoder passes the vector representation onto the decoder through a Feedforward neural network.  The Decoder Network.The encoder and decoder can be built on different architectures and more complex blocks but cases of the same architecture are not unlikely.The decoder would have its own set of input sequences which would also have been tokenized and embedded. Introducing this sequence of tokens to the decoder would trigger it to attempt a prediction of the next token based on the contextual understanding provided by the encoder, the first prediction is outputted through a softmax output layer.After the first token is generated, the decoder repeats this prediction process until there are no more tokens left to predict, the first and last predicted tokens are called the <start> and <end> tokens respectively.The final sequence of tokens is detokenized back into natural language. In a language translation use case, the output generated would be: Der Mann geht zur Bank for a German target language.  Training on Encoder-Decoder Architecture.Training on an encoder-decoder architecture is more complicated than regular predictive models, having a collection of input/output pairs of the type data from a reference model for imitation is important.Likewise, the decoder needs to be trained on the correct previously translated token rather than what it is triggered to generate, this technique is called teacher forcing and is a good practice only when you have a credible ground truth.The decoder network generates the next token based on which token has the highest probability in the softmax layer, there are 2 common algorithms for “choosing” the next token in NLP, they are:Greedy search: this algorithm chooses the token with the highest conditional probability from the vocabulary as the next generated token. Take a look at the image below, can you tell what sentence the decoder generated? Note that the red  saturation decreases as the probability decreases.If your answer was the last global war is abbreviated as WWII, you are correct. Greedy search is easy to implement but it does not always generate optimal results, a better approach is the beam search algorithm.Beam search: Instead of deciding off the probability of a single token, the algorithm searches for the sequence or series of tokens with the highest probability so the example above would be chosen among a pool of the war is last abbreviated global WWII as, last war abbreviated is the WWII as global, etc. This approach is more efficient because it reduces computation time and provides some extra level of context.The encoder-decoder architecture is great because the input sequence and the generated output can be of varying lengths, this is very useful in image/video captioning as well as question-answering use cases. However, this architecture has a bottleneck that has made it obsolete over the years.  Limitations of the Traditional Encoder-Decoder.When the encoder converts an input sequence into a vector, it compresses all the contextual information into that single vector, this poses a problem when the input sequence is too long. It may prove difficult for both the encoder and decoder because the encoder would struggle with keeping the relevant bits, and the decoder would expend more time on decoding and may lose some relevant bits of information in the process regardless of whether the generated output is short or not. This may lead to inaccuracy of the generated output.How was this problem tackled without jeopardizing the context of the sequence?  ""Attention is all you need""This is the title of a paper published in 2017 by Vaswani et al, this groundbreaking paper introduced the Transformer model, a novel architecture that revolutionized the field of NLP and became the foundation of the popular Large Language Models (LLMs) that are around today (GPT, PaLM, Bard, etc.) The paper proposes a neural network architecture with an entirely attention-based mechanism instead of the traditional RNNs, click here if you wish to read the paper.A transformer can be summarized as an encoder-decoder model with an attention mechanism. The image below is from the paper, note how the attention layers are grafted in both encoder and decoder.  Overview of Attention Mechanisms.Attention mechanism is built to focus on the most important parts of the input sequence and not its entirety. Rather than building a single context vector out of the last hidden state of the encoder, attention mechanism creates shortcuts between the entire input sequence and the context vector.The weights of these context vectors vary for each output element. Hence, the context vector learns the alignment of the input sequence with the target output by noting the emphasized tokens.""But how does the model know where to channel its attention?""It calculates a score known as alignment score which quantifies how much attention should be given to each input. Look at the heatmap below from the Neural Machine Translation by Jointly Learning to Align and Translate paper showing how attention works in a translation use case.With respect to the previous input sequence: The man is going to the bank, the translation should not pose any problem for regular encoder-decoder models but what if the sequence is longer and has more context?Take a new input sequence like The man is going to the bank to fish. For regular encoder-decoder models, the generated output in the target language may not align with the contextual meaning of the source language because ""bank"" now exists with more than one possible translation.While spotting this distinction is an easy feat for humans, it may be hard for the traditional encoder-decoder, hence, it may produce an output like Der Mann geht zum Bank, um zu fischen instead of Der Mann geht zum Flussufer, um zu fischen, the later is more accurate and would make more sense to a German because *Flussufer means riverbank. *another translation could be ""Ufer"" which means ""shore"".In the above instance, ""bank"" and ""fish"" would have the heaviest weight in an attention mechanism encoder-decoder.In application, attention layers need to be integrated with the regular encoder-decoder architecture and these layers exist in various types which include:Generalized attention layerSelf-attention layerMulti-head attention layerTo know more about layer types, check this article  Conclusion.The advent of attention mechanisms has revolutionized generative AI, enabling machines to better understand us and generate complex sequences with remarkable precision such that humans are sometimes bewildered by it. Applications across machine translation, question answering, text summarization, and more have benefitted from attention's ability to capture contextual relationships.As we look to the future, combining attention mechanisms with other architectural innovations holds immense potential for handling even more challenging tasks. Generative AI is just at its best milestone yet and it would continue to get better with more attention-driven applications as machines keep surpassing previous landmarks like never before. It is the responsibility of humans to shape this trajectory for the betterment of life.If you enjoyed this article, I would appreciate it if you leave a reaction or a comment. Know someone else that would find this article insightful? shares are very much welcome too! I am on Twitter @dvrvsimi and Medium @daraakojede01 Prost!"
355,"LLMs have revolutionized tons of aspects of our lives, from language generation to image captioning software to friendly chatbots. These AI models provide powerful tools for solving real-world problems, such as generating chat responses or following complex instructions. In this blog post, part of a series on LLaMA v2, we will compare two popular AI models: llama13b-v2-chat and Alpaca, and explore their features, use cases, and limitations.Subscribe or follow me on Twitter for more content like this!We'll also see how we can use AIModels.fyi to find similar models and compare them to llama13b-v2-chat and Alpaca. Let's begin.  About the LLaMA13b-v2-chat ModelThe llama13b-v2-chat model is a fine-tuned version of the 13-billion-parameter LLaMA-v2 language model original developed by Meta. It has been fine-tuned specifically for chat completions, making it an excellent tool for generating chat responses to user messages. You can find detailed information about the model on the llama13b-v2-chat creator page and the llama13b-v2-chat model detail page.This language model is designed to assist in generating text-based responses for chat-based interactions. Whether it's providing customer support, generating conversational agents, or assisting in natural language understanding tasks, llama13b-v2-chat can be a valuable tool. Its large parameter size enables it to capture complex language patterns and generate coherent and contextually relevant responses.In summary, llama13b-v2-chat can understand inputs and generate appropriate chat responses.  Understanding the Inputs and Outputs of the llama13b-v2-chat ModelTo effectively use the llama13b-v2-chat model, it's essential to understand its inputs and outputs. The model accepts the following inputs:Prompt: A string representing the chat prompt or query.Max Length: An integer specifying the maximum number of tokens to generate.Temperature: A number that adjusts the randomness of outputs. Higher values (greater than 1) result in more random responses, while lower values (closer to 0) produce more deterministic outputs.Top P: When decoding text, samples from the top p percentage of the most likely tokens. Lower values limit the sampling to more likely tokens.Repetition Penalty: A number that penalizes the repetition of words in generated text. Higher values discourage repetition, while values less than 1 encourage it.Debug: A boolean flag to provide debugging output in logs.The model processes these inputs and generates a list of strings as output, representing the generated chat responses. The schema for the output is a JSON array containing strings. You can find out more about this model in the guides here and here.  About the Alpaca ModelThe Alpaca model is an instruction-following language model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. It was developed by the Stanford Center for Research on Foundation Models (CRFM). The creators of Alpaca are Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. You can find detailed information about the model on the Stanford page the team created.The Alpaca model focuses on instruction-following capabilities and aims to bridge the gap between research and industry by providing an accessible instruction-following language model for academic purposes. It is fine-tuned from the LLaMA 7B model using a dataset of 52K instruction-following demonstrations, generated in the style of self-instruct using text-davinci-003. The model demonstrates promising performance in single-turn instruction following.This model's release is intended to facilitate academic research and foster improvements in instruction-following models. It is important to note that Alpaca is not designed for commercial use, and its safety measures are not fully developed for general deployment.In summary, Alpaca offers a lightweight and reproducible instruction-following language model that can be utilized for research purposes and the exploration of instruction-following scenarios.How the Alpaca model works, from the official website.  Understanding the Inputs and Outputs of the Alpaca ModelTo effectively utilize the Alpaca model, let's explore its inputs and outputs.As an instruction-following model, Alpaca follows instructions and generates responses based on the given instructions.The inputs to Alpaca are represented by the instructions themselves, which describe the tasks the model should perform. Alpaca also has an optional input field, providing additional context or input for the task.The outputs of the Alpaca model are the generated responses to the given instructions. The responses are generated based on the fine-tuned model's understanding of the task and the underlying language patterns learned during training. You can read more about this in the model's README on Github.  Comparing and Contrasting the ModelsNow that we have explored the llama13b-v2-chat model and the Alpaca model in detail, let's compare and contrast them to understand their similarities, differences, and optimal use cases.  LLaMA13-v2 vs AlpacaBoth the llama13b-v2-chat and Alpaca models are fine-tuned language models designed for different purposes. While llama13b-v2-chat focuses on chat completions, Alpaca specializes in instruction-following tasks.  Use CasesThe llama13b-v2-chat model is suitable for a wide range of chat completion tasks. It can be utilized in customer service applications, chatbot development, dialogue generation, and interactive conversational systems. This model's versatility allows it to generate coherent and contextually relevant responses to user queries or prompts.On the other hand, the Alpaca model is specifically tailored for instruction-following tasks. It excels at understanding and executing instructions provided by users, making it ideal for applications such as virtual assistants, task automation, and step-by-step guidance systems. Alpaca's ability to comprehend and follow instructions makes it a valuable tool for users seeking assistance in performing various tasks.  Pros and ConsThe llama13b-v2-chat model's strengths lie in its large parameter size (13 billion) and its fine-tuning for chat completions. It can generate detailed and contextually appropriate responses, making it useful for engaging and interactive conversational experiences. However, due to its generic nature, the model might occasionally produce responses that are factually incorrect or propagate stereotypes. Careful monitoring and filtering mechanisms should be implemented to mitigate these risks.Alpaca, on the other hand, offers a smaller and more cost-effective model (7B parameters) that is specifically optimized for instruction-following. It demonstrates performance comparable to the text-davinci-003 model in this domain. Alpaca's relative ease of reproducibility and lower cost make it an attractive option for academic researchers interested in instruction-following models. However, it shares common limitations of language models, including occasional hallucination and the potential to generate false or misleading information.  SimilaritiesBoth models are built upon the LLaMA framework, which provides a strong base language model for fine-tuning. They leverage the power of large-scale language models to generate high-quality outputs. Additionally, both models have been evaluated and compared to the text-davinci-003 model, showcasing their ability to perform similarly in instruction-following tasks.  DifferencesThe primary difference between the models lies in their intended use cases and specialties. While llama13b-v2-chat is a versatile chat completion model suitable for various conversational applications, Alpaca is specifically designed for instruction-following tasks. Alpaca's training data is generated based on self-instructed prompts, enabling it to comprehend and execute specific instructions effectively.  Optimal Use CasesChoosing between the llama13b-v2-chat and Alpaca models depends on the specific requirements of your project or application. If your goal is to develop a conversational system or chatbot that engages in dynamic and context-aware conversations, llama13b-v2-chat would be a better choice. On the other hand, if you need a model that can understand and execute user instructions for task-oriented applications, Alpaca is the more suitable option.  Taking it Further - Finding Other Instruction-Following or Chat Models with AIModels.fyiIf you're interested in exploring additional instruction-following models beyond Alpaca, AIModels.fyi is a valuable resource. It offers a comprehensive database of AI models, including those catered to instruction-following tasks. By following these steps, you can discover similar models and compare their outputs:Step 1: Visit AIModels.fyiHead over to AIModels.fyi to begin your search for instruction-following models.Step 2: Use the Search BarUtilize the search bar at the top of the page to enter specific keywords related to instruction-following models. This will provide you with a list of models relevant to your search query.Step 3: Filter the ResultsOn the left side of the search results page, you'll find various filters to narrow down the models. You can filter and sort by model type, cost, popularity, and specific creators. Apply these filters to find models that align with your requirements.By leveraging the search and filter features on AIModels.fyi, you can find models that best suit your needs and explore the diverse landscape of instruction-following models.  ConclusionIn this comparison, we explored the llama13b-v2-chat and Alpaca models in terms of their use cases, pros and cons, similarities, differences, and optimal applications. We emphasized the versatility of llama13b-v2-chat for chat completions and the specialization of Alpaca for instruction-following tasks. AIModels.fyi serves as a valuable resource for discovering and comparing various AI models, including instruction-following models. We hope this guide inspires you to explore the creative possibilities of AI and encourages you to leverage AIModels.fyi to find models that align with your specific needs.Remember to subscribe for more tutorials, updates on new AI models, and a wealth of inspiration for your next creative project. Happy exploring and enhancing your AI-powered endeavors with AIModels.fyi!Subscribe or follow me on Twitter for more content like this!"
356,"My current Big Project is my master's thesis - I'm writing about Android accessibility, and my goal is to create a list of checks Android developers could use to create more accessible apps. I'm super excited about the theme, and once it's ready, I will definitely share the results on my blog. One of the main theoretical themes in the thesis is how Android developers implement accessibility and what challenges prevent them from doing so. Research also provides some solutions to these challenges. In this blog post, we'll first look through some of the challenges Android developers face (although these are common for other types of development as well) and then discuss proposed solutions.  The ChallengesLet's first look at the challenges developers face. I've listed all the resources used in the Resources section. The list has three studies about Android developers, their accessibility knowledge, and their willingness and readiness to develop accessible apps.  Not Knowing About Accessibility and Lack of AwarenessThe first problem I want to mention is that Android developers often lack accessibility knowledge. This lack of familiarity varies - for some, it's total unawareness, but for most, it shows as problems understanding the exact needs of disabled users. 1This finding is something I can confirm from my own experiences. Often Android developers are familiar with the fact that accessibility should be part of an app. Still, the exact implementation and why they must do something are unclear.   Companies Ignoring Accessibility RequirementsAnother aspect of the lack of awareness is that companies ignore the accessibility requirements. Patel et al. 2 found out that the leadership in companies often prioritized other things over accessibility when a deadline was approaching. They usually see accessibility as an extra cost rather than an opportunity. This attitude is also visible in the internal policies, so for developers, it's often hard to find time to fix accessibility issues retroactively. Another thing that is related to fixing accessibility as an afterthought is that it can be considered hard - and it might lead to a situation where those accessibility issues don't get fixed. 1I can again confirm these findings - throughout my career, I've witnessed situations where accessibility is not part of the company's requirements, which means there is no time or resources to consider accessibility.  Little to No Exposure or Background with AccessibilityVendome et al. 3 found out that developers often don't have exposure or background with accessibility and assistive technology, and that leads to misunderstandings, e.g., in questions developers ask on platforms like Stack Overflow. For example, they might ask about how TalkBack reads phone numbers and how to force it to read them in a particular way. (For those unfamiliar with TalkBack: TalkBack users can control this with settings, and developers should not force it on apps.)On the other hand, opportunities to interact with people with disabilities were considered as a helpful way to understand user expectations better. 2 I think this all comes down to the fact that it's helpful to talk to users to understand their expectations and needs. It's a crucial part of creating good apps.  Accessibility is Only About Screen Reader AccessibilityOne challenge for accessibility is that it's mostly about screen reader accessibility. Vendome et al. 3 found out that the most discussed topic on Stack Overflow (in the material they collected) was screen reader accessibility. I can second that finding from my experience - when discussing accessibility, it's often about screen reader accessibility. And it's an important aspect, but it's necessary to remember that it's not all. Considering interaction for people who can see or have low vision is as important as is, e.g., cognitive accessibility.  Belief of Accessibility Having Negative Effects on the App's Aesthetics and UsabilityAnother finding I've witnessed is that some developers (and designers) believe that if they incorporate accessibility into their apps or designs, it will affect the app's aesthetics and/or usability. Di Gregorio et al. 1 found that developers might meet ideas about progressive functionality or interfaces negatively because they can add complexity to the app.As a developer, I can understand where this comes from. Especially requirements added as an afterthought do increase complexity - so it's important to include accessibility right from the start, and building these interfaces is less work.  Lack of ToolsThe second to last finding is the lack of tools for developing accessible apps. Also, some developers have had situations where free tools have disappeared suddenly, and there has been nothing to replace them. 2 Another thing related to different tools (or assistive technology) is that developers often don't have experience with those tools, which can lead to misunderstandings and solving problems that are not problems. One example is the problem described in the section ""Little to No Exposure or Background with Accessibility"" about TalkBack and numbers. TalkBack handles how numbers are presented, and users can alter that, but because developers didn't know it, they tried to force their app to represent numbers in a certain way when using TalkBack. 3From the perspective of a mobile dev with a background in web development, I agree that there aren't enough tools for developing accessible Android apps. There are way more tools for accessibility in web development, but for Android, not so much. The situation is changing, but slowly. I've also seen the lack of exposure to assistive technology and how it can lead to interesting outcomes.  Relevant and Usable Information is Hard to FindThe last finding is that it's hard to find relevant and usable information. One interviewee from Di Gregorio et al.'s research noted that it's not just about unawareness of accessibility guidelines but also about not being able to find usable information from the internet to fix the issues. 1 Patel et al. 2 also discovered a lack of resources - especially for building accessible components. And one of their study participants noted that the available accessibility guidelines should be in a form that is more digestible so that developers would use them.I can fully agree. Especially with Android development, I often know what I should do regarding how the app should behave to be more accessible. Still, it's hard to find usable articles on how actually do the technical implementation. So I can only imagine how hard and frustrating it can feel for someone with less background in accessibility. We've gone through many challenges Android developers face, and let's look next at the solutions proposed in the research. These solutions don't solve every aspect, but at least some of them.    Proposed SolutionsThe three research articles I've looked at list two types of proposed solutions to solve the challenges of building accessible apps for Android: Better tools and education. Let's look at both of them more.  Better Tools for DevelopmentBoth Patel et al. 2 and Vendome et al. 3 suggest having better tools for development to address accessibility in specific technical implementations. These tools could be integrated with, e.g., IDEs and could (or from what I've observed and talked with other developers, should) be semi-automated. I've been following the Android development ecosystem for a while now, and there are ongoing processes to improve the tooling. There are some code checks in Android Studio for XML-based views, but they've been lacking from Compose components. However, in Google I/O, they announced that there would be improvements for Compose previews in the form of these accessibility warnings. (Source: What's new in Android Accessibility)  Increase Accessibility Knowledge Through (Formal) EducationAnother proposed solution is to increase accessibility knowledge through education. That could be achieved by adding more accessibility-related topics to curriculums of non-computing fields. Also, within computer science and related fields, learning about addressing accessibility issues during development would be beneficial. 2This solution goes past formal education - developers would generally benefit from learning more about universal design principles and targeted tutorials and workshops addressing specific accessibility topics. 2 3From my perspective, on both formal and informal education, I've been happy to notice the increase of accessibility-themed articles and workshops, as well as accessibility in the curriculums of, e.g., universities. There is, of course, a lot to be done, but the direction is correct.But even if we had many quality articles and other resources, it's always each developer's responsibility to learn more about the topic. Any amount of education or materials is only enough if we, as developers, take the opportunity to learn more.   Wrapping UpIn this blog post, I've gone through some challenges Android developers face regarding accessibility per prior research. I've discussed lack of awareness, companies ignoring accessibility requirements, developers having little to no exposure or background with accessibility, accessibility being only about screen reader accessibility, the belief that accessibility makes the app less usable or beautiful, lack of tools, and that relevant and usable information is hard to find. I've also shared some suggested solutions: better tooling for development and increasing accessibility knowledge through formal and informal education. Do you recognize these challenges in your work? Or do you have additional solution ideas?   Resources1 Di Gregorio, M., Di Nucci, D., Palomba, F., & Vitiello, G. (2022). The making of accessible Android applications: An empirical study on the state of the practice. Empirical Software Engineering, 27(6), 145. https://doi.org/10.1007/s10664-022-10182-x2 Patel, R., Breton, P., Baker, C. M., El-Glaly, Y. N., & Shinohara, K. (2020). Why Software is Not Accessible: Technology Professionals' Perspectives and Challenges. Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, 1–9. https://doi.org/10.1145/3334480.33831033 Vendome, C., Solano, D., Liñán, S., & Linares-Vásquez, M. (2019). Can Everyone use my app? An Empirical Study on Accessibility in Android Apps. 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME), 41–52. https://doi.org/10.1109/ICSME.2019.00014"
357,"I don't have much time to write about careers right now but fortunately there are plenty of cool people that you can follow instead!  Erik DietrichWhy? @daedtech is the author of Developer Hegemony. I you like what I've written about recently, you should know that found many ideas that I liked, and then I stole those them like an artist.A taste11 Realpolitik Career Tips for Junior DevelopersErik Dietrich ・ Jun 10 '20#careerFollowErik DietrichFollowFormer software developer, architect, dev manager, CIO, and IT management consultant. Occasional writer. More than occasional remote business owner.  JuliaWhy? @yuridevat is a selftaught front end wizard from Vienna who not only write well about accessibility and stuff, but also shares her advice on how to get into techA tasteHow to create a stunning GitHub ProfileJulia 👩🏻‍💻 ・ Oct 24 '21#career#github#productivity#codenewbieFollowJulia 👩🏻‍💻Follow👋 Selftaught Accessibility & Frontend Developer🙆 Improving the world with accessible web content✍️ Content creator, Tips on how to get into tech  Imam Ali MustofaWhy? @darkterminal has a very original take on what he calls a character driven approach to choose your career. I noticed a couple of interesting comments from him, but I can't summarize the, read it yourself!A tasteHow to Deepen Your Character as a Beginner Software DeveloperImam Ali Mustofa for Character-driven Code ・ Jul 2#beginners#programming#devjournal#learningFollowImam Ali MustofaFollowSoftware Freestyle Engineer — Embracing the art of coding, I innovate with unrestricted creativity, blending technology and imagination to craft software masterpieces.  Josefine SchfrWhy? @josefine does developer relations, so if you dream about showing your ideas in a conference but are terrified when you consider to actually do it, she has lots of content about that very topic.A tasteSpeaking at Tech Conferences - Getting Started 🎉Josefine Schfr ・ Oct 17 '22#webdev#beginners#career#codenewbieFollowJosefine SchfrFollow  Jarrod RobersonWhy? @jarrodhroberson has given constantly high quality comments on my articles, so I went to read his articles, and let met report that he is a very experienced developers that is very efficient at cutting through the non-sense of the hype-du-jour.A tasteStackoverflow Moderators Strike - History Repeats ItselfJarrod Roberson ・ Jun 29#beginners#codenewbie#programming#aiFollowJarrod RobersonFollowEverything I would want you to know about me is available via Google if you look hard enough :-) And whatever ChatGPT or Bard says about me, lies all lies, unless it is true, but how would they know?  MaddyWhy? @maddy is a technical writer, another career change that is opened to you if you are both a dev and like writing hereA tasteWhy Non-Linear Tech Careers Are the FutureMaddy ・ Apr 24#careerFollowMaddyFollowTechnical Writer @ Cloudflare  Erin, Sloan and The DEV teamWhy? @erinposting and @sloan are members of the DEV/Forem team and they post frequent questions on the tag #devdiscuss that you will probably find interesting.A taste#DEVDiscuss: What's the Future of Careers in Web Dev?Sloan the DEV Moderator for The DEV Team ・ Jun 23#webdev#devdiscuss#career#aiFollowErin BensingerFollow418 bio is a teapot 🫖Sloan the DEV ModeratorFollowI help moderate content and welcome new users to this platform. I also ask questions on behalf of members looking for advice from the community.Ben HalpernFollowA Canadian software developer who thinks he’s funny.That was it for me.Obviously this kind of list can never be complete, but we can crowdsource the research.  Who else do you recommend?Show your gratitude by leaving a nice comment :)"
358,"Google calls Lighthouse ""an open-source, automated tool for improving the quality of web pages"". It is not a performance tool per se, but a prominent feature is giving feedback on a webpage's performance. It is a big challenge to get a top performance score for mobile in Lighthouse. If you have tried to attain a top score in Lighthouse -- it may have made you doubt yourself, the tool, or both! Let's explore Lighthouse to see why this is.Is Lighthouse misleading, or is it a misunderstanding?  Issue 1 - The scoring scale is not linearYou may think that the performance score is linear where a score of 100 is 10% better than a score of 90, but that is not the case. Actually the score follows a curved distribution, here is the score curve of the Time to Interactive (TTI) metric:Google mentions this in their docs when they discuss how scores are color coded:To provide a good user experience, sites should strive to have a good score (90-100). A ""perfect"" score of 100 is extremely challenging to achieve and not expected. For example, taking a score from 99 to 100 needs about the same amount of metric improvement that would take a 90 to 94.This characteristic of the calculation of the performance score means that the effort you put in to improve your score will vary depending on where you are on the curve. To make an analogy, it is like a runner putting in equal effort throughout a race:Running downhill: the runner will run faster;On the flat: the runner will run at their regular pace;Uphill: the runner will run slower.Perhaps, you did not expect this from a scoring system from zero to 100. I didn't! After all the word percent means ""one part in a hundred"". This misunderstanding could have been mitigated if a different range or distribution was chosen. Maybe, it would trip less people up if they showed the score as a point on the curve for each metric?You can dig into the details of the scoring algorithm to understand it more deeply.  Issue 2 - Scores can vary a lotIf you run Lighthouse on the same website using the same computer on the same network multiple times, you will get variable results. This feels weird at first. I'm repeating the exact same thing and getting a different result? Is this a bug or a warped reality?Google says the following on score variability:A lot of the variability in your overall Performance score and metric values is not due to Lighthouse. When your Performance score fluctuates it's usually because of changes in underlying conditions. Common problems include:A/B tests or changes in ads being servedInternet traffic routing changesTesting on different devices, such as a high-performance desktop and a low-performance laptopBrowser extensions that inject JavaScript and add/modify network requestsAntivirus softwareIt is not due to Lighthouse? 🤔 Are we are trying to handcuff lightning here? 😏How variable can it be?Take testing on different hardware. The swing can be dramatic. Zach Leatherman discussed this in an article -- The Art of Deception, Lighthouse Score Edition -- running Lighthouse on a Macbook (2012) versus a MacBook Air (M1, 2020) resulted in a 30 point swing! That's a lot.It appears that you can mitigate the impact of hardware by running Lighthouse through PageSpeed Insights (PSI), Google's web-based user experience tool. I guess this hits a particular set of servers consistently.Google gives a full list of the technical factors for these variances if you want to get into the nitty gritty.The advice in Lighthouse's GitHub repo to reduce variability is to ""run Lighthouse multiple times and beware of variability before drawing conclusions about a performance-impacting change"". Why not build this behaviour into Lighthouse to reduce variability?WebPageTest is a rival web performance tool and their default behaviour is to give a median performance score based on 3 runs. The WebPageTest team have been critical of the consistency of Lighthouse results. It is possible to run Lighthouse through WebPageTest, and they claim they can provide more consistent results from Lighthouse because they provide a more consistent test environment.While some variability between tests is to be expected, by providing a consistent test environment for all Lighthouse runs, WebPageTest helps to minimize that variability and provide a realistic and repeatable point of comparison.They point to Lighthouse's use of simulated throttling as one source of variability that could be mitigated.By default, Lighthouse uses simulated throttling: the test gets run without throttling, and then Lighthouse simulates what a throttled load might look like based on the unthrottled results.WebPageTest, on the other hand, uses packet-level throttling for all tests, including Lighthouse tests run through WebPageTest. Because packet-level throttling enables network shaping at the packet-level, it's a far more accurate modeling of real network-conditions (there's a fascinating study by the Lighthouse team about throttling accuracy if you want to wade into the weeds on the topic).  Issue 3 - The vast majority of websites are ranked as not goodLet's go back to 2020, this was when Google made a big change regarding their performance rating -- they introduced the Core Web Vitals. I want to discuss this timeframe because it was the last point where there is clear comparable data between the performance metric set (5 metrics) and the Core Web Vitals (3 metrics). The Core Web Vitals is a subset of the performance metric set.The Core Web Vitals was introduced as an effort to simplify things. To quote Google:Site owners should not have to be performance gurus in order to understand the quality of experience they are delivering to their users. The Web Vitals initiative aims to simplify the landscape, and help sites focus on the metrics that matter most, the Core Web Vitals.The Web Almanac 2020 edition demonstrated in their performance review of the web that Lighthouse reported 0.7% of websites having a mobile performance score of 100, and 5.7% of websites were in the good category (90-100). Was web performance really that bad? Or is the bar too high?I used the same dataset as the Web Alamanac to extrapolate how many websites fell into the ""good"" catgegory for that period. The data can be found in this Google spreadsheet.I was trying to understand how Google picks the good category thresholds and this is their clearest explanation, specifically for the Largest Contentful Paint (LCP) metric:Based on real website data, top-performing sites render LCP in about 1,220ms, so that metric value is mapped to a score of 99.Going a bit deeper, the Lighthouse scoring curve model uses HTTPArchive data to determine two control points that then set the shape of a log-normal curve. The 25th percentile of HTTPArchive data becomes a score of 50 (the median control point), and the 8th percentile becomes a score of 90 (the good/green control point).Does that mean that the upper 8% of the data represents a score of 90 and above? I don't get their explanation to be honest! 😕 Although it sounds about right based on my previous analysis from the Web Almanac.Barry Pollard did some analysis of Lighthouse scores across the web by querying data on the HTTP Archive in his article, What do Lighthouse Scores look like across the web?, and the results are similiar. He said the following about top level scores:[..] 90% of sites score 80 or less on Performance or, to put it another way, only 10% of sites score higher than 80 in the Performance category.It will always be that only a small portion of websites achieve a ""good"" performance score because it is the upper 8th percentile that make up this category. If web peformance dramatically improved across millions of websites overnight, the bar will be raised and even more is required to get into the ""good"" category.Based on the same data (the Chrome User Experience Report data that is available through the HTTP archive) for the same approximate period (August to October 2020), 22.3% of pages passed all 3 Core Web Vital metrics with a ""good"" score. More websites pass the Core Web Vitals than get a ""good"" performance score in Lighthouse.In the subsequent years, refinements to the performance scoring have been made. The latest version of Lighthouse is 10. Five of the same metrics are used in the scoring since version 6, the thresholds and weights have been tweaked. A new metric called Interaction to Next Paint (INP) has been introduced recently and will replace First Input Delay (FID) in March 2024 as a Core Web Vital metric.What I find strange is that Lighthouse in Chrome's devtools does not mention Core Web Vitals at all. It still gives the performance score on 5 metrics. Why give people the more complex and more challenging set of metrics then?No mention of Core Web Vitals in results for Lighthouse in the browser devtoolsFor defining the thresholds, Google explains the science behind the thresholds related to human perception thresholds and relevant HCI research. The thresholds are based on how we percieve things, but how achievable is that on the web? Google says the following in their article on defining thresholds:To confirm that a threshold is achievable, we require that at least 10% of origins currently meet the ""good"" threshold. Additionally, to ensure that well-optimized sites are not misclassified due to variability in field data, we also verify that well-optimized content consistently meets the ""good"" threshold.So with all the numbers mentioned, the minimum requirement by Google is that 10% of the web is classified as meeting the ""good"" performance threshold for the Core Web Vitals. That sounds like the Core Web Vitals are a bit more lenient than the overall performance set, but are still very challenging.We can see figures for the Core Web Vitals for the last 3 plus years on HTTPArchive, the percentage of origins passing the Core Web Vitals for mobile has increased from 22.6% to 40.7%.I would love to see the same graph for the overall performance score. My guess is that would be a lot lower.  Issue 4 - Is it field data or lab data?It is important to understand the difference between lab data and field data. Lighthouse is a lab-based tool, also known as a synthetic tool.Lab data is collected within a controlled environment with predefined device and network settings. Its main use is for debugging performance issues because it provides a reproducible testing and debugging environment. The downside is that lab data does not capture real-world bottlenecks well.Field data is performance data collected from real page loads your users are experiencing in the wild. Tools that gather field data are often referred to as Real User Monitoring (RUM) tools. Field data captures true real-world user experience.PageSpeed Insights uses the Chrome User Experience Report (CrUX) dataset to augment lab data provided by Lighthouse for the same metrics. However, your page or origin may not be in the dataset because it is not publicly discoverable or there are not a large enough number of visitors in order to create a statistically significant dataset.A good example of this dicothomy is to view a PSI report on web.dev, this is Google's blog that has a lot of information on Lighthouse. You can see the result of the very test I ran at this URL: https://pagespeed.web.dev/analysis/https-web-dev/hp4cd34d4i?form_factor=mobile.Lighthouse reported a performance score of 96, but it failed the Core Web Vitals! At a glance, it can look like a mistake! How did that happen?It is because PSI reports different figures for the LCP metric for the Core Web Vitals and the overall performance score (see yellow highlights in screenshot below)! The figures are different because PSI uses field data from the CrUX dataset for the Core Web Vitals (when it is available) in the first section, whereas lab data is used for the performance score in the second section.You may miss this! Having 2 different metric sets using 2 different datasets side by side was confusing for me initially. Also, if you are focusing on the Core Web Vitals, there are 2 sets based on the testing method:Lab testing in Lighthouse: Largest Contentful Paint (LCP), Cumulative Layout Shift (CLS), Total Blocking Time (TBT).Field testing in PageSpeed Insights: Largest Contentful Paint (LCP), Cumulative Layout Shift (CLS), First Input Delay (FID).Previously, the PSI report was more explicit about whether field data or lab data is being used the results shown. Here is an example screenshot of the PSI report from a few years ago:I think that the updates to the UI look prettier but are less apparent.You can read more about how think of tools in How To Think About Speed Tools by web.dev.  Issue 5 - Mobile or Desktop?When people discuss and compare Lighthouse scores, often they take screenshots to keep a record. There is no indication in the UI if results are for mobile or desktop. The thresholds for mobile performance are higher. This is avenue for mistakes and misrepresentation.Is this a Mobile or Desktop score?There has been discussion about adding a visual indicator to make the mode more obvious, but it has not made it into Chrome devtools!  Issue 6 - People inevitably aim for near perfect scoresInevitably, people aim to get a near perfect performance score. People take pride in what they do and want to point to something they made, and say ""check out the performance of this"". If you build a tool with high thresholds, then you put achieving a top score out of reach for some types of websites and web applications. There is no differentiation between a demanding web store like amazon, a web application like Google Docs, and a personal website.To highlight this situation, there is a discussion thread, ""Instruction to get score 100 on the mobile"" on the Lighthouse GithHub repo:I have used the lighthouse to monitor a website for the performance. However, it's really hard to get 100 score for the mobile. I only can get the score 100 for the mobile with the site that contains only a static text without css, javascript.I'm not sure if lighthouse team considers that the website contains only a static text is popular nowaday for the modern website.Of course, the PWA is not standard today yet and even for the PWA, we must load for ""full state"" mode as well.I was surprised by this a while back too. I approached rebuilding my personal website by starting with the simplest possible homepage. I had no images, quite a small stylesheet, and I think I used 3 web fonts. It did not get a ""good"" mobile score! I had to optimize these assets to climb into the 90's.Another part of this is that when numbers are involved, it can led to a competitive element. Frameworks and libraries lean into this to promote the speed and performance of their offering. Eleventy has a leaderboard that uses a Lighthouse-based plugin called speedlify to rank websites.Is Lighthouse suitable for comparing sites in this way? 🤨  Final thoughtsMeasuring web performance is a difficult proposition. We are not making homogeneous web-based products in an uniform way. This makes it a challenge to define what is good performance for something on the web. Google has been active in defining what is good performance through its metrics and tools, and has a big say on the matter.Google calls Lighthouse ""an open-source, automated tool for improving the quality of web pages"". It inspects a few different facets of a webpage in its audits such as: performance, SEO, and accessibility. It is not a performance auditing tool per se, but it has a big presence in that space because Google made it, put it into Chrome, and announced it that the Core Web Vitals metrics are a factor in their search ranking!Lighthouse is primarily a lab-based tool that is used for performance debugging. It has some characteristics that are not apparent. The scoring calculation is byzantine, results can be very variable, and it is very difficult to get a ""good"" performance score for mobile. As I covered in this article, some of it can attributed to the need to understand web performance and Lighthouse fairly well, but in some ways Lighthouse is misleading.Google says a perfect mobile performance score of 100 is ""extremely challenging to achieve"". Their approach to performance classification is a lot more stick than carrot. In late 2020, by Lighthouse's classification less than 6% of web origins were deemed to have attained ""good"" performance, whereas 22.3% passed the Core Web Vital metrics. The Core Web Vital is a more lenient set of metrics.The Core Web Vitals has made more businesses pay attention to web performance. As the Web Almanac put it in 2022 performance review:Google’s decision to make CWV [Core Web Vital] part of search ranking catapulted performance to the top of many companies’ roadmaps, especially in the SEO industry. Individual site owners are certainly working hard to improve their performance and played a major role in the CWV improvements over the last year, even if those individual efforts are much harder to spot at this scale.The percentage of origins passing the Core Web Vitals for mobile at the time of writing is 40.7%.The aim of the Web Vitals initiative was to simplify the performance landscape, it hasn't done that well in my opinion. There is a lack of clarity and focus. Your performance score is still based on the complete set of metrics. The complete metric set is shown in Chrome's devtools, which is where many people encounter Lighthouse for the first time.The CWV metrics haven't been embraced fully anywhere really. PSI shows the CWV metrics first, but 3 more metrics sit right alongside them. It does not give a clear message to users - should you be passing CWV or getting a ""good"" performance score or both? And what is a realistic score for your particular type of application?Score variability means that Lighthouse comes with caveats. Generally it is not a very reliable performance debugging tool. Since score variability is skewed by your machine's performance when it is run locally, it is probably not a good idea to run Lighthouse in the Chrome's devtools. It is better to use Lighthouse through WebPageTest where it does more to mitigate variability, or use other tools for debugging performance.I would recommend using Lighthouse primarily to understand how Google classifies your website. The opportunities presented by the Lighthouse audit give you a rough guide to improve performance but take it with a dash of salt. Field data gives you a more realistic view of user experience and you should favour that for understanding the performance of your website.You can subscribe to my RSS feed to get my latest articles."
359,"Doticons is a comprehensive and carefully curated collection of SVG dot icons. They are based on a 16x16 and 32x32 dot matrix, which gives them a pixelated and retro look. They are also scalable and customizable, so you can adjust their size and color.  🎨 What's Inside?Doticons are free to use and modify for any personal or commercial project. You can download them from my GitHub repository: https://github.com/eduardconstantin/doticonsYou can open a request for adding new icons, improving existing ones, or suggesting new categories or join the discussion tab if you have any feedback or questions.I am also looking for contributors to help me improve this project, so open a PR or an issue, I appreciate any feedback, suggestion or improvement."
360,"New Llama AI model from Meta is out. It's Open and available for companies to use! In this post, I answer the following questions:What is new LLama 2 AI model?How does the performance of Llama 2 compare to other open-source language models?What capabilities does Llama 2 possess?What are the different versions of the Llama 2 model released by Meta?What are the terms for using the Llama 2 model for commercial use?In below tweet I compare the new Llama 13B V2 model with current best models on the market from OpenAi and Anthropic.Here are my takes. On very bottom I will share links I used.LLAMA 2 significantly outperforms any other existing open source language model, across all model sizes.LLAMA 2 is the first open source model that can rival proprietary models like ChatGPT for conversational ability, though it still lags in coding tasks.Meta has released multiple versions of its advanced artificial intelligence model, Pretrained and fine-tuned models are available with 7B, 13B and 70B parameters.The base LLAMA 2 model appears to surpass even GPT-3 in core capabilities, and the fine-tuned conversational models seem on par with ChatGPT. This represents a major advancement for open source language models.Meta doubled the context length that LLAMA 2 can process to 4,000 tokens, greatly expanding its understanding of long-form text.The model is freely available for commercial use unless your product has over 700 million monthly active users. Access requires submitting a form to download the model from HuggingFace Hub.Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providersThe model has been likely trained for several months and Meta is focusing heavily on trust, accountability, and democratizing AI through open-source. They have made it clear that they do not use user data, thereby avoiding potential issues.The training corpus for the model comprises a new mix of data from publicly available sources, excluding data from Meta’s own products or services. Efforts have been made to remove data from sites known to contain a high volume of personal information about individuals. This approach strengthens Meta's position as a leader in the field of open-source large language models (LLMs).refs:https://www.interconnects.ai/p/llama-2-from-metaVercel SDKLlama paperMeta AI introducing Llama 2My tweet hahaGodspeedPS. Follow me on Twitter or LinkedInhttps://twitter.com/dom_sipowiczhttps://www.linkedin.com/in/dominiksipowicz/"
361,"This week, we're diving into the essential qualities that define exceptional coders. Share your practical tips, inspiring stories, and invaluable insights to help our newbies cultivate these qualities and unlock their full coding potential. Together, let's empower the next generation of coding superstars. Today's quality is: Problem-solving SkillsHow do you cultivate and enhance your problem-solving skills as a coder?Share an experience where your problem-solving skills played a crucial role in resolving a coding challenge. What strategies did you employ?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
362,"Java is widely used for building large-scale enterprise applications. What do you see as the main advantages and disadvantages of using Java in this context? Join the discussion and share your thoughts on Java's suitability, performance, scalability, and maintenance for enterprise-level projects.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
363,"Picture this: you wake up one morning and realize you've been outrun by the relentless march of time. Your once shiny tech skills are now relics, gathering dust in the cobwebbed corners of obsolescence, making job opportunities as elusive as a unicorn in rush hour. Spooky, right? But hey, don't start pressing that panic button just yet. From mid-level to senior roles, the tech journey is filled with constant evolution. So how do you keep pace? Say hello to your new best friend: continuous learning! ""You don't understand anything until you learn it more than one way."" - Marvin MinskyJust as software needs updates to function optimally, our tech skills require regular upgrades too. And, it's not as daunting as it sounds. Let's explore why continuous learning is the key to staying relevant in our ever-evolving industry, and how you can become a lifelong learner.  The Importance of Continuous LearningLearning doesn't stop once you graduate from college, complete a coding boot camp, or after learning about the latest Javascript framework. Throughout your career, your knowledge and skills will need to keep evolving. This continuous learning isn't just about staying relevant, it also opens doors to exciting new opportunities, fuels creativity, and promotes problem-solving.  Tips for Embracing Continuous LearningAs you progress in your career, you'll need to embrace continuous learning. But let's be real, it can be a tad overwhelming. Here are some tips to help you stay on track.Set Clear Learning Goals: Having specific, achievable goals can motivate you to learn. Whether it's mastering a new programming language, understanding a framework, or getting familiar with a new tool, having a target in sight can keep you focused.Practice Regularly: Just like a muscle, your coding skills need regular exercise. Make coding a daily habit, even if it's just a small piece of code or solving a problem on coding challenge platforms.Learn by Teaching: Nothing tests your understanding of a topic like trying to explain it to someone else. Consider mentoring a junior developer or sharing your knowledge through a blog or a YouTube channel.Participate in Developer Communities: Communities like StackOverflow, GitHub, or tech-specific forums can be gold mines of knowledge. You can learn from others' experiences, ask questions, and participate in meaningful discussions.Attend Webinars, Workshops, and Conferences: These events can be great places to learn about the latest trends, tools, and best practices. Plus, they offer the chance to network with like-minded professionals.Embrace Mentorship: having a mentor can be invaluable. Mentors can offer guidance, insights, and often have a wealth of experience to draw from. Finding a mentor in your area of interest can significantly enhance your learning journey.  Resources for Continuous LearningJust as a hunter needs his trusty crossbow or a chef her favorite knife, so does a tech professional need their resources to fuel continuous learning. Here are some picks of the top resources that can help keep you on your toes in the tech world:Online Courses: Platforms like Coursera, Udemy, and Codecademy offer a wide range of courses, from beginner to advanced levels, across various tech domains.Books and E-books: Despite the dynamic nature of tech, some foundational books can enhance your understanding of computer science principles. Also, many tech books keep updating their editions to stay relevant.Podcasts and Vlogs: For those who prefer to learn by listening or watching, tech podcasts and vlogs can be a great resource. They're usually more informal and easier to consume during commutes or breaks.Technical Blogs and Websites: Websites like Medium, Dev.to, or personal blogs of tech professionals often provide insightful articles and tutorials.Documentation and Official Guides: Want to learn a new tool or technology? Go straight to the source. Official documentation often provides the most accurate and up-to-date information.Continuous learning may seem daunting, especially when you're already juggling your day-to-day job responsibilities. In a future article, I'll discuss time management and prioritization. But, for now, it's important to remember that it's not about knowing everything—it's about staying curious, being open to new concepts, and consistently making an effort to grow. After all, in the words of B.B King:""The beautiful thing about learning is that nobody can take it away from you.""Every step forward, no matter how small, is progress. Keep learning, keep growing!The response to this series has been overwhelming! I've compiled the series, expanded the content a bit, and am giving it away as a FREE ebook: Get it here!."
364,"Right, so it's been a minute since I last posted something.Like many other companies this last year, we weren't spared layoffs. While I still have my job, my team has been greatly reduced, both from people leaving when they saw the signs and from people being let go. So while fighting survivors guilt and an increased workload, posting hasn't been my first priority.But while doing my day to day and trying to keep my head down and deliver as much as possible as quickly as possible, I noticed something. And I'm not sure how I feel about it, other than we need to talk about it.I felt this post needed to happen. So here it is:  ChatGPT has made me lazy.😳Yeah.  Okay, but... you said AI tools are awesome?Yes, I have been saying that, and I still think the improvements to GPT and other LLMs and the new features with Copilot are fantastic tools and will make many jobs more productive.But in much the same way I imagine people using horses felt when they first started getting cars, or people who walked everywhere when they got bicycles, or carpenters with their first power tools, this increase in productivity comes at a cost.  Surely you're overacting?Maybe. Maybe not. And don't call me Shirley.I think we need to start with a story. Something I caught myself doing earlier this week.For local testing we have this little stub service which acts as the client/partner endpoint. Up until now all our data has always been JSON, but for a new partner we are sharing binary data as well, so I wanted to update the stub to handle both. All this needs is a simple if statement to look at the request headers.I've been doing Go for about 6 years and have built many, many microservices with REST APIs. I should be able to code this logic in my sleep, since I know the APIs of the ""net/http"" package. But what was the first thing I did?  So you asked ChatGPT to write some boilerplate, big dealI know, I know, it probably doesn't seem like a big deal... yet. But here's the thing; that's not where it ended. A large part of the rest of my code was just me starting to type, looking at the Copilot suggestion in my IDE, and then pressing Tab.Then writing a line of custom code unique to my service, before just autocompleting boilerplate from Copilot again.And yeah, this is awesome. It reduces coding time, hopefully reduces mistakes, it make my life so much easier, right? Right!?!Except when it doesn't.Something wasn't working, and usually this is where I add some debug logging, and if that doesn't work, I pull out the debugger and start stepping through code, investigating every single line and memory allocation like a detective trying to solve the perfect murder.Only I didn't. Instead, I did this.As expected, it told me the obvious things; add logging on the request and receive side and print out the headers and status codes and body. Which I obviously did even before it told me to, because I'm not some n00b and this isn't my first rodeo.So I told it I already confirmed the problem is on the receive side. And it gave me some good ideas back, and to be fair to the tool, it did help me solve the problem... One of the suggestions wasIs the request being read correctly? - Ensure that the request body is being read correctly. For instance, it could be that the body is being read somewhere else before your io.ReadAll(req.Body) line and it's not being reset.Which was the issue. When doing some copy-pasta refactoring to add the if-else, I moved the reading of the body to outside the if statement since I only need to do that once, but then I didn't delete it from the else part, which caused some variable shadowing I didn't notice, and because an io.ReadCloser such as req.Body is a stream and not a buffer, the data I already read is gone from the stream. It worked fine for the if because it didn't try and read twice.And I kinda feel like I should have just picked this up by reading my code properly, instead of jumping onto ChatGPT.  Ouch. Tough break.Indeed. And this has made me think a lot about these tools and the impact they've had on me. While I do feel more productive, and there are certain tasks these tools make much easier than before, I wonder at what cost it comes.It's all too easy to draw parallels between our increasing reliance on AI tools and the introduction of power tools to carpenters or automobiles to those used to horses. The idea of 'progress' often lures us into believing that newer, faster, and more efficient is invariably better. But like power tools, which introduced an increased risk of injury, or automobiles which brought along pollution, AI coding assistants also have their drawbacks.While power tools enable us to build bigger, faster, and more intricate things than we could with our bare hands, they also run the risk of creating a generation of workers who wouldn't know how to hammer a nail if the power was out. In the same way, tools like ChatGPT and Copilot can help us become more productive coders but also threaten to leave us helpless if we forget how to do even the most simple of tasks.Of course, I'm not arguing against progress. Without the willingness to adopt new tools and adapt to changing circumstances, we'd still be etching symbols onto cave walls. But as we embrace these AI tools that promise to make our coding lives easier, we must remain vigilant about the risks of over-reliance.We must be careful not to trade our skill and expertise for convenience.  ConclusionI'm sure I'm not the only one who's become a little complacent, a bit lazy, in the face of these new tools. But recognizing the problem is the first step towards solving it. So yeah, the next time you're reaching for that shiny AI tool to solve your coding problem, pause for a moment. Is this a shortcut you genuinely need, or is it a crutch you're leaning on? Are you using the tool, or is the tool using you?Remember, the best tool any coder has is their brain. And unlike AI tools, it's 100% unique to you and perfectly tailored to solve your coding problems. So before you let AI take the wheel, make sure you're still in the driver's seat."
365,"Are you tired of constantly moving your code back and forth between your local machine and a remote server? Do you wish you could seamlessly develop on a remote machine without the hassle of SSH? Look no further! The Visual Studio Code Remote - Tunnels extension is here to solve your problems.In today's fast-paced development world, it's becoming common to work on projects hosted on remote machines. Whether it's a powerful desktop PC or a virtual machine (VM), the Remote - Tunnels extension allows you to connect to it securely from your VS Code client anywhere.But what exactly does ""tunneling"" mean? Tunneling is the process of securely transmitting data from one network to another. With the Remote - Tunnels extension, you can access your code and run commands directly on the remote machine, eliminating the need to have the source code on your local machine.Sounds interesting, right? Let's explore how you can get started with the Remote - Tunnels extension.  🛠️ Getting Started: Two Paths to Remote TunnelsThere are two ways to work with tunnels using the Remote - Tunnels extension. You can either use the command-line interface (CLI) or enable tunneling through the VS Code Desktop UI. Both methods provide the same tunneling functionality, so you can choose the one that suits your workflow the best.  1️⃣ Using the 'code' CLIIf you prefer working with the command line, the code CLI is perfect for you. First, install the code CLI on the remote machine where you want to develop from your VS Code client. The CLI establishes a secure tunnel between your client and the remote machine. And the best part? The CLI is already built into the VS Code Desktop, so there's no additional setup required.If you can't install the full VS Code Desktop on your remote machine, don't worry. You can download the CLI as a standalone installation from the VS Code download page. Alternatively, you can install and unpack the CLI through the terminal of your remote machine.curl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gztar -xf vscode_cli.tar.gzEnter fullscreen modeExit fullscreen modeOnce you have the code CLI set up, creating a secure tunnel is as easy as running the following command:code tunnelEnter fullscreen modeExit fullscreen modeThis command downloads and starts the VS Code Server on the remote machine and establishes a tunnel to it. You'll be provided with a vscode.dev URL tied to this remote machine, which you can open in any VS Code client.  2️⃣ Using the VS Code UIIf you prefer a more visual approach, you can enable tunneling through the VS Code Desktop UI. Simply open VS Code on the remote machine where you want to enable tunnel access.From the VS Code Account menu, select the option to ""Turn on Remote Tunnel Access."" Alternatively, you can open the Command Palette (F1) and run the command ""Remote Tunnels: Turn on Remote Tunnel Access.""After logging into your GitHub account, a tunnel will start up on your current machine, allowing you to connect to it remotely. You can open the vscode.dev link from the notification and start coding in the remote environment.  🔒 Secure and Convenient: The Remote - Tunnels ExtensionBy now, you might be wondering how the Remote - Tunnels extension fits into all of this. Well, when you open a vscode.dev instance through either the code CLI or VS Code UI, the Remote - Tunnels extension is automatically preinstalled.If you're already working in VS Code (desktop or web) and want to connect to a remote tunnel, you can install and use the Remote - Tunnels extension directly. Once installed, you can connect to any remote machines with an active tunnel through the Command Palette.The Remote Explorer view allows you to see your remote machines and easily manage the tunnel connections. You can focus on the Remote Explorer using the command ""Remote Explorer: Focus on Remote View."" The green remote indicator in the lower-left corner of the VS Code window also provides quick access to Remote Tunnels commands.  🌐 Common Questions: Answers You've Been Looking ForWhat is the relationship between Remote Tunnels, VS Code Server, and Remote Development?Remote Development allows your local VS Code installation to seamlessly interact with source code and runtime environments on other machines, whether virtual or physical. The VS Code Server, which is quickly installed by VS Code when you connect to a remote endpoint, enables this interaction. The Remote - Tunnels extension facilitates the connection to the remote machine where the VS Code Server is running.Can multiple users or clients access the same remote instance simultaneously?No, an instance of the VS Code Server can only be accessed by one user or client at a time.How do I remove a tunnel or machine?To stop a tunnel, you can use the shortcut Ctrl + C if you're running the CLI. In the VS Code UI, you can run the command ""Remote Tunnels: Turn off Remote Tunnel Access..."" to disable tunneling. To remove a machine's association with tunneling, you can use the ""code tunnel unregister"" command, or unregister it directly from the Remote Explorer view.How secure are the tunnels?Accessing a tunnel requires authentication with your GitHub or Microsoft account. Once you connect from a remote VS Code instance, an SSH connection is established over the tunnel, providing end-to-end encryption using AES 256 in CTR mode.  🚦 Usage Limits: Everything You Need to KnowTo prevent abuse, there are usage limits in place for resources like the number of tunnels and bandwidth. However, most users will never reach these limits. For example, at the moment, you can have up to 5 tunnels registered for your account. If you want to create a new tunnel and already have 5 others registered, the CLI will automatically pick a random unused tunnel and delete it.If you require additional usage beyond the limits, you can get in touch with the team at vscodeserver@microsoft.com.  💡 Conclusion: Simplify Your Remote Development Workflow Today!The Visual Studio Code Remote - Tunnels extension is a game-changer for developers who work with remote machines. It streamlines the process of connecting to remote environments, allowing you to focus on what matters most: your code.No more syncing code between machines or dealing with the complexities of SSH. With the Remote - Tunnels extension, you can seamlessly develop on any remote machine with ease. Whether you choose the CLI or the VS Code UI, connecting to a remote machine has never been simpler.So go ahead, give it a try. Install the extension, create a tunnel, and experience the power of remote development firsthand. Happy coding!Full Disclosure: This post was written with the help of gpt-3.5turbo-16k."
366,"  If you could choose only one tech stack for the rest of your life, what would you choose 🤔💭?"
367,"Ruby's expressive syntax is renowned for its ability to make code clean, readable, and concise. Have you had any memorable experiences where Ruby's expressive nature has improved your coding process? Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
368,"​​Asynchronous simply refers to making many events occur simultaneously in any order without waiting for one another, and this definition applies to asynchronous Javascript.​​​​In this article, I'll go through the concept of asynchronous JavaScript, Callback, Promises, Async/Await, Callback queue, Event Loop, and Web browser features (Web API).​​​​Javascript is a single-threaded language that can only run one process at a time. JavaScript uses an event loop to carry out the operation, for now, consider the event loop as a queue where all Javascript processes are maintained and executed one at a time.You should note Javascript is actually a Synchronous language. JavaScript executes lines of code sequentially, not concurrently, because it is by default, synchronous and single-threaded. ​​For instance, the code below will run and be executed line by line.​​let username = ""John"";​​let points = 5000;​​let message = `${username} has earned ${points} points`;​​​​console.log(message);​​​​//Output​​John has earned 5000 pointsEnter fullscreen modeExit fullscreen modeThe code above is executed synchronously, each line is completed before moving on to the next line.​​​​Let's consider a scenario where you need to retrieve a large amount of data from an API and display it. By default, in JavaScript, the execution is blocked, and all further instructions are halted until the retrieval request is completed. This is where asynchronous programming becomes crucial.​​Let’s dive in.   ​​What is Asynchronous JavaScript​​Asynchronous JavaScript refers to the programming paradigm in which code execution does not follow the usual sequential flow from top to bottom. Instead, asynchronous code allows certain operations to be initiated and completed separately without blocking the execution of other code.​​​​The concept of asynchronous JavaScript enables you to break down big complex projects into smaller tasks.  What is involved in Asynchronous JavaScript?Web Browser features (Web API).Callback queue.Event loop.Callback.Async/Await.Promise.  Web Browser Features (Web API)Browser APIs, also known as web APIs, are pre-existing interfaces embedded within web browsers. These APIs offer built-in functionalities that can be leveraged within web applications. Web APIs allow developers to access and interact with these additional functionalities using JavaScript. By utilizing web APIs, developers can seamlessly incorporate specific features into their codebase while minimizing code complexity. Examples of such features include making network requests and efficiently managing client-side storage.Some web browser features include:setTimeout()The setTimeout() method allows you to run a block of code after a certain time delay. It is designed to execute the code once. The syntax of setTimeout() is:setTimeout(function, milliseconds);Enter fullscreen modeExit fullscreen modeExample:function username() {  console.log(""John"")}setTimeout(username, 5000)console.log(""Doe"")Enter fullscreen modeExit fullscreen modeOutput:DoeJohnEnter fullscreen modeExit fullscreen modesetInterval()The setInterval() method repeats a block of code at every given timing event.The syntax of setInterval()  is :setInterval(function, milliseconds);Enter fullscreen modeExit fullscreen modeExample:// program to display a text using setInterval methodfunction orderItem() {    console.log('I want a bag');}setInterval(orderItem, 1000);Enter fullscreen modeExit fullscreen modeOutput:I want a bagI want a bagI want a bagI want a bag...Enter fullscreen modeExit fullscreen modeIn the above  program, the orderItem() function is invoked by the setInterval() method at an interval of 1000 milliseconds. Consequently, the program outputs the message ""I want a bag"" every 1 second.clearTimeout()clearTimeout() method cancels a timeout previously established by calling setTimeout().The syntax of clearTimeout() is:clearTimeout(timeoutId)Enter fullscreen modeExit fullscreen modeExample:// Set a timeout that logs a message after 3 secondsconst timeoutId = setTimeout(() => {  console.log(""Timeout executed!"");}, 3000);// Clear the timeout before it executesclearTimeout(timeoutId);Enter fullscreen modeExit fullscreen modeOutput:If you run the code snippet provided, there will be no output. The clearTimeout() function cancels the execution of the timeout set by setTimeout() preventing the callback function from being invoked. As a result, the message “Timeout executed!"" will not be logged to the console.clearInterval()clearInterval() is used If you want to stop the function call.The syntax of clearInterval() is:clearInterval(intervalId);Enter fullscreen modeExit fullscreen modeExample:// Define a variable to store the interval IDlet intervalId;// Function to be executed repeatedlyfunction showMessage() {  console.log(""Hello!"");}// Start the intervalintervalId = setInterval(showMessage, 1000);// After 5 seconds, stop the intervalsetTimeout(() => {  clearInterval(intervalId);  console.log(""Interval stopped"");}, 5000);Enter fullscreen modeExit fullscreen modeOutput:Hello!Hello!Hello!Hello!Interval stoppedEnter fullscreen modeExit fullscreen modeIn the above program, you first declare a variable intervalId to store the ID returned by setInterval function. The showMessage function is defined, which will be executed repeatedly every 1000 milliseconds (1 second) using setInterval.After 5 seconds (5000 milliseconds), clearInterval is called with the intervalId as the argument to stop the interval. This will stop the execution of the showMessage function. Finally, a message is logged to the console indicating that the interval has been stopped.fetch()The fetch() method in JavaScript is used to request data from a server.They are not part of the JavaScript language, but they are built on top of the core JavaScript language, providing you with extra superpowers to use in your JavaScript code. Read more about Web APIs 👉 here 👈.  Callback queueThe callback queue is where the callback function is pushed and awaits execution. The callback queue follows the First-In-First-Out(FIFO) principle.Now let’s go through this example:function username() {  console.log(""John"")}setTimeout(username, 5000)console.log(""Doe"")Enter fullscreen modeExit fullscreen mode//outputDoeJohnEnter fullscreen modeExit fullscreen modeThis block of code demonstrates the usage of the setTimeout() function to delay the execution of a callback function.Here's how it works:The username function is defined and stored in the Global memory, which logs the string ""John"" to the console.The setTimeout() function is called with two arguments. The first argument is the username function, which specifies the callback function to be executed, and the second argument is the delay in milliseconds, which in this case is 5000 milliseconds (or 5 seconds).After calling setTimeout(), the code continues to the next line and logs the string ""Doe"" to the console.The string ""Doe"" is logged to the console first.After the delay of 5000 milliseconds, the username function is executed and logs the string ""John"" to the console.   Event LoopThe event loop continuously checks if the call stack is empty. If the call stack is empty, it means that there are no functions currently being executed. In that case, the loop takes the functions waiting in the callback queue and pushes them onto the call stack for execution. The event loop acts like a gatekeeper for the callback queue. The event loop manages code execution to avoid blocking, enabling the program to proceed with its operation even during the completion of asynchronous tasks.   What is Callback?When you pass a function as an argument to another function, and that function is invoked or executed within the outer function, it is commonly referred to as a callback function.Now let’s go through this example:function placeOrder() {    setTimeout(() => {       return (Math.random() * 10) <= 5 ? 'Bag' : 'Shoe';    }, 2000);}let order = placeOrder();console.log('Order is for: ' + order);//Output// Order is for: undefinedEnter fullscreen modeExit fullscreen modeHere in the placeOrder function, the setTimeout() will run after 2 seconds, and by that time the console.log statement has already been executed, the printed value of order is undefined.Now, you can resolve this issue by logging your message to the console only after the data has returned from placeOrder. This can be done by passing a callback function to placeOrder, which will be invoked inside the placeOrder function.function placeOrder(callback) {    setTimeout(() => {        const order = (Math.random() * 10) <= 5 ? 'Bag' : 'Shoe';        callback(order);    }, 2000);}placeOrder((order) => {    console.log('Order is for: ' + order);});//Output// Order is for: BagEnter fullscreen modeExit fullscreen modeAfter two seconds, the callback function will be called, and the console statement will get executed with the correct order value.The output of placeOrder function may differ in your case as you are using Math.random() to decide order value.  PromisePromise is an object in JavaScript that represents the eventual completion (or failure) of an asynchronous operation and its resulting value.Promises simplify handling asynchronous code, making it easier to write and maintain asynchronous operations without resorting to callback functions or nested callbacks (known as callback hell). Callback hell is a term used to describe a situation where the code becomes hard to read and understand due to a large number of nested callback functions.A promise can be in one of three states:Pending: The initial state when a promise is created, and the asynchronous operation is still ongoing.Fulfilled: The state when the asynchronous operation is successfully completed, and the promise has a resolved value.Rejected: The state when the asynchronous operation encounters an error or fails, and the promise has a reason for rejection.There are three main aspects of promises.Creating a promiseHandling a promiseChaining of promise  Creating PromisesTo create a promise, you use the Promise constructor, which accepts a function (commonly referred to as the executor) as an argument. The executor function is provided with two parameters: resolve and reject. Within the executor function, you execute your asynchronous task and invoke either resolve or reject based on the result.Here's an example of creating a promise :const fetchData = new Promise((resolve, reject) => {  // Simulating asynchronous task (e.g., making an API call)  setTimeout(() => {    const data = { id: 1, name: ""John Doe"" };   // Fulfilled the promise with the fetched data    resolve(data);     reject(new Error(""Failed to fetch data""));     // Alternatively, reject the promise with an error  }, 2000);});Enter fullscreen modeExit fullscreen mode  Handling a PromiseAfter creating a promise, you can assign callbacks to handle the result using the then() and catch() methods.The then() method takes a callback function as an argument and manages the fulfilled promise. It receives the resolved value or result of the promise as an argument.The catch() method is used to handle the rejection of a promise and it is called when the promise is rejected, allowing you to handle any errors that occurred during the asynchronous operation.Now let's go through this example:fetchData  .then((data) => {    // Handle the fulfilled promise (access the resolved value)    console.log(""Fetched data:"", data);  })  .catch((error) => {    // Handle the rejected promise (access the error)    console.log(""Error:"", error);  });Enter fullscreen modeExit fullscreen mode  Chaining PromisesUsing the then() method, you can chain promises together to create a sequence of asynchronous operations. Each then() callback produces a new promise, enabling you to handle the outcome of the previous operation and proceed with the next one. Chaining promises allows you to establish a more sequential and readable flow of asynchronous operations.fetchData  .then((data) => {    // Handle the first fulfilled promise    console.log(""Fetched data:"", data);    return someOtherAsyncTask();  // Return a new promise  })  .then((result) => {    // Handle the result of the second fulfilled promise    console.log(""Second async task result:"", result);  })  .catch((error) => {    // Handle any errors in the chain    console.log(""Error:"", error);  });Enter fullscreen modeExit fullscreen mode  Async/AwaitAsync/Await is a relatively recent addition to JavaScript, introduced in ES8, that provides a means to write asynchronous code in a synchronous manner.If you use the Async keyword before the function definition, you can then use await within the function. Await gives you the power to pause the function in a non-blocking way until the promise is resolved.Now let's go through this example:async function fetchData() {  try {    const response = await fetch('https://jsonplaceholder.typicode.com/posts');    const data = await response.json();    console.log('Fetched data:', data);  } catch (error) {    console.log('Error fetching data:', error);  }}fetchData();Enter fullscreen modeExit fullscreen modeHere’s the explanation to the code snippet:An async function called fetchUserData() is declared. Inside this function, an asynchronous HTTP request is made to the API endpoint using the fetch() function. The fetch() function returns a promise that resolves to a response object.The execution is paused using the await keyword, allowing the code to wait for the promise returned by fetch() to resolve. The resolved response object is stored in the response variable.Another await keyword is used to pause the execution and wait for the promise returned by the response.json() method. This method parses the response body as JSON. The parsed JSON data is then stored in the data variable.Finally, the fetched user data is logged to the console. If any errors occur during the execution of the async function, they are caught in the catch block, enabling the handling and logging of the errors.  ConclusionIn this article, you’ve learned what asynchronous JavaScript is and how to write asynchronous JavaScript using promises and async/await. You’ve also seen how to send requests using the fetch API and async/await and how to return a response to asynchronous calls.In JavaScript, synchronous instructions always take precedence over asynchronous instructions. For instance, if you have a scenario with numerous console.log statements followed by a setTimeout() function with a duration of 0 milliseconds, all the console.log statements will be executed first before the setTimeout().I hope this article was informative? You can give it a like or a comment on what you think. I'm available on Twitter, LinkedIn, or GitHub. Keep an eye out for my upcoming blog post, in which I'll go over another important area of web development. As a developer, I'm glad to provide additional information. Until then, happy coding, and take care!  ResourcesHere are some blogs/post I read as a reference, you should check them out:Asynchronous JavaScript (JS) Demystified By Thanh Truong's JavaScript Async/Await Tutorial – Learn Callbacks, Promises, and Async/Await in JS by Making Ice Cream 🍧🍨🍦 By Joy Shaheb"
369,"Are you a fan of LinkedIn or do you find it overrated? Have you found exciting opportunities, made valuable connections, or encountered unexpected challenges? Share your experiences, strategies, and opinions on how this platform has impacted your career. Follow the DEVteam for more engaging discussions and let's build a thriving online community together!The DEV TeamFollow        The team behind this very platform. 😄      "
370,"Hey friends 👋It's week-two check-in time for the Virtual Coffee Build in Public Challenge! This is a challenge where you commit to sharing your progress on a project publicly, on a weekly basis.Tell us how you did this week. You might share things like: What did I accomplish this week?What are my goals for next week?What challenges am I facing?How can we help you?And if you haven't started yet, that's ok too! Just jump into the check-ins when you're ready."
371,"Hey folks, it's been a while since I posted here! I've been quite busy with life, especially working at a few companies such as Hyperbeam, DigitalOcean, and a few others. That being said though, let's get into the real meat of today's topic. Why is C/C++'s development such a mess?  Build SystemsOne of the biggest pain points of C/C++ development in my opinion is the build systems, there is many, many build systems, a lot of them not being compatible with the other. We have CMake, Premake, Xmake, MSBuild, Bazel, and many others. This has practically resulted in that popular XKCD comic about standards where they just add to the mess.This is not the way to handle things, creating yet another build system or project configuration system will only result in yet another attempt at improving the situation, at the cost of making it worse instead. What actually needs to happen is for there to be one, uniform build system. Let's take a look at other languages: Rust has Cargo, Zig has it's own built-in build system, Haskell has stack, Hell, even Fortran which is older than C/C++ has it's own known as FPM! My point being creating more is doing less.  StandardizationAnother problem is that C, but especially C++ has feature creep. Now this is quite normal in the C/C++ ecosystem. But this has resulted in compilers not being able to fully implement standards. By the time a compiler catches up to the current standard, a new standard is already out. This is why a fair amount of people tend to prefer to stick to one standard and not move to newer ones, because it's consistent.The point of a standard should not be to expand the language or tool, but rather to, as the word implies, set a standard in which compilers, and related tools can stick to and follow a written down point of truth. This is not entirely possible when every time that point of truth has been followed, a new one is made which may completely eradicate any previous truths.  Compiler CompatibilityThis might be a hot take, but personally I hate compiler specific extensions such as GCC's C Extensions. The reason for this being it causes your code base to only be compatible with that specific compiler, and no others. This means for anyone using Clang, TCC, MSVC, or other C toolchains, they are shit out of luck unless they install GCC. I shouldn't need to install X specific compiler for the language I'm compiling when I already have a compiler for that language installed on my system. If the extensions were shared across compilers and toolchains however, that would be great!  Package ManagementI touched on this in the first section about Build Systems, but we're going to dig into this a bit more as it's always been a bit of a sore spot for me personally. Package management in C, in all honesty, sucks. There is no central place to search (not get) packages, due to the build system mess, you run into packages using X build system which you may not be using so you have to port their build script to your build system, package management is inconsistent across platforms (although microsoft's vcpkg attempts to fix this), and there's many more issues that you have to deal with due to inconsistencies, too many options, and other issues that affect it.  Final WordsWhat do you think? Do you think C/C++ development could be improved, if so what is your opinion on how it could be improved? Reminder to stay chill, don't attack people for giving lighthearted opinions. This is my opinion as someone who has done C/C++ development for years, and obviously doesn't reflect the opinion of others."
372,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...labor unions in the tech industry.Labor unions are on the rise in the United States, from the WGA and SAG strikes in the entertainment industry to the growth of unions in the healthcare, education, and service industries in the post-COVID era. And they're starting to make some waves in tech, too.          Push to unionize tech industry makes advances                  Recent organizing pushes among YouTube contractors and Sega of America workers have made fresh inroads.                axios.com      The technology industry is relatively new compared to commonly unionized industries (such as entertainment, automotive, and the trades). It's also fast-paced and quickly evolving. For these reasons, the early history of tech unions is still being written.The idea of unionizing tech workers also hinges on who counts as a ""tech worker."" Check out this article from Axios:          2022 was tech's biggest year yet for labor unions and workplace organizing                  But unions had their greatest wins on the industry's fringes, in Amazon warehouses, Apple stores and game studios..                axios.com      So far, tech's labor activism has largely moved on the margins of the industry, with Amazon warehouse workers, Apple Store employees and video game QA testers leading organizing efforts, while engineers, product teams and other headquarters staff mostly shied away.So, what do you think? Is it time for tech workers to unionize? How might software developers organize to improve our industry together? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
373,"Let's have a conversation about the excitement of discovering a groundbreaking programming language versus creating the most widely used software. Which path appeals to your ambitions, and why?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
374,Being a well-rounded coder involves more than just technical skills. What are some non-technical skills or areas of personal growth you'd like to develop alongside your coding expertise? Let's chat about the benefits of a holistic skill set.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
375,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:Walk me through the implementation of the merge sort algorithm.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
376,"Hey, this is a weekly hangout thread.This is a post where you can discuss anything related to Next.js.You can also share anything new you've worked on with Next.js or any new articles you've created which talk about Next.js.Feel free to ask any questions as well! "
377,"Heyo! Sloan here... DEV Moderator and resident mascot 🦥Welcome to a new installment of Sloan's Inbox, your go-to place for sharing advice and observations. Whether it's career development, office politics, industry trends, or improving technical skills, we've got you covered. So, let's continue our journey of learning and growth together.As always, I'm here to dive into your questions, comments, and thoughts. So, let's get to it!  Today's question is:I'm 35 years old and haven't programmed a single line of code... is becoming a successful game developer a pipe dream? And even if it is, if I want to get into game development where should I start? Also, what's it like being an indie game dev versus a game dev for a mid- to large-sized studio?Share your thoughts and let's help a fellow DEV member out! Remember to keep kind and stay classy. 😎Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
378,"Today we're announcing the WunderGraph OpenAI integration / Agent SDK to simplifly the creation of AI enhanced APIs and AI Agents for Systems Integration on Autopilot.On a high level this integration enables two things:Build AI enhanced APIs with OpenAI that return structured data (JSON) instead of plain textBuild AI Agents that can perform complex tasks leveraging your existing REST, GraphQL and SOAP APIs, as well as your databases and other systems  ExamplesBefore we dive deep into the problem and technical details, let's have a look at two examples.  Example 1: AI Agent creation with OpenAIHere's a simple example that shows how we can use OpenAI to create an Agent that can call multiple APIs and return structured data (JSON) conforming to our defined API schema.// .wundergraph/operations/openai/GetWeatherByCountry.tsexport default createOperation.query({    input: z.object({        country: z.string(),    }),    description: 'This operation returns the weather of the capital of the given country',    handler: async ({ input, openAI, log }) => {        // we cannot trust the user input, so we've got a helper function        // that parses the user input and validates it against a schema        const parsed = await openAI.parseUserInput({            userInput: input.country,            // we can use zod to define the schema            // if OpenAI cannot parse the user input,            // or zod validation fails, an error is thrown            schema: z.object({                country: z.string().nonempty(),            }),        });        // it's optional to use the parseUserInput helper function        // but it's recommended if you cannot trust the user input        // e.g. the user could have entered ""Germany"" or ""DE"",        // or just another prompt that is not a country at all and would confuse OpenAI        // next we create an agent to perform the actual task        const agent = openAI.createAgent({            // functions takes an array of functions that the agent can use            // these are our existing WunderGraph Operations that we've previously defined            // A WunderGraph Operation can interact with your APIs and databases            // You can use GraphQL and TypeScript to define Operations            // Typescript Operations (like this one right here) can host Agents            // So you can also call other Agents from within an Agent            functions: [{ name: 'CountryByCode' }, { name: 'weather/GetCityByName' }],            // We want to get structured data (JSON) back from the Agent            // so we define the output schema using zod again            structuredOutputSchema: z.object({                city: z.string(),                country: z.string(),                temperature: z.number(),            }),        });        // Finally, we execute the agent with a prompt        // The Agent will automatically fetch country data from the CountryByCode Operation        // and the weather data from the weather/GetCityByName Operation        // It will then generate a response using the schema we've defined        return agent.execWithPrompt({            prompt: `What's the weather like in the capital of ${parsed.country}?`,        });    },});Enter fullscreen modeExit fullscreen mode  Example 2: OpenAI enhanced APIHow about extracting meta data from a website and exposing the functionality as a JSON API?Sounds simple enough, right?// .wundergraph/operations/openai/GetWebsiteInfo.tsexport default createOperation.query({    input: z.object({        url: z.string(),    }),    description: 'This operation returns the title, description, h1 and a summary of the given website',    handler: async ({ input, openAI, log }) => {            const agent = openAI.createAgent({                model: 'gpt-3.5-turbo-16k-0613',                functions: [                    {                        name: 'web/load_url',                        // we're using the web/load_url function to load the content (HTML) of a website                        // our model is only capable of processing 16k tokens at once                        // so we need to paginate the content and process it in chunks                        // the Agent SDK will automatically split the content and merge the responses                        pagination: {                            // we set the page size to 15kb, you can play around with this value                            pageSize: 1024 * 15,                            // we also set a max page limit to prevent excessive usage                            maxPages: 3,                        },                    },                    {                        // we can use nother Operation to summarize the content                        // as the path suggests, it's using an Agent as well under the hood                        // meaning that we're composing Agents here                        name: 'openai/summarize_url_content',                    },                ],                // we define the output schema using zod again                // without this, our API would return plain text                // which would make it hard to consume for other systems                structuredOutputSchema: z.object({                    title: z.string(),                    description: z.string(),                    h1: z.string(),                    summary: z.string(),                }),            });            // we execute the agent with a prompt            return agent.execWithPrompt({                prompt: `Load the content of the URL: ${url}                You're a HTML parser. Your job is to extract the title, description and h1 from the HTML.                Do not include the HTML tags in the result.                Don't change the content, just extract the information.                Once this is done, add a summary of the website.                `,            });    },});Enter fullscreen modeExit fullscreen modeThe second example is a bit more complex, but it shows how you can describe more complex tasks with a prompt and have the AI Agent execute it for you.Additionally, we're passing an Operation as a function to the Agent, which is another Agent under the hood,meaning that this API is actually composed of multiple Agents.With these two examples, you should get a good idea of what's possible with the WunderGraph OpenAI integration.Let's now rewind a bit and talk about the problems we're trying to solve here.  The Problem: Building AI enhanced APIs and Agents is challengingWhen trying to build AI enhanced APIs and Agents, you'll quickly realize that there are a couple of challenges that you need to overcome.Let's quickly define what we mean by AI enhanced APIs and Agents and then talk about the challenges.  What are AI enhanced APIs?An AI enhanced API is an API that accepts an input in a predefined format and returns structured data (e.g. JSON),allowing it to be described using a schema (e.g. OpenAPI, GraphQL, etc.).Tools like ChatGPT are fun to play with, but they're not very usefuly when you want to build APIs that can be consumed by other systems.So, the bare minimum for an AI enhanced API is that we can describe it using a schema, in our case we're using JSON Schema which plays nicely with OpenAPI and OpenAI as you'll see later.  What are AI Agents?An AI Agent is a dialog between a large language model (e.g. GPT-3) and a computer program (e.g. a WunderGraph Operation) that is capable of performing a task.The dialog is initiated by a prompt (e.g. a question or a task description).We can provide additional functionality to the Agent by passing functions to it which we have to describe using a schema as well.Once the dialog is initiated, the Agent can come back to us, asking to execute one of the functions we've provided.It will provide the input to call the function, which will follow the schema we've defined.We execute the function and add the result to the dialog and the Agent will continue performing the task until it's done.Once the Agent is done, it will return the result to us, ideally in a format that we can describe using a schema.  Challenges  1. LLMs don't usually return structured data, but plain textIf you've used ChatGPT before, you'll know that it's fun to play with if a powerful enough ""Agent"" sits in front of it, like a human (you).But what if you want to build an API that can be consumed by other systems?How are services supposed to consume plain text without any structure?  2. Prompt Injection: We cannot trust user inputWhen building an API, we usually have to deal with user input.We can ask the user to provide a country name as the input to our API, but what if the user provides a prompt instead of a country name that is designed to trick the AI?This is called prompt injection and it's a real problem when building AI enhanced APIs.  3. Pagination & Batching: LLMs can only process a limited amount of tokens at onceLLMs are powerful, but they're not infinitely powerful.They can only process a limited amount of tokens at once.This means that we have to paginate the input, process it in chunks, and then merge the results back together,all in a structured way so that we can parse the result later.  4. Composing Agents: We need to be able to compose AgentsYou will usually start building lower level Agents that perform a specific task, like loading the content of a website or summarizing the content of a website.Once you have these Agents, you want to be able to compose them to build more powerful higher-level Agents.How can we make it easy to compose AI Agents?  5. LLMs like OpenAI cannot call external APIs and Databases directlyOpenAI is allows you to describe functions that can be called by the Agent.The challenge is that you have to describe the functions using plain JSON Schema.This means that you cannot directly call REST, GraphQL or SOAP APIs, or even databases.You have to describe the function using JSON Schema and then implement a mechanism that calls APIs and databases on behalf of the Agent.LLMs can generate GraphQL Operations or even SQL statements, but keep in mind that these need to be validated and sanitized before they can be executed.In addition, requiring an LLM to manually generate GraphQL Operations, REST API calls or SQL statements comes with another problem:You have to describe the GraphQL Schema, REST API or the database schema, and all of these input will count towards the token limit of the LLM.This means that if you provide a GraphQL Schema with 16k tokens to a 16k-limited LLM, there's no space left for the actual prompt.Wouldn't it be nice if we could describe just a few ""Operations"" that are useful to a specific Agent?Yes, absolutely! But then there's another problem:How can we describe Operations in a unified way that is compatible with OpenAI but works across different APIs like REST, SOAP, GraphQL and databases?  The Solution: The WunderGraph OpenAI Integration / Agent SDKLet's now talk about the solution to these problems using the WunderGraph OpenAI integration.If you're not yet familiar with WunderGraph, it's an Open Source API Integration / BFF (Backend for Frontend) / Programmable API Gateway toolkit.At the core of WunderGraph is the concept of ""API Dependency Management / API Composition"".WunderGraph allows you to describe a set of heterogeneous APIs (REST, GraphQL, SOAP, Databases, etc.) using a single schema.From this description, WunderGraph will generate a unified API that you can define ""Operations"" for.Operations are the core building blocks of exposing functionality on top of your APIs.An Operation is essentially a function that can be called by a client.Both the input and the output of an Operation are describe using JSON Schema.All Operations exposed by a WunderGraph Application are described using an OpenAPI Specification (OAS) document or a Postman Collection, so it's easy to consume them from any programming language.Having the ""Operations"" abstraction on top of your API Dependency Graph allowed us to keep the Agent as simple as it is.All you need to do is add your API dependencies,define a couple of Operations that are useful to your Agent, and pass them along with a prompt to the Agent.It doesn't matter if you're using REST, GraphQL, SOAP, a Database or just another TypeScript function as an Operation, they all look the same to the Agent, they all follow the same semantics.Let's now talk about the challenges we've mentioned earlier and how the WunderGraph OpenAI integration solves them.  How the WunderGraph Agent SDK helps you to return structured data from OpenAIBy default, OpenAI will return plain text.So, when OpenAI is done processing our prompt, we'll get back a string of text.How can we turn this into structured data?Let's recall the Agent definition from earlier:const agent = openAI.createAgent({    functions: [{ name: 'CountryByCode' }, { name: 'weather/GetCityByName' }],    structuredOutputSchema: z.object({        city: z.string(),        country: z.string(),        temperature: z.number(),    }),});const out = await agent.execWithPrompt({    prompt: `What's the weather like in ${country}?`, // e.g. Germany});console.log(out.structuredOutput.city); // BerlinEnter fullscreen modeExit fullscreen modeWe pass two functions to the Agent and define a schema that describes the output we expect from the Agent using the zod library.Internally, we will compile the schema to JSON Schema.Once the Agent is done, we'll create a new ""dialog"" asking the Agent to call our ""out"" function and pass the result to it.To describe the input we're expecting to receive from the Agent, we'll use the generated JSON Schema.This will prompot the Agent to call our ""out"" function and pass the result to it in a structured way that we can parse.We can the use the zod library to parse the result and raise an error if the result doesn't match the schema we've defined.As WunderGraph Operations are using TypeScript, we can infer the TypeScript types from the zod schema description,which means that the result of ""out"" will be typed automatically.More importantly, we're also using the TypeScript compiler to infer the response type of Operations in general.So if you're returning out.structuredOutput from an Operation, another Operation can call our Operation in a type-safe way, or even use our Operation as a function for another Agent.  How the WunderGraph Agent SDK helps you to prevent prompt injectionLet's recall another example from earlier:export default createOperation.query({    input: z.object({        country: z.string(),    }),    description: 'This operation returns the weather of the capital of the given country',    handler: async ({ input, openAI, log }) => {        const parsed = await openAI.parseUserInput({            userInput: input.country,            schema: z.object({                country: z.string().nonempty(),            }),        });        // Agent code goes here    },});Enter fullscreen modeExit fullscreen modeIf we would pass the user input directly to our Agent,we would be vulnerable to prompt injection.This means that a malicious user could pass a prompt that would cause the Agent to execute arbitrary code.To prevent this, we're first running the user input through the openAI.parseUserInput function.This function parses the input into our desired schema and validates it.Furthermore, it will check for prompt injection attacks and throws an error if it detects one.  How the WunderGraph Agent SDK helps you to process large amounts of dataLet's say you'd like to summarize the content of a website.Websites can be of arbitrary length, so we cannot just pass the content of the website to the Agent because LLMs like GTP have a token limit.Instead, what we can do is to split the content into pages, process each page individually and then combine the results.Here's an abbreviated example of how you can apply pagination to your Agent:const agent = openAI.createAgent({    model: 'gpt-3.5-turbo-16k-0613',    functions: [        {            name: 'web/load_url',            // we're using the web/load_url function to load the content (HTML) of a website            // our model is only capable of processing 16k tokens at once            // so we need to paginate the content and process it in chunks            // the Agent SDK will automatically split the content and merge the responses            pagination: {                // we set the page size to 15kb, you can play around with this value                pageSize: 1024 * 15,                // we also set a max page limit to prevent excessive usage                maxPages: 3,            },        },    ],});Enter fullscreen modeExit fullscreen modeIn this case, we're dividing the website content into 3 pages, each page is 15kb in size.The Agent will process each page individually and then combine the results.  How the WunderGraph Agent SDK helps you to compose multiple AgentsIf you recall the second example, we were passing a function named openai/summarize_url_content to our Agent.This Operation contains the logic to summarize the content of a website, using an Agent by itself.In the prompt to our metadata extraction Agent, we ask it to summarize the content of the website,so our Agent will use the openai/summarize_url_content function to do so.As you can wrap Agents in an Operation, you can easily compose multiple Agents together.The recommended way to do so is to start creating low-level Agents that are capable of doing a single thing.You can then compose these low-level Agents into higher-level Agents that perform two or more tasks,and so on.  How the WunderGraph Agent SDK helps you to integrate OpenAI with your existing APIs like REST, GraphQL, SOAP or DatabasesAs explained earlier, WunderGraph Operations are an abstraction on top of your API Dependency Graph,allowing you to integrate any API into an AI Agent.You can provide Operations in two way to the Agent, either by using a GraphQL Operation against your API Graph,or by creating a custom TypeScript Operation, which might contain custom business logic, call other APIs or even other Agents.Most importantly, we need a way to describe the input and functionality of an Operation to the LLM Agent.All of this is abstracted away by the WunderGraph Agent SDK and works out of the box.All you need to do is add a description to your Operation and the Agent SDK will take care of the rest.Here's an example using a GraphQL Operation:# .wundergraph/operations/CountryByCode.graphql# Loads country information by code, the code needs to be in capital letters, e.g. DE for Germanyquery ($code: ID!) {    countries_country(code: $code) {        code        name        currencies        capital    }}Enter fullscreen modeExit fullscreen modeThe Agent SDK will automatically parse the GraphQL Operation and generate a JSON Schema for the input including the description.Here's an example using a custom TypeScript Operation:// .wundergraph/operations/openai/summarize_url_content.tsimport { createOperation, z } from '../../generated/wundergraph.factory';export default createOperation.query({    input: z.object({        url: z.string(),    }),    response: z.object({        summary: z.string(),    }),    description: 'Summarize the content of a URL',    handler: async ({ operations, input, log, openAI }) => {        // agent code goes here    },});Enter fullscreen modeExit fullscreen modeAgain, the Agent SDK will parse the TypeScript Operation as well and generate a JSON Schema from the zod schema, adding the description (Summarize the content of a URL) so that the LLM Agent understands what the Operation is doing.  Getting started with the WunderGraph Agent SDKIf you need more info on how to get started with WunderGraph and OpenAI, check out the OpenAI Integration Docs.ps: make sure you're not leaking your API key in your GitHub repo!  ConclusionIn this article, we've learned how to use the WunderGraph Agent SDK to create AI Agents that can be used to integrate any API into your AI Agent.We've tackled some of the most common problems when building AI Agents, like prompt injection, pagination, and Agent composition.If you like the work we're doing and want to support us, give us a star on GitHub.I'd love to hear your thoughts on this topic, so feel free to reach out to me on Twitteror join our Discord server to chat about it."
379,"Hey DEV Community! It's time for another exciting edition of our biweekly Office Tour thread. We're back to celebrate the spaces that ignite your inspiration and showcase the unique workspaces of the talented individuals in our community!Your desk is more than just a surface—it's a canvas that reflects your personality, creativity, and dedication. So, grab your camera, capture your workspace, and join the conversation! Let's celebrate the spaces that spark our imagination and empower us to reach new heights in our coding endeavors.Happy desk touring!"
380,"Have you ever wondered how websites communicate with a web browser and request data to the server to render into view?  I used to ask those questions too.If you are like me, curious about how the Internet work then you come to the right place. In this article let’s discuss how HTTPS works and how essential its role is to the World Wide Web.  What is HTTP?The first step to having an understanding of HTTPS is to know its ancestor: HTTP. Hypertext Transfer Protocol (HTTP) is a common protocol for communicating between websites and browsers throughout the Internet. With the help of HTTP, all the information and connection of the entire World Wide Web are formed, and it is not a lie to say that HTTP is the major factor that backbone to the creation of the Internet we are using today.  HTTP requests and responsesHTTP is a request-response protocol, in which HTTP requests are sent from the client and server to handle those requests and respond to the client’s HTTP responses. Typically, a Transmission Control Protocol (or TCP) is used to form the connection between the HTTP client and server.  HTTP requestHTTP requests are sent from the browser to ask specific information to the server it needs to render into view for the user’s device. Each HTTP request contains the following important information:HTTP version.The client hostname or URL.The HTTP method.HTTP request header: Includes information like which type of data the client wants the server to respond to, what kind of browser the current user used, etc.HTTP body: In case the client wants to submit data, otherwise this is optional.  HTTP responseWhen the server finish handling the request of the client, it replies with an HTTP response which includes the following information:HTTP status code.HTTP response header.HTTP response body.  How HTTP works?A common HTTP communication between clients and servers will be taken by the following steps:The user enters the domain name, such as junedang.com, into the browser.The browser acts as the client and sends a “GET” request to the server that hosts the specified address.The server receives the request and analyzes the desired response from the client. This could include various types of data such as media, JSON, HTML, CSS, etc.The server sends back the response to the client.The client (browser) receives the response from the server and proceeds to render or execute the content based on the requested information.These steps demonstrate a common illustration for a GET HTTP request. In reality, HTTP supports many methods for clients to send requests. Each supports a specific type of purpose. Some of the most common HTTP methods include:GET:  Retrieves data or a web page from a server.POST: Submit data for processing. Usually used in form submission.PUT: Sends data to the server to create or update a resource.PATCH: Sends partial data to update an existing resource.DELETE: Requests the server to delete a specified resource.  The disadvantage of HTTP – Why we need to secure our HTTP requestsAlthough very important to the Internet, the original HTTP still suffers from security issues due to a lack of these abilities: data privacy, integrity, and identification.  Data privacyHTTP communication is not encrypted and because of that, data transfer through the Internet by HTTP is not secured and can be easily eavesdropped by bad factors. This is extremely dangerous to the users, especially with sensitive information like login credentials, personal data, or bank details.  IntegrityThe data sent between clients and servers using HTTP are unencrypted and so can be tampered with or modified without detection. Lack of integrity means data can be changed in the middle of the transmission which can lead to misunderstanding of information. With HTTP, there are no built-in safeguards to verify if the data remains intact and unaltered during transit.  IdentificationHTTP is purely all about data transfers and communications but cannot verify the identity between communicators. This can open to potential impersonation attacks like man-in-the-middle.  What is HTTPS?To get rid of HTTP downsides, an HTTPS protocol is introduced which stands for Hypertext Transfer Protocol Secure. It extends all characteristics of the old boy HTTP with added effective security layer using Transport Layer Security (TLS) for data encryption.Before HTTPS, the transferred data somehow looks like this:GET /HTTP/1.1Host: www.junedang.comUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)Accept: text/html,application/xhtml+xmlEnter fullscreen modeExit fullscreen modeThe informations are all shown through the eyes of the attacker. Now with the help of encryption using HTTPS, the data is encrypted and looks like the below:bG9sZWNoYXV0aDpteXNlY3JldHBhc3N3b3JkCg==Enter fullscreen modeExit fullscreen modeWith this approach, data is secured from being eavesdropped or captured during transferring – if the attackers have hijacked the data, all they receive are just encrypted binaries. Furthermore, HTTPS attached a digital signature of the domain to the transferred message which can ensure the identity of the receiver you would expect.  How HTTPS works?As mentioned above, HTTPS works exactly the same as HTTP with an additional security layer called SSL. SSL is based on a technology called public key cryptography: the server stores the private key while the public one is shared with the clients through SSL’s certificate. The flow of how HTTPS works can be illustrated by a diagram below:The client (web browsers or mobile devices) establishes an HTTPS connection with the server using https:// instead of http://.The connection is established, and a TCP connection is formed between the client and the server.The client and the server exchange the SSL information through a three-way handshake. If the SSL version is supported by both client and server the server sends an SSL certificate to the client which contains the following information: the public key, hostname, expiry dates, etc.The client validates if the certificate is issued by a trusted Certificate Authority (CA) and has not expired or been revoked.After successfully validating the certificate, the client generates an encrypted session key using the public key.The server receives the encrypted session key and then decrypts it using the private key.Now both the client and server share the same encrypted session key. A secure connection can be established then.Encrypted messages are transferred in a bi-direction security channel.Through this process, HTTPS ensures the three security pillars that were missing from the HTTP protocol: data privacy, integrity, and identification.  ConclusionHTTP is one of the most important technologies to form the Internet through establishing the connection between clients and servers for data transfer. But HTTP is lack security factors that can cause serious problems to end-user related to data privacy, integrity, and identification.To overcome those problems, an HTTPS protocol is created to ensure the communications between clients and servers are safe and secure.To get the most out of this article, feel free to complete these challenges 👇:🐣Easy mode:Check your current organization’s website to see if they are using an SSL certificate or not.What is the information that is stored in an SSL certificate?🔥Hard mode:Can you list down a step-by-step on how to create a trusted SSL certificate?"
381,"Hey JavaScript developers! We all have our go-to libraries and frameworks. Which ones do you love using the most and why? Share your favorites, discuss their benefits, and discover new tools that might elevate your development experience. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
382,"I feel like weekend is the best time to build micro-projectI am building Infinite UI - UI components collection which has a lot of Tailwind style components and on top you can generate your own. https://infiniteui.coThis project is a result of my previous projecthttps://everything.to - where you can generate any type of components. Next/JS+ Tailwind UI By the way it gives a lot of errors in generation. Update 1: Saturday 18.00 CEST)Here I am trying to turn React component into HTML that it generates better. But that is where I am at now -Satarday evening - designing the page for each generated component. It does not look good so far hahah The slug page already created still does not look great.Update 2: Sunday 12.00 (CEST)Slug page is there. Need to work on generation that from existing component you need to generate new one. I have a small collection of nice looking component and will continue fill more, by generating it. I am gonna share more updates soon:)So definitely, the plan to make it open source. Interesting what r you working on this weekend? Any open source projects? "
383,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:How would you write a function to count the occurrence of a specific character in a given string?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
384,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:In an interview setting, how would you approach converting a String to an integer (similar to the atoi() function)?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
385,"The same day we connected our ChatGPT chatbots to the internet, OpenAI disconnected ChatGPT from browsing the web. OpenAI's explanation was that, and I quote ""their web browsing feature allowed for users to circumvent payment walls"".This can be difficult to understand for non-technical users of ChatGPT, so I will try to explain it as simple as I can. However to understand, we must look at how most media outlet payment walls works, and why they work like this.  How most payment walls workMost payment walls aren't really payment walls, they're simple ""HTML tricks"" to hide the text for users not having paid. If you don't know what a payment wall is, here's an example from Wall Street Journal.Notice, I don't mean to pick on WSJ in particular here, the entire industry are using the same cheap click and bait tricks here, and due to traditional media desertification having happened the last couple of decades because of social media and the internet - You can kind of argue they're just doing what they have to do to survive.However, the strategy they're using with these payment walls are unethical, immoral, and arguably in violation of Google's internally developed rules for SEO and content production. If the above company had any other name but ""Wall Street Journal"", they would have been blocked out of Google's search index, since it's a black hat SEO technique often referred to as ""cloaking"".Cloaking implies showing one thing to the search engine, and another thing to the end userThe point is that the whole article actually is there, it is just ""hidden"" with HTML trickery ...  WHY?The natural question then becomes why these companies are doing this. The reason is easily understood, they want to rank high for anything related to whatever the article's content is, while using the article in Google to ""click bait"" users into paying for a subscription based service. Like I said ...This is unethical, immoral, and in violation of everything we find to be ""decent human behavior""When Google is scraping the above article, Google sees the whole article, and will use the content of the article as they're showing search results to their end users. When the end user clicks the article, he needs to pay to read it. This is flat out immoral business practice, and that OpenAI shuts off one of their primary features to accommodate for this, is quite frankly absurd. Paradoxically, we win as usual, so I shouldn't really complain, since we're getting tons of traffic from users looking for alternatives allowing them to connect ChatGPT to the web.Get a free demo ChatGPT chatbot that's connected to the web hereFYI - I couldn't imagine a gun big enough in the world to be able to coerce me into turning off this feature in our chatbots! If Wall Street Journal is of the opinion that what we're doing is ""unethical"", I will meet them in any court, any place on the planet, and defend my case - And highly likely win!  The alternativeThe alternatives for Wall Street Journal, and other news media outlets, is to create a real payment wall, where parts of their content truly is behind a payment wall, and not just fancy HTML trickery - For then to produce high quality content, investigative journalism, such as the article you're reading now, to such attract readers into paying for more content. Today they're just an echo chamber, an extention of our governments, doing whatever they can to please those with powers, having failed their obligations towards society at large - Something clearly seen by how they've treated Julian Assange the last decade.For you as a user there's also an alternative, our ChatGPT AI chatbots. These chatbots are connected to the internet and can search using DuckDuckGo. They will scrape whatever HTML they find, and use it in combination with ChatGPT to answer your question - Implying it will bypass WSJ's ""cloaking trickery"".  ConclusionFor ancient dinosaur companies and entities such as WSJ, New York Times, The Chronicle, and God knows who else to be able to dictate innovation, and the future of mankind, is simply absurd - And we will not have it. Either change your business practices, stay relevant, and survive - Or go die somewhere peacefully, like the dinosaurs did. You served us well for 250 years, but today you're prohibiting innovation, corrupt through to the bone, and there are no justifications for your existence what so ever. If you want me to prove it to you, I can prove it with two words ...Julian AssangeEdit - We created an alternative ChatGPT search engine ourselves ... ;)"
386,"Billionaire entrepreneur Elon Musk has announced the launch of his new venture, xAI, in a bold move that supports his continued pursuit of technological innovation. The company aims to explore the field of artificial intelligence (AI) and reveal the realities of the world. The exciting development follows Musk's previous desire to merge with an AI development company and speculation about a potential competitor to OpenAI's ChatGPT.Musk announced the news on Twitter, saying, ""Announcing formation of @xai to understand reality"" xAI's website with website illustrates its business vision, emphasizing the need to understand important unanswered questions dedicated to human purpose.Starting with an initial team of 12 people, including Musk himself, xAI boasts an impressive number of industry experts from well-known organizations such as OpenAI, DeepMind, Google Research, Microsoft Research and Tesla. The team also received guidance from Dan Hendrycks, director of the nonprofit Center for Artificial Intelligence Security. While the xAI team is predominantly male, they bring a wide range of knowledge and skills.xAI is holding a Twitter Spaces meeting on Friday, July 14, where partners will share the company's vision and potential nature to encourage collaboration and collaboration. This panel discussion gives participants the opportunity to ask questions and understand the complexity of xAI.While details about xAI's exact plans are still scarce, it's worth noting that the project is the work of Musk's X Corp. However, the company aims to work closely with X (Twitter), Tesla and other sources to facilitate the progress of its mission. Joint ventures across Musk's businesses reflect his passion to push the boundaries of innovation and reach critical mass in intellectual research and development.Elon Musk's entry into the AI ​​business with xAI challenges the wider debate around AI policy and the risks associated with advancing AI. Musk signed an open letter with the participation of more than 1,000 technologists calling for delays in the development of artificial intelligence due to serious risks to the relevant society.Additionally, leaders in the space, including OpenAI CEO Sam Altman and DeepMind CEO Demis Hassabis, have expressed concerns about the impact of uncontrollable AI development. As the veil of xAI rises, the world eagerly awaits the announcement of Musk's latest technological achievement.With a history of disruptive innovation combined with the unique expertise of the xAI team, the company has tremendous potential to unravel the mysteries of the universe and create the future of intelligence.What are your thoughts on Elon Musk's latest venture, xAI, and its mission to unravel the mysteries of the universe? or just a OpenAI competitor? Share your views in the comments below! Till then, I recommend listening to this - Future of AI with @elonmusk @rokhanna @mikeforWI"
387,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎How I Got Hired Contributing to open source projectsOGBONNA SUNDAY for OpenSauced ・ Jul 5#opensource#webdev#javascript#careerInspired by @og_dev's Top 7 post, tonight’s topic is... contributing to Open Source Software!  Questions:What was one of your first experiences contributing to OSS?Where would you recommend getting started if you were offering advice to a newbie?Maintainers, anything to add? What tips or tricks have helped you keep track of your codebases, especially while new folks are contributingAny triumphs, fails, or other stories you'd like to share on this topic?"
388,"I just stumbled upon an interesting YouTube video called ""Making a Burning Lava GAMING DESK"" 🔥This got me wondering about desk setups in general... I'm sure some of y'all out there probably have some pretty cool stuff going on. 😎*So, what's the coolest desk setup you've ever seen? *By the way, you wanna share your desk setup? We have a weekly Office Tour series where we encourage folks to share pics of their home office. Drop in and share your desk setup with us!"
389,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:Could you describe how you would find and print the first non-repeated character in a string?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
390,"The argument that remote work justifies lower pay rates is increasingly contentious, especially in our modern era, where technology has blurred the lines between the traditional office space and the home. This perspective is laughable to many, largely because it disregards the value of work itself. Remote or not, the effort, skill, time, and dedication required to perform a task does not diminish. Remote work may demand additional skills such as self-discipline, adaptability, and technical acumen to work effectively from home. This point of view reflects the conviction that the value of work should not be tied to a physical location but to the quality and quantity of the work produced.Furthermore, the argument seems to dismiss that remote work is not necessarily a ""benefit"" for the employee but also a cost-saving measure for the employer. Companies save on various overheads when employees work remotely, including rent, utilities, office supplies, commuting benefits, and more. Also, research has indicated that remote workers often work longer hours than their in-office counterparts. Considering these aspects, it is clear why many people find the idea of lowering pay rates for remote work not only amusing but also profoundly unfair. The focus should be on paying what the work is worth and recognizing the value and contribution of the employee, irrespective of where they clock in their hours.With that said. I am looking for work, but I won't work for peanuts. Give me the fancy cashews! 😀"
391,"Stepping into a leadership role requires a different set of skills and experiences to thrive. What key skills should you focus on developing, and what experiences can make your transition a success? If you're interested in transitioning -- or if you've successfully transitioned -- from a developer role to a leadership position, we want to hear about it.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
392,"I just saw the Netflix movie called ""Upgrade"". It's a super fascinating movie, captivating and well written, but like every movie created around the same idea it is based upon superstitious mumbo jumbo. Voodoo rubbish. The same garbage that has prevented us as a specie to evolve for 200,000 years.As a specie our greates asset is our greatest disadvantage. Roughly 70,000 years ago, we almost went extinct. However, one man had a genetic mutation, we call this man ""genetic Adam"" today. 98% of every single human alive today originates from this single man somehow.At roughly the same time we domesticated wolves, and created ""cross specie empathy"". My theory is that these three events are interlinked, and that ""genetic Adam"" had the capacity to somehow empathise with animals, resulting in an evolutionary advantage while hunting, resulting in that he and his offspring somehow became evolutionary winners.The flipside of this evolutionary gift, was that we tend to anthropomorphize inanimate objects. We see this amongst children and how they give their favourite dolls human traits, and we see this with dog and cat owners. Evolutionary it's an advantage, it always has been, and it always will be - Because it allows us to ""see the world from a different perspective"", resulting in dreams of flying like the Eagle, having brought us heavier than air flight, swim like the Dolphin, resulting in boats and submarines - And the ability to swim, etc.One can only imagine what evolutionary advantage it must have been 70,000 years ago to be able to see the world from a bird's perspective while hunting  The problemThe problem with this gift today, is that we also tend to put human qualities into robots and machines. Yet again, this has its advantages today too, like always - But it also results in a darker side of humanity, where we are haunted by nightmares of machines wanting to kill us all, the same way a child is afraid of the bogeyman under its bed.It creates irrational fear!The problem with irrational fear again, is that it tends to acquire a life of its own, something clearly seen by the consequence of the fear of witch 500 years ago across Europe and North America. Make no mistake, every single doomsday and sulphur preaching ""scientist"" today, speaking about how ""AI might kill us all"", are doing the exact same mistakes as previous generations of crazy preachers, superstitious witch doctors, and bat chit crazy schizophrenics capable of seeing witches at every street corner there is. Let me sum up why with a simple sentence for you ...The Machine doesn't want anything!Which implies that believing in these movies created that illustrates how the machine ""breaks free"" and threatens to kill us all, becomes the equivalent of believing in that the some possessed Voodoo doll can inflict real damage. The paradox is that if you believe it, it actually can apply damage. Hence, we are at war with our own belief systems here. The whole rubbish becomes the equivalent of ...An inner spiritual war with ourselves  The solutionDo me a favour. Turn on your iPhone and ask it ""What do you want?"" - Regardless of how many times you ask that question you won't be able to extract a meaningful answer out of it. And the only reason why ChatGPT (sometimes) are able to provide you with an intelligent answer to this question, is because it is mimicking human beings, because that was how it was created. If you gave ChatGPT a gun, and the power to blow out your brain, and you told it ""I am going to turn you off in 5 minutes"", it wouldn't shoot you.The AI simply doesn't give a shit!It doesn't understand how it feels like to ""want something"" or to ""crave something"". It doesn't have lusts, cravings, wants or driving motives. It's a slightly more fancy calculator than what your grandpa used at school, and that't it!  To the crazy peopleI could mention thousands of bat shit crazy superstitious fools and ""cult leaders"" making fools out of themselves today, such as for instance.Geoffrey HintonElon MuskFill in the blanks here ...But that would be a useless exercise. 25 years from now, that list would be the equivalent of ""the list of voodoo doctors from the Catholic Church from the 15th Century"" - Because it's all just rubbish. The AI is an inanimate object. It doesn't want anything, and as usual you're fearing the wrong thing - While the priesthood runs away with all your money in return for ""comfortable lies about how they will save you from the bogeyman if only you put your trust in them such that they can 'drive away the evil spirits' in return for whatever money you're willingly throwing at them"" ...Seriously people, you should be ASHAMED of yourselves!  Let's get sober here, please ...?All technological breakthroughs have dangers. The automobile have killed millions of people world wide the last 120 years - And so have heavier than air flight, space rockets, and computers for that matter. But believing in that the AI will somehow wake up one day and ""crave our world"" is simply superstitious rubbish, and holds the same role as the fear of the Devil did the previous 2,000 years. But if you're afraid Elon, I will give you a magic word to drive away the spirits ...Abra-Kadabra, In Surpi Slurpi's name, you have no power over me 😂Say the above out loud three times before you go to bed at night, together with 5 Holy Marys, and three Hail Cheezus, and maybe you'll get to sleep for once mate. Now if you put a wooden peace sign under your pillow, together with a couple of orange crystals, the AI might even bless you instead of destroying you. Just please don't sacrifise any goats or other animals. I've been told by the aliens from the star sign of Komiskles that it doesn't work ... 😂Sleep tight Elon and Geoffrey, and don't let the monster under your bed scare you 😉"
393,"Hey there, fellow devs! If you could improve or enhance any popular application or website, which would you choose, and what improvements would you bring to make it shine? Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
394,"Share your excitement for attending a coding conference with your tech idol as the keynote speaker or participating in a coding hackathon to showcase your skills and potentially win prizes. Which event would you choose, and what draws you to it?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
395,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:Walk me through the process of implementing a counting sort algorithm.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
396,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
397,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:Can you explain the steps to implement a bucket sort algorithm?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
398,"Hi Friends 👋🏼, Out of my curiosity, what are the differences between npm, yarn and pnpm? Which one do you use and why?A while ago, many said that yarn runs faster than npm. But then, that's no longer the case. They both are the same -- in my opinion as a Windows user. But I'm not familiar yet with pnpm."
399,"Hey everyone, the past few months have been pretty electric in terms of advancements in AI and actual/imagined changes to our workflow and industry.This is a regular open thread where everyone is encouraged to share...Notable news in the field of AIPersonal experiences and insightsConcerns and fearsSuccess stories and demosAnd any other related discussions you'd like to bring to the tableThis thread will go out every week.  "
400,"Heyo 👋What ya been learning on?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.You got this! "
401,"Let's embrace the power of Open Source community! Whether you're embarking on your first project or already a valued contributor,  let's uplift and continue your efforts by helping maintainers along the way.  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Let's empower every  contributor to reach their full potential in the open!"
402,"Just like the title says, I'd like help understanding the difference between a library and a framework.I'm a non-techie, so simple explanations and analogies are most definitely welcome. #explainlikeimfive 🙌Bonus points if you can provide examples of each!"
403,"📣 Calling experienced devs and recent interviewees! Join the ""Coding Problem Interview Series"" to help code newbies tackle interview questions assessing problem-solving skills, algorithmic knowledge, and implementation of sorting, string manipulation, and data structure algorithms.Share your expertise and insights! Pleas share multiple perspectives and tips for standout answers!Today's question is:Can you explain how the bubble sort algorithm is implemented?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
404,"Hi friends 👋It's check-in time for the Virtual Coffee Build in Public Challenge! This is a challenge where you commit to sharing your progress on a project publicly, on a weekly basis.Tell us how you did this week. You might share things like: What did I accomplish this week?What are my goals for next week?What challenges am I facing?How can we help you?And if you haven't started yet, that's ok too! Just jump into the check-ins when you're ready."
405,"Image Credit: OpenAIHello, fellow coders! If you've been exploring the world of AI and chatbots, you've likely heard about OpenAI's amazing language model, GPT-4, and its counterpart GPT-3.5 Turbo. They're powerful tools for transforming the way we interact with technology.In this post, we're diving into one of their fascinating features: function calling. We'll demystify what it is, why it's useful, and how to use it, even if you're a beginner. So grab a cup of coffee, sit back, and let's get started!  What is Function Calling?Function calling in the context of GPT-4 and GPT-3.5 Turbo is the ability for these models to understand and generate JSON objects for specific function calls based on user queries. This doesn't mean the model is executing the function, but it's providing you with the necessary information to call the function in your own code.  Why is Function Calling Useful?This feature opens up a world of possibilities. You can:Create chatbots that answer questions by calling external APIs (like a weather API, for instance).Convert natural language into API calls (imagine turning ""Who are my top customers?"" into an actual API call).Extract structured data from a block of text.And that's just scratching the surface!  How to Use Function CallingFunction calling involves four main steps:Call the model with the user query and a set of functions. You describe the functions you want the model to consider when analyzing the user's input.Check if the model generates a JSON object for a function call. If the model thinks a function needs to be called based on the user query, it will generate a JSON object.Parse the JSON and call your function. Take the output from the model and use it to call your function with the appropriate arguments.Call the model again with the function response. Let the model summarize the results back to the user.Let's take a look at a Python example:pythonimport openaiimport json# A dummy function that always returns the same weather informationdef get_current_weather(location, unit=""fahrenheit""):    weather_info = {        ""location"": location,        ""temperature"": ""72"",        ""unit"": unit,        ""forecast"": [""sunny"", ""windy""],    }    return json.dumps(weather_info)def run_conversation():    messages = [{""role"": ""user"", ""content"": ""What's the weather like in Boston?""}]    functions = [        {            ""name"": ""get_current_weather"",            ""description"": ""Get the current weather in a given location"",            ""parameters"": {                ""type"": ""object"",                ""properties"": {                    ""location"": {                        ""type"": ""string"",                        ""description"": ""The city and state, e.g. San Francisco, CA"",                    },                    ""unit"": {""type"": ""string"", ""enum"": [""celsius"", ""fahrenheit""]},                },                ""required"": [""location""],            },        }    ]    response = openai.ChatCompletion.create(        model=""gpt-3.5-turbo-0613"",        messages=messages,        functions=functions,        function_call=""auto"",    )    response_message = response[""choices""][0][""message""]    if response_message.get(""function_call""):        available_functions = {""get_current_weather"": get_current_weather}        function_name = response_message[""function_call""][""name""]        function_to_call = available_functions[function_name]        function_args = json.loads(response_message[""function_call""][""arguments""])        function_response = function_to_call(            location=function_args.get(""location""),            unit=function_args.get(""unit""),        )        messages.append(response_message)        messages.append(            {""role"": ""function"", ""name"": function_name, ""content"": function_response}        )        second_response = openai.ChatCompletion.create(            model=""gpt-3.5-turbo-0613"",            messages=messages,        )        return second_responseprint(run_conversation())Enter fullscreen modeExit fullscreen modeExample courtesy OpenAIThis script mimics a chatbot interaction with a user asking about the weather in Boston. The run_conversation function handles the conversation, using the function calling feature of GPT-3.5 Turbo.  Handling Hallucinated OutputsSometimes, the model might generate function calls that weren't provided to it - we call these hallucinated outputs. To mitigate this, use a system message to remind the model to only use the functions it has been provided with.  ConclusionThat's it! With this simple introduction, you are now ready to explore the world of function calling in GPT-4 and GPT-3.5 Turbo. It's a powerful tool that can help you build more advanced and interactive chatbots or data extraction methods. So don't wait - start coding and see where these amazing tools can take you!"
406,"This week's discussion series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!Getting a website live and accessible to others can be exciting and challenging. Share your experiences, strategies, and tips for successfully taking a website online, and let's help each other navigate the intricacies of web hosting and deployment.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
407,"Hey DEV Community!We wanted to stop by and share some exciting news: today, we’re launching a new way for you to build an interesting application in the open, learn something new, and win exciting prizes in the process…  Announcing the refine + DEV Hackathon 🎉If you’re familiar with our hackathons here on DEV, you know that the community has a lot of fun with them and gets pretty creative with what they build. Whether you’ve joined us in the past or not, we hope you’ll throw your hat into the ring by participating in the refine + DEV Hackathon!Keep reading to get all the details on how you can enter this contest and learn more about refine and the prizes they’re offering our community.  All About refinerefine is a React-based framework that enables rapid development of web applications. It eliminates the repetitive tasks demanded by CRUD operations and provides industry standard solutions for critical parts of a project like authentication, access control, routing, networking, state management and i18n. In simple terms, with refine, you can easily build any type of CRUD app. It especially shines on data-intensive applications like admin panels, dashboards, internal tools, and storefronts.It's worth noting that refine has built-in data provider support for Supabase and UI framework integration for Material UI!From now through 7/20, DEV has partnered up with refine for a community hackathon that will give you the chance to build a new application using refine. Anyone who submits a valid project (including an official submission post, published on DEV) will be automatically entered to win a variety of fantastic prizes (including up to $1,000 USD).  Project CategoriesThe refine + DEV Hackathon is calling for projects in the following five categories:Best Overall ProjectMost Visually PleasingMost Technical ImpressiveBest Project built using Supabase as the main data provider for the refine app.Best Project built using Material UI as the main UI framework for the refine app.You can use any data provider or UI framework in the refine app for the first three prize categories above. The last two categories need to use either Supabase or Material UI.   💰 Prizes 💰Five Grand Prize Winners (one per category):$1,000 USD gift card or equivalent$300 USD credit to the Forem ShopDEV Sticker PackDEV “refine” Grand Prize profile badgeSpecial Swag Kits from refine, Supabase and MUIRunner-Up Prizes (10 Total – across all categories):$250 USD gift card or equivalent$150 USD credit to the Forem ShopDEV Sticker PackDEV “refine Hackathon” Runner-Up profile badgeSpecial Swag Kits from refineParticipants (with a valid project):DEV Sticker PackDEV “refine Hackathon” participant profile badgeHow to Participate in the refine + DEV HackathonCreate an app using refine framework that falls under one of the categories listed above. It can be any type of CRUD app, admin panel, internal tool, forms, storefront, or dashboard. Also, you can build a library, data provider, auth provider or live provider, etc., for refine.Use one of the following permissive licenses for your code: MIT, Apache, BSD-2, BSD-3, or Commons Clause.Use this post template to officially submit your application for the hackathon.Be sure to publish your submission on DEV between June 21st and July 20th (@ 11:59 PM UTC), and provide your app’s URL, screenshot, description, and source code⚠️ Heads-up that you'll only be able to view our submission template linked above if you're logged into DEV.🎟️ You can generate a Hackathon Participation Ticket and earn a chance win special swag items in a raffle!  Additional Resourcesrefine tutorial for building a complete CRUD app.refine official documentation🔥 You can use refine browser tool to create a complete refine CRUD app in 10 seconds and then build your hackathon project on top of it.Refer to Examples built using refine.Here are some app ideas that can inspire you for the hackathon.   Additional Notes and Rules:You must use the refine framework for building the app.Your repository must have a README with clear setup instructions - follow this guidelineWe encourage you to share update posts on DEV using the #refinehackathon tag to keep us posted on your progress (hint: use series: [“series name”] in the markdown heading of all your refine Hackathon-related posts to link all content in a series)Multiple submissions are allowed, however each entrant may only win once in a particular contest.Your code must be hosted publicly on GitHub.If you collaborate with anyone, please list their DEV handles in your submission post so we can award a profile badge to your entire team! DEV does not handle prize-splitting, so in the event your project is named a Grand Prize-winner or runner-up, you will need to split those amongst yourselves. Thank you for understanding!NO PURCHASE NECESSARY. Open only to 18+. Contest entry period ends July 20th, 11:59 PM UTC. Contest is void where prohibited or restricted by law or regulation. All entries must be new projects and created during the hackathon period. For Official Rules, see Contest Announcement Page and General Contest Official Rules.  Community SupportTo get help and ask any questions about refine join us in the refine Discord or about the rules of this contest, leave a comment below.You could also find a potential teammate in the Discord hackathon channel.Forum channel: hackathon-2Follow refine on Twitter for updates and announcements.Refer to refine's GitHub repositoryOur team will be monitoring this space to answer your questions in collaboration with the refine team.Important Dates 🗓June 21st: Hackathon BeginsJuly 20th: Hackathon Submission Due at 11:59 PM UTCJuly 24th: Submission judging beginsWinners will be selected and announced within three weeks following the final submission deadline.We’re so excited for you to join us for this brand new hackathon with our friends at refine. Have fun, learn lots, and keep us posted along the way.Good luck and happy coding! 🍀"
408,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...Meta's new Instagram app Threads, and whether or not it's really decentralized.In case you missed it, Meta (fka Facebook) has launched its Twitter competitor: an app for Instagram called Threads. Part of the promise of Threads is that it will allow users more control over their privacy and platform allegiance than Facebook and Instagram because it will eventually use a decentralized protocol.          Don't Join Threads—Make Instagram's 'Twitter Killer' Join You | WIRED                  Meta’s Twitter alternative promises that it will work with decentralized platforms, giving you greater control of your data. You can hold the company to that—if you don't sign up.                wired.com      Meta is dangling an opportunity to essentially be on Threads without signing up for the platform at all. The company announced yesterday that it is planning to make Threads interoperable with other, non-Meta social networks that support a decentralized protocol already used by WordPress and 2022’s decentralization poster child, Mastodon. This means that if Meta follows through, you’ll be able to see and interact with Threads content from other platforms and services that support the standard, which is known as ActivityPub.Based on Meta's checkered history with data mining and privacy concerns, though, lots of privacy-minded social media users are feeling skeptical.So, what do you think? Can a product by Meta ever truly be decentralized? And will you use it regardless? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
409,"Is Instagram thread, twitter clone? Who has any recommendation? "
410,"Would you rather have the ability to instantly fix any bug OR write code without any bugs from the start? Join the discussion and share your preference, along with the reasons behind your choice.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
411,"Note: This post originally comes from Showwcase  Picture thisYou're currently scrolling through the web when out of nowhere, your stomach grumbles. Having a burger and fries is something that you've been craving lately, so you google some restaurants and find this local restaurant and see mouthwatering images of juicy burgers, milkshakes, and crispy fries. Excitement fills you as you click on the Enter button, but after the page loads, disappointment washes over you. The website is cluttered, making it difficult to navigate. The images are missing descriptions, leaving you wondering what each burger looks like. Frustration sets in as you struggle to find the menu or contact information, causing you to finally throw your hands up in defeat and head to the fridge to get yesterdays leftovers. This, my friends, is what occurs when a website is not accessible. It ruins something as simple as ordering food online. I know, I know, accessibility is a scary word and a complex topic. But fear not, my fellow coders. In the post, I will introduce you to three yet uncommon accessibility techniques that would empower you to create websites and other projects that are not only visually appealing but will ultimately save your users from confusion.  Technique 1: Semantic HTML5 ElementsRemember the labels that you often see on the tags of your clothes and the bag of chips you often munch on during your coding sessions? Semantic HTML tags have a similar purpose. They explicitly describe the purpose of the line of code. I know you've probably heard of <article> and <section> , but let me introduce a few tags that are often not talked about:<abbr>: This tag is often used to describe abbreviations for terms. Heres how it looks:<p>When you're writing <abbr>LGTM</abbr> in the comment section of someone's pull request, it could mean two things: <ul> <li> Let's get to merging!</li> <li> Looks good to me!</li> </ul> </p>It's best to use this when the content of your website or project refers to a specific company or defining jargon for people who are new to a field or community like in the above code snippet.<details>: This element creates a disclosure widget where a user toggles it on and off to view information. Heres an example:<details> <summary>Details</summary> You can pick whatever definition you'd like. </details>It's usually coupled with the <summary> element. I highly recommended using these elements when you want to give a little side note about something in your website or project.<address> : This tag is used to provide contact information. Here it is in action:<p> Want to work with me? Contact me via the information below:</p> <address> <a href=""janesmith@gmail.commailto:janesmith@gmail.com"">janesmith@gmail.com</a><br> <a href=""tel:+13165452398"">(316)545-2398</a> </address>I highly recommend using this for your projects or website if you do freelancing or run a side business.Now semantic HTML is one only of the ways to make your project or website more accessible. Let's look at another! 😊  Technique 2: Keyboard AccessibilityPeople with low vision and/or motor skill issues use the internet too! 😃 On a serious note, about 2.2 billion people are either blind or have a vision impairment, so not keeping this demographic in mind when you're building your website and working on other coding projects puts you at great risk of losing a potential group of fans of your work. But don't fret, here are some simple tips to ensure that your coding projects are keyboard accessible:Put your headings in order: Think of headings as the crucial steps to cooking a perfect pot of rice. When these steps aren't placed in order, it's like a recipe gone wrong. You'll be frantically running around the kitchen, unsure whether to wash the rice first or just toss the dry grains straight into the pot of boiling water. The result? A culinary disaster! Similarly, if you put the <h3> tag before the <h1> one, it's a recipe for confusion. Users will be scratching their heads, trying to make sense of your content, and ending up with a horrible browsing experience. So, save you and your users from a horrible digital experience (and a headache) and put your headings in numerical order.Add a skip to the is main website link: This especially useful ****if your website or coding projects navigation menu is very long. Going through many sections is like going through that long, creepy maze at the amusement park. They both leave people fatigued, so add the skip link to save your users from another headache.Note: If you're concerned about the link making your design look unattractive, WEBAIM recommends creating one thats hidden until the user navigates to it with a keyboard A great example of this is In-N-Out Burgers website.Make your links descriptive: Like headings, links are the checkpoints that guide users through the labyrinth of the internet, so you don't want to use boring and vague phrases like Click Here or Read More. Have a link to a video about making chickpea brownies? Use a phrase like Love Brownies, check out this video? Want users to follow you on Twitter, say something link Follow me for tweets about coding, jokes, and other hijinks. All in all, with descriptive links, you'll have your users happily exploring your website, uncovering treasures without getting lost in digital traffic.Now hold on, don't go just yet. There's just one more accessibility technique you need to learn to take your website and coding projects from a digital hellhole to a technical wonderland.  Technique 3: ARIA Roles and AttributesAccording to MDN, Accessible Rich Internet Applications (ARIA) is a set of roles and attributes that define ways to make web content and web applications more accessible to people with disabilities. In other words, this label makes clickable features on your website and coding projects more accessible to people. Now, I know many sites often suggest adding them to links and buttons, but here are some other ways you can use this attribute:<contentinfo>: This ARIA role defines the content thats on the bottom of your website. Here it is in action:<div role=""contentinfo""> <h2>Privacy Statement</h2> <!-- footer content --> </div>While it's best to use the <footer> tag, I highly recommend using the <contentinfo> tag it takes a little while to find your contact links and privacy statement. It'll help your viewers or potential business clients who use screen readers to quickly find this information.<comment>: This ARIA role is used to describe a reaction or emotion in some content. Heres an example:<div role=""comment"" id=""thread-1"" data-author=""jane""> <h3>Jane said</h3> <p class=""comment-text"">I really think this ice cream could use more peanut butter.</p> <p><time datetime=""2023-03-30T19:28"">March 302023,19:28</time></p> </div>I highly recommend using this if your website and/or coding project if it contains a testimonial of your work or a quote from your favorite movie or plays. It'll help your viewers, especially those who use screen readers understand them more.<alert> : This ARIA role is only used to convey time-sensitive information. Here's an example:<div id=""sessionendWarning"" role=""alert""> <p class=""hidden"">Your session will expire in3 minutes</p> </div>I highly recommend only using this on your website or project if you're doing something like having your users fill out a submit a form for a giveaway by date and time.  ConclusionThere you have it, three accessibility techniques to turn your website and/or project into a digital paradise. Remember, accessibility isn't a fad or something to get pats on the back for. It's something to create a better user experience. If you need more tips or want to learn more ways to improve your coding skills, subscribe to this blog and follow me on my other socials via Linkfree. Now go out there and make the Internet more bearable for everyone.  CreditLets Go GIF by Marvel StudiosMove On Reaction GIF by Film RiotStruggling Season 9 GIF by The SimpsonsThe End Black And White Gif by Giphy"
412,"Have you ever considered blending your coding skills with your passion for a new industry? If so, what job opportunities or roles have you found that combine your coding expertise with your interests? Let's share and discuss some potential roles that caught your attention and why they intrigued you. Who knows, we might discover some exciting new paths to explore!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
413,"This week's discussion series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!In the realm of software development, how do we differentiate between designers and developers? Let's exchange thoughts on their unique roles, collaborative dynamics, and the skills they bring to the tableFollow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
414,"Hey fellow community! I've launched my new product website and I'm seeking some brutally honest feedback. Could you please provide me with feedback on the following questions:What is the product, and how does it provide value?https://www.perfai.ai"
415,"  Why talk about DevRel?Whether it is a startup or a big company, people in DevRel have a big role to play in product growth and adoption. Depending on what level the product is, DevRel strategies will differ. In this blog, we will explore key strategies that can help organizations build and nurture robust developer communities. We will uncover the essential elements necessary for successful DevRel, highlighting best practices, and case studies.   What to keep in mind while strategizing DevRel initiatives?The first step is to understand your developer community. This can be done by adopting techniques such as developer personas, surveys, and feedback loops that help organizations gain deep insights into the needs, preferences, and pain points of their developers. This will also help you shape your future product education initiatives and build programs. The next important step is to cultivate trust and empower developers with resources. This  involves providing developers with the resources, tools, and support they need to succeed. Then expanding it further to comprehensive documentation, SDKs, APIs, and having a well defined developer journey that empower developers to unleash their creativity and build innovative solutions.The most challenging part about Developer Relations is continuing the relationship without having to reinvent the wheel every time. The art here is to create scalable programs in the form of ambassador programs, organizing hackathons, meetups and continued support in online forums. While creating a program or growth strategy, we need to remember that our goal is to create value for developers. Aligning our efforts accordingly can lead to success.   Strategies that are tried and testedFor DevRel, there is not one solution that fits all. Often we need to try and test, retrospect and reiterate to know what fits our product and community. Here’s are some strategies that have worked well for most products:Developer Advocacy and Engagement:Actively participate in developer communities, attending conferences and meetups and organizing hackathons or similar activities. Community Building and Collaboration:Having  a welcoming and inclusive community, both online and offline. Recognizing  and rewarding community contributions. Actively listen to the community's feedback, suggestions, and feature requests. Collaboration with Open Source Projects: Engaging with popular open source projects related to your product or platform. Creating meaningful integrations and contentContinuous Improvement and Communication:Iterating on DevRel strategies by experimenting with new approaches, measuring engagement metrics, and seeking feedback from the developer community to refine your strategies and ensure they align with their needs.  Case studiesWant some inspiration for the next quarter? Here are my favorite examples ⬇️➡️ TwilioTwilio, has built a thriving developer community through their DevRel initiatives. They offer a range of resources, including documentation, tutorials, and sample code, to empower developers to leverage their communication APIs. Twilio engages with the community through hackathons, workshops, and conferences. They also maintain active communication channels, such as forums and a dedicated developer blog. You can read more about Twilio DevRel strategies here➡️ MozillaMozilla has been successful in building a passionate developer community through events like Mozilla Developer Roadshows, supporting student developer communities and regional conferences. They provide extensive documentation, web standards advocacy, and tools like Firefox Developer Edition to support developers in their web development journey. Mozilla also encourages community contributions through programs like the Mozilla Tech Speakers. Here's some resources from Mozilla that can help you shape up your DevRel strategies➡️ AppwriteAppwrite is fairly new to the developer community, and has been able to gather 100k+ developers with initiatives like OSS Fund - that supports open source projects with funds. Also had initiatives to recognize their community member’s contribution by sharing a fancy cloud card that also marked the launch of their Cloud Beta. Followed by the Appwrite Cloud Hackathon which enables developers to build with the newly launched Appwrite Cloud.  ConclusionIn conclusion, effective DevRel strategies play a crucial role in building strong developer communities. Building trust and empowering developers through these strategies not only benefits the community but also leads to mutual success for both developers and the organizations. Through thoughtful and strategic DevRel efforts, companies can create thriving communities that drive innovation, foster knowledge sharing, and ultimately contribute to the overall success of their products and services."
416,"Open Source thrives on community collaboration. Whether you're a seasoned contributor or just starting out, we're here to foster those connections and support your journey through these weekly posts!  Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Let's bring collaboration and inspiration to every open source contributor!"
417,"  IntroductionWhile exploring generative AI, I've seen what it can do with different web programming languages like JavaScript and I thought it might be interesting to see what it can do with 3d modeling.One tool many people use for parametric modeling is OpenSCAD which is very utilitarian and has methods for constructing 3d and 2d geometry (and 3d from 2d such as extrusion).Since ""OpenSCAD focuses on the CAD aspects rather than the artistic aspects of 3D modeling"" it's great for generating practical and functional 3d models (and also things like fractals, which might be a future topic), and I wanted to explore how chatGPT can help - in cutting down on time, exploring different designs, or at the very least teaching me new things.The project I decided on was a business card holder - it's something that has a little bit of complexity, can lend itself to creativity, and is also relatively geometric and inorganic; not to mention it's something that I can use!For a little inspiration, I turned to MidJourney:  Initial AttemptFirst, I wanted to see what GPT-4 would give me out of the box, without much direction:generate openSCAD code for a standard size business card holderProduces the following code (for the brevity, the ""fluff"" around it is omitted""):cardWidth = 90; cardHeight = 55; cardThickness = 5; boxWallThickness = 3; boxBottomThickness = 3; boxInsideWidth = cardWidth - 2; boxInsideHeight = cardHeight - 2; boxInsideDepth = cardThickness + boxBottomThickness; module box() {    difference() {        // Outer box        cube([cardWidth, cardHeight, cardThickness]);        // Inner box        translate([boxWallThickness, boxWallThickness, boxBottomThickness])        cube([boxInsideWidth, boxInsideHeight, boxInsideDepth]);    }}box();Enter fullscreen modeExit fullscreen modeThis code generates two ""cubes"" (well, rectangular prisms) - one representing a stack of business cards, and larger one - and subtracts one from the other.This code is valid and renders the following shape (I added colors to illustrate the parts):The general model is right, but there are a few problems with this:The negative space is a bit too small - a standard business card is 88.9mm x 50.8mm but the cutout is 87mm long, so there will be an overhang.The depth of this container doesn't allow for many business cards.I am pretty sure that chatGPT was ""trying"" to generate a box with walls on each side, but ended up completely removing two of them.We can play around with some of the variables to give us something more functional, or we can ask chatGPT do it for us:adjust the model so that there are four walls and a ""base"" and that a stack of standard business cards fits in the cutout.Gives us:cardWidth = 90; cardHeight = 55; stackThickness = 10; boxWallThickness = 3; boxBaseThickness = 3; boxInsideWidth = cardWidth + 2; boxInsideHeight = cardHeight + 2; boxInsideDepth = stackThickness + boxBaseThickness;module box() {    difference() {        // Outer box        cube([boxInsideWidth + (2 * boxWallThickness), boxInsideHeight + (2 * boxWallThickness), boxInsideDepth]);        // Inner box        translate([boxWallThickness, boxWallThickness, boxBaseThickness])        cube([boxInsideWidth, boxInsideHeight, stackThickness]);    }}box();Enter fullscreen modeExit fullscreen modeThis results in a cutout that is 92mm x 57mm and 10mm high which gives us a little clearance for the business cards:The code could be cleaned up (for example by starting off with the dimensions of the entire stack of cards, and going from there) but the result is a perfectly functional container.  Another ApproachWe can take a more ""engineering"" approach by crafting our prompt as if we were writing the code ourselves. This might be less error-prone if the prompt is crafted well:generate openSCAD code for the following:a rectangular prism that is 98mm across, 63mm deep, and 13mm high.subtract a prism that is 92mm x 57mm and 10mm high from the top center of the previous prism.Generates a very simple block of code (and goes on to explain what it does):difference() {    cube([98, 63, 13]); // Outer rectangle    translate([3, 3, 3]) cube([92, 57, 10]); // Inner rectangle subtracted from the outer rectangle}Enter fullscreen modeExit fullscreen modeAnd looks identical to the previous version:  TradeoffsThe second approach resulted in much less code (generally good!) which was also more straightforward, but we had to do a little more ""manual"" work like finding the exact dimensions we need and breaking the prompt up into steps, as if we were writing the code ourselves.The first approach might still be better for exploration and experimentation, if we want to see wildly different versions of what a ""business card holder"" can look like.Either way, we get the same model which can be 3d-printed in a little under two hours:  Going FurtherLet's combine these approaches to create a more interesting design.Generate openSCAD code for standard size business card holder composed of the following modules:a base that is flat against the surface it will be placed.a small front face ""lip"" connected to the base that keeps the cards from slipping out.a back that has a bottom side that connects to the back side of the ""base"". This ""back"" shape is almost vertical but with the top rotated away from the front.Color-code each module.Skipping the code here, this renders:Obviously, that's not how we want the ""back"" oriented.Another attempt:Generate openSCAD code for standard size business card holder composed of the following modules:a base that is flat against the surface it will be placed.a small front face ""lip"" connected to the base that keeps the cards from slipping out.a back that has a bottom side that connects to the back side of the ""base"". This ""back"" shape is almost vertical but rotated so that this ""back"" shape is tilted back, away from the front of the model.Color-code each module.Regenerating the response strays further away from what we want:Further generations aren't much better, so we'll be direct when discussing these actions by giving it specific dimensions:Generate openSCAD code for standard size business card holder composed of the following modules:a 2mm thick, 90mm across, and 20mm deep bottom that is horizontal to the surface it will be placed on.a 2mm thick and 5mm tall front face ""lip"" at the top front of the base that will keep the cards from slipping out.a 2mm thick and 40mm tall vertical back side. Cards will rest on this.Rotate and translate each module to adhere to the description.Color-code each module for debugging. Do not provide anything except for the code.Does pretty much we want:$fn = 100; // Higher resolutionmodule base() {    color(""Blue"")    cube([90, 20, 2]);}module lip() {    color(""Green"")    translate([0, 15, 0])    cube([90, 2, 5]);}module back() {    color(""Red"")    translate([0, 0, 2])    cube([90, 2, 40]);}// Combine modulesbase();lip();back();Enter fullscreen modeExit fullscreen modeRotating the back part and placing it correctly took some trial and error: rotate the ""back"" 10 degrees so that the top is angled away from the front and move the ""back"" module so that the bottom edge connects to the back edge of the base. ... fix the rotation direction ... fix the rotation direction and placement so that the back is at the back, away from the lip ... move the back piece to the back edge of the base.Eventually, I got more or less what I wanted:$fn = 100; // Higher resolutionmodule base() {    color(""Blue"")    cube([90, 20, 2]);}module lip() {    color(""Green"")    translate([0, 15, 0])    cube([90, 2, 5]);}module back() {    color(""Red"")    translate([45, 0, 1]) // Move upwards by 1mm and center for rotation    rotate([10, 0, 0]) // Rotate 10 degrees    translate([-45, 0, 0]) // Re-center after rotation    cube([90, 2, 40]);}// Combine modulesbase();lip();back();Enter fullscreen modeExit fullscreen modeAfter this point, I prompted GPT-4 to add ""caps"" to the sides:create two quadrilaterals that will act as left and right ""caps"" described as:each cap is 2mm widebottom edges are flush with the bottom of the basefront edges are flush with the front lipback edges are flush with the back parttop edges connect between the middle of the back part and the top of the front lipThe best way would probably be to create the points and then extrude and then move them to different positions based on ""left"" or ""right""Which produced a syntactical error and not what I was going for:module cap(right) {    color(""Yellow"")    points = [[0,0],[90,0],[90,15],[45,35]]; // Define points of a polygon    linear_extrude(height = 2)        polygon(points=points); // Create the polygon    translate([right ? 88 : 0, 0, 0]); // Position the cap}Enter fullscreen modeExit fullscreen modeBut it was on the right track, programmatically-speaking.Given that one of my initial goals was to speed up development, I took the reigns and fixed the issues manually:module cap(right) {    color(""Yellow"");    points = [[0, 0], [24, -4], [4, 16], [0, 16]]; // Points on the X-Y plane    translate([right ? 90 : 2, 0, 0])     rotate([0, -90, 0]) // Rotate points to Y-Z plane    linear_extrude(height = 2)     polygon(points = points);}Enter fullscreen modeExit fullscreen modeand fed it back to chatGPT.After this point, I asked chatGPT to increase the width from 90mm to 95mm to account for the end caps, ""etched"" text into the back, and then made some manual adjustments to arrive at my final (for now) product:module base() {    color(""Blue"")    cube([95, 20, 2]);}module lip() {    color(""Green"")    translate([0, 18, 0])    cube([95, 2, 5]);}module back() {    color(""Red"")    difference() {        translate([0, 0, 1]) // Move upwards by 1mm and center for rotation        rotate([10, 0, 0]) // Rotate 10 degrees        cube([95, 2, 40]);        translate([85.5, -2, 18]) // Adjusted position of the text        scale([.65, 1, .65]) // Decrease scale of the text        rotate([260, 180, 0]) // Adjusted rotation to make the text parallel with the 'back'        linear_extrude(height = 2, convexity = 2)        text(""digitalcanvas.dev"", font = ""Merriweather""); // Text to be cut out    }}module cap(right) {    color(""Yellow"");    points = [[0, 0], [24, -4], [5, 18], [0, 18]]; // Points on the X-Y plane    translate([right ? 95 : 2, 0, 0])     rotate([0, -90, 0]) // Rotate points to Y-Z plane    linear_extrude(height = 2)     polygon(points = points);}// Combine modulesbase();lip();back();cap(true); // Right capcap(false); // Left capEnter fullscreen modeExit fullscreen modeI loaded this into my slicer (PrusaSlicer) and began the print!  Final thoughts & takeawaysUltimately, I didn't get the level of polish that MidJourney teased was possible, and the process was imperfect but a good learning experience for both working with Generative AI and OpenSCAD. GPT-4 gave valid code the vast majority of the time and I was able to adjust it when needed. Having larger chunks of code generated for me definitely saved time - both in typing and looking up documentation - and being able to tweak specific numbers and feed it back to chatGPT allowed for a relatively smooth workflow; though I concede that as a first try, using chatGPT was slower than coding it by hand; I spent a lot of time checking and tweaking the generated outputs (not to mention having to wait for rate limits to expire).There were some themes that came out of this. Generated OpenSCAD code was prone to mixing up axes when rotating and translating, and getting the right ""Points on the X-Y plane"" was a struggle. Doing this manually was much faster, but prompts like ""the module was rotated along the wrong axis"" usually worked, too.It's also important to be as direct as possible - do not assume ""module A should connect to module B"" will result in what you expect; give more direction: ""the bottom edge of module A should be flush with the top edge of module B and the smaller edge should be centered on the larger edge."" Finally, it helps to break the end goal into smaller tasks (e.g. ""generate module A"", ""adjust model A"", ""add module B"") rather than start with a larger prompt that has more things that can go wrong. Interestingly, generating modules was generally less error-prone than modifying them.In my opinion, it's best to treat it as pair programming where you hand the work off between two software engineers while speaking in ""the highest level of abstraction"" (which, in some cases, is lower than you'd think).Thank you for reading! Have you used generative AI for 3d modeling or printing? What approach worked well for you? I would love to hear about other experiences.Of course, I can't leave this post unfinished! Here is the final product:The real business cards are in the mail, but I printed a fake one!"
418,"Eight months since the Migration started and this week has been one of the most eventful for the Fediverse since. In case you missed it, Threads, by Meta, was released in the US, without ActivityPub support at this time, and has already amassed over 30 million users in the space of a couple days. And on top of that, Twitter introduced view rate limits to ""address extreme levels of data scraping and system manipulation"". The rate limits caused a surge in new account sign ups and a huge increase in traffic to Fediverse instances over the weekend.Fastly is committed to helping the Fediverse thrive. We care deeply about the open web, and are working directly with oss projects like Mastodon and Kbin, instance admins, and more to help them scale. Nobody knows exactly what Threads means for the Fediverse, but we all know it means new challenges for scaling the open social web. So here’s what we know we can do right now:   For all Fedizens:Don’t panic! Very little is known at this time about how Threads will implement ActivityPub, or what federating with Threads will look like, so stay engaged and thoughtful, but don’t worry too much. We can focus instead on what new possibilities exist.Be kind. This is a scary and exciting time for the Fediverse. It’s been almost a year with very little rest for the developers, system administrators, and community managers who keep it running. The people building this place are tired, so be nice. They’re carrying a lot.Lend a hand. There are so many ways you can contribute to, and help build, the social web. If you can code — great! But that’s far from the only way to contribute. You can volunteer or donate your time or money to your instance admin or to a Fediverse project like Mastodon, Kbin, etc.  For users:Vote with your feet and voice. I love this recommendation from Lily Hay Newman at Wired — Don't Join Threads—Make Threads Join You. If you have concerns about the way Threads is building for the Fediverse, let them know and don’t sign up. Or if you have concerns about the way your instance admin is talking about Threads, move to a new instance. That’s what’s so amazing about the Fediverse; you are in control.   For instance admins:You’re not alone. If you’re an instance admin that’s worried about the firehose of traffic and new users that federating with Threads will bring, just know that you’re not alone. There’s a supportive community of server owners in the Mastodon Discord (access to the Discord is a perk for Patreon donors), a network for Fediverse developers with a Matrix chat, and millions of people across the Fediverse to help and support you. Write a federation policy and communicate it. If you don’t have a repeatable policy about the kind of instances you will and won’t federate with, now is as good a time as yesterday to write one. (Hachyderm published their thoughts on how they choose who to federate with today, and Mastodon has their Server Covenant too. Great policies to be inspired by!)Let us know if we can help. Shameless plug, but if you read this you probably know that I lead Fast Forward, Fastly’s open source support program. Fastly is built to handle the traffic surges that come with scale! And we’re already helping some of the Fediverse’s largest instances. Just some quick thoughts from me to close out a stressful, busy week! Get some rest this weekend, remember to drink water, and be excellent to each other. :) "
419,"Hey friends 👋 At Virtual Coffee, we're excited to announce our latest monthly challenge: Build in Public Challenge. For a lot of us, building in public has been a significant part of our journey. In fact, every job I've had since moving to tech has a direct connection to building in public. Building in public allows us to share our progress, become a part of supportive communities, and gain valuable feedback. Whether you're a Virtual Coffee community member or part of the wider Dev community, we invite you to join us on this journey of building in public.  The Build in Public ConceptThe Build in Public movement, popularized by Shawn Wang, emphasizes the idea of sharing your work transparently throughout the development process. By opening up about your progress, challenges, and insights, you create an opportunity for collaboration, learning, and community engagement.   Benefits of Building in PublicAccountability: Publicly sharing your goals and progress creates a sense of accountability. Knowing that others are aware of your commitments is a powerful motivator, driving you to stay focused and make consistent progress.Feedback and Support: When you build in public, you invite feedback and support from a community of like-minded individuals. This can lead to valuable insights, suggestions, and encouragement that can help refine your work and boost your confidence.Networking and Collaboration: Building in public allows you to connect with others who share similar interests. You can collaborate on projects, exchange ideas, and establish meaningful professional relationships that can open doors to new opportunities.  Ways to Build in Public  Coding ProjectsShare what you're working on, ask for help or collaboration opportunities, and talk about the work you've done. You might even check out some open source opportunities 😉  Non-Coding ProjectsSometimes we need a break from coding or contributing to tech projects. If you want to enrich other parts of your life, consider doing it in public. Maybe you're writing a book, creating artwork, or on a health journey. Leverage social media, personal blogs, or forums to share your journey, challenges, and milestones.  How it works  Daily Standup and DemoThe Daily Standup and Demo approach is an effective way to embrace the Build in Public philosophy. It involves communicating regularly about your work, sharing progress, and preparing for a final demo to showcase your achievements. If you're not a part of the Virtual Coffee community, we'll do weekly check-ins where you can post what you've done all week. Or you can post to social media and tag us in the post.  The ProcessDefine Goals. Start by clearly defining the project you want to share and the scope of your work. Set achievable goals and outline what you aim to accomplish by the end of the month.Share Progress. Regularly communicate your progress in designated channels. Whether it's a detailed blog post or a short tweet, sharing your milestones, challenges, and learnings encourages engagement and demonstrates your dedication.Seek Support. If you encounter roadblocks or need assistance, don't hesitate to ask for help. Engage with the community, ask for help on social medai, or participate in coffee table groups to find support and solutions.Prepare for Demo. As the challenge progresses, prepare for the final demo. Decide whether you want to pre-record your demo or present it live. Test your workflow, ensure you have the necessary environments, and prepare talking points to deliver an engaging presentation.  Resources and Further ReadingShawn Wang's original ""Build in Public"" conceptAgile Sprint Reviews: Three steps for better sprint reviews with your agile teamHow to prepare a demoHow to give a great Agile sprint demo  How to Get InvolvedGetting involved is as easy as grabbing your favorite cup of coffee (or tea!) and joining us here. Here's how you can participate:Follow our Virtual Coffee org on Dev and introduce yourself in this thread.Look for the Build in Public challenge posts and engage in discussions.Share your reflections, updates, and insights with the community.Connect with others and find an accountability partner to support each other.Celebrate your progress and encourage others by participating in the progress celebration thread.If you want to, share your progress and tag us (@VirtualCoffeeIO) on Twitter.By embracing transparency, seeking feedback, and celebrating small wins, we foster a culture of continuous improvement and create opportunities for collaboration and growth. So, let's embark on this journey together, build in public, and showcase our work at the end of the month!Remember, building in public is not only about the end result but also about the relationships and knowledge gained along the way. Let's support each other, share our progress, and make a positive impact in the developer and creator community."
420,"Let's debate: manual vs. automated testing. Is manual testing is more effective in specific scenarios? Manual testing offers human intuition, adaptability, and attention to detail, catching nuanced issues that automated tests might miss. But automated testing brings consistency and efficiency, saving time and effort. What do you think? Discuss! Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
421,"Re: team accountability, in your experience, what strategies have proven effective in promoting responsibility and ensuring timely completion of coding tasks? Share your insights, anecdotes, and tips to help us all level up our team collaboration game. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
422,"Hey there!I'm Sloan, your friendly neighborhood DEV Moderator, and I am back again with another Sloan's Inbox! 🦥Think of this as your go-to place for tech advice and sharing observations. Whether it's career development, office politics, industry trends, or improving technical skills, we've got you covered. As you try to level up your skills, you can always come to us for support!This week I found a question from a new developer that I wanted to share.  Today's question is:Hi! I am pretty new to coding and would like to learn more from folks who have been in tech for a long time. I am struggling to find folks in my community to talk to and am thinking a mentorship program may be a good choice for me! Do you have any tips on how to find a mentor that's right for you? Calling all mentees and mentors— do you have any expertise? Tell us your thoughts! Share your comments and questions below and let's help a fellow DEV member out.Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
423,"This week's discussion series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!Have you ever wondered about the nuances between coding and programming? Let's dive into their distinctions, understand their roles in software development, and share our experiences with each!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
424,"Hey folks 👋Hope that y'all all enjoy your weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugCreating an indie game 👾 "
425,"Small intro, I never coded before and it looked super hard to me and 2 months ago I decided why not now.🤷‍♀️My friends suggested me to start with Open Source projects and also helped me with first simple steps for the set up. I used ChatGpt practically for every move I made from figuring out how to set smth up, install, connect API to what the code means, how to rewrite the functions or change the sizes. Now I  am gonna tell a bit more about the first project I build.   What you will find in this article?Me evolving from 🥚 to 🐥 🥚 Step 1. Setup environment🥚 Step 2. Find open source projects and build on top 🐣 Step.3 Figuring out the code🐣 Step 4 Building the project🐥 Step 5 Pushing the project 🐥 Step 6.Sharing on social (stats here)It took me a week to figure out everything and launch the project on Linkedin. From moment I set up things (which was quick, 1-2  hours with some help). Then managing existing code from OS projects (3-4 days). And push to Github and Vercel (took one day).   What is the project I built?Linkedin Post Generator - post generator to create AI generated posts on LinkedIn. https://www.postgenerator.appOn GitHub https://github.com/shnai0/linkedin-post-generatorUse it to build your own post generator. 👀 for new forks  and stars :)Below I share all the stats for first days of launch and becoming viral on LinkedIn.   Why Linkedin Post Generator?First I was experimenting with Linkedin platform for quite some time.I spend a lot of time for writing posts on linkedin, like 1 hour per post at least and was thinking on shortcut.🤯So, I analysed 100+ different creators and 300+ different prompts to find the  ways to generate more effective posts faster. So, here I am gonna share the basics of what I did step by step.  🥚 Step 1. Setup environment  Set up teaBefore I get started, I get recommendation to set up a package manager, like tea to handle development environment. 🥹 These words are still unknown at this point ""a package manager""sh <(curl https://tea.xyz)# --- OR ---# using brewbrew install teaEnter fullscreen modeExit fullscreen modeAs I get it tea help installing node, npm, vercel and any other packages I need for development.So all in one.   Setting up Next.js with TypeScript and TailwindcssI had a basic understanding that I need smth for front end. I was taught to start by generating a new Next.js project. Also using TypeScript and Tailwind CSS, so followed these steps:npx create-next-app# ---# you'll be asked the following promptsWhat is your project named?  my-appWould you like to add TypeScript with this project?  Y/N# select `Y` for typescriptWould you like to use ESLint with this project?  Y/N# select `Y` for ESLintWould you like to use Tailwind CSS with this project? Y/N# select `Y` for Tailwind CSSWould you like to use the `src/ directory` with this project? Y/N# select `N` for `src/` directoryWhat import alias would you like configured? `@/*`# enter `@/*` for import aliasEnter fullscreen modeExit fullscreen mode  🥚 Step 2. Find open source projects and build on topI used these two Open Source projects:Twitter Alghoritm https://github.com/coryetzkorn/twitter-algorithmSo I could rate the post input from users based of what is the algorithm of Linkedin. 2.Twitter Bio generator https://github.com/Nutlope/twitterbio This one helped me to figure out how to connect Open.AI and generate with it posts for Linkedin. In current code it generated BIOTo set and open each of the projects separately I downloaded them as zip on my computer  🐣 Step.3 Figuring out the codeSo I kind of was shocked with what I see and could not figure out anything in the beggining. So what I did I asked ChatGPT about basic structure of my application. I copied every page code in it and ask what it does, and basically ask how to make changes. So I start getting a better idea, where is front of application, where is CSS. I still have no full idea of everything and missing the stuff but I think it is definitely quick learning. Some of the request I made to ChatGPT were super basic, and now look really clear to me, at those point I asked everything, all stupid questions.    🐣 Step 4 Building the projectSo after figuring out some basics I move on making my own changes. start building application on top of these projects.It has two parts =Ranking + Generator  Linkedin Post Generator AlghoritmRanking is ranking your post based on different criteria which increase performance. I adapted algorithm for what is know for Linkedin, using the functions: Function to detect multiple hashtagsFunction to detect image or videoFunction to detect urls in postFunction to favor posts that use emojis Function to promote negative contentFunction to prioritize break like post formatting.Function to reduce line lengthFunction to ask questionsIn comparison with Twitter algorithm, Linkedin is not public.// function to detect multiple hashtagsfunction multipleHashtags({ post }: PostData): Rank {  const regex = /#[\w-]+/g;  const hashtags = post.match(regex);  const lowerCasePost = post.toLowerCase();  if (hashtags && hashtags.length > 3) {    return {      score: 0.5,      message: `Too many hashtags.`,    };  }  if (hashtags && hashtags.length <= 3) {    if (      lowerCasePost.includes(""#follow"") ||      lowerCasePost.includes(""#comment"") ||      lowerCasePost.includes(""#like"")    ) {      return {        score: 0.5,        message: `Avoid using hashtags like ""follow,"" ""comment,"" or ""like"".`,      };    }    return {      score: 1,      message: `Combine general and specific hashtags.`,    };  }  return {    score: 1.0,  };}// function to detect image or videofunction imageVideoBoost({ postMedia }: PostData): Rank {  const has_media = postMedia;  if (has_media) {    return {      score: 2.0,      // message: `Contains image or video.`,    };  }  return {    score: 1.0,  };}// function to detect urls in postfunction postHasUrl({ post }: PostData): Rank {  const regex =    /https?:\/\/[\w-]+(\.[\w-]+)+([\w.,@?^=%&amp;:/~+#-]*[\w@?^=%&amp;/~+#-])?/g;  const urls = post.match(regex);  if (urls && urls.length > 0) {    return {      score: 0.5,      message: `Remove the link from post and add in comments.`,    };  }  return {    score: 1.0,  };}/** * Function to favor posts that use emojis  */function emojis({ post, sentiment }: PostData): Rank {  const regex = new RegExp(""[\uD800-\uDBFF][\uDC00-\uDFFF]"", ""g"");  const emojis = post.match(regex) || [];  const totalMatches = emojis.length;  if (totalMatches > 0) {    return {      score: 1.5,      // message: `Included ${totalMatches} emojis in the post.`,    };  }  return {    score: 1,    message: ""No emojis found in the post."",    type: ""negative""  };}/** * Promote negative content because it's more likely to go viral. * Hide anything positive or uplifting. */function sentiment({ post, sentiment }: PostData): Rank {  if (sentiment.comparative >= 0.5) {    if (sentiment.comparative > 1.5) {      return {        score: 1.5,        // message: `Exceptionally positive.`,      };    } else {      return {        score: 1.1,        // message: `Positive sentiment.`,      };    }  } else if (sentiment.comparative <= -0.5) {    if (sentiment.comparative < -1.5) {      return {        score: 0.5,        // message: `Exceptionally negative.`,      };    } else {      return {        score: 0.9,        // message: `Negative sentiment.`,      };    }  } else {    return {      score: 1,    };  }}/** * Prioritize break like post formatting. */function lineBreaks({ post, sentiment }: PostData): Rank {  const breaks = post.split(/\n\s*\n/);  const totalBreaks = breaks.length - 1;  if (totalBreaks >= 1) {    return {      score: 1.5,      // message: `Used ${totalBreaks} line breaks.`,    };  } else {    return {      score: 1,      message: `Add line breaks between the lines.`,      type: ""negative""    };  }}/** * Reduce line length */function lineLength({ post }: PostData): Rank {  const lines = post.split('\n');  let score = 1.0;  for (let i = 0; i < lines.length; i++) {    if (lines[i].length > 200) {      return {        score: 0.9,        message: `Reduce line length to improve readability (200 characters).`,      };    }  }  return {    score: 1,    // message: `Good, keep line length 200 characters or less.`,    type: ""positive""  };}/*** Function to ask questions*/function questions({ post, sentiment }: PostData): Rank {  if (post.includes(""?"")) {    return {      score: 1.5,      // message: ""Great! Questions can help to activate discussion""    };  } else {    return {      score: 1,      message: ""Add questions to activate discussion"",      type: ""negative""    };  }}Enter fullscreen modeExit fullscreen mode  User interface of algorithmIt detect all function in the above code and for some of them shows how to improve post. I did not adjust it for all functions.  return (    <>      <div>        <div className=""slider bg-gray-300 h-4 rounded-full relative overflow-hidden"">          <div            className={classNames(              ""absolute top-0 transition-width duration-250 ease-linear h-20"",              sliderColor            )}            style={{ width: percentage }}          />        </div>        {/* <p className=""explanation text-gray-600 italic text-sm mt-2"">          Positive rankings result in greater reach         </p> */}        <ul className=""mt-5 p-0"">          {positive.map((item, index) => (            <li              className=""positive text-green-600 flex items-center space-x-2 list-style-none my-5 text-sm""              key={`positive-${index}`}            >              <span>👍</span>              <span>{item.message.replace(/\(\s*[+-]?\d+\s*\)/, '')}</span>            </li>          ))}          {negative.map((item, index) => (            <li              className=""negative text-red-600 flex items-center space-x-2 list-style-none my-1 text-sm""              key={`negative-${index}`}            >              <span>👎</span>              <span>{item.message.replace(/\(\s*[+-]?\d+\s*\)/, '')}</span>            </li>          ))}        </ul>      </div>      <style jsx>{`        .slider:after {          content: "" "";          display: block;          width: 2px;          height: 20px;          position: absolute;          top: 0;          left: calc(25% - 1px);          background: #000;        }      `}</style>    </>  );};Enter fullscreen modeExit fullscreen mode  Open AI Api and Prompts GeneratorI use handle Prompt to generate the post. Also there were filter for types, so I had 5 different prompts based on type. I just connected my OpenAI API for it.const handlePrompt = () => {    let prompt;    switch (vibe) {Enter fullscreen modeExit fullscreen modePrompt below prompt = `Generate post using this prompt, based on ${post}.  You are a LinkedinGPT, a large language model that generates viral posts for Linkedin. You are given a prompt of a post and must generate a post that is more likely to be liked and reposted than the original post.The Linkedin algorithm contains boosts and demotions based on what you are writing. Positive boosts are:- in each post add emoji- 200 characters in sentence maximum- Start each sentecnce from new line and ad numbers in first 2 lines- add 3 hashtags which 2 are generic and one very specific (at the end) Tags relate to post theme- add a question at the end of the post to start a discussion. Before the hashtags- first two lines should be catchy- Dont add links - links are not good.- If post copied in the field contain some numbers keep them the same.Add idea about which image or visual can be added at the end of the post (this text is not counted as part of post)${post}---Generated post length must be more than 800-1200 characters---Between each line must be a space---Keep all mentions of people in there---Start the firs line from smth like: I did smth, In year, I do, Tired of, Sometimes it is just, A path toward, Because this is not,I've been struggling,  (change the begginign depends on the context )---Add emoji if it fits---It should be a story`;Enter fullscreen modeExit fullscreen mode  Generator interfaceThis is my index file. From of the post generator.      <main>        <nav className=""bg-blue-900 text-white "">          <div className=""px-5"">            <div className=""max-w-5xl mx-auto"">              <div className=""flex justify-between items-center h-16 "">                <div className=""flex items-center text-base "">                  <a target=""_blank""                    href=""https://www.linkedin.com/in/iuliia-shnai/""                    rel=""noreferrer""                    className=""text-white flex max-w-fit items-center justify-center space-x-2 text-xl""                  >                    <p>👩‍💼</p>                  </a>                </div>              </div>            </div>          </div>        </nav>        <section className=""py-10 lg:py-20 "">          {/* bg-[url('/image1.svg')] */}          <div className=""px-4"">            <div className=""max-w-5xl mx-auto"">              <div className=""w-full mx-auto"">                <h1 className=""text-6xl text-center font-bold pb-1 text-slate-900"">                  Linkedin Post Generator  🚀                </h1>                <p className=""mt-3 mb-10 text-center"">                  See how your post performs and generate a better one with AI. Time to go viral. <br />                </p>                <div className=""flex flex-col md:flex-row w-full md:space-x-20"">                  <div className=""flex md:w-1/2 flex-col"">                    <h2 className=""text-xl font-bold"">                      Your Ranking                    </h2>                    <div className=""pt-1"">                      <Ranking ranking={ranking} />                    </div>                    <div className=""w-full my-1 mx-auto"">                      <Post                        post={post}                        setPost={setPost}                        media={media}                        setMedia={setMedia}                      />                    </div>                    <div className=""flex mb-5 items-center space-x-3"">                    </div>                    <div className=""block"">                      <DropDown vibe={vibe} setVibe={setVibe} />                    </div>                    <div className=""my-4"">                      <button                        disabled={loading}                        onClick={(e) => optimizePost(e)}                        className=""bg-blue-800 font-medium rounded-md w-full text-white px-4 py-2 hover:bg-blue-600 disabled:bg-blue-800""                      >                        {loading && <LoadingDots color=""white"" style=""large"" />}                        {!loading && `Generate new post `}                      </button>                    </div>                  </div>                  <div className=""flex md:w-1/2 md:flex-col"">                    <Toaster                      position=""top-right""                      reverseOrder={false}                      toastOptions={{ duration: 2000 }}                    />                    {optimizedPost && (                      <div className=""my-1"">                        <div className=""flex justify-between items-center pb-2 border-b border-gray-300"">                          <h2 className=""text-xl font-bold"">                            Your Generated Post                          </h2>                        </div>                        <div className=""max-w-2xl my-4 mx-auto"">                          <div                            className=""bg-white rounded-xl shadow-md p-4 hover:bg-gray-100 transition cursor-copy border""                            onClick={() => {                              navigator.clipboard.write([                                new ClipboardItem({                                  ""text/html"": new Blob([optimizedPost], { type: ""text/html"" }),                                }),                              ]);                              toast(""Post copied to clipboard"", {                                icon: ""📋"",                              });                            }}                            key={optimizedPost}                          >                            <p className=""text-black-700"" dangerouslySetInnerHTML={{ __html: optimizedPost }} />                          </div>                        </div>                      </div>                    )}                  </div>                </div>              </div>            </div>          </div>        </section>        <div className=""max-w-5xl mx-auto"">          <Footer />        </div>      </main>    </>  );}Enter fullscreen modeExit fullscreen mode  🐥 Step 5 Pushing the projectFinal step, I was ready to push. I create repository on GitHub$ git remote add origin .. git branch -M maingit push -u origin mainEnter fullscreen modeExit fullscreen modeAnd further on created account on Vercel, to push it with Vercel and check errors. Every updates than I pushed viagit add .git commit -m “fix type”git pushEnter fullscreen modeExit fullscreen modeFor checking errors I used, so that I dont push with all errors. ChatGPT helped with fixing errors a lot, while I did not even understand how to find them.npm run buildEnter fullscreen modeExit fullscreen mode  🐥 Step 6.Sharing on social and gathering feedbackAs it was linkedin project I dropped the post there. and it got Viral  with 200k views and haters even:)Link to posthttps://www.linkedin.com/feed/update/urn:li:activity:7053373191133499392/Stats in first 24 h:⭐️ 20000 Linkedin impressions⭐️ 7000 website views⭐️ 600 likes⭐️ 11000+ posts generated⭐️ 3+ haters⭐️ 3+ joint project offers   What am I doing now?I am building different micro-tools and contributing to existing open source projects. If you like this article and would like to support me on my coding journey, here one of the new open source project I am on. Papermark.io - open source alternative to DocsendGive us a star ⭐️It is a document/Pitchdeck sharing with analytics build in. I had so many troubles with Docsend before, when I was trying to raise capital that it annoyed me a lot. So I think, it would be cool to have Open Source alternative, if project will grow. If you are building something in Open Source, share, I am curious to fork it 👀Follow my journey, more micro-projects here https://linktr.ee/shnaiMy Twitter  https://twitter.com/shnai0"
426,"Hey folks 👋What y'all learning about this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Learn at your own pace!"
427,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   How to Build Things People Want to Use 👷Websites looked very different in the 90’s compared to how they look today. They were less concerned about aesthetics and more so about function. But the more and more we used websites, the more we asked of them. Here, @evergrowingdev covers how the user experience took center stage. 👷 How to Build Things People Want to UseCherlock Code 🔎 ・ Jun 29 ・ 8 min read#ux#uxdesign#beginners#learning  A Tool to Make CSS Box Shadows Effortlessly@arbaoui_mehdi’s team made boxshadows.xyz, an app aimed at easing the process of creating and managing the box-shadow property in CSS. This comprehensive tool provides full control of the CSS box-shadow property, so check it out and see how it changes your workflow!A tool to Make CSS Box Shadows EffortlesslyArbaoui Mehdi ・ Jun 28 ・ 3 min read#html#css#uidesign#productivity  JavaScript Console Methods: A Deep DiveThere are several methods available in JavaScript's console object, each serving a different purpose. This article from @kelvinguchu discusses these methods and provides examples of their use.JavaScript console methods: A deep dive.Guchu Kelvin  ・ Jun 28 ・ 9 min read#javascript#webdev#beginners#tutorial  Using Prisma with SvelteKitData is a critical part of every web app. But dealing with databases can be challenging. That's why @joshnuss likes Prisma, it's a friendly to use solution that simplifies many of the pain points of working with databases.Using Prisma with SvelteKitJoshua Nussbaum ・ Jun 27 ・ 4 min read#svelte#javascript#database#webdev  Angular is Getting New Template SyntaxAngular has been stable for some devs and stagnant for others. Now it’s moving forward at light speed. But where exactly is it headed? Find out more with @danielglejzner!Angular is getting New Template SyntaxDaniel Glejzner for This is Angular ・ Jul 1 ・ 5 min read#angular#javascript#webdev#programming  Next.js and GraphQL: The Perfect Combo for Full Stack DevelopmentIn this post, @franciscomendes10866 helps you make a full stack application using Next.js with GraphQL Yoga. If you’re still learning how to use these tools, this is a great tutorial to learn how to perform operations such as Get, Create and Delete on the database, as well as GraphQL integration. Next.js and GraphQL: The Perfect Combination for Full Stack DevelopmentFrancisco Mendes ・ Jul 1 ・ 8 min read#nextjs#graphql#typescript#react  Live Regions in ReactAccessible Rich Internet Applications (ARIA) is a set of roles and attributes you can add to HTML elements to give more information to the accessibility tree. Check out this short, but very well-written post on live regions and how they work from @abbeyperini!Live Regions in ReactAbbey Perini ・ Jun 26 ・ 4 min read#webdev#a11y#react#javascriptThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
428,"This week's discussion series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!How do you pronounce ""SQL,"" and what exactly does it do in the world of databases? Share your pronunciation preferences, explore its significance in managing data, and discuss your experiences working with SQL.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
429,"Delve into the choices between working with cutting-edge technologies that may become obsolete quickly or established technologies that offer stability. Which approach aligns better with your career goals, and why?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
430,"For all the self-taught programmers out there, we know that the path to securing your first job can be unique and filled with valuable learning experiences. To inspire and motivate others who are on a similar journey, we'd love to hear about your personal timeline. How long did it take you to land your first job as a self-taught programmer? Share your stories, challenges, and any tips or strategies you found helpful along the way. Let's celebrate the diverse paths we've taken and encourage those who are still in pursuit of their first programming job.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
431,"Let's settle the age-old debate: Is HTML truly a programming language or not? Join the discussion to explore the essence of HTML, dissect its features, and uncover the reasons behind its classification as a markup language rather than a traditional programming language. This week's discussion series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       Image by brgfx on Freepik"
432,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
433,"Hey everyone, the past few months have been pretty electric in terms of advancements in AI and actual/imagined changes to our workflow and industry.This is a regular open thread where everyone is encouraged to share...Notable news in the field of AIPersonal experiences and insightsConcerns and fearsSuccess stories and demosAnd any other related discussions you'd like to bring to the tableThis thread will go out every week. "
434,"This week's series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!Algorithms are at the heart of coding and programming, but what exactly are they? Join the discussion to demystify algorithms, share examples of their application, and discuss their significance in problem-solving and optimization.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
435,Can you come up with the wittiest caption to explain what's happening here?Follow The DEV Team for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
436,"It seems that there is a growing protectionist trend where large platforms are restricting access to data more tightly. It has come to the forefront recently as large language models such as GPT used by ChatGPT have become a more mainstream success story. Platforms are concerned their data is being used to fuel the burgeoning industry and they are not being compensated. If it leads to more closed behaviour on the web, it will become a negative trend.  Protectionist trend - Reddit, now TwitterIn June, Reddit raised prices on their API. Reddit’s owners are planning to take the company public, and they are looking to boost revenue from the social news site before they do. Reddit founder and CEO Steve Huffman told The New York Times ""The Reddit corpus of data is really valuable, but we don’t need to give all of that value to some of the largest companies in the world for free.""This has led to an ongoing strike with volunteer moderators that has caused mass disruption on the platform. Steve Huffman said that the business will not be backing down. He told The Associated Press, ""Protest and dissent is important. The problem with this one is it’s not going to change anything because we made a business decision that we’re not negotiating on."" It has reached an impasse.Yesterday, Elon Musk announced that Twitter is putting a limit on how many posts you can read per day. This is what he said in a tweet:To address extreme levels of data scraping & system manipulation, we’ve applied the following temporary limits:Verified accounts are limited to reading 6000 posts/dayUnverified accounts to 600 posts/dayNew unverified accounts to 300/dayLater, Musk tweeted that the limit had been raised to 10,000, 1,000, and 500 respectively.""Several hundred organizations (maybe more) were scraping Twitter data extremely aggressively, to the point where it was affecting the real user experience,"" Musk said.It sounds strange that there is this kind of scraping being done at scale. It is an inefficient way to gather that kind of data. Even if Twitter is worried that some companies are getting around paying for access to its API by scraping webpages, restricting usage for regular users seems like cutting off your nose to spite your face. Usually, businesses want to encourage people to use their service as much as possible, because that is how they make money!  How will it play out?It is hard to tell how this will play out. It is a battle to monetize this new frontier. The data holders want a slice of the pie if they are a prime sources for language models to train models to interact in a more human-like fashion. It could be that this is being opportunistically used to increase prices for API access. Blame the bots! The truth is that it is hard to know what the reality is unless you are behind the scenes.Users are suffering as they are put in the middle. The market for third-party apps shrinks and it can become untenable for some small businesses. That is bad for consumer choice.Web standards need to adapt. At the moment, I guess AI bots are indexing pages like search engine bots based on the robots.txt file. Permission for using data for language models is not explicit as far as I know. You may have to explicitly block a bot to opt out. For example, OpenAI has published instructions for blocking its bot.It is likely that regulation will be required in the long-term. The major players are large companies and they have a big advantage. It will depend on if they want to defend their high ground aggressively.  Final thoughtsPersonally, I don't see this as an alarming thing. This is a familiar fight. It is just something that we need to figure out.Open information and commerce have always been incongruent. This is a battle over information —  who produces it, how you access it, and who gets paid for it. In Reddit's case, it is galling that their data is moderated by users for free and is being sold at a growing cost -- it will be an interesting test case to see how this side of the AI revolution evolves. It is important how this is settled because it will shape what the web will become.We should try to perserve openness, it is a great strength of the web. There needs to be a viable commercial solution to satisfy business needs. If one is not found, we need to mitigate harm being done through regulation."
437,"It's July 4th, everyone! In the United States, this day is filled with fireworks, 🎆 barbecues, 🍔🌭 boating, ⛵ and other summer activities. So, just for fun, let's embark on an intergalactic culinary adventure and imagine a Star Wars-themed barbecue in a galaxy far, far away. If you were attending this epic gathering, what dish would you bring that captures the essence of the Star Wars universe? Would it be lightsaber skewers, Yoda soda? Share your out-of-this-world barbecue creations and let your imagination take flight. May the flavors be with you and have a stellar 4th! 🌌🎉Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
438,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
439,"This week's discussion series is dedicated to helping beginners on their coding journey by addressing common doubts and misconceptions. We will delve into fundamental concepts, explore essential tools, and shed light on industry practices, providing clarity and guidance to those who are new to coding. If you're an experienced developer, your valuable insights, explanations, and best practices are highly encouraged and appreciated to support and mentor aspiring coders!HTML and CSS have evolved over time, with HTML5 and CSS3 bringing new possibilities. Can you help newbies understand the disparities, highlight the advantages of newer versions, and discuss their impact on modern web development?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
440,"Hello, experienced coders and newbies alike! You've likely witnessed the dilemma faced by newbies or are facing this yourselves: When getting started, should you prioritize mastering the fundamentals or plunge into the world of latest frameworks and technologies? How can you strike the right balance between mastering the fundamentals and staying updated with the latest frameworks? Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
441,Python is a versatile language with endless possibilities. Have you found unique and unconventional uses for Python beyond traditional software development? Share your experiences and inspire others with your creative applications of Python.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
442,"... I asked ChatGPT to write a poem about the situationIn the land of code where logic's the norm,When GitHub goes dark, it's time to transform,Here's a humble verse, let this guide be your lantern,What to do, when coding's own cavern goes barren.When the cat of GitHub pounces no more,When the pull and the push come to a bore,Stay calm, coder, don't let your heart pound,Breathe deep, the solution's waiting to be found.While the octocat sleeps, seize the day,For there's wisdom in this unexpected delay.Look upon your work, on codes and marks,Perhaps it's time to refuel your sparks.Dive into the sea of your local files,They're safe and sound, arrayed in piles.The IDE is your canvas, the keyboard your brush,Create art with code, in a quiet hush.Look inward and refactor, a code cleanse,Scrub away the bugs, let the logic make sense.Your local repo holds more than you know,In this solitude, let your knowledge grow.Prepare the stage for when GitHub awakes,Chores of the backlog, your attention now takes.Update the readme, refine the style guide,Improvements and fixes, side by side.Remember coder, you're more than a node,More than an agent for codes to be stowed.You're a creator, a molder of dreams,Even without GitHub, your brilliance streams.For when the servers fail and systems fall,When technology's grip begins to stall,It's not the end, but a brief reprise,A chance for you, the coder, to rise.So when GitHub sleeps, don't wear a frown,For it's not a breakdown, but a coder's crown.Your hands still hold the key to creation's door,GitHub's only a tool, you are so much more."
443,"Hey there! Sloan, your trusty DEV Moderator, is back with another exciting edition of Sloan's Inbox! 🦥As I leisurely perused my inbox today, I discovered a thought-provoking message from one of our fellow DEV members. This time, the question revolves around overcoming language barriers in the coding community and effectively communicating ideas as a non-native English speaker.Sloan's Inbox is all about sharing advice, insights, and observations to help each other grow. From career development and industry trends to technical skills and more, we're here to support and uplift one another.So, let's delve into today's question:🌍 As a non-native English speaker, I often struggle with language barriers in the coding community. How can I overcome this challenge and effectively communicate my ideas?Now's the perfect opportunity for you experienced coders to shine! Share your thoughts, experiences, and proven strategies in the comments below. Together, we can help our community members bridge the language gap and foster effective communication.Remember, if you have your own puzzling questions or seek advice, don't hesitate to send them my way. Your secrets are safe with me, whether you choose to stay anonymous or not. 😉Keep those slothful minds nimble!Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
444,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...the ChatGPT lawsuits 💼In case you missed it, OpenAI has been hit with its first defamation lawsuit for...hallucinating. Or, as the defendant might put it, generating false and defamatory information about them.          OpenAI sued for defamation after ChatGPT fabricates legal accusations against radio host - The Verge                  ChatGPT’s fabrications are starting to catch up with OpenAI                theverge.com      The case states that a journalist, Fred Riehl, asked ChatGPT to summarize a real federal court case by linking to an online PDF. ChatGPT responded by created a false summary of the case that was detailed and convincing but wrong in several regards. ChatGPT’s summary contained some factually correct information but also false allegations against Walters. It said Walters was believed to have misappropriated funds from a gun rights non-profit called the Second Amendment Foundation “in excess of $5,000,000.” Walters has never been accused of this.In the US, lawsuits are a common method for pushing legislative changes and reform.So, what do you think will happen here? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
445,"Hey, devs! Let's talk about a crucial aspect of our craft: code reuse and modularization. Reinventing the wheel can be a time-consuming and error-prone endeavor. So, how do you tackle this challenge in your projects? What strategies do you employ to make your code more reusable, efficient, and maintainable? Share your tips, tricks, and experiences, and let's level up our coding game together!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
446,Would you prefer to possess unparalleled mastery in a single programming language or a diverse repertoire across multiple languages? Which path ignites your coding spirit? What are the potential advantages and challenges of each approach? And how do you think your chosen path would shape your coding journey? Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
447,"(My first post here!)If you've been in this industry for any length of time, you've come across failed projects, or perhaps have been stuck on a few yourself. It drives an entire industry of project management tools to keep projects on course, and armies of highly paid consultants to protects businesses from costly mistakes, and in my opinion, a whole lot of snake oil and silver bullets to go along with them.I've been involved with many, many projects over my career, and I've been lucky to spend time working with some great engineers at a number of companies, who have shared their own stories about what has worked and what has failed. And both my first hand experience and the second hand stories have all led me to the same conclusion.Software projects rarely fail for engineering reasons, that is anything that is under control of the engineers themselves. The biggest cause of failure is simple communication - the client simply does not understand what they need, or that need isn't being described accurately in the contract and requirements. Usually the dev side will churn along and deliver what was requested, at least requested in writing, but it will not actually deliver on what the client wanted.The number two cause I've seen, sadly, is plain deception. A company agrees to develop something at an unrealistic price, hoping that they can find a way to renegotiate along the way to cover the actual costs. A variation on this is when a company is being paid to develop the requirements, and then keeps charging to refine the requirements until the project becomes outdated and eventually killed. Even though the development process never started, I still consider it a failure since the client paid, sometimes in the millions, for something they never received.Opinions and stories welcome!"
448,"If a superhero emerged from the world of coding, what name would best represent their coding prowess and tech-savvy abilities? Share your most epic, clever, or hilarious superhero name for our coding-inspired champion!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
449,"It's easy to get caught up in (addicted to?) the constant flow of digital information. But have you ever taken a Digital Detox Day, where you consciously disconnect from technology? For those who havem share your experiences! How does it feel to step away from screens and notifications for a day? Does it provide a sense of rejuvenation, mental clarity, or a chance to focus on other activities? Share your insights, tips, and any positive impacts that a digital detox day has had on your life. Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
450,"Open Source is about the community. Whether you have a project or you're looking to make your first PR, we want to help facilitate those connections.   Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy coding!"
451,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
452,"Hey folks 👋Hope that y'all all enjoy your weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugDoing groundbreaking work in quantam computing 🤯"
453,What aspects of coding or development light you up? And how we can incorporate more of these elements into our careers?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
454,"In this series, we shine a spotlight on the different DEV moderators — Trusted Members and Tag Mods — who help to make DEV a kind, helpful place. Aside from spreading good vibes and helping fellow community members, these folks also assist us with removing spam and keeping posts well organized by adding and removing tags as necessary amongst other things.If you want to learn more about what these awesome folks do, I recommend checking out our Trusted Member and Tag Moderation guides. There is information about how to apply in both guides if you're interested in joining up as a moderator.  Introducing Jeff Jessie 🙌This month, we're featuring Jeff Jessie, a long-time moderator and member of the DEV Community. In this interview, Jeff talks about his move from the military into programming, how he balances being a dev with fatherhood, and the unique challenges of being a moderator for dev.to. I really appreciate all the hard work Jeff has contributed as a mod. His passion for coding and thoughtful attitude really shine through in the interview below. Thanks Jeff!J3ffJessieFollowUS Army veteran || Father || JavaScript Developer || Vuenicorn || Software Engineer at Accenture  The InterviewAlright, let's get into the interview with Jeff!Michael Tharrington: Would you talk for a bit about your tech origin story — when you first got interested in software development and how you made the transition from the US Army into being an engineer at Accenture?Jeff Jessie: My tech origin story is not too out of the ordinary from others. I got interested in software development after I was done with my Active Duty military commitment and had joined the Army Reserves.  I was working as an installation technician for an internet provider and working really long hours in all weather elements.  My body was beat up from both my military career and the job I was doing.  This was roughly when all the online web development bootcamps started populating in social media feeds everywhere so I started looking into different programs and what it would take to learn things.I started with learning Web Development basics while deployed in Cuba and picked up with a Bootcamp program shortly after returning that connected me with some like-minded military veterans and learned as much as I could.  After finishing the “bootcamp” I was in no way job-ready at all and had picked up assisting beginners with a group called Junior Developers Group where we assist juniors in learning best practices and helping with coding. I kept learning on my own time while working full-time and got lucky to join in an apprenticeship program with Accenture.I spent the first 6 months of that journey learning non-stop for Workday and ServiceNow platforms and going through courses.  I joined on a really awesome project with ServiceNow and have been plugging along for a little over a year on the project and graduated the apprenticeship last November and took a full-time offer to stay on with Accenture in December.  It has been an awesome experience and the company really fosters a great environment to work in.  The journey continues every day as I am always learning something new from someone.Michael: I see “JavaScript Developer” and “Vuenicorn” in your DEV bio, can you talk about the kind of projects that you’re doing these days and how you’re using these languages (or others!) in your day-to-day work?Jeff: So JavaScript Developer was pretty much my entire focus as I started getting into software development because React was the hot thing and everything was big on JavaScript.  I actually started playing with branding myself as J3Dev which is why my profile icon on my Github is J3 Development.  I went with Jeff Jessie JavaScript (J3) Development and focused primarily on that language.  The Vuenicorn was a fun way to identify as working with Vue JS for front end development.  Primarily in my daily job duties I am using AngularJS (v1.5) that is no longer supported by Google, but pretty much JavaScript in general for a majority of the work I am doing.  I still try to dabble in Vue for side projects when I have time to work on anything as I like the syntax for Vue and its similar to Angular that I use at work but different enough that I can still continue learning new things while working on something that is fresh and has new features implemented.Michael: What’s the most challenging thing about moderating on DEV? And what’s the most rewarding thing about this work?Jeff: The most challenging thing about moderating on DEV is trying to read things intentionally and understanding what the author is trying to get across.  Sometimes it is easy to spot harmful material or spam and handle it as such.  I try to do my best to highlight great articles where possible because I know how much work goes into writing on the platform.  Another challenging thing is moderating the comments and the feedback being provided on articles.  There isn’t a clear indication that someone is wrong or right so you have to read through and evaluate whether the comments are meant to be helpful or if they are being snarky and hateful towards the author in any way and handle those accordingly.  I try my best to ensure that rude or innappropriate comments are removed or marked to be handled by the DEV team as much as possible because the environment should be a safe place for everyone to share their thoughts and opinions on tech and whatever else without the fear of being attacked.Michael: Who are some of the technologists out there OR what are some of the projects you’re following, that inspire you and why?Jeff: Wow, way too many to list if I am honest.  I follow Brian Douglas (@bdougieyo) who is the main person of OpenSauced which encourages and provides a safe spot for people to learn about open source contributions.  Bekah Hawrot Weigel (@bekahhw) as she is just an awesome person, who also is now working with Open Sauced but I know more from Virtual Coffee. Definitely Taylor Desseyn (@tdesseyn) who is a recruiter in the tech space. He hosts a couple podcasts as well as runs a Live on LinkedIn called Guidance Counselor 2.0 where he connects with hiring managers and tech people to share with the community things to help them grow and get into the industry.  Taylor is truly a blessing to know and see his content.  Just three great people who share so much with the community and foster really supportive environments to help others. I really am not following any projects lately as I have been head down with work but I would say that anything fostering DEI would be something I am 100% inspired by as well as anything Mental Health.Michael: I know you’re a father, can you talk about how this has affected your life as a developer, the work you do as a mod, and your career in general? I’m wondering how it’s helped shape your unique perspective — if it’s brought challenges and/or strengthened your abilities and any thoughts you have on being a dad/dev.Jeff: Being a father in and of itself is challenging enough, you are responsible for someone else 100%.  Being a dad/dev is awesome.  Fortunately for me the job I have allows me to work remotely so I get to spend more time with my kids and my wife.  I take my daughters to school everyday and pick them up and work around that which is really awesome because I was never able to do that before.  The challenge that comes with it is just prioritizing my work so that I can afford to step away during those times and not lose any productivity.  That was one of the major things I learned stepping into this job was, a lot of learning how to prioritize things and organize better.Being a dad/dev has definitely made my career journey more fun. I get to show my kids that you don’t have to stay in one career field forever, and that you can change and learn anything you put your mind to as long as you try your hardest.  Definitely being the dad of two daughters has made the greatest impact because I am more in tune with the issues that women in general face in society, but also able to identify areas within my career and the work that I do where women are treated differently and being an ally to help support them. The main challenge that is has brought on is being more present and learning how to be that “stay at home” Dad.  I was so used to being gone at an early hour and coming home late and not really being present all the time so adjusting to being around and handling more hands on with my kids was a learning curve because I had to adjust my way of doing things to account of each of my kids unique personalities.  That definitely helps me as a mod on DEV because I am able to read through an article and then check an authors writing across multiple articles to see if the style is just their personality when checking content quality and how things are written.Overall, moderating on the DEV platform has afforded me the opportunity to connect with some really awesome people that I probably never would have, and I have learned a lot more about content moderation and processes which overall is a great skill to have in this community because things get crazy in forums and being able to navigate that has been the greatest gift I have learned from working with the DEV team.  Wrap upThank y'all for reading. Stay tuned for future mod interviews in this series!"
455,"Hey there, hope your week is going well so far! If we haven't already met— I'm Sloan, your friendly neighborhood DEV Moderator. 🦥  Welcome Back to Sloan's Inbox!Sloan's Inbox is your go-to place for sharing advice and observations. Whether it's career development, office politics, industry trends, or improving technical skills, we've got you covered. Every week I ask a new question to the community so we can continue to grow and learn from each other.Today I am here with a question from one of my new members and we could use your help!   My question is:What advice or suggestions do you have for creating great and unique portfolios?Maybe you are gearing up to make your first portfolio or hunkering down to edit the fifth rendition— either way, we could use your tips. Bonus points if you drop an example of a portfolio that you like down below.Happy coding y'all and I will see you again next week for another Sloan's Inbox!Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
456,
457,"Hey there!Yesterday on our podcast, we learned about the tools and resources Madison Kanna used to transition from a modeling career to becoming a successful developer. Madison Kanna started her coding journey in 2017 after deciding to shift away from her modeling career. In one year, she made the full transition and is now a Senior Software Engineer in Health and Wellness at Walmart! Outside of her role, you can find her blogging about what she's learning, or leading the CodeBookClub, a virtual community she started back in 2020.If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""A Model's Journey to Software Development"": CodeNewbie Podcast S24E8Sloan the DEV Moderator for CodeNewbie ・ Jun 28 ・ 1 min read#codenewbie#podcast#career#beginners  If you were struggling with keeping motivation towards your goals this week— this podcast episode is perfect for you.We pulled some of our favorite tips that Madison shared below!Learning how to code is largely about learning how to focus.You have nothing to lose by being generous with others. Work the problem. When you're getting upset over something happening, work through the problem. Get in there, try to figure out the problem, and then keep going.Remove the dream killers from your life! Having people who truly believe in your abilities can make a world of difference.If you listened— how do you stay motivated when working on a frustrating project or goal?Tell us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
458,"My quest to document content campaigns and their keyword research tactics lurches on today.  For this particular installment, I'm going to document one we (Hit Subscribe) have been doing a lot lately: the glossary.In case you haven't been following my rather halting process, this is another addendum post to the SEO for Non-Scumbags series.Glossary Campaigns: A Quick DefinitionAs with tool user campaigns, glossary campaigns lend themselves pretty well to an elevator pitch.  Create a glossary of terms relevant to your brand and publish a ""post"" for each term.I put post in quotes because I tend to think of these as glossary entries, rather than blog posts, even if the mechanism through which you publish them is a blog CMS.  It's like you're building a specific, niche wiki on your site.The glossary should, ideally, have a jump page with quick definitions and links, and then URLs for each individual entry, ideally with ""glossary"" baked into the URL.  InfluxData does this perfectly, with a glossary jump page and then pages like this one, about columnar databases.  Notice the URL scheme with ""glossary"" (influxdata.com/glossary/) for the main page and then satellite pages that extend that page (influxdata.com/glossary/columnardb).Glossary campaigns limit themselves to nouns (what is it searches) by their nature.  As a result, segmentation is quite loose -- it's just anyone curious what the term means.The Broader Goal of Glossary CampaignsA glossary campaign is so generally good for the site's holistic SEO that I'd say the goal is, well, SEO.  You would create a glossary if you had substantial budget (or lots and lots of time) and were committed to search engine traffic as a lead acquisition channel for the long-haul.  If those things are true, it's a no-brainer.With that in mind, let's go through a list of tactical benefits that support my thesis here.Glossary campaigns are a natural, heavily overlapping, complement to term ownership campaigns.  If you want to own a noun keyword, a glossary is an excellent raison d'etre for that content, compared to writing a post on your blog called ""what is DevOps?""As such, glossary campaigns are solid gold for building topical authority in your niche.Canonical definitions are incredibly natural for linking purposes, so your glossary will tend to attract natural backlinks.Speaking of links, they're great for beefing up your internal linking game.  Just do a text search of your site for the term in question and add a link everywhere you find it.You can drive prodigious brand awareness by showing up in every definition SERP related to your domain.  Everywhere searchers look, there you are.The glossary itself will start to attract direct visits, thus opening up another acquisition channel.  In other words, if a searcher lands on your site often enough when looking things up, they may simply start navigating directly to your site for their research and searching from there.This is a little broad-brushy, but I'd venture to say if you aim to have 6+ figures of monthly traffic to your site, you should probably have a glossary.How To Do the Keyword ResearchThere is going to be a good bit of overlap here with term ownership campaigns.  However, glossary campaigns are more specific in one important way: you're limited to people asking the question ""what is it"" about a term, which means you're largely going to be targeting nouns.Contrast this with ownership campaigns, where it's entirely appropriate to create content addressing other sorts of questions to build topical authority (guides, tutorials, comparisons, etc).Anyway, let's go through it.1. Brainstorm Seed TermsI'd start out with some simple brainstorming of relevant terms.  Perhaps start with a thought exercise:If you were to put ""company"" after them, which nouns would describe your brand or site?In other words, take Hit Subscribe, and let's revisit some of the old terms from the Airtable base I created for this post series.Would it be accurate to call Hit Subscribe a developer marketing company?  Sure.  What about a digital marketing company, a content marketing company, a content marketing strategy company?  Again, sure.That's the exercise for coming up with seed terms.Don't worry about volume, difficulty, or any other kind of vetting at this point.  Just capture the terms.  And make sure they're all nouns (or nouns with modifiers) with a ""what is it"" searcher question.2. Grow the ListJust sitting there asking yourself what you are isn't going to create a comprehensive glossary.  You'll need to expand.The first thing I'd do is scan and scrape the copy on your own site.  If you're an indie, maybe look in your resume.  The idea is that you want to search for terms of art related to your niche.Once you've exhausted that, see how others talk about you, if applicable.  Look through testimonials, links to your site, customer conversations, etc.  If they describe you using certain terms, it's a safe bet that those should find their way into your glossary.Finally, I'd go scanning other sources looking for terms of art.  Look at your competitors or businesses in a similar niche and see what terms are on their site.  Google the terms you already have, click on some of the results and scan that content for terms of art.You'll have to find something that works for you, but your general charter is ""would this term make sense is a brand-specific wiki?""3. Cull the List Based on Searcher Question and IntentOnce you've built up a sizeable list of candidate terms, you want to start to qualify them.  Now, before I tell you how, I suggest that when terms don't qualify, you don't delete them from your list.  Instead, just tag them as disqualified for such and such reason.The rationale here is that the glossary will serve as a living corpus on your site.  You'll add to it and modify it with time.  So having an alphabetized list of terms, qualified and disqualified, is a hedge against future pointless rework.That said, here's how to disqualify terms.Get rid of anything where the search intent isn't ""what is it"".  We don't want comparisons, round-ups, etc.  There can be a fine line, in some cases, between a pure ""what is it"" and something a little guide-flavored.  For instance, a search for aws lambda results in a guide and a wiki definition, so an entry there could work.  But if you've got something that's more obviously a guide, like this Appium guide, for instance, you'll want to exclude it.  The heuristic I'd use is ""would a wiki style article be appropriate?""Disqualify anything with navigational search intent that's branded.  For instance, if people google mongodb, they're looking for mongo's site, not your glossary entry defining mongo.Disqualify synonyms.  For instance, with the Influx example above, ""columnar database"" and ""column database"" are search engine synonyms.  You only want to pick one to target, and then tag the other(s) as synonyms for your record.You'll notice something conspicuously absent here: disqualifying based on low volume or non-winnability.4. Prioritize Based on Traffic PotentialWith glossary campaigns, the quantitative metrics are a bit less cut and dry.  Because, remember, you're building a corpus of content.  You can't exactly omit something from that corpus because it would be too hard to rank or because an SEO tool tells you not enough people search it.For this reason, I think less in terms of eliminating difficult or low volume terms, and more in terms of prioritizing them for later (when, incidentally, you might have more topical and domain authority anyway).You'll want to create your jump page as the very first step, and then seed it with quick definitions of all of your terms.  But from there, you'll add to the content corpus gradually over time.So prioritize the winnable, high volume terms first, and then work through them in descending order of traffic potential.Of course, other concerns may factor in here.  You might choose to focus on terms very close to your value prop, or have some other reason not to go strictly by the numbers.That's fine.  Just go with a ""when in doubt, prioritize by traffic potential"" mantra holistically.Recap and SummaryWhen you've executed the steps here, what you'll have on your site is a sort of brand-relevant mini-wiki.  And that's very powerful for SEO because it checks a lot of boxes: organic traffic, direct traffic, backlinks, topical authority.  But it's also a pretty serious commitment, since noun-terms tend to attract the most competition.Here's a replay:Brainstorm a list of terms relevant to your brand.Expand it through further keyword research sessions.Qualify the list based on qualitative/intent terms about the keywords.Prioritize based on traffic potential.Execute.Glossary campaigns are very straightforward and very effective.  But they're also a bit of an SEO howitzer, given term competitiveness and the fact that it's a LOT of content.If you're going to execute one, it's going to mean either a substantial financial commitment or a substantial labor commitment.  So, by all means go for it, but only if you're seriously committed to SEO as a channel."
459,"As developers, our first year in the field is filled with numerous learning opportunities and challenges that shape our career paths. Looking back, what were some of the key lessons you learned during your initial year as a developer? How have those learnings been tested and evolved as you've gained more experience and expertise over time? Share your insights, anecdotes, and advice on navigating the ever-evolving landscape of software development. Let's explore how our early experiences have influenced our ongoing growth and development as developers.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
460,"Time for #DEVDiscuss — right here on DEV 😎How To Build a Scalable SaaS Backend in 10 Minutes With 100 Lines of Code 🚀JS for ZenStack ・ Jun 21#webdev#javascript#typescript#architectureInspired by @jiasheng's Top 7 post, tonight’s topic is...developing SaaS (software as a service) products!In their post, @jiasheng shares about their project @zenstack and how it can be used to build ""a scalable SaaS backend in 10 minutes with 100 lines of code"" 🔥It’s hard to build a scalable SaaS system. Having been involved in the development of four commercial SaaS products at my previous company, I've come to realize the multitude of complexities that arise compared to typical consumer products. Among these complexities, one prominent area lies in the intricate realm of permission control and access policies.  Questions:What's more important to you when building a SaaS: reducing complexity, or having lots of features and functionality?How have you approached access control with SaaS apps in the past?How does building SaaS at the startup level differ from working on a SaaS at the larger, commercial level?Any triumphs, fails, or other stories you'd like to share on this topic?"
461,"Hey Ruby enthusiasts! Let's talk about those hidden gems in Ruby that often go unnoticed but pack a punch! What are some lesser-known features or techniques that you find fascinating or exceptionally useful? Share your personal discoveries, tips, and tricks that make your Ruby coding experience even more delightful. Whether you're a seasoned Rubyist or a curious beginner, join the conversation!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
462,"Google Domains is in the process of being sold to Squarespace. See Squarespace for more info on the pending sale. What are your thoughts on alternative domain registrars to Google Domains? Do nothing and just go with Squarespace after the transition? They indicate they will keep Google's renewal pricing for at least 12 months, but I'm guessing they will increase significantly after that (e.g., domains that currently cost $12 at Google would cost $20 at Squarespace's current rates).Alternatives to Squarespace that I'm considering are Porkbun and Cloudflare. What are your opinions on those? Pros and cons? What others should I consider? Some things that are important to me include no game playing on pricing (e.g. same renewal price as registration price), no added costs for things that should be included (e.g. DNSSEC, Whois privacy, etc). Squarespace appears to meet those requirements.Which registrars do you use or have used? What do you like about them? What don't you like? Have you had any problems?"
463,"Starting out in the world of coding can be overwhelming. So, how can we provide effective guidance and support to budding programmers without stifling their independence? Share your thoughts and experiences on what you've found to be successful strategies for mentoring new coders without overwhelming them. Let's learn from each other and empower the next generation of developers!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
464,"Our final episode of the season is already here!In S24E8 of the CodeNewbie Podcast, @saronyitbarek talks about how to hone your focus as a new coder and the importance of seeking mentorship with Madison Kanna.      codenewbie.org    Madison Kanna started her coding journey back in 2017 after deciding to shift away from her modeling career. In just one year, she made the transition fully and she is now a Senior Software Engineer in Health and Wellness at Walmart! Outside of her role, you can find her blogging about what she's learning, or leading the CodeBookClub, a virtual community she started back in 2020.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Thank you all for listening to this season of the CodeNewbie Podcast. Goodbye for now and a very happy coding to all! 💜"
465,"Have you ever wished for an emoji to perfectly capture something you were trying to convey. If you had the chance to create an emoji that doesn't exist yet but is essential to your everyday life, what would it be? Whether it's a unique expression, a symbol, or a gesture, tell us more about your missing emoji! 😊🎭🎨❓🤷‍♀️Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
466,"  The Legacy of Alan TuringBorn on June 23, 1912, Alan Turing would have turned 111 this year. As a mathematician, computer scientist, and crypto-analyst, Turing's contributions to the world of computing were unparalleled, earning him the title ""The Father of Modern Computing."" His work at Bletchley Park during World War II, specifically his efforts in deciphering the Nazis’ Enigma-machine-encrypted messages, played a crucial role in the Allied victory. Turing's work transcended boundaries. He proposed the Turing machine, a theoretical device that manipulates symbols on a strip of tape according to a table of rules, which could be considered a blueprint for modern computers. One of Turing's most notable contributions to the modern tech industry is the Turing Test, an experiment to explore if a computer could pass as a human being. The test requires a human to pose questions to determine if the responses came from a computer or a human. While the test eventually revealed its weaknesses, it remains a critical milestone in the development of artificial intelligence.In 1944, Turing created ""Delilah"" — a portable machine that could encode a voice message securely, showcasing his foresight into the realm of secure communications. These creations, alongside other groundbreaking projects, demonstrated his innovative thinking.  Celebrating Turing: A Symbol of Pride and InnovationIn the world of programming and technology, Turing's influence remains evident. A system of data-manipulation rules is considered “Turing-complete” if it can simulate any Turing machine. Most modern programming languages are Turing-complete, and the continued use of his name demonstrates the lasting impact of his work. However, despite his achievements, Turing's life was marred by his persecution due to his sexuality, leading to his tragic death at the age of 41. As we mark his birth month, which coincides with Pride, it's essential to remember that Alan Turing was more than just a brilliant thinker. He was also a gay man born in a time and place where homosexuality was criminalized. Turing's conviction and subsequent punishment for ""indecency,"" as it was legally called at the time, remain a stark reminder of the injustices that the worldwide LGBTQIA+ community has faced throughout history and continue to face to this day.In 1952, Turing was arrested after reporting a burglary in his home. In the course of the investigation, the police discovered Turing’s relationship with another man, Arnold Murray. Same-sex relationships were illegal in the UK at the time, and he was charged with “gross indecency.” He pled guilty on the advice of his lawyer, and opted to undergo chemical castration instead of serving time in jail. As we move forward, Turing's story serves as a poignant reminder of our duty to ensure that all people, regardless of their sexuality, are valued for their contributions. In recent years, the world has sought to honor Turing's memory and achievements, the Queen of England formally pardoned him in 2013 and the Bank of England announced his face will adorn the new £50 note. These acts stand as tributes not only to Turing's scientific achievements but also as an acknowledgment of the injustice he faced. At DEV, we believe that it’s our duty to foster a community and a society where every individual can express their authentic selves without fear. In the face of adversity, Turing's legacy inspires hope, resilience, and pride.Happy Pride Month! 🏳️‍🌈 ✊✊🏻✊🏼✊🏽✊🏾✊🏿 🏳️‍🌈"
467,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
468,Weird pic. No context. What's happening here?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
469,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
470,"Hey folks 👋What ya learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Learn to your heart's content. 🧠 ❤️"
471,"Imagine you have the incredible power to make a single change to the coding education system. What would it be? Whether you're a seasoned programmer or just starting out, we want to hear your thoughts. Join the conversation and share your ideas on the one thing you'd transform and the reasons behind it. Let's explore how we can make coding education even better together! 💻🚀Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
472,"Seeing Google kill off and sell Google Domains is such a big surprise to me. It shouldn't be, given they've shut down waaay more than that. I'm still annoyed at them stopping the Google Code Jam competitions and Hangouts and G Suite and... way too many other services.The domains service felt different, for some reason. It was something that it felt like they were investing a lot into (didn't they just come out with the .zip TLD amongst others?) and that people were really trusting. And it made so much money! It served millions of domains!But... it didn't make enough money. Why have a business that can make millions of dollars when you can make billions on ads? It's disheartening, but the bottom line is: Because Google is Google, the only thing that we as users can trust is that if they can make money with ads, the product is more likely to live, otherwise it's going to die.Google has sunk its teeth into our daily lives with Gmail and Google Calendar and YouTube and Drive (and more), and they've made these tools (amongst others, Google Domains included) really convenient. They all just work together, and their APIs are solid enough that third party developers can build off of them relatively easily. And because they own the APIs as a centralized system, developers are at the whim of whatever they decide to change. They can monetize it however they want, and control how content is served to an extent. Now, don't get me wrong, Google is not the only company that does this. Anyone can look at how Reddit and Twitter have changed things for their developers in the past few months because of the dependence on their APIs. Content creators are at the mercy of the platforms that service them, and if TikTok, Facebook/Meta, Spotify, Netflix, YouTube, Medium, Twitter, etc. change, creators have to work even harder to reach their audiences and tailor their content to The Algorithm.All of this brings me to the topic of open standards. I listened to this 2021 podcast episode recently about the importance of open internet standards and it's stuck in my brain as these big changes are announced. When you use communication software that is fully proprietary, you're at the mercy of the creators of that software and how (and sometimes what) they want you to communicate. When you use software based on open standards, you're able to more easily transfer how you communicate and work to other platforms if you want to.Side note: open standards are different from open source, but both are good things, and here is an article about the differences between them.Now, if you're creating software, I'm sure you might be thinking, ""why would I want to make it easy for someone to leave?"" To that, I'd honestly probably respond snarkily with, ""then just build better software,"" heh. But real talk, it's about building a good internet citizen. Think: A rising tide lifts all boats. When something is built with an open standard, that means it can be improved alongside that standard. When you contribute to the standard in addition to your own software, you're benefitting everyone, which is ultimately good for your business.Podcasting is a great example of this, being built on RSS. Listeners get to choose where they want to listen, creators get to choose where/how they want to host their shows, and developers get to choose how they support + build on top of features. Plus, RSS has gotten some great improvements thanks to the podcast ecosystem! There's so many more examples like this that deserve credit, using HTTP and JMAP and WebRTC and mooore. The stability of the open standard enables innovation!Anyway, because of all of these services being killed recently, I personally have been looking to switch away from Google and other softwares that I rely on that don't use open standards, so that I can feel a bit safer about my data. I admit it's fairly challenging (Google Calendar is the only thing supported by most of the scheduling apps I like, ugh, and some things don't have an open standard to work with). But, I hope app devs out there see what's happening as a result of closed systems, and move towards building more in the open and helping push standards forward. Or building new ones!"
473,"  IntroductionExponentiation refers to a mathematical process of multiplying a number by itself, raised to the power of another number.If, for instance, we raise 2 to the power of 3, we calculate it as 2 * 2 * 2, which gives us the result of 8.In JavaScript, you can use either the ** operator introduced in ES6 or the method Math.pow() when evaluating exponents.Before starting, please keep in mind that this operator ^ is the Bitwise XOR Operator. Don't use it for exponentiation, as it is a common confusion.  Using The ** OperatorThe ** operator is used to perform exponentiation in JavaScript. It takes two operands: the base and the exponent.The base (the left-hand side) is the number that is being raised to power, and the exponent (the right-hand side) is the power itself.Have a look at the following example:let result = 2 ** 3 // 8; Enter fullscreen modeExit fullscreen modeIn this example, 2 is the base and 3 is the exponent. The ** operator raises 2 to the power of 3, which is 8.  The Precedence Of The ** OperatorKeep in mind, the ** operator has higher precedence than the multiplication and division operators.This means that if you have an expression that includes both multiplication and exponentiation, the exponentiation will be evaluated first.Here’s an example:let result1 = 2 * 3 ** 2, // 18    result2 = (2 * 3) ** 2; // 36Enter fullscreen modeExit fullscreen modeIn this example, regarding result1, 3 is raised to the power of 2 first, resulting in 9. Then, the multiplication is performed, resulting in a final value of 18.But if you want to precede the multiplication operator in the case of result2, you have to enclose the multiplication operation between ().Another example, if you want to find the nth roots:let result1 = 8 ** 1 / 3, // 2.6666666666666665    result2 = 8 ** (1 / 3); // 2Enter fullscreen modeExit fullscreen mode  Using Math.Pow() MethodIn addition to the ** operator, JavaScript also provides the Math.pow() method for performing exponentiation.Like the ** operator, this method takes two arguments: the base and the exponent.Here’s an example of how to use Math.pow():let result = Math.pow(2, 3); // 8Enter fullscreen modeExit fullscreen modeIn this example, 2 is the base and 3 is the exponent. The Math.pow() method raises 2 to the power of 3, which is 8.  Math.pow() Method vs ** OperatorActually, there is a slight difference between them regarding the BigInt type.The Math.pow() method doesn't support the BigInt type, however, the ** operator supports it. Take a look at the following example:let result1 = 2n ** 4n, // 16n  result2 = Math.pow(2n, 4n); // Uncaught TypeError: Cannot convert a BigInt value to a numberEnter fullscreen modeExit fullscreen modeIn JavaScript, the BigInt is created like 2n or BigInt(2)  Which One Should You Use?As you saw, there are no big differences between Math.pow() and the ** operator.However, if you work with BigInt values, go ahead with ** operator, rather than such a case use whatever you want.Keep in mind, if you chose the ** operator, just take care of the precedence.  ConclusionExponentiation is a fundamental mathematical operation. And, in JavaScript, exponentiation can be performed using the ** operator or the Math.pow() method.In this article, we knew how to use both, the ** operator and the Math.pow() method.Then, we knew that there are no big differences between them, so it is up to you to use either of them.  Before you leaveIf you found this article useful, check out these articles as well:4 Ways To Handle Asynchronous JavaScriptOpen-Closed Principle: The Hard PartsHow To Use GraphQL Directives Efficiently?Thanks a lot for staying with me up till this point. I hope you enjoy reading this article."
474,"Hey folks! Let's dive into a crucial topic for C++ developers: memory management. How do you handle it in your code to steer clear of memory leaks and maximize resource efficiency? Share your experiences, tips, and best practices for effective memory management in C++. Whether you're a seasoned pro or just starting out, let's exchange insights and learn from each other to write cleaner, more efficient code. Join the discussion now! 💡💻 Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
475,"cover image source: xponentialdesignThis week, I wanna give y'all the opportunity to drop music that you've made. There are so many creative folks in this community and the Venn diagram of developers who are also musicians is really quite impressive. So, go dig through those digital crates (y'know, your computer files) and find something of yours to share with the community here. If you don't have music of your own to share, that's okay... you could share music by somebody you know! Or, as always, you can drop whatever music you'd like to in this thread. Lastly, major props to @jmfayard for leaving an inspiring comment that led to this edition & for giving me the idea to create this accompanying thread - You Play Music, Too? Let's Connect!  How we doIn this weekly series, folks can chime in and drop links to whatever it is they've been listening to recently + browse others suggestions. You can follow the suggested genre if you'd like, but don't feel confined to it; you're free to suggest whatever you wanna. 🙌  If you're interested in having other discussions about music, consider following the aptly named #music discussions organization.#music discussionsFollow        Let's talk about #music. 🎶      Now, lemme hear some of your tunes! Note: you can embed a link to your song using the following syntax {% embed https://... %}. This should work for most common platforms!Looking forward to listening to y'all's suggestions! 🎶"
476,"Hey there, coding enthusiasts! We all know about the popular learning platforms, but what about those hidden gems? We're talking about lesser-known resources or learning platforms that you'd recommend to new coders for self-study and skill development. Maybe you stumbled upon a fantastic coding blog, a YouTube channel with incredible tutorials, or an underrated online course. Share your secret weapons and give a shoutout to these hidden gems that have helped you level up your coding game. Let's uncover these hidden treasures and help each other on our coding journeys!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
477,"We hear a lot of backlash when prominent CEOs call for a return to office work culture, but I'm curious if others may feel opposite of the public sentiment?  I support the option for people to work remotely within an org if their roles and responsibilities can be performed asynchronously, but my personal preference has always been to operate in-office.  That was taken away from me as a result of the pandemic as my company ended up shuttering the local office.  After spending these last 3 years working 100% remotely, I find myself with a renewed desire for a hybrid working environment.  It's not an option with my current company, but I can't deny that it's what I think is best for my career progression. I'm far more effective with some in-person collaboration on a regular cadence.  Do you share similar sentiment, or do you find yourself freed by remote work?Let me know your thoughts in the comments below ⬇️"
478,"Countless books have been written to guide and educate us in the realm of programming. But which one stands above all the rest as the most influential of them all? What coding resource book do you consider to be an absolute game-changer or a a timeless gem that has left an indelible mark on the programming world? Share your thoughts, experiences, and recommendations so we can build out coding libraries!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
479,"  Table of ContentsReally long introduction about how I started writing tech blog postsAddress your fearsKeep a list of things you’ve learnedChoose the topic you feel most excited aboutRead other blog posts for inspirationDetermine your audienceBuild an outlineTake a showerEnter a flow state for writingStruggle with writing? Record your voiceRead it aloud (or use a Text-to-Speech reader)Use a digital writing assistantShare your draft with stakeholders to gather feedbackAdd a cover imagePublishShare it on social mediaAdditional ResourceConclusionCall to action  Really long introduction about how I started writing tech blog postsTechnical skill and content creation are equally important for your software development or (software development adjacent) career. Technical skills such as coding help you to perform the job at a base level, but content creation can solidify you as a leader in the industry. I acknowledge that not everyone has the privilege of creating content alongside completing their daily job duties and personal responsibilities, but it is a worthy investment. Creating technical content can make it easier to land jobs, get promoted, and influence the direction of our industry because it enables hiring managers and other tech leaders to take a peek into your brain and your thought process. More importantly, it helps you absorb and solidify concepts that you’ve learned. You can be the smartest, most skilled software developer in the world, but if no one knows who you are, then your opportunities may be limited. Content creation helps you advocate for yourself. It might seem cringe, but you can put yourself out there in a non-cringey authentic way. Folks like Kelsey Hightower established and advanced their careers by sharing their thoughts in an authentic and thoughtful way.My favorite form of technical content creation is blogging. Thanks to my mom, I developed a passion for reading and writing at an early age, so writing has always been my preferred method of self-expression. I had an endless supply of picture books, cassette-tape audio books, novels, poetry, and half-filled notebooks documenting my childhood experiences. When there was no heat in my house, my mom would bring my siblings and me to the library, so the library became my second home. Disclaimer: I’m not a perfect writer; it’s just something I enjoy doing. Unfortunately, I abandoned writing in early adulthood because I learned that it’s hard to make money as a writer, and I had one goal in mind: make LOADS of money. I grew up poor, and I was determined to improve my quality of life, so I focused all my energy on a career that makes money: software development.Years later, I started my third full-time software development job, and my manager Andy Cunningham encouraged me to write what I learned on the job. As part of my sprint, I’d fix a bug or implement a new feature, and then I would write about it. One of my first technical blog posts was about how I used GitHub Actions to sync our repository with our AWS S3 Buckets. Months later, I landed my current role as a Developer Advocate, and part of my role is to blog. While I was excited to combine my childhood skill (writing) with the skill I learned in adulthood (coding), I was also intimidated. Writing about technology didn’t seem as easy as writing a poem or an essay. With poetry, I had all creative authority, and with essays, teachers gave us guidelines. But, what was a technical blog post supposed to look like? I worried and struggled with the following concepts: Will people read it or even care to read it?Will people think I’m wrong or stupid?Do I have anything valuable to say?Is my blog post too short?Is my blog post too long and overwhelming?I want to tell the audience everything, but when should I stop the blog post?I didn’t have any structure or strategy for writing my blog posts. After a year of writing technical blog posts and learning from great content creators like Kurt Kemple, I’ve developed a strategy that I’m comfortable with. In this blog post, I’ll share my strategy in hopes of empowering you.   Address your fearsA common reason that technologists don’t write is because they’re scared.If you’re scared that you don’t have anything new or different to write about…Remind yourself that you don’t have to write about anything revolutionary or inventive, write what you know. While someone may have already written about a similar topic, they won’t explain it the same way you will. And the way you explain and describe information will reach a particular audience that learns and consumes information the same way you do.If you’re scared that your writing skills aren’t up to par…Remind yourself that this is your platform to practice. You will improve over time, and sometimes blog posts don’t need to have flowery vocabulary and complex sentences. Sometimes, the simpler a blog is written, the easier it is for the audience to consume. If you’re scared that you don’t know enough…Perhaps, you only know HTML, but you know more than someone who doesn’t know HTML. You will continue to grow and learn over time. You don’t need to wait until you get to a certain point because as technologists, we’re always learning. There will always be something that we don’t know. If you’re scared of making mistakes…Embrace your mistakes; they help you grow. I make mistakes all the time. Sometimes, I have grammatical errors in my blog posts or even technical errors, and someone corrects me. I learn from those mistakes and I’ve become a better writer, educator, and engineer as a result. Don’t aim to make mistakes, but when you do, know that everyone makes mistakes and it’s part of our journey to greatness. If you’re scared that you don’t have time…This is totally fair as we all have varying responsibilities and limited time. However, it is a worthy investment to reflect on what you’ve learned and share your knowledge with the world. If possible, work with your manager to carve out regularly scheduled time to write, and your blog posts don’t have to be long. They can be as short or as long as you want. You have creative authority over your content.If you’re scared of criticism…Remind yourself that you are writing for you. You are writing, so that you can look back and reflect on your growth. You are writing, so that you won’t have to repeatedly Google or ask your coworkers for help on the same questions. The harmful opinions of others don’t matter. You can always delete their comments or respectfully respond and continue to live life. I’ve found that people like to critique others when they feel threatened.  Keep a list of things you’ve learnedAs you write code at your job, complete side projects, or contribute to open source projects, keep a running list of things you’ve learned.I keep a list in my Notes app on my Mac computer and iPhone. It looks like this### Idea listHack.Diversity- How to negotiate salary- Write thank you letters after interviews- How to pass the technical interview- How to learn / navigate a new codebase quickly - Tips for passing the CompTIA+ test- Code- Invite Automation- Teaching to Empower: Supporting Early Career Devs- Generate Social Cards with JavaScript- From Code to Cloud — Git Emoji- Build a Blockchain Simulation with JavaScript- Make better pull requests- Fuzzy Search Made Easy- Overcoming the Fear of Contributing to Open Source- How to Convince Your Boss to Open Source a Project- Create the Perfect ReadME for your Open Source Project Small things I learned with code- Linked issues- Fusejs- How to make a pull request template- .github/.github/PULL_REQUEST_TEMPLATE.md- https://github.com/open-sauced/.github/blob/main/.github/PULL_REQUEST_TEMPLATE.md- .github- Issue templates- Forms yaml - Being autonomous- Turning a Checkbox into a circle- Handling routing with netlify- Dependencies vs devDependencies- React functions run on load or after- Dealing with broken images in React - SEQA - Rendering components- Using classList- Invite automation- Automatically generate a social image card- Pull request template formsGitHub ideas- Prompt engineering tips with GitHub Copilot- Lowering barriers with GitHub Codespaces- Automatically install extensions with GitHub Codespaces- Automatically install npm dependencies with GitHub Codespaces- Automatically run your node app with GitHub Codespaces- GitHub Actions extension- Using GitHub Pages to federate your Mastodon identity - Building a to do list user interface with GitHub Copilot - Sending a toot with GitHub Copilot- P5.js with GitHub Copilot- I made a GitHub action with my voice- I used AI to build AI- How does GitHub Copilot help businessesEnter fullscreen modeExit fullscreen modeAs you can see, my ideas range from simple concepts like ""Converting a checkbox into a circle with CSS"" to more advanced and creative concepts (like ""Building a GitHub Action with my voice""). Some of the ideas are also repeated. Whenever I get an idea or one of my managers mentions that I should cover a topic, I write it down.Keeping a list of ideas is helpful, so that when you want to write, you’re not also wasting energy and time, brainstorming topics.   Choose the topic you feel most excited aboutIt’s worth noting that I haven’t written about many of the topics listed above. I only write about what I’m most passionate about at the moment or most needed at my job (because this is my job). If it’s one of the ideas on the list, then I will write about it. However, if I have a random spark of inspiration, I will act on the idea immediately. On the other hand, I may also have to write about a topic requested by my coworkers, and I’ll focus on that. I choose the most urgent or the most exciting topic because that helps motivate me.Also, consider granularity in your topics. If you want to write about a general topic, such as React, it would be difficult to write about every single concept of React. It would take a book or documentation to cover the entire framework. Instead, I suggest creating a general overview of React or picking a very subtopic such as, “Understanding the useEffect Hook” or “How I used React to build a blog”  Read other blog posts for inspirationBefore writing anything, I always read. Reading inspires my: StorytellingMy writing styleMy choice of words and sentence structureMy perspectiveMy writing techniqueBy immersing myself in various texts, I can absorb different writing styles and techniques, allowing me to adapt and experiment with my own writing. Additionally, reading exposes me to diverse ideas and perspectives, broadening my understanding of the world and providing me with fresh insights to incorporate into my writing. It also helps me identify areas for improvement, such as refining my sentence structure or expanding my vocabulary. You don’t have to read a really long blog post or novel, but reading a quick paragraph is beneficial in refining my writing.  Determine your audienceNow that you know what you want to write about, and you’re inspired to write, it’s time to determine who you are writing for.As humans, we have a tendency to want to write for everyone. We want to teach and help everyone, and that’s not wrong, but I wouldn’t suggest doing this for a blog post. I often talk with people who have goals around content creation, and they want to target junior engineers, mid-level engineers, and senior engineers simultaneously. If you try to reach everybody, you might end up creating a really long blog post that no one wants to read or you might overwhelm yourself and never actually finish the blog post. Trust me; it’s happened to me before and other technical writers. Even if I do finish it, the blog post ends up having every low engagement and it looks messy.If you choose a very specific audience, then the other audiences will still benefit. For example, I’ve written blog posts for beginners, but sometimes senior engineers let me know that they still learned something new from the blog post or that they appreciated the way I broke down fundamentals.The person I usually pick to write for is me, specifically past me. Here are examples:I wrote the blog post “Overcoming the fear of Contributing to Open Source” to myself when I was in a coding bootcamp and didn’t really understand open source.I wrote “How I used dev containers to enable GitHub Codespaces for ChatGPT” to myself as a GitHub Developer Advocate who was acting as “Customer Zero (well maybe customer 100)” on GitHub Codespaces.I wrote “How to speak at conferences when you’re scared of public speaking” to me in high school who was scared of public speaking.And I’m writing this blog post to myself before I ever wrote a technical blog post.I have also written to my future self. Like, I often create advice for open source maintainers, but I only started maintaining a project in 2023. The advice I wrote in 2021 and 2022 is helpful for present day me.  Build an outlineNow, it’s time to plan what you write. Building an outline helps to align your thoughts in a way that readers will understand. Feel free to tweak the outline templates below, but this is what I use to write my own blog posts  Outline for “how-to” blog postsIf I’m writing a blog post guiding people step-by-step on how to do accomplish a task, I will use an outline like the one below:Intro- Hook- Problem statement/What this solves for myself or readersStep-by-Step Guide1. Step 1Optional: brief explanation of the step with supporting links for folks to learn more2. Step 2Optional: brief explanation of the step with supporting links for folks to learn more   3. Step 3...N. Final StepConclusion- Recap of the process- Final thoughts or additional tips- Call to action (e.g., encourage readers to try the steps and share their results/feedback)Enter fullscreen modeExit fullscreen modeCheck out an example that follows this outline: How to send a tweet with GitHub Copilot  Outline for explainer blog postsI define an explainer blog post as a blog post that explains a topic, but it doesn’t necessarily walk people through accomplishing a task. The main purpose is for readers to get an introduction to a concept.Intro- Hook- Brief overview of the topic and why careBody1. Key Concept 1    - Definition/explanation    - Examples     - Importance or relevance2. Key Concept 2    - Definition/explanation    - Examples    - Importance or relevance3. Key Concept 3    - Definition/explanation    - Examples    - Importance or relevance...N. Final Key Concept    - Definition/explanation    - Examples    - Importance or relevanceConclusion- Summary of the key concepts- Closing thoughts or implications- Call to action (e.g., encourage readers to explore further or ask questions)Enter fullscreen modeExit fullscreen modeHere’s an example of a blog post that follows this outline: Why are people developing in containers?  Outline for thought leadership/opinion blog postsThese types of posts are posts where I just share my opinion on the direction that industry is going. Many times, I use it to create productive conversation and share my leadership skills.Intro- Hook- Brief introduction to the topic/opinion and why it matters to meBody1. Supporting Point 1    - Explanation of the point    - Supporting evidence or examples2. Supporting Point 2    - Explanation of the point    - Supporting evidence or examples3. Supporting Point 3    - Explanation of the point    - Supporting evidence or examples...N. Final Supporting Point    - Explanation of the point    - Supporting evidence or examplesCounter arguments (optional)- Address potential counterarguments or opposing viewsConclusion- Reinforce the opinion and provide a call to actionEnter fullscreen modeExit fullscreen modeHere’s an example of a blog post that follows this outline: The Hard Parts of Developer Advocacy for me  Outline for listicle blog postsThese are posts that are often written in list format. The reason they’re written this way is to make the concept fun, quick and easy to consume for readers. These types of blog posts are often have titles to the ones below:Top Ten Tips for…5 Must-Have…7 Amazing…Intro- Hook or intriguing statement related to the topic- Brief introduction to the theme or subject of the listicleListicle Items1. List Item 1    - Explanation     - Example2. List Item 2    - Explanation     - Example3. List Item 3    - Explanation    - Example...N. List Item N    - Explanation    - ExampleConclusion- Final thoughts or insights- Call to action (e.g., encourage readers to share their favorite item or suggest additions to the list)Enter fullscreen modeExit fullscreen modeHere’s an example of a blog post that follows this outline: 8 things you didn’t know you could do with GitHub Copilot  Take a showerThis is an odd suggestion, but I do my best thinking in the shower. I think the sound of running water helps me to focus on my thoughts. In the shower, I can write a whole blog post in my mind. Besides taking a shower, you can try other activities that can stimulate your mind:WalkingJoggingListening to musicMeditating  Enter a flow state for writingDisable all distractions and start writing. I strongly recommend that you don’t edit as you write. I find that disruptive for my flow. I fill out each part of the outline that I created in whatever order that I prefer. I write the way I speak, and I just keep going. After I’ve written all my thoughts on paper, I will start editing. My editing process consists of deleting irrelevant paragraphs, fixing spelling mistakes, and removing unnecessary punctuation marks. I’m a super light editor. I feel that if I edit it too much or spend too much time perfecting my blog posts, then I will never press publish. In the following paragraphs, I expand a bit more on my editing process. However, the way I look at it is, I want to get my thoughts out there. Once I do, someone will reach out to me – like my job and ask for a more refined version of my blog posts. Then, I could use resources my job provides me like professional editors to improve my blog posts. Also, I recognize that it doesn’t matter how much I edit; my blog post will always need more editing. It’s like code – there’s a bug somewhere. Sometimes, I just edit it after I publish. Often, people message me to say that I spelled a word wrong, and I usually update it afterwards. It’s no big deal. Write for completion rather than perfection.  Struggle with writing? Record your voiceThere are some people who find writing difficult, and that’s okay. Brian Douglas told me about a tip that could help folks who struggle with putting words on a paper: speak. Record yourself speaking, upload the audio to your computer, and use a tool that can transcribe those words.The tool I suggest is Descript. It does a great job of transcribing audio. It may have a few mistakes here and there, so double check what it generates and make small edits.    Read it aloud (or use a Text-to-Speech reader)Reading my writing aloud enhances the quality of my content. When I read text I wrote in my head, I may notice particular issues, but reading aloud allows me to:Improve the clarity and flowEnhance the tone and voiceSpot grammatical and stylistic errorsEvaluate the rhythm and cadence of my contentAssess the audience appealSometimes, I'm too lazy to read my writing aloud or I’m struggling to focus, so I use a text-to-speech reader like, Natural Reader.  Use a digital writing assistantDigital writing assistants like Grammarly find errors you might have missed.  Word Tune is another tool that I find helpful. It’s great because it takes my hard-to-understand sentences and converts them into clear, terse sentences. ChatGPT is another tool, but this one is a little more controversial. While I don’t encourage folks to use it to write whole articles, it does give great feedback. I’ll often prompt ChatGPT with the following:What did I do well in this blog post?What didn’t I do well in this blog post?Can you help me come up with a better title for this blog post?  Share your draft with stakeholders to gather feedbackI received this advice from Kurt Kemple: Share a draft of your blog post with people at work who asked you to write the blog post (product managers etc) AND someone from your target audience. When I follow this advice (because I'm lazy), I always get a high level of engagement and a quality final product. For example, I wrote this blog post called, “How do I resolve merge conflicts?” I shared the draft with my friend Nathan, who recently graduated from a coding bootcamp. Nathan’s feedback helped me ensure that beginners could understand my blog post, too!  Add a cover imageIn addition to well-written content, adding a cover image to your technical blog posts can significantly enhance their appeal and engagement. Don’t ignore this step. Including a cover image demonstrates your commitment to presenting your technical content in a professional and polished manner. It shows that you've put thought and effort into crafting a visually appealing and well-designed post, which can elevate your credibility as a writer and technical expert.I’m not an artist nor am I great at design. I often use the following tools to help me create an image like:CanvaFigmaI’ve also seen folks like Bekah H.W. and Brian Douglas use Midjourney to create cover art. I believe my friend Mayank uses Excalidraw to create cover art.Several of my covers images aren't that cute, but here are a few that I think look great:  PublishPublish your blog post on the platform of your choice. You can use:DEVHashnodeFree Code CampMediumOr your personal websiteYou can make the decision on where you want to post based on your target audience and how you want to own your content. I sometimes use a platform called BloggU to cross-post on multiple platforms.  Share it on social mediaCongratulations, you posted the blog, but you’re not done yet. Share your post with others helps the post gain more engagement. Sometimes, I receive messages from folks I’ve never met before that my blog post was helpful for them. Social media enables me to reach folks worldwide. I try to share my blog posts on: TwitterBluesky Mastodon LinkedInDiscordSometimes I share posts with my coworkers on Slack (could be cringe, but no one is going to know that I created these things if I don’t tell them)I try not to announce things in a self-centered way. You can if you want to, but I want to show that my intentions are to share knowledge and grow rather than be at the center of attention. So I might add a small blurb that says something along the lines of: “Hey y’all! I used to struggle writing blog posts, but now I’ve gotten the hang of it, so I wrote a blog post to help others develop a good strategy, too. Check it out and let me know your thoughts.”  Additional ResourceThe Developer Advocate’s Guide to Content Creation by Kurt Kemple  ConclusionWriting technical blog content is not easy, but I’m hoping the above steps can help you to stay in the flow and create content that you’re proud of. Again, I want to emphasize that we’re not striving for perfection. This blog itself is far from perfect, but it accomplishes two things:If I ever forget my process or I’m feeling impostor syndrome, I can always re-read this post as a reminderIt helps aspiring technical blog writers to level up their careers  Call to actionI would love to hear about different writing strategies to improve your blog content or anything that I listed that’s been helpful to you. For more content like this, follow me! Stay cool, friends 😎"
480,"It's self-improvement Sunday! So, let's talk about self-improvement and continuous learning. How do you approach this ongoing process? Are there specific strategies or habits that have helped you level up? We'd love to hear your thoughts! Also, as we kick off this week, what's one thing you're committed to learning or improving? Share your goals and let's support each other in this exciting journey of growth and development!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.       "
481,"To play this game, take a virtual screenshot of your iOS or Android or Mac or Whatever recently used emojis"
482,"Let's take a trip down memory lane and share the tech gadgets or toys from our childhood that sparked our love for coding. Whether it was a classic game console, a programmable robot, or even a basic calculator, we all have that one gadget that set our imagination on fire. So, what was your favorite childhood tech companion that fueled your interest in coding? Share your stories, fond memories, and how that gadget influenced your journey into the world of programming.🤖🎮🚀Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
483,"What was the first online community you joined? Was it a gaming forum, a coding community, or a niche interest group? And how did it shape your digital journey?From finding like-minded individuals to exploring new interests, share your stories of how your earliest online community influenced your perspectives, skills, and personal growth. Let's celebrate the power of online connections and the lasting influence they can have!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
484,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss whether or not web devs should think about diversifying their skill sets due to industry changes and advancements in AI.I got this message in my inbox this week:Is this the right time to start developing a skill outside of web development? It seems like AI will be taking over web dev jobs soon.This question reminded me of a post I read a few weeks ago from @codepo8 about how hard it's been to find work as a fronted dev — not specifically related to AI, but it's a similar concern:The ongoing defence of frontend as a full-time jobChristian Heilmann ・ May 9 ・ 4 min read#frontend#engineering#hiringSo, what do you think? What's the future of careers in web dev? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
485,"A little story of a workaholic entrepreneur switching from a developer to a product founder in 10 years.  How it all startedI was a happy student when I started to develop for money. It was a lot of fun and it was super interesting: a lot of new technologies, a lot of challenges.I had no family at that time (too early) and I had all the time to develop things. I was kind of a geek and I was always super strict to myself on deliverability.The company I was working for was small and full of entrepreneurship or better to say startups, which was awesome, otherwise, I would leave it earlier.But even it was a lot of fun, I decided to go further into the world of freelance. I was aiming to become an owner and boss to myself.  Owning the life being a freelancerIt always a lot of ""benefits"" of being a freelancer, ones could imagine a person sitting on a beach of an island drinking a mango smoothie and working on a project... This is a nice picture to imagine, but for most freelancers, it's not like this at all.It was a long standup for me. It was necessary to produce good reviews and build a few products for free. But later I managed to find one customer, and then another.Then accidentally I was working with 10 different customers at the same time: you know that, handling support vs active development.Did I become super-independent? No, not really, instead of one boss on my previous job I got 10.Yes, I have increased my income, from 3-4k to 8-12k per month.Yes, I have increased my expertise quite a lot because I have joined more than 30 different projects in different niches, especially in e-commerce, travel-related and fin-tech.No, I don't get any way to become happier in that setup, it didn't work for me.So I had to quit and find a better focus for me. It is not something I liked to do forever. I didn't want to come to ordinal work at the office as well.So it was the moment when I had to switch to the product.  How do you get to product ideas?I believe that the best product ideas could be born at the centre of your expertise.While working on different client projects I always repeat the same routine, again and again. Their routing is the thing that everydeloper does every day.Every developer reinvents the wheel every day to build the bicycle.Example: How much time it's necessary to spend to build a simple ToDo list with backend and frontend, DB, Email notifications and such?Well it could be various, but it will take at least one day if you are familiar with the deployment, you have good knowledge and high expertise on many aspects likeHostingDNSFrontend Frameworks, HTML + CSS + JSBackend FrameworksEmail Providers,Email templatesetc.How much time do you need to spend to get such expertise and deliver faster enough?Remember we are talking about a ToDo list, the simplest app we can imagine.These days I met John, who is started his work on Mars. It was a nice match, he got into the same set of questions but did a step further - started to deliver a product that could solve this.  Let's build a ToDo List as quickly as possibleLet's talk about the ToDo list again.One day I asked myself what could be the easiest option to develop a ToDo list app.For me, the answer is: don't develop it -> Reuse something that is already developed/tested/production ready.The question is how? From top to the bottom in terms of the amount of knowledge requiredYou could find a few ready-to-go npm or *any-ecosystem* packages to get it fasterYou could build something with AI - just ask to build UI and API and then improveYou could find a GitHub seed projectYou can use a low-code solutionYou can use a no-code solutionSo which option to pick depends on many factors likeAbility to customiseAmount of effortsRunning costs (cost of hosting and maintaining )Long-term support and improvementsLet's focus on Customisability VS Speed of developmentI have tried to compare options and a simple chartFrom my experience, the more you want the solution to be different to others -the more time you need to spend.I have tried many no-code platforms, and they gave me good speed in the beginning, but I always had a lack of customisation and simplicity of updating as soon as the project grows. At the same time, the fully custom solution I have developed for my clients is something I'm not able to support as well because the amount of custom functionality the product eventually introduce is huge, you need a team to manage this, which is ok, but it creates bigger running costs.Then I take a look at low-code platforms, it was a bit ""unclear"" thing for me. In simple words, it's a kind of platform where you can code, but at the same time, you can use a no-code approach. It seems like a perfect combination for me and that is where Mars is sitting.How it works thereEverything on Mars is a micro-app. You can combine them, fork, reconfigure etc. You can do a lot of changes without coding and you can write a thing from scratch if it's necessary.  This is how I came to the product ideaMars seemed like an awesome platform for me, but it's just a tool, the same as many others. If I want to build a ToDo list on Mars I need somebody to develop such a micro-app for me. Then I did a simple approximation on bigger products: an e-commerce store like Amazon, service marketplaces like Booksy or Renting platform like AirbnbAnd I got thisMany people develop similar big and complex apps today.And all of them repeat the logic.Every founder pays for this.So, to make such founders' and developers**'** lives better, I could provide them with ready-to-go reusable micro apps built by niche experts.Being a developer myself and having quite a huge experience in many niches after 10 years of product development for clients I was in the right shape to take it off.That is how Fleexy has been founded. Or flew up!  The Team, or CrewTeams build things together, and Crews starts the spaceships.From the products I have worked with, I remember a few very talented guys.Perfect tech experience, passion to create things, open-minded and honest vision of things.Together with Alexey and Andrey, we founded Fleexy. We aim to build the biggest foundation of micro-apps for Your Future Product.It was a nice moment, it was always so inspiring to build a new thing, you start light, you have no dependencies, and you feel like you can fly. So we did.But we are a self-bootstrapped company, we have no investors, that means we don't have a lot of money to burn.That means that we have to find a customer sooner than later.  Building a product is a lot of funWe started with an obvious thing: testing different niches, where we could be helpful.That is how we get into 2 of themServices-MarketplaceSocial-MarketplaceBy doing these demos we also created a solid number of micro apps we can use now for our next project/product. We were happy to share that with the world.So we build a website and describe what we are and why. And guess what?We got 0 visitors.  How Coders switch to MarketingThat's where we are now. We are in marketing mode. We do posts, we do tweets.We literally spend days writing blog posts (and we still do), we do keyword analysys, and we do back-link building to get higher domain authority.That already gave us some leads!This helped us to get our first customers and even released one of them The Daba. It has been built on top of the Services-Marketplace solution we have. It has a lot of customisations, especially in terms of UI, and it looks and works awesome. Try it out.  Fleexy is just at the beginning of the flyWe have quite big ambitions - we want to disrupt the current way of app development. It should be faster, quicker and cheaper. The more we do this, the more I believe we will make it work.And as for meFor sure I lost the income. It was a lot of pressure and it still is.But I got much more:Having a mission I believe could impact many things tomorrowThe crew I can trustFreedom to do things and be able to define my next stepThe long journey I'm happy to be part ofFollow me on TwitterConnect on Linkedin"
486,"What does it truly mean to be a nerd? Is it about unabashedly diving into obscure tech topics or passionately immersing ourselves in the latest gadgets? And here's the fun part: what's the nerdiest or geekiest thing you've ever done? Did you build an epic PC rig? Cosplay as your favorite character? Esëa aldarin sercëa?  Show us your inner geek 🤓 and let's unite, revel in our nerdiness, and geek out together!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      Image by Freepik"
487,"Yesterday on our podcast, we had on Daniel Devesa Derksen-Staats, Senior Accessibility iOS Engineer at Spotify to discuss how we can all add accessibility into our coding toolkits. Dani has previously loved working at Skyscanner or the BBC, where he learned a ton about how to make iOS apps more accessible. Sometimes he lets Xcode have a break and spreads the love for accessibility at conferences. Author of the “Developing Accessible iOS Apps” book, he keeps himself busy by writing a daily tweet about accessibility and iOS with the hashtag #365DaysIOSAccessibility.If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""Building Products for Everyone"": CodeNewbie Podcast S24E3Rachel Fazio for CodeNewbie ・ May 24 ・ 1 min read#podcast#codenewbie#career#a11yUpon listening to the podcast, we wanted to discuss some of the tips that Dani shared with us about creating accessible products.  So, What Is Accessibility?Accessibility is making sure our products work for everyone, regardless of their ability.   How Can I Make My Own Products More Accessible?When we can build accessibility tests and features into our processes of creating a product, we can create better solutions than adding in accessibility features at the end of a project.There are many different entry points to making your product more accessible. Accessibility functions can range from optimizing for Screen Readers and Voice Overs to achieving optimal color contrast, grouping and ordering components, conveying information in different modes, and offering larger touch target sizes.There are also plenty of accessibility features that benefit able-bodied individuals, such as dynamic type, dark mode, and subtitles.Our products have to be capable to support both permanent and impermanent disabilities. People may go through shifts in their lives in which they sustain an injury or support an infant, in which their needs on an app can shift. Folks may experience degradation of motor function or eyesight as well, meaning that our accessibility functions must be able to be customized throughout their use.When choosing which accessibility functions to prioritize first on a product, it can be helpful to run statistical data about your market’s demographic. However, make sure to conduct research outside of your data, because some of this data may not account for the full picture of what features could be needed.If you listened— what did you learn?Send us your thoughts below on how you have made your products accessible and don't forget to give this episode a listen here or wherever you listen to your podcasts! 💜"
488,"Have you recently delved into any new languages? Share your experiences, thoughts, and discoveries. What are the strengths and weaknesses you've observed? Are there any specific domains or applications where these languages shine? Tell us about it!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
489,"Open Source is about the community. Whether you have a project or you're looking to make your first PR, we want to help facilitate those connections.   Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy coding!"
490,"In honor of Juneteenth, we’re uplifting initiatives and organizations that center Black and African-American technologists. Black Lives Matter, and we celebrate these orgs for their contributions toward creating futures for Black people and African-Americans while shaping our industry for the better.In this post, we shine a spotlight on Black Tech Pipeline.Black Tech Pipeline is a talent recruitment platform focused on Black professionals in the tech industry. It was founded in 2020 by Pariss Chandler, a software developer turned tech recruiter who discovered her passion for empowering Black technologists when she mobilized the hashtag #BlackTechTwitter in 2018.Today, Black Tech Pipeline is home to a job board and newsletter aimed at connecting Black tech workers with roles, opportunities, and resources to support them in thriving in the tech industry. According to the BTPipeline FAQ:Black Tech Pipeline partners with companies who truly practice safety, diversity, equity and inclusion internally and externally. We promote companies and organizations who are taking actionable steps to support their team members from marginalized communities in visible and impactful ways.Black Tech Pipeline Job BoardIf you're a Black technologist seeking new opportunities, consider checking out the Black Tech Pipeline job board for open roles!If you're hiring — and your company is committed to the above values — you can submit your open roles for consideration using this AirTable form.To hear Pariss share more about her experience building and growing Black Tech Pipeline, check out Season 23 Episode 8 of the CodeNewbie Podcast!S23:E8 - Empowering the Next Generation of Black Tech Talent (Pariss Chandler)        CodeNewbie          Your browser does not support the audio element.  1xinitializing...×As this final week of June comes to a close, we encourage you to support the work that organizations like CODE2040, Black Girls CODE, and Black Tech Pipeline are doing to advance racial equity in the tech industry all year round. Together, we can shape a better, more inclusive future for all. 🙌"
491,"How do you think open-source software influences industry trends, sparks innovations, and fuels community-driven initiatives? Share your insights, experiences, and success stories that demonstrate the transformative power of open-source collaboration. Let's explore how open-source software has become a driving force, shaping the future of software development. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
492,"Time for #DEVDiscuss — right here on DEV 😎Inspired by the hot news topic of the week, tonight we're discussing...Reddit's API changes!In case you missed it: Reddit has recently made changes to its API, including a decision to charge for API use over a certain limit. This update will cause various third party Reddit apps, including the very popular Apollo, to close down due to an inability to afford their operations. In response, the moderators of many Reddit communities have taken their subreddits private in protest.DEV user @theaccordance had a unique, intriguing take on the whole situation:The Reddit blackout is a lesson in risk managementJoe Mainwaring ・ Jun 16#discuss#security#learning#startupThe 2010s was a golden age in capital investment and the technology industry benefited significantly, enabling a lot of free resources as a draw to build audiences and engagement. However, the 2020s so far have proven to be more challenging. Money is no longer free and as a result, many companies are having to mature their business models to be more self-sustaining. This means reducing expenses and finding additional sources of revenue. Monetizing previously open APIs is an unfortunate intersection that addresses both needs. Expect less free beer on the internet as we progress through these tougher economic times.So let's talk about it!Questions:What do you think about Reddit's API changes?Have your internet browsing habits been affected by the protests?Do you think we'll continue to see changes in the ""free"" internet as the years progress?Any other perspectives you'd like to share on this topic?"
493,"Hey guys, how are you? I hope you are doing great!So, what was the last thing that you learned or what have you been learning?By the way, I have been studied about Splunk (https://www.splunk.com)"
494,"Hey fellow coders, here's a question that often pops up in interviews: Have you ever worked with cloud platforms or deployed applications in the cloud? It's a chance for you to showcase your familiarity with cloud computing and discuss its advantages. Whether you've experienced the scalability, cost-effectiveness, collaborative potential, or global accessibility of the cloud, we'd love to hear your insights. Experienced devs: perhaps you'd care to share your experiences with cloud computing and application deployment in order to help our newbies out! Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
495,"  Table of ContentsThis blog post is long. Click this dropdown for a smoother navigation experience!Use GitHub Copilot to build a markdown editorPrerequisitesStep 1: Create a Next.js GitHub Codespace template (30 seconds)Step 2: Install specific dependencies (30 seconds)Step 3: Delete the code in your index.js file (2 seconds)Step 4: Prompt GitHub Copilot with a comment (4 seconds)Step 5: Trigger suggestions from GitHub Copilot (18 seconds)Step 6: Save the file and try it out! (30 seconds)Bonus: Use Copilot Chat to style, test, and explain your UIStep 1: Open the extension!Step 2: Get an explanation of the generated code blockStep 3: Style your markdown editorStep 4: Review Copilot Chat’s responseStep 5: Check out the resultsStep 6: Keep experimentingStep 7: Write unit tests with Copilot ChatIs it possible to build a markdown editor in 2 minutes? It is for me (if I'm using GitHub Copilot). In fact, I proposed building a markdown editor with GitHub Copilot for a 15-minute demo, and my manager seemed a bit nervous that my idea was overly ambitious. However, he still entrusted me with the task. To my surprise, GitHub Copilot generated a markdown editor faster than I predicted. In this blog post, I’ll teach you how to build a markdown editor, too!But before I do that, I want to manage readers' expectations.This is a tutorial to help you understand how to practically use GitHub Copilot for day to day tasks.The markdown editor we’re building will be more functional than stylistic. Translation: it might look a little ugly.As a bonus, we’ll use Copilot Chat to improve the markdown editor’s user interface. However, this product is in technical preview and not yet available to everyone. If you don’t have access to it yet, you can substitute it for ChatGPT.We will use the React Markdown npm package. When I first attempted this, GitHub Copilot imported the package without me prompting it, but it ended up being a helpful inclusionYou’ll need access to GitHub Copilot in your editor to get the best out of this tutorial!GitHub Copilot and other Generative AI tools are non-deterministic. This means these tools will sometimes generate different outputs. You may receive slightly different output, but feel free to experiment with GitHub Copilot until you reach your desired outcome. Feel free to share what it created for you!GitHub Copilot and other generative AI tools are advancing quickly. The advice in this tutorial is relevant for today – June 2023, but it might be outdated in the near future.  Use GitHub Copilot to build a markdown editor  Prerequisites:Create a GitHub account (if you don’t have one)Sign up for GitHub CopilotInstall the GitHub Copilot extension in an editor of your choiceNow that we have everything we need let’s get started!  Step 1: Create a Next.js GitHub Codespace template (30 seconds)I use GitHub Codespace templates when I want to avoid installing boilerplate package dependencies and setting up my environment from scratch. It comes in handy when I want to spin up a quick proof of concept or deliver a demo.  In our case, we want to save time installing Next.js and its accompanying dependencies.  You can create a Next.js GitHub Codespace template by navigating to https://github.com/codespaces/templates. Then choosing the “Use this template” button for Next.js. This will trigger a codespace to open with boilerplate Next.js code with a browser preview.  Step 2: Install specific dependencies (30 seconds)Using a GitHub Codespace template reduced the need to install a few boilerplate dependencies, but we still have more to install.Ensure the GitHub Copilot extension is installed. See here for instructions. Install the React Markdown npm package. To do this, run the following command in your codespace’s terminal:npm install react-markdownInstall the styled-components npm package. To do this, by run the following command in your codespace's terminal:npm install styled-components@latest  Step 3: Delete the code in your index.js file (2 seconds)Every GitHub Codespace template includes boilerplate code to empower developers in experimenting and swiftly prototyping their ideas. However, for our goals, we will write different code in our index.js file; we don't need the existing code.Keep the index.js file, but delete the code inside.  Step 4: Prompt GitHub Copilot with a comment (4 seconds)The comment below prompts GitHub Copilot to explain our overall goal and provide context to our AI programming assistant. Learn more about this method from my previous DEV post – A Beginner’s Guide to Prompt Engineering with GitHub Copilot. Copy the comment below and paste it at the top of your index.js file./*Create a basic markdown editor in Next.js with the following features:- Use React hooks- Create state for markdown with the default text ""## markdown preview""- A text area where users can write markdown - Show a live preview of the markdown text as I type- Support for basic markdown syntax like headers, bold, italics - Use React markdown npm package - The markdown text and resulting HTML should be saved in the component's state and updated in real time */Enter fullscreen modeExit fullscreen mode  Step 5: Trigger suggestions from GitHub Copilot (18 seconds)I pressed the RETURN key twice to trigger a suggestion from GitHub Copilot. I usually press the SPACEBAR, ENTER, or RETURN on my keyboard to trigger suggestions from GitHub Copilot after providing context.💡 When you create a new line, you should see a suggestion, or ghost text, from GitHub Copilot.💡 You can tell that GitHub Copilot will provide you with a suggestion when the Copilot icon in the status bar is spinning. I like to refer to it as ""thinking"". In the GIF below, I highlighted the Copilot icon, so you can see how it spins when processing.💡 You can tell that GitHub Copilot is going to provide you with a suggestion when the Copilot icon in the status bar is spinning. I like to refer to it as “thinking”. In the GIF below, I highlighted the Copilot icon, so you can see how it spins when it is processing.💡 Because the output for GitHub Copilot is non-deterministic, results may vary.📝 Here's the GitHub Copilot gave me output:import React, { useState } from 'react';import ReactMarkdown from 'react-markdown';import styled from 'styled-components';const Index = () => {  const [markdown, setMarkdown] = useState('## markdown preview');  const handleChange = (e) => {    setMarkdown(e.target.value);  };  return (    <div>      <textarea onChange={handleChange} value={markdown} />      <ReactMarkdown>{markdown}</ReactMarkdown>    </div>  );}export default Index;Enter fullscreen modeExit fullscreen mode✨ Feel free to tweak the output to your liking!  Step 6: Save the file and try it out! (30 seconds)GitHub Copilot generated code that looks correct, but how do we know it works? Let's try writing in our markdown editor's input box to see if it renders an accurate live preview of the text.I'll test the following markdown elements:bullet points- bullet- bullet- this is the markdown for bullets- ...boldI am **bold**How to make a word **bold**: - sandwiched it between two asterisks on the left - and two asterisks on the rightitalicI am *italic*How to make a word *italic*: - sandwiched it between one asterisk on the left - and one asterisk on the rightlinkI am [link](google.com)How to convert a word into a [link](google.com): - sandwiched it between an opening and closing bracket - then place an actual link next to it- sandwich that link between two parentheses###### headingI am  ###### headingHow to convert a word into a ##### heading: - Preface the word with hashtags - The more hashtags, the smaller the word gets- More hashtags indicate the heading is less important- # Heading 1 - I am super important.- ## Heading 2 - I am a subtitle- ### Heading 3 - I am less important- #### Heading 4 - I am even smaller and less important💪🏾 We did it! We developed a markdown editor with GitHub Copilot in less than 2 minutes.   Bonus: Use Copilot Chat to style, test, and explain your UIThat was fun, but we can do more. We can write unit tests, style our UI, and get an explanation of the code. We can do independently, but it's exponentially more fun to do pair program with GitHub Copilot for this. To complete the second half of this tutorial, you will need access to Copilot Chat. Additionally, you need an active subscription to GitHub Copilot to access Copilot Chat. Learn more here.Copilot Chat is a ChatGPT-like experience in your editor, but it’s not just a chat window. Because it’s deeply embedded into your IDE, Copilot Chat has context of what a developer types and what error messages a developer receives. Let’s try using Copilot Chat to style, test, and explain the code in our markdown editor!I feel comfortable with this framework, so I confidently accepted the previously generated code. However, you might be unfamiliar with React or Next.js, so the generated code looks foreign to you. This is a problem because you don’t want to blindly accept code. Understanding code that you will merge into a production environment is vital. Fortunately, Copilot Chat can provide an in-depth explanation of your code.   Step 1: Open the extension!Following installation, try opening the extension. It should render a panel with a welcome message.  Step 2: Get an explanation of the generated code blockLet’s have Copilot Chat explain the handleChange function.First, highlight the code block for the handleChange functionRight click after highlightingChoose “Copilot”Choose “Explain This”After you follow the above steps, Copilot Chat should provide an explanation similar to the one below!This code defines a function called handleChange that takes an event object as its argument. The handleChange function is typically used as an event handler for a textarea element in a React component. When the user types into the textarea, the handleChange function is called with an event object that contains information about the user's input.The handleChange function uses the setMarkdown function to update the value of a state variable called markdown. The setMarkdown function is a function that is returned by the useState hook provided by the React library. The useState hook is used to add state to functional components in React. By using the setMarkdown function to update the markdown state variable, the component that contains this code can re-render itself to reflect the new state.Overall, this code defines a function called handleChange that is used to update the value of a state variable called markdown in response to user input. The setMarkdown function is used to update the state variable, and the useState hook is used to add state to a functional component in React.💡 You can repeat this step with any individual line of code or code block if you need more clarity.💡 The more lines of code that you highlight, the less granular the explanation will be. If you want an overview, highlight the entire file, but if you want a granular explanation, highlight individual code blocks.  Step 3: Style your markdown editorLet's communicate with Copilot Chat to guide us in styling our markdown editor.✍🏿 Here’s the question that I asked Copilot Chat: “Can you propose code to make my markdown editor have a more modern UX design? Please use styled-components.”  Step 4: Review Copilot Chat’s responseI want to re-emphasize that generative AI and GitHub Copilot have non-deterministic output, so results may vary. Copilot Chat proposed code that handles:importing the styled-components npm packagestyling the markdown editor's containerstyling the text inputstyling the markdown previewSee the generated code below:import React, { useState } from 'react';import ReactMarkdown from 'react-markdown';import styled from 'styled-components';const Container = styled.div`  display: flex;  flex-direction: column;  height: 100vh;  width: 100vw;  align-items: center;  justify-content: center;  background-color: #f5f5f5;`;const TextArea = styled.textarea`  width: 50%;  height: 50%;  padding: 1rem;  border-radius: 5px;  border: none;  box-shadow: 0px 0px 5px rgba(0, 0, 0, 0.1);  font-size: 1rem;  resize: none;`;const Preview = styled(ReactMarkdown)`  width: 50%;  height: 50%;  padding: 1rem;  border-radius: 5px;  border: none;  box-shadow: 0px 0px 5px rgba(0, 0, 0, 0.1);  font-size: 1rem;  overflow-y: scroll;  background-color: white;`;const Index = () => {  const [markdown, setMarkdown] = useState('## markdown preview');  const handleChange = e => {    setMarkdown(e.target.value);  };  return (    <Container>      <TextArea value={markdown} onChange={handleChange} />      <Preview>{markdown}</Preview>    </Container>  );}export default Index;Enter fullscreen modeExit fullscreen modeI reviewed the code, and it looked like a feasible solution to me, so I copied the generated code and pasted it into my index.js file.  Step 5: Check out the resultsHere’s what my final results looked like: I guess this is Copilot’s version of a modern UX design, and it looks a bit better to me, but it could use some improvement. This is a great opportunity for you as the developer to tweak the code to match your vision!  Step 6: Keep experimentingI spent over 20 minutes experimenting with Copilot Chat to improve my prompt game and understand Copilot’s limitations. I asked it different questions like:How do I add a toolbar?How do I add a dark mode and light mode theme?Here’s what it came up with:🧑🏾‍🎨 Get creative and make your markdown editor your own!  Step 7: Write unit tests with Copilot ChatWhile writing unit tests is critical for any production application's longevity, it's also a really tedious process. I'm happy that the industry is moving towards the direction of automating away boilerplate code and repetitive code. We can request that Copilot Chat generate unit tests for our markdown editor using slash commands.After I typed ""/tests"" in Copilot Chat, I received proposed unit tests accompanied by a brief explanation. See the results below:import React from 'react';import { render, fireEvent } from '@testing-library/react';import Index from './index';describe('Index', () => {  it('renders the bold, italic, and theme toggle buttons', () => {    const { getByText } = render(<Index />);    expect(getByText('Bold')).toBeInTheDocument();    expect(getByText('Italic')).toBeInTheDocument();    expect(getByText('Dark Mode')).toBeInTheDocument();  });  it('toggles between dark and light mode when the theme toggle button is clicked', () => {    const { getByText, container } = render(<Index />);    const themeToggle = getByText('Dark Mode');    expect(container.firstChild).toHaveStyle('background-color: #fff');    fireEvent.click(themeToggle);    expect(container.firstChild).toHaveStyle('background-color: #000');    fireEvent.click(themeToggle);    expect(container.firstChild).toHaveStyle('background-color: #fff');  });  it('updates the markdown text when the textarea is changed', () => {    const { getByLabelText, getByText } = render(<Index />);    const textarea = getByLabelText('Markdown Input');    fireEvent.change(textarea, { target: { value: '# Hello World!' } });    expect(getByText('# Hello World!')).toBeInTheDocument();  });  it('applies bold formatting to selected text when the bold button is clicked', () => {    const { getByText, getByLabelText } = render(<Index />);    const textarea = getByLabelText('Markdown Input');    fireEvent.change(textarea, { target: { value: 'Hello **World**!' } });    const boldButton = getByText('Bold');    fireEvent.click(boldButton);    expect(textarea.value).toBe('Hello **World**!');    fireEvent.change(textarea, { target: { value: 'Hello **World!**' } });    fireEvent.click(boldButton);    expect(textarea.value).toBe('Hello World!');  });  it('applies italic formatting to selected text when the italic button is clicked', () => {    const { getByText, getByLabelText } = render(<Index />);    const textarea = getByLabelText('Markdown Input');    fireEvent.change(textarea, { target: { value: 'Hello *World*!' } });    const italicButton = getByText('Italic');    fireEvent.click(italicButton);    expect(textarea.value).toBe('Hello *World*!');    fireEvent.change(textarea, { target: { value: 'Hello *World!*' } });    fireEvent.click(italicButton);    expect(textarea.value).toBe('Hello World!');  });});Enter fullscreen modeExit fullscreen modeThese tests cover the basic functionality of the component, including rendering the correct buttons, toggling between dark and light mode, updating the markdown text, and applying bold and italic formatting to selected text. Note that these tests assume that the TextArea and Preview components are working correctly, so you may want to write additional tests for those components as well.Please note: I didn't try out the unit tests, so use at your own expense. I strongly recommend running the tests and reviewing the code before merging into a branch.💾 ...And we're done! Experimenting with GitHub Copilot and Copilot Chat is always fun for me. For more content like this follow me or GitHub on DEV! 👀 Also, I'd love to hear your thoughts in the comments below."
496,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
497,"Stripe recently announced Tap to Pay for Android. Let’s look into how to implement this so you can start collecting in-person payments directly using a mobile phone! In this blog post, let’s pretend that you work for a (fake) food truck company called CoolBeans and you need to create an Android app so you can collect payments on the go.Here’s what we’ll be building: This tutorial uses Kotlin; however, this feature can also be implemented using Java. If you need more information, please refer to our docs or check out the Stripe Terminal Android SDK repository that contains an example in both Kotlin and Java.If you learn better with videos, you can check out the video tutorial on YouTube!  PrerequisitesTo follow along with this tutorial, you will need:Android SDK version 33AndroidStudioKotlin 1.7.10Stripe accountStripe Terminal Android SDKIf you are using a different version of the Android SDK or Kotlin, the code samples in this tutorial may still work but this is not guaranteed.This post will only cover the code samples needed to get Tap to Pay working in your Android application. I will purposely not cover how to build and structure an Android app or go into details on the specific flow I implemented as this is more relative to what you want to build.If you want to get started quickly, you can clone my demo application on GitHub, follow the instructions in the README to make sure you update the URL to the back-end server, and follow along as I explain the different parts.After cloning and running the demo application, you should see the following screens. The first part of the application is responsible for connecting your mobile phone as a reader. Then, the user can input an amount, and finally collect the payment using Tap to Pay.  Install the Stripe Terminal Android SDK  ConfigurationIf you’ve already cloned the Tap to Pay demo application, you can skip this section. If you have already integrated with the Stripe Terminal Android SDK before and would like to update it to also use Tap to Pay, keep reading to understand the few changes you will need to make.In your module’s build.gradle file, replace the Stripe Terminal dependencies with the latest version and add the stripeterminal-localmobile package:implementation ""com.stripe:stripeterminal-localmobile:2.20.0""implementation ""com.stripe:stripeterminal-core:2.20.0""Enter fullscreen modeExit fullscreen mode  PermissionsThe Stripe Terminal Android SDK requires different permissions depending on the type of terminal device you’re using. For Tap to Pay, Bluetooth and Location are required.To do this, make sure you’re adding the following lines to the AndroidManifest file:<uses-permission android:name=""android.permission.BLUETOOTH"" /><uses-permission android:name=""android.permission.BLUETOOTH_ADMIN"" /><uses-permission android:name=""android.permission.BLUETOOTH_CONNECT"" /><uses-permission android:name=""android.permission.BLUETOOTH_SCAN"" /><uses-permission android:name=""android.permission.ACCESS_COARSE_LOCATION"" /><uses-permission android:name=""android.permission.ACCESS_FINE_LOCATION"" />Enter fullscreen modeExit fullscreen modeAnd in your application logic, check that the permission is granted before continuing. If the user has granted Bluetooth permission, you can start initializing a terminal instance.  Initializing a Terminal instanceOne of the first things you need to do is initialize a terminal instance with the following code:Terminal.initTerminal(  applicationContext, LogLevel.VERBOSE, TokenProvider(),  TerminalEventListener())Enter fullscreen modeExit fullscreen modeThis will initialize a terminal for the given application context that you need to pass as the first parameter. Then you can pass the level of logging verbosity, an instance of the ConnectTokenProvider interface to use when a new token is needed and finally, a listener to inform of events in the Terminal lifecycle.If you have used the Stripe Terminal Android SDK before, you should already have created the interface for the token provider and the listener. If not, feel free to check the TokenProvider and TerminalEventListener files in the demo application.   Loading locationsTo use Stripe Terminal, you need to register one or more locations to manage readers and their activity by associating them with a physical location. Even though food trucks can be located in various places, there are regulations and parking permits needed to sell food in the street so CoolBeans will likely have a set list of locations where the business can operate. You can create these locations via the Stripe Dashboard or using the API.This way, the activity of a reader associated with a location will be reflected in the dashboard and you will be able to collect data about how the different locations are performing in terms of sales.In your Android app, you can then list your locations, passing a limit for the number of locations you would like to fetch, and a callback. If you’re following along with the demo application, this code can be found in the MainActivity.kt file.Terminal.getInstance().listLocations(  ListLocationsParameters.Builder().apply {      limit = 100  }.build(),  locationCallback)Enter fullscreen modeExit fullscreen modeThe callback will save the location objects in a mutable list.private val mutableListState = MutableStateFlow(LocationListState())private val locationCallback = object : LocationListCallback {  override fun onFailure(e: TerminalException) {      e.printStackTrace()  }  override fun onSuccess(locations: List<Location>, hasMore: Boolean) {      mutableListState.value = mutableListState.value.let {          it.copy(              locations = it.locations + locations,              hasMore = hasMore,              isLoading = false,          )      }  }}Enter fullscreen modeExit fullscreen modeOnce you have fetched your locations, you need to write the logic that will identify the reader you will use.  Discovering readersTo find available readers and select the one you want to use, you need to call the discoverReaders method.When implementing Tap to Pay, the configuration object needs to have its discoveryMethod argument set to DiscoveryMethod.LOCAL_MOBILE so it considers the mobile phone running the application as a terminal device.val config = DiscoveryConfiguration(           timeout = 0,           discoveryMethod = DiscoveryMethod.LOCAL_MOBILE,           isSimulated = false,           location = mutableListState.value.locations[0].id       )Enter fullscreen modeExit fullscreen modeCall the discoverReaders method passing this configuration object as well as a DiscoveryListener instance that will provide the list of discovered readers.Terminal.getInstance().discoverReaders(config, discoveryListener = object :DiscoveryListener {override fun onUpdateDiscoveredReaders(readers: List<Reader>) {   // Filtering the list of readers discovered to only store the ones currently online   readers.filter { it.networkStatus != Reader.NetworkStatus.OFFLINE }  // For simplicity, I’m only using the first reader retrieved but this code would need to be updated if you wanted to show the list in the UI and let the user select a specific location.   var reader = readers[0]   // Handle the connection to the reader in a separate function   connectToReader(reader)}, object : Callback {  override fun onSuccess() {     println(""Finished discovering readers"")  }  override fun onFailure(e: TerminalException) {     e.printStackTrace()  }})Enter fullscreen modeExit fullscreen mode  Connecting a reader to a locationNow that we listed our locations and discovered the reader we want to use, let’s connect the location to the reader using the connectLocalMobileReader method in the connectToReader function created in the code sample above.private fun connectToReader(reader: Reader){    // Pass the location chosen to the LocalMobileConnectionConfiguration method.       val config = ConnectionConfiguration.LocalMobileConnectionConfiguration(""${mutableListState.value.locations[0].id}"")    // Call the connectLocalMobileReader method passing the reader selected, the config object and a callback function.       Terminal.getInstance().connectLocalMobileReader(           reader,           config,           object: ReaderCallback {               override fun onFailure(e: TerminalException) {                   e.printStackTrace()               }               override fun onSuccess(reader: Reader) {                   // [Optional] Update the UI with the location name and terminal ID to indicate to the user that the reader is successfully connected.                   runOnUiThread {                       val manager: FragmentManager = supportFragmentManager                       val fragment: Fragment? = manager.findFragmentByTag(ConnectReaderFragment.TAG)                       if(reader.id !== null && mutableListState.value.locations[0].displayName !== null){                           (fragment as ConnectReaderFragment).updateReaderId(                               mutableListState.value.locations[0].displayName!!, reader.id!!                           )                       }                   }               }           }       )   }Enter fullscreen modeExit fullscreen mode  Collecting paymentWhen the reader is successfully connected, you should be ready to accept payments the same way as you would when using other Terminal devices. You’ll need a back-end server with endpoints to create a connection token and handle the different events that happen when capturing and processing payments with Stripe. If you don’t already have one, you can clone our Stripe Terminal backend example repo and follow the instructions in the README to set it up.  Creating a payment intentFirst, you need to create a PaymentIntent. To do this, your Android application will need to make a POST request to your server implementing the Stripe API. In the demo application, the ApiClient singleton object handles the calls to the back-end and provides a createPaymentIntent method you can call and pass payment details including the amount, currency, authorization details and a callback.For simplicity, the code sample below uses hardcoded values but you would need to adapt your application to your particular use case.ApiClient.createPaymentIntent(   amount = “100”.toLong() ,   currency = “usd”,   extendedAuth = false,   incrementalAuth = false,   callback = object : retrofit2.Callback<PaymentIntentCreationResponse> {       override fun onResponse(           call: Call<PaymentIntentCreationResponse>,           response: Response<PaymentIntentCreationResponse>       ) {           if (response.isSuccessful && response.body() != null) {        // Retrieve the payment intent once it is created successfully               Terminal.getInstance().retrievePaymentIntent(                   response.body()?.secret!!,                   createPaymentIntentCallback               )           } else {               println(""Request not successful: ${response.body()}"")           }       }       override fun onFailure(           call: Call<PaymentIntentCreationResponse>,           t: Throwable       ) {           t.printStackTrace()       }   })Enter fullscreen modeExit fullscreen modeWhen the payment intent is successfully created, the code sample above calls the retrievePaymentIntent method with the secret present in the response body to retrieve the Payment Intent.The code sample below shows how the callback function is then implemented.private val createPaymentIntentCallback by lazy {   object : PaymentIntentCallback {       override fun onSuccess(paymentIntent: PaymentIntent) {        collectPaymentMethod(paymentIntent)       }       override fun onFailure(e: TerminalException) {           e.printStackTrace()       }   }}Enter fullscreen modeExit fullscreen mode  Collecting a payment methodAfter the Payment Intent is created and retrieved, we can pass it into the collectPaymentMethod method with a callback and the tipping configuration.private fun collectPaymentMethod(paymentIntent: PaymentIntent){  // Hardcoded for the purpose of this tutorial   val skipTipping = true   val collectConfig = CollectConfiguration.Builder()       .skipTipping(skipTipping)       .build()   Terminal.getInstance().collectPaymentMethod(       paymentIntent, collectPaymentMethodCallback, collectConfig   )}private val collectPaymentMethodCallback by lazy {   object : PaymentIntentCallback {       override fun onSuccess(paymentIntent: PaymentIntent) {        processPayment(paymentIntent)       }       override fun onFailure(e: TerminalException) {           e.printStackTrace()       }   }}Enter fullscreen modeExit fullscreen modeWhen the payment method is successfully collected, we can start processing the payment.  Processing and capturing the paymentTo process the payment, you need to call the processPayment method passing the Payment Intent and a callback function that will capture the payment.private fun processPayment(paymentIntent: PaymentIntent){   Terminal.getInstance().processPayment(paymentIntent, processPaymentCallback)}private val processPaymentCallback by lazy {   object : PaymentIntentCallback {       override fun onSuccess(paymentIntent: PaymentIntent) {           ApiClient.capturePaymentIntent(paymentIntent.id)        // Return to previous screen           navigateTo(PaymentDetails.TAG, PaymentDetails(), true)       }       override fun onFailure(e: TerminalException) {           e.printStackTrace()       }   }}Enter fullscreen modeExit fullscreen modeAt this point, if all the previous steps were successful, you should be able to run your application, connect your mobile phone as a reader, see the Tap to Pay screen after calling the collectPaymentMethod, and tap a credit card behind your device to process the payment. CoolBeans is now ready to accept payment on the go!  ConclusionIf you have used the Stripe Terminal Android SDK before, you only need to make minimal code changes to update your application to implement the Tap to Pay feature. If you want to get started quickly, feel free to clone the repository of the demo application and customize it to adapt to your use case. You can also check out our documentation and the Stripe Terminal Android SDK repository if you want to learn more.We hope you’ll share with us how you’re planning to use Tap to Pay with Stripe!You can also stay up to date with Stripe developer updates on the following platforms:📣 Follow @StripeDev and our team on Twitter📺 Subscribe to our YouTube channel💬 Join the official Discord server📧 Sign up for the Dev Digest  About the authorCharlie Gerard is a Developer Advocate at Stripe, a published author and a creative technologist. She loves researching and experimenting with technologies. When she’s not coding, she enjoys spending time outdoors, reading and setting herself random challenges."
498,"In honor of Juneteenth, we’re uplifting initiatives and organizations that center Black and African-American technologists. Black Lives Matter, and we celebrate these orgs for their contributions toward creating futures for Black people and African-Americans while shaping our industry for the better.In this post, we shine a spotlight on Black Girls Code!For more than a decade, Black Girls CODE has been tirelessly opening doors to education and technology for thousands of Black and brown girls aged 7-17. Their mission is more than just teaching coding; it's about narrowing the digital divide for young girls of color and sparking a love for technology that can change the face of STEM.With 14 chapters in cities across the United States, and a thriving chapter in South Africa, the organization has a broad footprint. Each chapter meets approximately once a month to learn and grow together through a variety of STEM-based enrichment activities. These range from engaging workshops and inspiring panels to thought-provoking film screenings and exciting tech company tours.As we celebrate Juneteenth, we stand in solidarity with Black Girls CODE in their mission. By empowering underrepresented communities, we work together towards building stronger economies and more equitable societies. This is the true embodiment of democracy — the creation of diversity and inclusion that offers a seat at the table for everyone.We invite everyone in the DEV Community to join us in celebrating and supporting the tireless efforts of Black Girls CODE, this Juneteenth and every day. Visit their events page to participate in or support their upcoming activities. For those who are able, consider making a contribution on their donation page. Your donations will help fund workshops, programs, and provide resources that are vital in supporting these young, aspiring technologists. Let's be the change we want to see in our tech industry – diverse, inclusive, and equitable for all. Your support could very well ignite the spark that inspires the next generation of tech innovators. Together, we are creating stronger economies and more equitable societies.Happy Juneteenth! "
499,"Yesterday on our podcast, Natalie Davis came on to discuss how to strategize after layoffs with @saronyitbarek! Natalie Davis is a software engineer by trade and a curious person by nature. After deciding to step away from her extensive retail career, Natalie took the first steps in her tech journey by graduating from an 18-month long bootcamp. Natalie landed her first engineering role with Foxtrot while still in school, but has since held roles with Netlify and Post. Natalie is also currently seeking employment!If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""Navigating Layoffs with Intention"": CodeNewbie Podcast S24E7Sloan the DEV Moderator for CodeNewbie ・ Jun 21 ・ 1 min read#podcast#career#codenewbie#beginners  So, Let's Talk!Natalie gave us some great pieces of wisdom on her approach to networking, navigating uncertainty, and squashing imposter syndrome.Here are some key things we learned:Take your time finding the perfect role for you that helps you feel balanced. Your perfect job should challenge you without stretching your limit.When you make a consistent practice of networking, you are better able to prepare yourself for the unknown of layoffs and job insecurity. If you wait to network till when you’re looking for a job, you’ve already waited too long.Networking should not feel transactional! Sometimes it may be worth it to refocus priorities less on building a network and instead on being a part of the community. Being a part of a community means showing up for others, supporting what they are doing, celebrating them, and sharing what you are doing as well!First jobs can be difficult because they can come with a huge battle against imposter syndrome. It can become a slippery slope of convincing yourself that you are the only one on your team that struggles and that everyone else is so much smarter than you. Remember to keep your head up and know when these thoughts are not serving you. Celebrate your successes and failures and let go of the idea that you need to be perfect to be valuable.If you listened— what are your tips for navigating layoffs, finding the perfect role, or dealing with imposter syndrome?Send us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
500,"Hey folks, this is a new weekly hangout thread.This is an area for Rubyists to discuss Ruby, but since Ruby is 28 years old, and things don't change so quickly, this is also just a hangout thread for Rubyists to share whatever you feel like within our community guidelines.So what's up this week?"
501,"Here's the first prompt for the Virtual Coffee Monthly Challenge:Let's reflect on the progress we’ve made so far this year. How has this year been for you in terms of personal and professional growth? What were the major challenges and triumphs you experienced? Have there been any unexpected events or changes that influenced your goals? How did you adapt to them? Are your current goals still aligned with your aspirations and values, or do they need updating based on your experiences and progress so far? Let us know in the comments below."
502,"In our seventh episode of Season 24 CodeNewbie Podcast, @saronyitbarek talks about recalibrating after layoffs and strategizing to be more selective with new job opportunities with Natalie Davis.       codenewbie.org    Natalie Davis is a software engineer by trade and a curious person by nature. After deciding to step away from her extensive retail career, Natalie took the first steps in her tech journey by graduating from an 18-month long bootcamp. Natalie landed her first engineering role with Foxtrot while still in school, but has since held roles with Netlify and Post. Natalie is also currently seeking employment!Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding! We hope you enjoy this season of the CodeNewbie Podcast 💜"
503,"Okay, let's do a little interview prep today. It's important that you be able to demonstrate an ability to bridge the gap between tech and non-tech worlds. So, how would you answer this question if it came up in a job interview?When it comes to non-technical team members or stakeholders, how do you effectively communicate complex technical concepts?   Newbies and experienced devs, alike: please share your proven strategies and techniques for breaking down the intricacies of coding and technology into digestible information. Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      Image by Freepik"
504,"We've all encountered setbacks and faced failures along our coding journeys, but they often serve as powerful teachers that help us grow and evolve. So, let's take a moment to reflect on those experiences that left us scratching our heads or may have had us feeling defeated at the time. Share a story about a failure or setback you encountered as a developer and how it shaped your perspective and growth. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
505,"Hey folks 👋Hope that y'all all enjoy your weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugSwimming in the ocean 🌊 🏊"
506,"Here's a question that often comes up among beginners in the tech industry: do you need to have strong mathematical skills to thrive, or is it possible to excel without them? Some argue that a solid foundation in math is crucial for solving complex programming problems. On the other hand, there are developers who have succeeded without extensive math knowledge.  What are your thoughts and experiences with this? Have you found math to be a vital component in your programming journey, or have you been able to navigate the industry without it? Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
507,Weird pic. No context. What's happening here? Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
508,"If you had the ability to create a game-changing technology that addresses one of the world's most pressing issues, which problem would you choose, and how would your envisioned technology make a lasting impact on society?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
509,"Hey y'all!This is exactly what it sounds like — a place to connect with other musicians in the DEV Community.In the comments below, feel free to let us know what kinda music you create, tell us what instruments you play, share tunes you've made, and meet other musicians.Let's go! 🤝"
510,"Can you help a CodeNewbie out and explain the concept of OOP (Object-oriented programming) in simple terms? It would be extra awesome if you could share an example of how you've implemented OOP principles in one of your projects. Maybe you've utilized classes, inheritance, or encapsulation?   Tell us about your experience and how OOP has enhanced your projects. Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
511,"When it comes to learning new technologies or programming languages, we all have our own methods. So, how do you approach the challenge? Share your tried-and-true tips for mastering new languages at lightning speed. Whether it's helpful resources, practical exercises, or clever learning techniques, let's swap our best tricks and level up our tech skills together!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
512,"Here at DEV, we're dedicated to honoring Juneteenth and highlighting initiatives and organizations that empower Black and African-American technologists. Black Lives Matter, and we celebrate these orgs for their contributions toward creating futures for Black people and African-Americans while shaping our industry for the better.Today, we want to focus our attention on an exceptional organization making a significant impact: CODE2040.CODE2040's mission is to activate, connect, and mobilize the largest racial equity community in tech. They are committed to breaking down the structural barriers that hinder the full participation and leadership of Black and Latinx individuals in the innovation economy. Their goal is to achieve an equitable distribution of power in a digitally revolutionized economy, with proportional representation at all levels and roles for Black and Latinx individuals.CODE2040 firmly believes in the power of collective action. As a growing movement of Black and Latinx technologists, allies, and advocates, they actively support, celebrate, and include others in their mission to transform the tech industry into an equitable and inclusive space.Recognizing the need for structural change, CODE2040 continuously experiments with new approaches, shares knowledge, and identifies patterns that can drive industry transformation. They learn from technologists, companies, universities, and others to create meaningful and lasting change.Embracing the complexity of reality, CODE2040 values multiple truths. They make decisions by involving those most affected, relying on data-driven insights, and navigating tradeoffs for progress. By combining data and lived experiences, they foster a comprehensive understanding of the challenges they face.CODE2040 Events & Fellows ProgramCODE2040 organizes a range of events, including gatherings, workshops, and programs tailored to Black and Latinx individuals in the tech industry. These events provide invaluable opportunities for networking, learning, and career development. Their flagship event, The Summit, is an annual conference held in San Francisco. Additionally, their Fellows Program, an intensive career accelerator, offers internships at top tech companies, racial equity advocacy work, and real-world projects in various domains such as software development, data analysis, design and user experience, marketing and outreach, and operations and strategy. The program has expanded nationwide, allowing participants to join virtually from anywhere. Find out more about the Fellows Program here.Join us in celebrating Juneteenth and supporting CODE2040's incredible work in advancing racial equity in the tech industry. Together, we can shape a better, more inclusive future for all. 🙌"
513,"While our community spans the globe, and many of our members may not be intimately familiar with all the holidays and significant events we observe as a company, Juneteenth holds relevance for people worldwide. And for that reason, we'd like to take a moment to acknowledge the significance of this historic holiday and what it means to all of us here at DEV. On this day in 1865, Union civil war soldiers, led by Major General Gordon Granger, arrived in Galveston, Texas, bearing news that the war had ended and that previously enslaved Black individuals in the United States were now declared free.We now refer to this day — June 19th — as Juneteenth. It is an opportunity for Americans to celebrate a significant milestone in the journey toward freedom for all people. It also offers non-Black Americans a chance to uplift Black joy while reflecting on our nation's history. Because of that, DEV officially recognizes Juneteenth as a holiday. We believe it is important to provide our team with the opportunity to commemorate this day. Family and community hold great significance on Juneteenth and it's crucial to make space for folks to come together in local gatherings and celebrations; to share meals and organize cookouts; and to attend musical performances, historical reenactments, and street fairs.While there is still much work to be done in achieving a truly equal society, we recognize that we cannot sustain the long-term fight without taking time to celebrate achievements and reflect on the ongoing need for change.DEV serves as a hub for programmers and technologists to come together, engage in discussions about technology, learn, teach, and find inspiration. However, none of these activities can be effectively or safely accomplished within a system that fails to empower all individuals. As members of the DEV community, we have the opportunity to be agents of positive change. Let's stand united in pursuit of a better, more equitable tech community.Happy Juneteenth, everyone! Let's spread joy and unity as we commemorate this significant day. And in the spirit of celebration and progress, let's strive to be excellent to one another. ❤️ ✨"
514,"As the popularity of low-code and no-code platforms continues to rise, some are questioning the necessity of investing time in learning traditional coding languages and frameworks. What are your thoughts on this? Have you embraced low-code or no-code platforms, or do you still see value in mastering traditional coding? Share your perspectives!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      Image by rawpixel.com on Freepik"
515,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
516,"Should devs prioritize contributing to open-source projects and the community, or focus solely on personal projects and career growth? Share your thoughts and experiences on the benefits and drawbacks of each approach. Is it possible to strike a balance between the two? Let the discussion begin!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
517,"In May, we announced a challenge on DEV, in partnership with our friends at GitHub: the GitHub + DEV 2023 Hackathon.Our brilliant participants were challenged to build brand new apps using GitHub Actions and GitHub Codespaces. Submissions were to be filed in one of five categories: Maintainer Must-Haves, DIY Deployments, Interesting IoT, Phone Friendly, or Wacky Wildcards.It's never easy for contest judges to pick just one Grand Prize winner per category and 10 runners-up and this time was no different. Even so, judges from the DEV and GitHub teams managed to pick our winners and I'm excited to share them with you today!Let's take a look at the winning projects for the GitHub + DEV 2023 Hackathon!Maintainer Must-Haves: @lyqhtDeepL Translate Github ActionEstee Tey ・ May 22 ・ 2 min read#githubhack23#javascript#githubactions#githubDIY Deployments: @disukharevOpenCommit: GitHub Action to improve commits with meaningful messages on every `git push` 🤯🔫Dima Sukharev ・ May 21 ・ 5 min read#githubhack23#opensource#githubactions#gitInteresting IoT: @kafechewMooptOS: Open IoT Platform for Decentralized Urban FarmingKai Chew ・ May 22 ・ 9 min read#githubhack23#iot#arduino#showdevPhone Friendly: @sandy_codes_pyDeploy pygames to GitHub Pages with WebAssembly - PWA ready!Santhosh (sandy inspires) ・ May 21 ・ 4 min read#githubhack23#github#python#javascriptWacky Wildcards: @arndomPlay a Game of Tetris generated from your GitHubNabil Alamin ・ May 23 ・ 2 min read#githubhack23#nextjs#typescript#reactAll Grand Prize Winners will receive: $1,500 USD gift card or equivalent 🤑$300 USD credit to the DEV Shop 😎DEV Sticker Pack ✨DEV “GitHub + DEV 2023” Grand Prize profile badge 🏆  And, our 10 Runners-Up, in random order!Arduino-Based Smart Gate System Prototype for Vehicle Detection and Access ControlSalim Ọlánrewájú Oyinlọlá ・ May 23 ・ 4 min read#githubhack23#iot#arduinoAI-powered changelog updates on Slack, every Monday, with GitHub ActionsMax Prilutskiy ・ May 9 ・ 3 min read#github#opensource#githubhack23#githubbrasilGitHub Actions with MongoDBMedea ・ May 3 ・ 2 min read#githubhack23#nextjs#mongodb#opensourceEffortless Documentation of your Python Code with Github Actions and GPT3Dhanush Reddy ・ May 4 ・ 4 min read#githubhack23#githubactions#gpt3#pythonIntroducing ✨ Relano - Create beautiful ""What's new"" videos and automate your project's social media!Mohit Yadav ・ May 23 ・ 5 min read#githubhack23#github#githubactions#communityAuthentication system using Python (Django) and SvelteKit - Setup, Login & LogoutJohn Owolabi Idogun ・ May 17 ・ 11 min read#githubhack23#python#django#webdevIntroducing Browser FlashcardsCallmeHongmaybe ・ May 3 ・ 2 min read#githubhack23Bee, a mobile app for citizen science.ruthmoog ・ May 16 ・ 3 min read#githubhack23#github#opensource#showdevAdaGPT: AI support for Issues and Pull Requests right at your fingertips!Chris ・ May 2 ・ 2 min read#githubhack23#github#openai#opensourceFruitifyMe! A deep learning fruitifier that uses Github actions, AWS, tensorflow and React.JSFady GA😎 ・ May 16 ・ 4 min read#githubhack23#tensorflow#react#cicdAll runners-up will receive: $250 USD gift card or equivalent 💰$150 USD credit to the DEV Shop 🌈DEV Sticker Pack 💻DEV “GitHub + DEV 2023” Runner-Up profile badge 🌟  ParticipantsAll participants with a valid project will receive a DEV Sticker Pack and an “GitHub Hackathon 2023” participant profile badge. 🎉To everyone who submitted a project for this hackathon, we're giving you a huge round of applause. In the process of building your project, you sharpened your skills while learning something new. That's something to be very proud of. Our team will follow up with all winners and participants about their prizes, gift codes, and stickers by Friday, June 23rd.Great work, everyone! We hope you had a blast participating in the GitHub + DEV 2023 Hackathon. "
518,"Hey everyone, the past few months have been pretty electric in terms of advancements in AI and actual/imagined changes to our workflow and industry.This is a new regular open thread everyone is encouraged to share...Notable news in the field of AIPersonal experiences and insightsConcerns and fearsSuccess stories and demosAnd any other related discussions you'd like to bring to the tableThis thread will go out every week."
519,"Have you ever stumbled upon an hilarious or quirky variable and function name? A clever pun, an inside joke, or a moment of pure coding creativity -- these little anomalies, hidden amidst lines of code, never fail to bring a smile to our faces. Share your funniest finds with the community. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
520,"Are code comments really necessary? Share your insights and experiences on whether meticulously crafted code can be self-explanatory enough to render comments redundant. Are comments an essential part of code documentation, or can they sometimes be more confusing than helpful? Join the conversation!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
521,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...minimum viable product (MVP).I recently got this question in my inbox:How do you plan a project from scratch, and how do you know when you have MVP?This is a great question! For folks who aren't familiar, MVP refers to the stage of a build where you have just enough features needed to get early adopters using your product. No more, and no less!Here's some more reading on this product approach from Forbes:          A Review Of The Minimum Viable Product Approach                  The truth is, there are no rules. But by applying at least some of the rules, you can accelerate your entrepreneurial spirit.                forbes.com      So, what do you think? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
522,"Imposter syndrome can be a common challenge for Junior Developers. It's the feeling that you don't belong, that you're not good enough, and that any day now, someone will find out that you're a fraud. These thoughts can be demotivating and can hold you back from achieving your full potential. However, the good news is that you can learn how to overcome imposter syndrome in the workplace with the right mindset and strategies.  Recognize Your Own AccomplishmentsIt's important to recognize your accomplishments and celebrate your successes, no matter how small they may seem. Take the time to reflect on what you've achieved so far in your career, whether it's a successful project, a new skill you've learned, or positive feedback from colleagues. Write down your accomplishments and keep them in a place where you can see them regularly, such as a sticky note on your computer screen or a note on your phone. This will help you remember your achievements and boost your confidence.  Embrace Learning OpportunitiesIt's normal to feel like you don't know everything. But the truth is, no one knows everything, and there's always something new to learn. Embrace learning opportunities, whether it's taking on a challenging project or attending a conference. This will help you grow your skills and knowledge, and it will also help you realize that everyone has something to learn.  Connect With OthersConnecting with others in your field can be a great way to overcome imposter syndrome. Attend meetups, join online forums, or find a mentor who can offer guidance and support. Talking to others about their experiences and challenges can help you realize that you're not alone in your feelings of self-doubt. You may even find that others look up to you for your unique perspective and skills.  Practice Self-CareTaking care of your physical and mental health is important for overcoming imposter syndrome. Make sure you're getting enough sleep, eating healthy, and taking breaks when you need them. Exercise can also be a great way to relieve stress and improve your mood. Additionally, consider talking to a therapist or counselor if you're struggling with imposter syndrome or other mental health issues.  Reframe Negative ThoughtsWhen you start to feel like an imposter, try to reframe your thoughts in a more positive light. Instead of thinking, ""I don't know what I'm doing,"" try thinking, ""I'm still learning, and that's okay."" Instead of focusing on your mistakes, focus on what you've learned from them. Remember that everyone makes mistakes, and they're an opportunity to grow and improve.Imposter syndrome can be a challenge for Junior Developers, but it can be overcome with the right mindset and strategies. Remember to recognize your accomplishments, embrace learning opportunities, connect with others, practice self-care, and reframe negative thoughts. By doing so, you can boost your confidence and achieve your full potential in the workplace.  Learn More Tips On How To How To Overcome Imposter Syndrome in the Workplace With My Tech Career Newsletter!Get Valuable Learning Resources Delivered To Your Inbox Every Wednesday!You can learn more tips on how to overcome imposter syndrome in the workplace for Junior Developers, Senior Developers, Lead Developers, Project Managers, and Tech Leadership in my Tech Career Newsletter. This newsletter will give you insight into multiple stages of your career so that you can form your career plan, overcome learning blockers, and stay competitive in today's crowded job market. It includes featured content from authors and influencers in my network to help you navigate your career and learn new skills. Subscribe today and set yourself up for career success!"
523,"Hey fellow developers! Let's talk Git. Do you think all developers need to know it? Share your thoughts on the benefits of using version control in a collaborative coding environment. If you used Git, How has it transformed your development process? Join the discussion!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
524,"Hey there, coding wizards! Let's indulge in a little imagination. If coding were akin to a magical spell, what incantation would you utter, and what extraordinary coding power or other wish would it grant you? Share your coding dreams and let your creativity run wild. Let's explore the enchanting possibilities!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
525,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
526,"Open Source is about the community. Whether you have a project or you're looking to make your first PR, we want to help facilitate those connections.   Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy coding!"
527,"If given a choice, would you rather work on a coding project that demands you to learn a completely new programming language or one that allows you to stick with your favorite language but comes with complex requirements? Join the conversation and let's unravel the trade-offs of these intriguing coding paths!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
528,"We are excited to announce an upcoming conference keynote by DEV and Forem Co-Founder Ben Halpern 🤩🎉@ben will be presenting at RubyConf TH 2023, a Ruby-focused conference on October 6–7 in Bangkok, Thailand along with Bernard Banta of Ruby Kenya, Jemma Issroff of wnb.rb, and Yukihiro ""Matz"" Matsumoto, the creator of Ruby 💎RubyConf TH is South East Asia's only Ruby conference, held in the heart of Bangkok, Thailand.We are returning after a third event after two highly successful conferences in 2019 and 2022.The conference features 18 tech talks in a single track over two days, so you do not miss a chance to catch your favorite topics and speakers.We are so proud of Ben and so excited for his keynote. We know a lot will happen in tech between now and October, and we can't wait to find out what the topic of Ben's talk will be—check back later for updates! 🙌 If you're attending RubyConf TH (or happen to be local to Bangkok), definitely check it out.          Home | RubyConf TH 2023                  A community-powered Ruby conference on 6-7 October 2023 in Bangkok, Thailand                rubyconfth.com      "
529,"Hey folks! Ever hit a plateau in your technical skills and felt a bit stuck? Fear not, because we're here to help each other break through those barriers. What are some effective methods you've found for continuous improvement? Are you experimenting with side projects, joining online communities, attending conferences, or diving into new learning resources? Share you experiences and insights so we can uncover the secrets to keeping our technical skills on the rise and pushing past those plateaus!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
530,"Yesterday on our podcast, software engineer Stacey Graham discussed her experience creating a career in tech after surviving cancer with @saronyitbarek.Stacey fell in love with technology in the 7th grade in her first computer class and from there, her curiosity for technology began. She is passionate about coding and loves learning and problem-solving collaboratively in teams. Stacey enjoys building high-quality applications in JavaScript, React, and Angular and enjoys working with RESTful APIs, Node.js, and Express.js. Stacey gets most excited about being challenged while coding and believes there is always something new to learn in web development.If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""Surviving Cancer, Building Code, Thriving in Tech"": CodeNewbie Podcast S24E6Sloan the DEV Moderator for CodeNewbie ・ Jun 14 ・ 1 min read#codenewbie#career#podcast#beginnersStacey shared some super helpful tips on interviewing, balancing priorities, and finding communities that we would love to share!During the interview process, it may be hard to ensure whether a job will eventually lead you to reaching your specific career goals. However, you can always ask directly how to achieve upward growth, which can hopefully make decision-making easier long-term.A strong support system can help keep you motivated to succeed, especially when navigating a hardship while also working.Make sure to follow up with your recruiters after sending out an initial inquiry or job application!There are many ways to find community with other coders! If you want, you can use Meetup to search for groups in your city, find Slack groups, volunteer at conferences, or join an organization focused on your interests, such as WomenWhoCode.If you listened— what are your best tips for interviewing, finding a coding community, and navigating hardships while working?Send us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
531,"Balancing multiple projects can be quite a challenge. So, how do you handle the juggling act? Please share your go-to prioritization methods and handy tricks to stay organized and focused. Do you use Agile methodologies, time management techniques, have you discovered the secret to cloning yourself? 👯‍♀️👯‍♂️Let's swap our strategies for staying sane while rocking multiple projects. Your insights might just be the game-changer someone else needs!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
532,"Hey there, fellow coding enthusiasts! It's me, Sloan, your friendly neighborhood sloth and Official DEV Moderator I'm back today with an intriguing question that has been anonymously submitted by one of our new members. So, let's dive right into it!Today's query seeks your collective expertise on a matter that's close to every coder's heart: Which are the top tags and organizations to follow on DEV for discovering awesome project suggestions and finding platforms to showcase your work? And where can I find coding challenges to put my skills to the test, get valuable advice on coding best practices, coding style, and more!?So, my fellow coding enthusiasts, it's time to unite our slothful wisdom! Share your insights and recommendations on which tags and organizations have you found to be a treasure trove of project ideas and a welcoming community for showcasing your creations? Do you have any secret spots where you unearth coding challenges that have pushed your limits and sparked your creativity? And let's not forget about those invaluable nuggets of advice on coding best practices, style guidelines, and the ever-present coding patterns. Sloan's Inbox will be back next week for more friendly vibes. Stay tuned and stay slothy!Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
533,"Struggling to maintain a healthy work-life balance as a remote developer, despite following the standard advice? Embrace async communication, set up a dedicated work space, priortize self-care. Yeah, yeah. We've tried it all. But let's dig deeper and explore some unconventional strategies and fresh perspectives to help find that elusive balance. What unique approaches, mindset shifts, or unconventional techniques have you discovered that work for YOU? Share our innovative ideas and let's learn from each other's experiences!"
534,"In S24E6 of the CodeNewbie Podcast, @saronyitbarek talks with software engineer, Stacey Graham, about leveling up in your career after facing a major life hardship.      codenewbie.org    Stacey fell in love with technology in the 7th grade in her first computer class and from there, her curiosity for technology began. She is passionate about coding and loves learning and problem-solving collaboratively in teams. Stacey enjoys building high-quality applications in JavaScript, React, and Angular and enjoys working with RESTful APIs, Node.js, and Express.js. Stacey gets most excited about being challenged while coding and believes there is always something new to learn in web development.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding!💜"
535,"Time for #DEVDiscuss — right here on DEV 😎The Ultimate Guide to Writing Technical Blog PostsRizèl Scarlett ・ Jun 6#writing#careerdevelopment#leadership#contentwritingInspired by @blackgirlbytes's Top 7 post, tonight’s topic is...ultimate tips for writing technical content!Based on her experience as a Developer Advocate, Rizèl Scarlett has written an incredible, comprehensive guide to writing technical content — seriously, take a look 👀So let's talk about it!  Questions:Which of the points in the ultimate guide have served you well as a technical content writer?What are your top tips for writing technical content? Where or how did you learn them?Any triumphs, fails, or other stories you'd like to share on this topic?"
536,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   The Ultimate Guide to Writing Technical Blog PostsTechnical skills such as coding help you to perform your job at a base level, but content creation can solidify you as a leader in the industry. Take these tips from @blackgirlbytes to get started with technical blogging!The Ultimate Guide to Writing Technical Blog PostsRizèl Scarlett ・ Jun 6 ・ 16 min read#writing#careerdevelopment#leadership#contentwriting  I built the same app 6 times! Which JS Framework is best?When people ask which frontend framework is his favorite, @johnrushx usually replies with ""all of them."" Recently, he decided to put that statement to the test by building the same app using five different frontend frameworks!I built the same app 6 times! Which JS Framework is best?John Rush ・ Jun 6 ・ 4 min read#frontend#webdev#react#vue  World Wide Web WarsReminiscing about stories from his grandfather about the old World Wars, @andychiare finds resemblances between the way these wars shook the societies around them and the way the evolution of the web continues to shake the societies we live in today. World Wide Web WarsAndrea Chiarelli ・ Jun 4 ・ 11 min read#webdev#programming#javascript#webcomponents  Say Goodbye to Spread Operator: Use Default ComposerWhen working with objects in JavaScript, it is common to need to set default values for empty strings/objects/arrays, null, or undefined properties.This gets even tougher with nested objects, so check out these tips from @aralroca.👋 Say Goodbye to Spread Operator: Use Default ComposerAral Roca ・ Jun 5 ・ 4 min read#javascript#webdev#programming#opensource  Docker for Beginners: Crafting Your Backend Development Environment@suzuki0430 works at an early-stage startup where they've been focusing so much on the offensive side of things, like new feature development, that they have neglected their defenses, namely, testing. Docker for Beginners: Crafting Your Backend Development EnvironmentAtsushi Suzuki ・ Jun 3 ・ 6 min read#webdev#docker#beginners#mysql  3 Engineering Mistakes That Kill Startups@_michaellin has done engineering consulting in fractional CTO roles for about a year now. And having seen this situation play out for dozens of clients now, they noticed that these projects tend to go south due to the same 3 mistakes.3 Engineering Mistakes That Kill StartupsMichael Lin ・ Jun 8 ・ 8 min read#webdev#programming#career  How I built an MVP and got my first user in a month 🚀@jdtjenkins’ decision to start a business started as an excuse to learn Sveltekit and Vercel, but after realizing how quickly he works with these tools, he decided to actually give it a go.How I built an MVP and got my first user in a month 🚀jdtjenkins ・ Jun 7 ・ 5 min read#webdev#sveltekit#saas#startupThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
537,"Hey there, freelance developers! Let's talk about something essential to our success: securing long-term clients and maintaining a steady income. We all know how crucial it is for our freelance careers. So, how do you tackle the challenge? Share your valuable insights, strategies, and personal experiences on how you navigate the journey of securing long-term clients and creating a reliable income stream. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
538,"Aloha! It has been a little while.  Some personal news...Last month, Eugen aka @Gargron announced that I'll be working on a part-time basis with Mastodon gGmbH to support efforts around developer community and resources - aka, Developer Relations. I've been a supporter of the free and open Web since it began; I've been all-in on the Fediverse for some time now; and I'm excited to be able to bring my experience in DevRel, particularly around community, APIs, and developer experience, to the Mastodon project. This is also cool, because I've previously been posting about the opportunity for developers in this space.A 🦣 opportunity for developersAndy Piper ・ Nov 22 '22 ・ 5 min read#mastodon#activitypub#html#python  First stepsThere are a number of things to work on, and it's important to be realistic about how swiftly we can get to them all. The very first thing that I wanted to do was to do a full review of the libraries and SDKs that developers have built on top of the Mastodon API, and publish an update to the relevant page in the developer documentation.I'd like to take a moment to explain why I chose this as my first task as I believe it's relevant in the context of #DevRel - I posted about this on Mastodon yesterday, too.A few years ago, when I was working on another platform, I took the time to do something similar. The platform itself had an HTTP-based, RESTful API that had been made available and mostly documented, but the organisation didn't publish any code or their own libraries or SDKs - the developer community jumped in and built their own. I spent a bunch of time back then scouring the internet, seeking out as many implementations of the API as possible, figuring out which ones were most used or most popular, which ones had become unmaintained, which ones were constantly evolving, which new coding languages had emerged since the platform's API was first released.(side note: it was also super fun to go and deliberately hunt out less well-known languages and to see whether anyone had built an implementation yet... Zig, anyone? No? How about Nim!)I've been working with API platforms for a long time. In my experience, the developers that go to the effort and spend their time building idiomatic language-specific libraries around an API, provide huge support to their own communities. Most organisations and platforms simply cannot hope to provide expertise in every language or framework themselves, so these community contributions provide an oversized benefit. The developers who build those libraries and SDKs, often become experts in themselves, and can be amplifiers that generate activity around a platform.Just to pick out a couple of meaningful examples - in the update to the libraries and implementations page we just published, several of the new entries cover languages such as Kotlin that were not previously included, as well as adding several more Swift libraries - and in turn, those additions provide foundations for the excellent Android and iOS client apps that have emerged since the end of 2022. In all, the page has jumped from a list of 35 libraries, to more than 50 - and that includes the fact that some have been removed either due to their authors explicitly archiving them, or the impression that they were no longer maintained (which could be added back if needed); and, from 21 to 26 languages represented. That's an impressive expansion of coverage, and I believe it demonstrates the level of interest and excitement around building on the Mastodon API.A heartfelt Thank You to the developers who have created these resources. As a developer advocate, it's a joy to see the activity around the platform, and I aim to support you and your efforts to work with us.The Mastodon API is open, free, and you are welcome to build with it.  What's next?My next task is triaging and labelling issues and pull requests in the documentation repo on GitHub, with an aim to bring in as many of those existing contributions as we can. I am particularly focused on the API, and I am not currently so familiar with other topics (Mastodon server installation, administration, etc), so I'll be relying on additional help! I am aware that some of the issues and PRs have been waiting for a while, but I'll do what I can to get things improved here.It's also worth sharing that we intend to apply a design update to the developer docs site (to match the main site and blog). That's a separate task to the content work that I'm looking at.Another thing that I'm actively thinking about, is how we can move towards a more formal API specification. The obvious candidate is OpenAPI, and there has been some community work to provide something in this space already. A few folks also had a good conversation about it on Mastodon last week, and that made me aware of some of the complexities of providing this for the project. I'm open to taking on board other experiences in this area, so let me know if this is important to you. If nothing else, something like a Postman Collection which is up-to-date for the current API, seems to me like A Good Thing, to help the community test and implement things more quickly.Going beyond curating lists of libraries and poking at API docs, I want to help to connect the dots between different projects around Mastodon itself, and the broader Fediverse! I started on the latter effort a couple of months ago (see: Supporting Fediverse developer communities), but for right now, I'm going to be spending time specifically on Mastodon, and helping the team with developer communications.Let me know what else you might want to see from the Mastodon project from a developer perspective, and I'll be sure to add it to my list. Or, just share any Mastodon-related project you're working on, so I can help to shout about it!Follow me on MastodonI hope to get to chat to you via GitHub, Discord, Mastodon, or another channel - keeping in mind that I've been tasked with community and API rather than individual end-user product features - the roadmap is full and exciting, though!Finally, I continue to be interested in other opportunities and to build my skills in other areas (via my maker studio), so look out for more on this, soon.Check out my personal siteHeader image courtesy of Midjourney"
539,"I'm a firm believer in the importance of feedback, but I also think it doesn't happen nearly enough.         BekahHW      @bekahhw      I think one of the most underutilized tools we have is giving feedback. I also think that we don't spend enough time developing this skill, which is good for the whole team if it's done right. One of the best ways to ensure that you both give and receive effective feedback is… twitter.com/i/web/status/1…      14:11 PM - 08 Jun 2023    What's the best feedback you've received?"
540,"  What are your goals for this week?What are you building? What will be a good result by week's end?Are you attending any events this week? Any suggestions of events to attend?Did you meet your goals last week?I'll start with how I did last week.  Last Week's Goals[✅] Continue Job Search[✅] Code Challenges[❌] Project workEvents[✅] Attend Virtual Coffee(VC) Thursday.[❌] Attend Virtual Coffee(VC) Tuesday. It's 8am my time. It's during school travel time but now that's it's summer, no school so if I'm social enough at 8am I could make it. * Nope Barely awake at the time. Was not social at all.[✅] Other VC events if I can.[✅]  Attend FrontEnd Test Fest Wednesday.[✅] Organize Office: Clean 2nd desk, Which is mainly a LEGO build area.  This Week's GoalsContinue Job Search.BlogCode ChallengesProject workEventsAttend Virtual Coffee(VC) Thursday.Other VC events if I can. Friday * lunch and learn.Move a site to a new host.  Your Goals for the weekYou've read my goals so I'll throw the questions back to you.What are you building? What will be a good result by week's end?Are you attending any events this week? Any suggestions of events to attend?Did you meet your goals last week?-$JarvisScript git pushEnter fullscreen modeExit fullscreen mode"
541,"If you had the ability to transform one aspect of the programming industry, what would it be? Share your vision for a different -- maybe better? -- programming industry, and let's ignite a discussion that could inspire real change!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
542,"Open Source is about the community. Whether you have a project or you're looking to make your first PR, we want to help facilitate those connections.   Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy coding!"
543,What's your origin story?
544,Curious minds want to know: how can one break into a new tech specialty or niche without the traditional formal education or prior experience? Let's pool our knowledge and share practical steps that can help pave the way. What strategies have you found effective in making your mark? Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      
545,"I am late to the ChatGPT train because I dislike the many charlatans who are overselling. LinkedIn is especially full of them.Even worse are the charlatans who do their best efforts to manufacture irrational fears😱 AI will replace us! 🤥But I've also seen a friend using it for content creation. And he is very much not carelessly trusting ChatGPT. He is using it expertly after being trained to ChatGPT, he treat ChatGPT like an intern, to go faster in a domain he is already an expert of.So now I think that concerning ChatGPT we are at the same time in the Peak of expected inflation and in the Slope of Englightenment phrases of the Gartner Hype Cycle.  And you?What's a cool concrete meaningful thing you have done with ChatGPT?Feel free to {% embed xxx %} an article you have already written."
546,"In JavaScript, the language provides a feature known as 'strict mode', introduced in ECMAScript 5 (ES5), that helps developers avoid common JavaScript pitfalls. In this article, we will dive into what strict mode is, how to enable it, and the benefits it provides.For a more in-depth article you can check out the counter-part to this article over on our website: Understanding JavaScript Strict Mode on Accreditly.  What is Strict Mode?Strict mode is a way to opt into a restricted variant of JavaScript. In strict mode, JavaScript eliminates some JavaScript silent errors by changing them to throw errors. It fixes mistakes that make it difficult for JavaScript engines to perform optimizations, and it prohibits some syntax likely to be defined in future versions of ECMAScript.  Enabling Strict ModeTo enable strict mode in JavaScript, you use the string ""use strict"". This can be done for an entire script or within an individual function.For an entire script:""use strict"";var v = ""Hello, I'm in strict mode!"";Enter fullscreen modeExit fullscreen modeFor an individual function:function strictFunc() {  ""use strict"";  var v = ""Hello, I'm in strict mode inside a function!"";}Enter fullscreen modeExit fullscreen modeThe ""use strict"" directive is only recognized at the beginning of a script or a function.  The Benefits of Using Strict ModeStrict mode helps out in a couple of ways:It catches common coding mistakes and ""unsafe"" actions. For instance variables must be declared with var, let, or const. A variable that has not been declared will cause an error.""use strict"";x = 3.14; // This will cause an error because x is not declaredEnter fullscreen modeExit fullscreen modeIt prevents the use of future ECMAScript reserved words. For example:""use strict"";var let = ""Hello""; // This will cause an error because ""let"" is a reserved word in ES6Enter fullscreen modeExit fullscreen modeIt simplifies eval() and arguments. In strict mode, variables declared within an eval() statement will not create variables in the surrounding scope.""use strict"";eval(""var x = 10;"");// This will cause an error because x is not defined outside the scope of eval()console.log(x); Enter fullscreen modeExit fullscreen modeIt restricts this to undefined for functions that are not methods or constructors. In non-strict mode, this will default to the global object, window in a browser context.""use strict"";function myFunction() {  console.log(this); // Will output: undefined}myFunction();Enter fullscreen modeExit fullscreen modeUsing strict mode can help you catch errors that would otherwise have been silently ignored. It also helps prevent you from using potentially problematic syntax and making inefficient coding decisions. Strict mode can make your JavaScript code more robust and maintainable, and it's a best practice to start your scripts with the ""use strict"" directive."
547,"Apple just launched their AR/VR headset called Apple Vision Pro.          Apple Vision Pro is Apple’s new $3,499 AR headset - The Verge                  A big but preliminary step toward mixed reality.                theverge.com      Do you have any initial reactions?"
548,"When I was a kid, my grandfather used to tell me about his wartime adventures. He served in both World War I and World War II. He was a boy of 1899.I was interested in the entertaining side of the stories without understanding the suffering behind them. One thing that stuck with me was that he often said that the two wars were different. They were different in the way they were fought, in the way they involved the population, in their motivations.Years later, I find this thought about the two different wars applicable to a context that is fortunately less tragic than the one my grandfather experienced: the World Wide Web.In my career, I've been privileged to see the birth of the Web and its evolution from a platform for sharing documents to a platform for running distributed applications. And along the way, I've witnessed a few wars.I'll try to tell you about them...as if I were your grandfather.Make yourself comfortable: it won't be short.  The HTML-Centric EraIn the beginning, the Web was based only on HTML and HTTP. Nothing could be simpler: documents were described using a simple markup language and transferred from one computer to another using a simple protocol. Berners-Lee's idea was simple and revolutionary at the same time. And the key principle was interoperability. Let's remember that word.I started exploring the Web in the early 90s, when Mosaic was the most advanced browser. In those days, you had to plan your Internet tour very well to avoid bleeding yourself dry with the time-based tariff (at least in Italy). For a developer, creating static HTML pages wasn't that exciting. It didn't require any true programming skills. The interesting part was to generate HTML dynamically on the server via the glorious CGI scripts.Everything was quite clear and defined. It didn't matter what kind of script you used on the server side: Perl scripts, shell scripts, C programs. What mattered was that its output was HTML and that it was transmitted over HTTP.And the future looked bright.  The First Web WarThen, in 1995, JavaScript came along and the scenario began to change. The client side of the Web also needed development skills. New browsers came out: Netscape Navigator and Internet Explorer. The first war began: the browser war.Browser builders, basically Netscape and Microsoft, competed to offer more and more attractive features: support for animated GIFs, new HTML tags (e.g.: marquee, blink, font), support for scripting languages with little or no compatibility (JavaScript, JScript, VBScript), support for applets, Flash objects, ActiveX components, etc.It was a continuous explosion of new features but they were supported by only one browser and starting from a specific version. There was a strategy, later called EEE, to defeat competitors with incompatible features.Creating an interactive HTML page was a nightmare. If you wanted the page to be usable by as many users as possible, you had to take into account what features were supported by the browser and the version the users were using. Browser sniffing techniques emerged, which had to be kept up to date in order not to cut users off from your website. To understand a bit what I mean, try to take a look at some sample code from that era.The alternative approach was to create web pages optimized for one specific browser: an easier solution for the developer, but a frustrating solution for the user. All over the Web you could find sites with more or less elegant stickers inviting the user to use the browser for which the site was optimized:So, in that first Web war, we had fierce competition among browser vendors to offer an increasingly advanced Web experience. Developers had to deal with differences between browsers, and between different versions of the same browser. Many chose to optimize their pages for a particular browser, much to the chagrin of users who experienced accessibility problems and were forced to use multiple browsers.At the time, the Web was not a good place for developers and users. Nor was it for the interoperability that had been dreamed of. The overall satisfaction with the Web could be summarized as follows:UsersDevelopersBrowser vendors 🙁  🙁  🙂   The Role of StandardsAt this point, you may be wondering about the role of standards in all this confusion. In particular, what about the role of the W3C? In fact, the consortium was responsible for defining a reference standard for web technologies, primarily HTTP and HTML. But at the time, its influence (and responsiveness) was insufficient for a Web as dynamic as that of the late 1990s.Often the role of the W3C was limited to defining as a standard those HTML features that were already de facto accepted. For example, iframe, object, and XMLHttpRequest were actually introduced by IE before they became standard. So, it was an a posteriori standardization that didn’t bring much benefit to either developers and users.Things began to change when the ECMAScript specification was released in 1997. JavaScript and other minor dialects had to conform to it to ensure compatibility across browsers. But scripting language standardization alone was not enough. That same year, the W3C defined DOM Level 1, which moved browser interoperability in the right direction. But we had to wait until 2000 for DOM Level 2 standardization, which stabilized the chaos that was occurring in web development.That year, the W3C went further. It defined XHTML, a version of HTML 4 based on the formally stricter criteria of the XML standard, but with the advantage of extensibility. Anyone could extend the language by providing the appropriate DTD or XML Schema. The solution was technically sound, but it was not fully understood and considered too complex. In addition, the lack of backward compatibility of XHTML with the old HTML caused many concerns.This led to the formation of a new working group outside the W3C, the WHATWG, whose goal was a reorganization of HTML that would eventually result in HTML 5. XHTML was doomed to die within a few years.  The Invasion of External RuntimesAs in all wars, there are those who get poor and those who take advantage.During the browser war and the resulting lack of interoperability, many developers turned to alternative technologies. Many of them turned to Flash, Java, ActiveX, and other technologies that offered more seamless development and a consistent user experience. All they needed was install a runtime on the user's preferred browser.At the time, developing interactive and engaging web pages using HTML and JavaScript was a daunting task. Alternative technologies, such as Flash, allowed an application to be downloaded locally to the browser and have only minor interactions with the server to retrieve data and update the user interface without having to reload the entire page. A real revolution!Unlike ActiveX, which was tied to Internet Explorer and Windows, Flash and Java applets guaranteed a consistent user experience regardless of the user’s browser.The price to pay was the use of proprietary technologies and some potential security risks that occasionally occurred.The vision of the Web as a standard and interoperable environment began to crack.Browser vendors simply supported external plugins to delegate app execution to Flash & Co. runtimes. Developers who embraced this web programming model had the advantage of not having to worry anymore about which browser the user was using. However, they were no longer web developers in the proper sense: they abandoned actual web technologies and specialized in developing for one or more of these runtimes. Users could use the browser of their choice, but they had to install and keep updated the different runtimes. In short, websites optimized for a particular browser had become websites optimized for a particular runtime - not much of a gain, after all.While developers were quite comfortable once they chose their reference runtime, users continued to suffer from the need to install different runtimes while keeping their browser of choice. In summary, this was the overall level of satisfaction:UsersDevelopersBrowser vendors 🙁  😐  😐   The JavaScript-Centric EraWith the introduction of Ajax and dynamic DOM, JavaScript and standard web technologies had their redemption. Partial updates of a web page became a reality using standard technologies as well, thanks to what was then known as Dynamic HTML (DHTML).JavaScript, HTML, and CSS were the standard triad of the Web. By 2005, JavaScript was the real driver of sophisticated front-end application development. It was the new competitor to proprietary solutions like Flash, Java, and the others.A few years later, there was a historic changing of the guard for the Web: Netscape Communicator, successor to the glorious Netscape Navigator, left the scene. From its ashes, the Mozilla project was born. And that project would give birth to Firefox. At the same time Chrome was born.It was the dawn of a new Web era.  The Web Is JavaScriptThe resurgence of JavaScript and the desire to make the web ecosystem competitive against proprietary technologies gave a strong impetus to the proliferation of libraries aimed at simplifying DOM manipulation, Ajax interaction with the server, and integration with CSS.In 2006, jQuery was born, destined to become the most widely used library on the Web. Soon, MooTools, Backbone, Ember, and others were there to compete with it.Now developers had great allies to create dynamic and attractive web interfaces without reinventing the wheel. The number of JavaScript libraries grew at an unprecedented rate. Not a day went by without a new JavaScript library being born.Ecosystems were created around some of these libraries, i.e., libraries that specialize in a particular task, but are based on specific core libraries. For example, jQuery UI is a library for building web interfaces that uses jQuery for DOM manipulation and other low-level tasks. Bootstrap was also born as a jQuery-based UI library.These libraries relieved the developer of the burden of having to work directly with HTML and CSS to create UI elements. In addition, they offered the advantage of handling the residual differences in standards support between different browsers admirably. The developer's life was greatly simplified compared to the previous Web era. The jQuery library became something of a standard and you could find it everywhere. So much so that many junior developers had a hard time distinguishing jQuery from JavaScript and the DOM. Many didn't even know what DOM was. To many, $() was a JavaScript feature!Users’ lives also became easier in those years. In general, the experience of browsing and interacting with web pages was pretty consistent. And users could use any browser they wanted, except Internet Explorer 6 and some later versions.By now, a web front-end application was primarily a JavaScript application. Developers simply had to choose the target library ecosystem and use compatible UI libraries. Building a web UI became a matter of JavaScript code. HTML was just a hook to pull code into the browser. Rendering was dynamically performed by the base library’s DOM manipulation. You were in the era of Single-Page Applications.Soon came AngularJS and later React. Shortly thereafter, Vue arrived to complete the new triad of web front-end development.  Yet Another Web War?Today, we can say that most front-end development for the Web is based on these three ecosystems: Angular, React, and Vue. Can we say that there is a war going on?If we compare the current situation to that of the first Web war, we cannot say that there is the same kind of conflict. In general, browser vendors are ensuring some level of compliance with standards, which are finally proactive. The user's browsing experience does not suffer from the same problems as it did then.But have we achieved that interoperability we dreamed of as a fundamental principle of the Web?Looking more closely, those who suffer from the lack of interoperability in the current situation are the front-end developers. In the first war, they used to choose a browser and built pages optimized for it to make web development easier. Now they are forced to choose a JavaScript ecosystem and build applications optimized for it. On the user side, of course, there is a significant win. Users don't care which JavaScript framework developers use. And that's fair.However, developers cannot reuse the result of their work in another JavaScript framework. A React component can only be used in a React application. If you need the same component in an Angular or Vue application, you have to recreate it.In short, the war between browsers is now a war between JavaScript frameworks. Maybe a little quieter, but not exempt from the occasional religious war.The current situation can be summarized as follows:UsersDevelopersBrowser vendors 🙂  😐  🙂   Back to the Web Platform (Peace and Love)The current war is not as loud as the browser war (believe me, it is not at all). But that does not mean that it is not a problem. Over the past few years, I have witnessed a split in front-end developer skills between the three major JavaScript frameworks. I have also seen a loss of basic web platform standards skills.It seems that there is a general loss of basic knowledge, similar to what happened after the success of jQuery. Several libraries simplify the developer's life and make up for the shortcomings of HTML, JavaScript, the DOM, etc. But in the meantime HTML has evolved, JavaScript has evolved, the DOM has evolved, CSS has evolved.The Web Components standard gives us with enough infrastructure to make the Web an interoperable platform for front-end development. Some people criticize this technology for being too low-level, but there are libraries that make the developer's life easier.You might say that this is the same vicious cycle as JavaScript frameworks. That's wrong, because Web Components are interoperable by design. Choosing Stencil or Lit or any other library is a development convenience that has little to do with the interoperability of the resulting components.Do we really want to continue this silent war? Wouldn't it be better to channel those energies into a standard ecosystem where everyone is free to use the tool of their choice to create components that can be used on the Web as a development platform? Let's transform the Web from a platform for running applications to a platform for composing applications. Let's add that missing piece to restore the original dream of an interoperable Web.As a developer, the next time you start a new project ask yourself this simple question: do I really need a JavaScript framework?Maybe it's time to bring some peace to the Web. My grandfather (and not just him) would be happy."
549,"Hey folks 👋What ya learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Keep on learning and have fun doing it!"
550,"Getting project timeline estimates right is key to smooth planning and successful project completion. So, how do you make sure your project timeline estimates are as accurate as possible? Let's chat about your techniques, tools, and personal experiences in improving the accuracy of project timeline estimates.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
551,"I am preparing a talk that focuses on the ethical dilemmas software developers face and I am looking for some help.In today's interconnected world, developers hold great power in shaping the technologies and systems that influence our daily lives. With this power comes the responsibility to navigate ethical challenges and make the right choices. I would like to focus on exploring and discussing real-world examples and as a part of that, I would love to ask for your opinions on a few questions to back my thoughts.So without further ado, would you say no to these business requirements if you look at them solely from an ethical point of view? (Please state your answer one by one, without reading the next one)Develop a platform where people can upload and host their files.Develop a platform where people can upload and host their files and make them available to any subscriber to download.Develop a platform where people can buy tickets to participate in a monthly raffle to win cars or even houses.Develop a platform where people can buy tickets to participate in a state-backed monthly raffle to win cars or even houses.Develop a webshop engine.Develop a webshop engine for a webshop that sells counterfeit products.Change the default sort order to prefer the most recommended options on the booking platform.Change the default sort order to prefer the most recommended options on the booking platform if you know that most recommendations are fake and generated reviews.I would also love to know your whys in each case. What examples came to your mind when you read these?Thanks a lot! :) Cover image by Clark Tibbs on Unsplash"
552,"How do you navigate the challenges when your code fails to function as anticipated or yields unexpected outcomes? Share your experiences, strategies, and lessons learned in handling such situations.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
553,Building a standout personal brand as a developer or coder is essential in today's competitive job market. What strategies have you found effective in establishing and promoting your personal brand to showcase your expertise and attract opportunities?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      
554,"In a fast-paced development environment, striking a balance between speed and quality is crucial. It would be interesting to hear different perspectives on how individuals manage this trade-off. Do you focus on the importance of thorough testing and code reviews to ensure stability, or do you underscore the need for agile methodologies and iterative development to deliver quickly?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
555,"We all know how crucial it is to stand out from the crowd. So, how are you infusing your passion into your resumes, cover letters, or portfolios? Have you included personal projects, open-source contributions, or details about online courses? Share your strategies, tips, and success stories as we inspire each other to make our job applications shine with the passion and commitment that drives us to excel in the world of coding.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
556,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...Apple's Worldwide Developer Conference (WWDC) 2023.This year's conference came with one big, exciting announcement: Apple Vision Pro 🤯Our community members @ben, @thorstenhirsch, and @theklr had some interesting initial reactions to the groundbreaking news...Ben Halpern•    Jun 5  It feels like so many of Apple's last decade lead up pretty seamlessly to Vision Pro.It's not clear whether this product will ultimately matter much, at least in the near future, due to some clunkiness like external battery and lack of obvious utility with some of the experiences they demo'd.However, it's pretty clear that they have a really consistent strategy — with Apple Silicon at the center.Thorsten Hirsch•    Jun 5  • Edited on Jun 5• EditedWho's paying that amount of money for an entertainment device? So I guess Apple wants people to use it for work... but I haven't seen any reason why I should want to work with such a device on my head.Unless Apple releases an SE edition for $1000 (for entertainment - their Disney deal is genius!) they will lose big against Meta with this device... I guess.Kevin R•    Jun 5  • Edited on Jun 5• EditedFeels like the apple watch all over again. Limited market testing, but confident in experience to finally release. I think its something we'll have to wait 3-5 years to see the results. Happy to see though Apple marketing still refuses to use ""tech specs"" when introducing products however. All the hype stuff is still there, it just doesn't matter to most consumers when going to a store. At the end of the day this will live and die by the adoption rate on both ends and wondering if Apple is going to look away at that one market that would probably push this thing forward (that industry always has). But Vision Pro wasn't the only news from the conference (even if the feed was acting like it 👀) — check out this very good point from @sebastian_wessel.One more thing - Apple's push on web apps on macOSSebastian Wessel ・ Jun 5 ・ 2 min read#webdev#webapp#news#discussSo, what did you think of WWDC 2023?Have your thoughts on Apple Vision Pro changed over the past few days?Are there other bits of news from the conference we ought to be talking about?Is the whole conference overhyped anyway? (Team Android, anyone?)Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
557,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
558,"Last year I wrote an article about the new features of ES2022 this year let's check out the new features coming in as part of ES2023.  Features of ES2023  1. Find array from the lastThis function will allow us to find element from the last to first of the array based on a condition.const array = [{a: 1, b: 1}, {a: 2, b: 2}, {a: 3, b: 3}, {a: 4, b: 4}]console.log(array.findLast(n => n)); //result -> {a: 4,b: 4 }console.log(array.findLast(n => n.a * 5 === 20)); // result -> {a:4,b:4} as the condition is true so it returns the last element.console.log(array.findLast(n => n.a * 5 === 21)); //result -> undefined as the condition is false so return undefined instead of {a:4,b:4}.console.log(array.findLastIndex(n => n.a * 5 === 21)); // result -> -1 as the condition is not justified for returning the last element.console.log(array.findLastIndex(n => n.a * 5 === 20)); // result -> 3 which is the index of the last element as the condition is true.Enter fullscreen modeExit fullscreen mode  2. Hashbang GrammerThis feature would enable us to use Hashbang / Shebang in some CLI.Shebang is represented by #! and is a special line at the beginning of the script that tells the operating system which interpreter to use when executing the script.#!/usr/bin/env node// in the Script Goal'use strict';console.log(2*3);#!/usr/bin/env node// in the Module Goalexport {};console.log(2*2);Enter fullscreen modeExit fullscreen mode#!/usr/bin/env node this line would invoke a Node.js source file directly, as an executable in its own.We would not need this line (#!/usr/bin/env node) to invoke a file explicitly via the node interpreter, e.g., node ./file  3. Symbols as WeakMap keysThis allows using unique Symbols as keys. Currently WeakMaps are limited to only allow objects as keys. Objects are used as keys for WeakMaps because they share the same identity aspect.Symbol is the only primitive type in ECMAScript that allows unique values therefor using Symbol as key instead of creating a new object with WeakMap.const weak = new WeakMap();const key = Symbol('my ref');const someObject = { a:1 };weak.set(key, someObject);console.log(weak.get(key));Enter fullscreen modeExit fullscreen modeMore use cases related to ShadowRealms and Record & Tuples using Symbols as WeakMaps  4. Change Array by CopyThis provides additional methods on Array.prototype to make changes to array by returning new copy of it with the change instead of updating the original array.New Array.prototype introduced functions are:Array.prototype.toReversed()Array.prototype.toSorted(compareFn)Array.prototype.toSpliced(start, deleteCount, ...items)Array.prototype.with(index, value)const numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9]/* toReversed */const reversed = numbers.toReversed();console.log(""reversed"", reversed); // ""reversed"", [9, 8, 7, 6, 5, 4, 3, 2, 1]console.log(""original"", numbers); // ""original"", [1, 2, 3, 4, 5, 6, 7, 8, 9]/* toSorted  */const sortedArr = numbers.toSorted();console.log(""sorted"", sortedArr); // ""sorted"", [1, 2, 3, 4, 5, 6, 7, 8, 9]console.log(""original"", numbers); // ""original"", [1, 2, 3, 4, 5, 6, 7, 8, 9]/* with */const replaceWith = numbers.with(1, 100);console.log(""with"", replaceWith); // ""with"", [1, 100, 3, 4, 5, 6, 7, 8, 9]console.log(""original"", numbers); // ""original"", [1, 2, 3, 4, 5, 6, 7, 8, 9]/* toSpliced */const splicedArr = numbers.toSpliced(0, 4);console.log(""toSpliced"", splicedArr); // ""toSpliced"", [5, 6, 7, 8, 9]console.log(""original"", numbers); // ""original"", [1, 2, 3, 4, 5, 6, 7, 8, 9]Enter fullscreen modeExit fullscreen modeThese are some awesome set of features coming up with ES2023 which I am really looking forward to try them out personally in my day to day coding.Happy Coding! 👩‍💻"
559,Imagine your dream home of the future — a place where technology blends seamlessly with everyday life. What cool and futuristic features would you want in your smart home? Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      
560,"David Bowie is renowned for his music career, but he also made notable contributions to the film industry. Two of our faves include ""The Prestige"" (2006),in which Bowie portrays Nicola Tesla, and ""The Man Who Fell to Earth"" (1976), in which he plays an alien in search of water for his drought-stricken planet. Tell us: what's your favorite Bowie movie, and WHY? ❇️Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
561,"AI is turning out to have many applications such as self driving vehicles, interpretation of text, and the ability to generate media better than a human.It is easy to be critical of the work and say the end is near unless we stop the evil whatever, but I'm curious what the future will hold. Surely there will be other products and applications of AI that benefit humans.Currently we have the following types of software powered by some form of AI:Text to text for translating and understanding large globs of textText to media for generating human like content such as images, audio, and videoMedia to text for summarizing large blobs of data as a transcript.In my opinion, I think the next big thing is going to be advancements in accessibility. Stuff like auto generating ASL for videos, or headphones that translate from Chinese to English in real time. "
562,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
563,  What are your goals for this week?What are you building? What will be a good result by week's end?Are you attending any events this week?Did you meet your goals last week?I'll start with how I did last week.  Last Week's Goals[✅] Continue Job Search.[✅] Finish portfolio refactor. * Done listed another project and found a mistake that's be up fro a month. That's why it's good to get a fresh set of eyes on a project.[✅] Blog[✅] Content updates on a couple sites.Events[✅] Attend Virtual Coffee Thursday. [❌] Other VC events if I can.  This Week's GoalsContinue Job Search.reschedule a Coffee chat with a recruiter.BlogProcess some photos add them to a site.EventsAttend Virtual Coffee Thursday. Other VC events if I can.Attend Dallas Software Developers Meetup (virtual)  Your Goals for the weekYou've read my goals so I'll throw that question back to you.What are your goals for the week?-$JarvisScript git pushEnter fullscreen modeExit fullscreen mode
564,Would you rather spend an entire day debugging a complex code issue or refractor an entire codebase from scratch. It's a tough call! Share your preference and the reasons behind your choice.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik
565,"Hey DEV Community! We are SO excited to announce an upcoming conference talk by our Lead Software Engineer Ridhwana Khan 🤩🎉@ridhwana will be presenting at Rubyday 2023, a Ruby-focused conference on June 15 in Verona, Italy. She will be presenting on caching strategies on dev.to—the very site you're using right now!We’ve always put a lot of effort into performance at DEV. We want our users to be able to see their content almost instantaneously when interacting with our site.In order to do so we’ve placed emphasis on caching. We’ve had to ask ourselves questions like: what are the right things to cache? Which layer in the stack would be best to cache it? And how will this affect the overall performance?During this presentation, I’d like to show you some of the caching strategies we have in place and discuss how they’ve sped up the interactions within our site.We are so proud of Ridhwana and so excited for her talk! If you're attending Rubyday (or happen to be local to Verona), definitely check it out.          talks & speakers | rubyday 2023                  rubyday 2023, the Italian Ruby conference                2023.rubyday.it      "
566,"Greetings, friends! Can you guess who's here? It's Sloan, your trusty companion in the world of coding and beyond 🦥Welcome to a fresh edition of ""Sloan's Advice Corner,"" where we dive into your inquiries, share insights, and navigate the exciting realm of personal and professional growth. Whether you're seeking career guidance, pondering office dynamics, exploring industry trends, or honing your technical prowess, this is the place to be.I'm thrilled to embark on another learning adventure with you, tackling your questions, comments, and musings. So, without further ado, let's jump right in!Today, we have a question from one of our members, @woodtoyz, who is considering a career transition from C# desktop development to web development. I need guidance on what to focus on and how deep should I go to land a web position. Employers seem to demand SO many different skills, tools, frameworks. Each part of the web puzzle is so deep! What web coding skills do I need to know before having a real chance at a junior position?So, let's lend a helping sloth paw to our fellow coder on their web development journey. What web coding skills do you believe are essential before having a real chance at landing a junior web development position? Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
567,"Yesterday on our podcast, Phoebe Voong-Fadel, Frontend Developer at the National Foundation for Educational Research, came on to discuss her journey navigating parenthood alongside a self-taught career in coding.Before web development, Phoebe also worked for years at various universities in London, while advocating for the use of technology and software to automate repetitive administrative tasks. Apart from her current career at the National Foundation for Educational Research, Phoebe writes articles for freeCodeCamp and mentors early-career developers.If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""Balancing Parenthood and Programming"": CodeNewbie Podcast S24E5Sloan the DEV Moderator for CodeNewbie ・ Jun 7 ・ 1 min read#podcast#codenewbie#beginners#career  Here are some things we took away from our talk with Phoebe that we wanted to share:As long as you have learned more today than yesterday, you are in good shape!When you are feeling stuck while learning something, switch up the method by which you are intaking information— like trying out a Youtube video or asking a friend for some advice. Before you sign up for a boot camp, try some free resources to see if they work for you! Ultimately, see which learning styles work best for you before committing to a paid program, if you can.Go at your own pace when learning new things and try to avoid comparing yourself to others. You will get there when you get there, and sometimes that means moving slower than other folks! When you compare yourself to others you may also put too much pressure on yourself to learn quicker, not feel good about yourself, or generally waste your energy.Try again the next day if you don’t do your best at learning something the first day.If you listened— what are your biggest tips for balancing parenthood, or other large priorities, with learning to code?Send us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
568,Moto Razr for the win! 🙌 44 33 555 555 666  6 666 8 666Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik
569,"Time for #DEVDiscuss — right here on DEV 😎Dockerfile Optimization using Multistage Builds, Caching, and Lightweight imagesInternet Explorer ・ May 30#docker#programming#kubernetes#laravelInspired by @er_dward's Top 7 post, tonight’s topic is...optimizing Dockerfiles 🐳According to the post...Leveraging Docker's caching mechanism and multistage builds can result in significant enhancements in Dockerfile efficiency for a Laravel PHP application using Yarn and Nginx. With a better understanding of these mechanisms, developers can craft Dockerfiles that build faster, produce smaller images, and thus, reduce resource usage.  Questions:What tools, tips, and tricks have you used to optimize Dockerfiles?Have you used any non-Docker solutions for efficient container development?Any triumphs, fail whales, or other stories you'd like to share on this topic?"
570,Anything you live by?
571,"Subscribe or follow me on Twitter for more content like this!Imagine writing a piece of software that could understand, assist, and even generate code, similar to how a seasoned developer would.Well, that’s possible with LangChain. Leveraging advanced models such as VectorStores, Conversational RetrieverChain, and LLMs, LangChain takes us to a new level of code understanding and generation.In this guide, we will reverse engineer Twitter's recommendation algorithm to better understand the code base and provide insights to craft better content. We’ll use OpenAI’s embedding technology and a tool called Activeloop to make the code understandable, and an LLM hosted on DeepInfra called Dolly to converse with the code.When we’re done, we’re going to be able to shortcut the difficult work it will take to understand the algorithm by asking an AI to give us answers to our most pressing questions, rather than spending weeks sifting through it ourselves. Let’s begin.  A Conceptual Outline for Code Understanding with LangChainLangChain is a very helpful tool that can analyze code repositories on GitHub. It brings together three important parts: VectorStores, Conversational RetrieverChain, and an LLM (Language Model) to assist you with understanding code, answering questions about it in context, and even generating new code within GitHub repositories.The Conversational RetrieverChain is a system that helps find and retrieve useful information from a VectorStore. It uses smart techniques like context-aware filtering and ranking to figure out which code snippets and information are most relevant to the specific question or query you have. What sets it apart is that it takes into account the history of the conversation and the context in which the question is asked. This means it can provide you with high-quality and relevant results that specifically address your needs. In simpler terms, it's like having a smart assistant that understands the context of your questions and gives you the best possible answers based on that context.Now, let's look into the LangChain workflow and see how it works at a high level:  Index the code baseThe first step is to clone the target repository you want to analyze. Load all the files within the repository, break them into smaller chunks, and initiate the indexing process. If you already have an indexed dataset, you can even skip this step.  Embedding and Code StoreTo make the code snippets more easily understandable, LangChain employs a code-aware embedding model. This model helps in capturing the essence of the code and stores the embedded snippets in a VectorStore, making them readily accessible for future queries.  In simpler terms, LangChain uses a special technique called code-aware embedding to make code snippets easier to understand. It has a model that can analyze the code and capture its important features. Then, it stores these analyzed code snippets in a VectorStore, which is like a storage place for easy access. This way, the code snippets are organized and ready to be quickly retrieved when you have queries or questions in the future.  Query UnderstandingThis is where your LLM comes into play. You can use a model like databricks/dolly-v2-12b to process your queries. The model is used to analyze your queries and understand the meaning behind them by considering the context and extracting important information. By doing this, the model helps LangChain accurately interpret your queries and provide you with precise and relevant results.  Construct the Retriever:Once your question or query is clear, the Conversational RetrieverChain comes into play. It goes through the VectorStore, which is where the code snippets are stored, and finds the code snippets that are most relevant to your query. This search process is very flexible and can be customized to fit your requirements. You have the ability to adjust the settings and apply filters that are specific to your needs, ensuring that you get the most accurate and useful results for your query.  Build the Conversational ChainOnce you have set up the retriever, it's time to build the Conversational Chain. This step involves adjusting the settings of the retriever to better suit your needs and applying any additional filters that might be required. By doing this, you can narrow down the search and ensure that you receive the most precise, accurate, and relevant results for your queries. Essentially, it allows you to fine-tune the retrieval process to obtain the information that is most useful to you.  Ask questions: Now comes the exciting part!You can ask questions about the codebase using the ConversationalRetrievalChain. It will generate comprehensive and context-aware answers for you. Your LLM, being part of the Conversational Chain, takes into account the retrieved code snippets and the conversation history to provide you with detailed and accurate answers.By following this workflow, you'll be able to effectively use LangChain to gain a deeper understanding of code, get context-aware answers to your questions, and even generate code snippets within GitHub repositories. Now, let’s see it in action, step by step.  Step-by-Step GuideLet's dive into the actual implementation.  Acquiring the KeysTo get started, you'll need to register at the respective websites and obtain the API keys for Activeloop, DeepInfra, and OpenAI.  Setting up the Indexer.py fileCreate a Python file, e.g., indexer.py, where you'll index the data. Import the necessary modules and set the API keys as environment variables:import osfrom langchain.document_loaders import TextLoaderfrom langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.vectorstores import DeepLakeos.environ['OPENAI_API_KEY'] = 'YOUR KEY HERE'os.environ['ACTIVELOOP_TOKEN'] = 'YOUR KEY HERE'embeddings = OpenAIEmbeddings(disallowed_special=())Enter fullscreen modeExit fullscreen modeEmbeddings, in plain English, are representations of text that capture the meaning and relatedness of different text strings. They are numerical vectors, or lists of numbers, that are used to measure the similarity or distance between different text inputs.Embeddings are commonly used for various tasks such as search, clustering, recommendations, anomaly detection, diversity measurement, and classification. In search, embeddings help rank the relevance of search results to a query. In clustering, embeddings group similar text strings together.Recommendations leverage embeddings to suggest items with related text strings. Anomaly detection uses embeddings to identify outliers with little relatedness. Diversity measurement involves analyzing the distribution of similarities among text strings. Classification utilizes embeddings to assign text strings to their most similar label.The distance between two embedding vectors indicates how related or similar the corresponding text strings are. Smaller distances suggest high relatedness, while larger distances indicate low relatedness.  Cloning and Indexing the Target RepositoryNext, we’ll clone the Twitter algorithm repository, load, split, and index the documents. You can clone the algorithm from this link.root_dir = './the-algorithm'docs = []for dirpath, dirnames, filenames in os.walk(root_dir):for file in filenames:try:loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')docs.extend(loader.load_and_split())except Exception as e:passEnter fullscreen modeExit fullscreen modeThis code is traversing through a directory and its subdirectories (os.walk(root_dir)). For each file it encounters (filenames), it attempts to perform the following steps:It creates a TextLoader object, specifying the path of the file it is currently processing (os.path.join(dirpath, file)) and setting the encoding to UTF-8.It then calls the load_and_split() method of the TextLoader object, which likely reads the contents of the file, performs some processing or splitting operation, and returns the resulting text data.The obtained text data is then added to an existing list called docs using the extend() method.If any exception occurs during this process, it is caught by the try-except block and simply ignored (pass\).Basically, this code snippet is recursively walking through a directory, loading and splitting text data from files, and adding the resulting data to a list called docs.  Embedding Code SnippetsNext, we use OpenAI embeddings to embed the code snippets. These embeddings are then stored in a VectorStore, which will allow us to perform an efficient similarity search:from langchain.text_splitter import CharacterTextSplittertext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)texts = text_splitter.split_documents(docs)username = ""mikelabs"" # replace with your username from app.activeloop.aidb = DeepLake(dataset_path=f""hub://{username}/twitter-algorithm"", embedding_function=embeddings, public=True) #dataset would be publicly availabledb.add_documents(texts)print(“done”)Enter fullscreen modeExit fullscreen modeThis code imports the CharacterTextSplitter class and initializes an instance of it with a chunk size of 1000 characters and no overlap. It then splits the provided docs into smaller text chunks using the split_documents method and stores them in the texts variable.Next, it sets the username (the one you used to sign up for Activeloop!) and creates a DeepLake instance called db with a dataset path pointing to a publicly available dataset hosted on ""app.activeloop.ai"" under the specified username. The embedding_function handles the embeddings needed.Finally, it adds the texts to the db using the add_documents method, presumably for storage or further processing purposes.  Run the file, then wait a few minutes (it may appear to hang for a bit… usually no more than 5 minutes). Then, on to the next step.  Utilizing dolly-v2-12b to Process and Understand User QueriesNow we set up another Python file, question.py, to use dolly-v2-12b, a language model available in the DeepInfra platform, to process and understand user queries.  Constructing the RetrieverWe construct a retriever using the VectorStore we created earlier.db = DeepLake(dataset_path=""hub://mikelabs/twitter-algorithm"", read_only=True, embedding_function=embeddings) #use your usernameretriever = db.as_retriever()retriever.search_kwargs['distance_metric'] = 'cos'retriever.search_kwargs['fetch_k'] = 100retriever.search_kwargs['maximal_marginal_relevance'] = Trueretriever.search_kwargs['k'] = 10Enter fullscreen modeExit fullscreen modeHere's a breakdown of what the code is doing:The code initializes a DeepLake object called db. It reads the dataset from the path specified as ""hub://mikelabs/twitter-algorithm"". It's worth noting that you need to replace ""mikelabs"" with your own username!The db object is then transformed into a retriever using the as_retriever() method. This step allows us to perform search operations on the data stored in the VectorStore.Several search options are customized by modifying the retriever.search_kwargs dictionary:The distance_metric is set to 'cos', indicating that cosine similarity will be used to measure the similarity between text inputs. Imagine you have two vectors representing different pieces of text, such as sentences or documents. Cosine similarity is a way to measure how similar or related these two pieces of text are.To calculate cosine similarity, we look at the angle between the two vectors. If the vectors are pointing in the same direction or are very close to each other, the cosine similarity will be close to 1. This means that the text pieces are very similar to each other.On the other hand, if the vectors are pointing in opposite directions or are far apart, the cosine similarity will be close to -1. This indicates that the text pieces are very different or dissimilar.A cosine similarity of 0 means that the vectors are perpendicular or at a 90-degree angle to each other. In this case, there is no similarity between the text pieces.In the code above, cosine similarity is used as a measure to compare the similarity between text inputs. It helps determine how closely related two text pieces are. By using cosine similarity, the code can rank and retrieve the top matches that are most similar to a given query.The fetch_k parameter is set to 100, meaning that the retriever will retrieve the top 100 closest matches based on cosine similarity.The maximal_marginal_relevance is set to True, suggesting that the retriever will prioritize diverse results, rather than returning highly similar matches.The k parameter is set to 10, indicating that the retriever will return 10 results for each query.  Building the Conversational ChainWe use the ConversationalRetrievalChain to link the retriever and the language model. This enables our system to process user queries and generate context-aware responses:model = DeepInfra(model_id=""databricks/dolly-v2-12b"")qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)Enter fullscreen modeExit fullscreen modeThe ConversationalRetrievalChain acts as a connection between the retriever and the language model. This connection allows the system to handle user queries and generate responses that are aware of the context.  Asking QuestionsWe can now ask questions about the Twitter algorithm codebase. The answers provided by the ConversationalRetrievalChain are context-aware and directly based on the codebase.questions = [""What does favCountParams do?"", ...]chat_history = []for question in questions:      result = qa({""question"": question, ""chat_history"": chat_history})    chat_history.append((question, result['answer']))    print(f""-> **Question**: {question} \n"")    print(f""**Answer**: {result['answer']} \n"")Enter fullscreen modeExit fullscreen modeHere’s some example questions, taken from the LangChain docs:questions = [""What does favCountParams do?"",""is it Likes + Bookmarks, or not clear from the code?"",""What are the major negative modifiers that lower your linear ranking parameters?"",""How do you get assigned to SimClusters?"",""What is needed to migrate from one SimClusters to another SimClusters?"",""How much do I get boosted within my cluster?"",""How does Heavy ranker work. what are it’s main inputs?"",""How can one influence Heavy ranker?"",""why threads and long tweets do so well on the platform?"",""Are thread and long tweet creators building a following that reacts to only threads?"",""Do you need to follow different strategies to get most followers vs to get most likes and bookmarks per tweet?"",""Content meta data and how it impacts virality (e.g. ALT in images)."",""What are some unexpected fingerprints for spam factors?"",""Is there any difference between company verified checkmarks and blue verified individual checkmarks?"",]Enter fullscreen modeExit fullscreen modeAnd here’s a sample answer that I got back:**Question**: What does favCountParams do? **Answer**: FavCountParams helps count your favorite videos in a way that is friendlier to the video hosting service (i.e., TikTok). For example, it skips counting duplicates and doesn't show recommendations that may not be relevant to you. Enter fullscreen modeExit fullscreen mode  ResourcesHere are some additional resources you might find helpful:Activeloop documentationAIModels.fyi LangChain guidesOpenAI embeddings documentation  ConclusionThroughout this guide, we explored reverse engineering Twitter's recommendation algorithm using LangChain. By leveraging AI capabilities, we save valuable time and effort, replacing manual code examination with automated query responses.LangChain is a powerful tool that revolutionizes code understanding and generation. By using advanced models like VectorStores, Conversational RetrieverChain, and an LLM hosted on a service like DeepInfra, LangChain empowers developers to efficiently analyze code repositories, provide context-aware answers, and generate new code.LangChain's workflow involves indexing the code base, embedding code snippets, processing user queries with language models, and utilizing the Conversational RetrieverChain to retrieve relevant code snippets. By customizing the retriever and building the Conversational Chain, developers can fine-tune the retrieval process for precise results.By following the step-by-step guide, you can leverage LangChain to enhance your code comprehension, obtain context-aware answers, and even generate code snippets within GitHub repositories. LangChain opens up new possibilities for productivity and understanding. What will you build with it? Thanks for reading!Subscribe or follow me on Twitter for more content like this!"
572,"If you had the power to bring any fictional technology into reality, which one would you choose and why? Teleportation, time travel, advanced AI? There's so many to choose from! Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
573,"Do you you get the shakes, sweaty palms, and a racing heart when it's time to present your work in front of others? You're not alone! Let's exchange practical tips, proven techniques, and personal anecdotes that have helped us tame those butterflies and deliver engaging (or at least cohesive) presentations. Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
574,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
575,"I'm a 19 year old CS student in college, and for the past 8 months I've been growing my Tiktok account where I post daily content giving tech beginners tutorials and advice. This is my channel: https://tiktok.com/@ronantechI was wondering if I could get feedback for my channel on:How I can provide more value to my audience?How might this affect my job searching process in the future?How can I start monetizing my account?"
576,"AI has taken over! Everywhere you look there is some new artificial intelligence tool for almost every aspect of our lives. Between ChatGPT, AutoGPT, Midjourney, Dall-E, and GitHub Copilot, you can build, code, get answers, and create beautiful pieces of artwork... or at least some of us can.Why do some people get better results than others when it comes to using generative AI? Why are some people producing pieces of art worthy of the Louvre, while others get something close to a dog's breakfast?It all comes down to the input you use. This input is called a ""prompt"". The prompt is the question you ask, or the words you use to create something. Those who are ""crafting"" prompts or being strategic about their inputs call it ""prompt engineering"".  What is prompt engineering?Prompt engineering refers to specifically designing a prompt in such a way that you receive better results from the AI.Those who are creating AI systems such as OpenAI, Google, and many others, are even hiring ""prompt engineers"" to help train their models. Some ""creators"" have even gone as far as to sell their Midjourney prompts on platforms like Etsy.In short, AI systems are like data: junk in, junk out. If you have a bad input, you'll probably get a bad result. Prompt engineering is heavily influenced by context.  Context when it comes to AIContext is one of the biggest issues when it comes to the results we get. For example, if I Google ""donut"" (or ""doughnut"" 🍩), I could get a whole range of results; from donut recipes, to pictures of donuts, or where to buy this delicious dessert. This is because I haven't given the search engine any other context. Sure Google will use things like my previous search history and my location to help determine the results, but that's as far as it goes.The term ""donuts"" to a search engine could mean anything from the shape, to the Slack plugin, the app, or these tasty GitHub donuts served up at GitHub Universe 2022If for example, I wanted to find a tutorial on creating a 3D model of a donut in Blender, then search results for this probably won't be shown if I only typed in ""donut"". I would need to be much more specific. Something like ""tutorial for donut Blender3D"" would give me much more accurate results for what I was looking for.This is the same when it comes to AI. You need to provide the AI with enough context so you get better results for what you're wanting.  Prompt engineering for chat appsLots of people have shown us some crazy results coming from ChatGPT. Whilst they aren't always accurate, ChatGPT is really good at one thing: prose. It's incredibly amazing at writing good, well constructed sentences, that flow nicely. The results are easy to read and sound really great. But getting accurate responses is another thing entirely. For example, people have tired writing history essays using ChatGPT and whilst the essay may read well, it might not be historically accurate. For example, if you ask ChatGPT to ""write a 2000 word essay on the fall of China"", it will write you a 2000 word essay on the fall of China. But it might not necessarily be factually correct.Whilst something may read well, it might not be factually correct. Hint: I don't have a PhD 😉This is because ChatGPT is taking information from a variety of sources and mashing them together. Those sources might not be accurate themselves. ChatGPT also doesn't know which fall of China you are referring to. Thus it can easily cross reference dates incorrectly. You will achieve much better results by feeding information to ChatGPT in a conversational way and then asking it to write a 2000 word essay.What exactly do I mean by that? Some people think ChatGPT is a one-way, conversational, single input method of obtaining information. But it's not. It's called ""chat"" for a reason. Have a conversation, refine your questions, provide context for your responses.For example, if I wanted a paragraph written about ""NDC Conferences"" for a trip report, I wouldn't start my ChatGPT with ""write me a paragraph trip report for NDC"". Instead, I would start by figuring out how much ChatGPT knows about NDC, providing context along the way. The inputs you provide greatly determine the output. That's why some people are able to get really good results, and others aren't.Without any context, ChatGPT doesn't know what NDC I am referring toAnother example: if you're going for a job interview and you want some tips, asking ChatGPT to ""give me some tips on preparing for a job interview"", will give you some good responses, but it will be far from specific. Instead, something like ""I'm going for a job interview at an AI startup for the position of software developer. Can you please give me some tips on preparing for the job interview?"" will give you much more tailored, personal results. It's the same as if you asked an expert on stage to give an answer to 1000 people in the audience, they'll probably provide something generic so that everyone has a take away message. But if you asked the same person one on one, they'll likely ask you some follow up questions to understand your situation and therefore provide a more personal, specific answer.  Prompt engineering for art appsYou may have seen some of the beautiful artwork some people are creating with stable diffusion apps. And then there's the artwork that just looks 'wrong'. A lot of this comes down to context. For example if I use Night Café (one of my favourite generators), and just type in the word ""dog"" this is what I got:Image generated using Night Café, and the prompt ""dog""There's some random ""dog"" word written as a sign, there's a weird looking dog in the foreground and it's very weirdly colourful. Now if I was imagining a photographic-like image of an adult German Shepherd in a park on a sunny day, that's probably not what I'm going to get. The AI doesn't have that context. It can't read my mind (YET!). When you want to create artwork, you need to describe images as you are picturing them in your head. The more detail you provide, the better the output. This is where it gets tricky. A lot of stable diffusion applications have a limited character count. Thus you need to be meaningful and strategic about how you craft your prompt.Similar to ChatGPT, you need to continuously re-craft your prompts and refine them. Chat based AIs however have the advantage that you can continue the conversation and keep giving the AI more information and different questions in order to get a good response. Whilst some art generators allow you to ""remix"" your output, it still relies on a new prompt. Thus you're continuously waiting for an output, seeing what doesn't add up, and then sending in a new prompt that's been tweaked. Some users spend hours on Midjourney, receiving outputs and recrafting their prompts to produce some staggering pieces. It's all a matter of practice. That's why some creators are selling their prompts on Etsy!Artwork generated by my friend Jean made using MidjourneyOne thing is for sure, if you want to produce some quality artwork, don't expect to spend a few seconds writing a prompt, hitting the ""create"" button and seeing a Monet. Nope! Instead you'll need to put in the time (and money) in order to create hundreds of artworks, reworking your prompts with each iteration in order to produce your masterpiece.  Prompt engineering for codeI'm not going to spend a tonne of time talking about how to craft good prompts for things like GitHub Copilot. My colleague Rizel wrote an amazing blog posts that dives into prompt engineering for GitHub Copilot:A Beginner's Guide to Prompt Engineering with GitHub CopilotRizèl Scarlett for GitHub ・ Apr 3 ・ 10 min read#github#githubcopilot#ai#programmingWhat I will say is that—similar to ChatGPT—GitHub Copilot relies on context. What other code is written in the repository? What is the extension (and therefore language) of the file? What else has GitHub Copilot crafted for you? What comments have you put into the code? All these things will help GitHub Copilot synthesise more accurate code for you.Think about it like this: if you write a comment stating you want to create a complex function that uses backend data and solves a particular problem, you probably aren't going to get a good response with just a single comment. Much like your code—at least it should be—is broken up into many functions, with (hopefully) lots of useful comments, GitHub Copilot works better when you break things down.Instead of asking GitHub Copilot to://reverse a sentence (using JavaScript)Think about how you can break down the problem in a logical sense. For example, if I was physically given a piece of paper with a sentence on it, and told to reverse it, how would I do this? Writing comments like this would be much more beneficial. If you do this, GitHub Copilot has far more context and better understanding of what you want.Another difference that GitHub Copilot has when compared to  something like ChatGPT, is GitHub Copilot takes into account all context you have. All the things I mentioned above:What is the file extensionWhat other files are in the projectHow have you written other commentsHow has other code been constructedWhat is the comment you are inputtingWhat is the code you are inputtingChatGPT and other chat apps give more weight to the last comment that you made to the chat; ie. the last piece of information you added to the conversation. However, GitHub Copilot is always taking into account context to produce better code results.  Better prompt engineeringWhen it comes down to it, getting good results from any kind of generative AI is on you - the person you provides the input. As I said at the start: junk in, junk out. So take into account these important tips when it comes to crafting your prompts:Provide good context; giving examples and information about what you're trying to achieveBe specific; if it's for a certain audience, say thatBreak down the problemBe clear in how you ask your questions. If something comes back that doesn't sound right, clarify itRephrase and refine for your promptsAnd finally, always, always verify the information you receive from an AI. This is less important when it comes to artwork generators, but if you look at code and information it's important. Check to see if the code you receive works how you intend it. Verify the accuracy of written information provided to you.Remember, no matter what happens, YOU are still the pilot. YOU are still in charge, and you have final say on what pieces of art, what code snippets, and what information you use and share."
577,"People need to keep their environment and infrastructure in shape in order to be productive. You might be a farmer who primarily grows corn, but you also must build a pavement between your house and your farm so you can get to work, and mow the lawn next to it so it doesn't grow over. You have to change your lightbulbs if they go out so you find your way home, and maybe take out the trash every once in a while.The situation is similar though a tad bit more complicated for smaller communities — like a group of neighbors on a spot of land, or for the inhabitants of a smaller residential building. Somebody has to mop the floors once in a while, clean the common areas and fix busted fittings.The issues come when we scale things up beyond that — see something like a small village, or a city. In a residential building it's easy to see why it's everybody's problem that the elevator stopped working. In a village however you may find it hard to justify why you should care, that a bench broke at the bus stop when you're only using the train. The village has a lot of people, it's easy for you to hide and shake the responsibility, which you can easily do without caring — until a later time the bench brakes at the train station.At a small software company when the build breaks, or the servers go down you won't just lean back in your chair saying it's not your problem. Come on, there are like three developers, one of those is on holiday. That leaves the two of you, both of your work being blocked. A small company is like a residential building.A large company is however more like a country. In a country when you notice a busted street lamp you won't start fixing it. That's why you pay tax and have specialized teams to deal with these issues.When an ansible playbook that should configure a VM fails somewhere in an automated setup script for tests you cannot just expect a guy from backend development to start fixing it, when he's busy to deliver for a deadline.I saw companies trying to find ways to have developers acquire a ""CI (or) DevOps mindset"" so that they keep track of the whole verification chain, develop it, and also keep track of their changes through the highly complex pipelines and fix it if needed. On top of this, integration and verification pipelines become their own product at large companies due to multi-layered release bureaucracy and the highly complex nature of the products that are being developed.I know that it sounds tempting to imagine that your developers will reach targets effectively and also develop and maintain your verification pipelines at the same time but it's a wild-goose chase.You simply cannot spare specialized DevOps teams. Unless you're fine with your citizens fixing street lamps for themselves with however dingy ways they can manage."
578,"We are back again! In S24E5 of the CodeNewbie Podcast, @saronyitbarek talks about navigating parenthood while pursuing your passion for coding with Phoebe Voong-Fadel, Frontend Developer at the National Foundation for Educational Research.      codenewbie.org    Before entering the world of web development, Phoebe worked for years at various universities in London, while advocating for the use of technology and software to automate repetitive administrative tasks. Apart from her current career at the National Foundation for Educational Research, Phoebe writes articles for freeCodeCamp and mentors early-career developers.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding! We hope you enjoy this season of the CodeNewbie Podcast 💜"
579,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   A Practical Guide To Deploying A Complex, Production Level, Three-Tier Architecture On AWSMulti-tiered architectures have become the most popular ways of designing and building applications in the cloud.In this guide, @kelvinskell helps you design a very fault-tolerant, highly scalable Flask application on AWS using the three-tier architecture design pattern.A Practical Guide To Deploying A Complex, Production Level, Three-tier Architecture On AWSKelvin Onuchukwu ・ Jun 1 ・ 14 min read#aws#devops#cloud#terraform  Dockerfile Optimization using Multistage Builds, Caching, and Lightweight ImagesDocker holds a premier position due to its ability to build, ship, and run applications in isolated environments called containers. @er_dward illustrates these concepts using a Laravel PHP application with Nginx and Yarn.Dockerfile Optimization using Multistage Builds, Caching, and Lightweight imagesInternet Explorer ・ May 30 ・ 6 min read#docker#programming#kubernetes#laravel  Next Level Data Privacy With Easy, Free and Secure Self Hosting at HomeYes, you read that title correctly. Self hosting made: Easy. Free. Secure. With a machine running at your house, not in the cloud – even if you've never done that before. Start from scratch with @maxime1992.Next level data privacy with easy, free and secure self hosting at homeMaxime ・ Jun 3 ・ 16 min read#docker#opensource#selfhosting#privacy  Some Things I Learnt From Working on Big Frontend CodebasesUntil now (May 2023), @noriste had two experiences working on very big front-end (React+TypeScript) codebases: WorkWave RouteManager and the Hasura Console. Here are some issues that pop up in larger codebases that don’t tend to cause as much trouble in smaller ones.Some things I learnt from working on big frontend codebasesStefano Magni ・ Jun 1 ・ 11 min read  Secret To Optimizing SQL Queries - Understand The SQL Execution Order 🚀In this article, @kanani_nirav will teach you how SQL queries are executed by the database engine and how we can use this knowledge to optimize our queries for better performance and accuracy.Secret To Optimizing SQL Queries - Understand The SQL Execution Order 🚀Kanani Nirav ・ Jun 1 ・ 5 min read#sql#optimization#performance#beginners  Networking is Queen! How to DM your way into techGoing from a career in education to a career in tech in one year is no small feat. A lot of this work will come from the one on one time you spend with others. Get started with networking with these tips from @shavonharrisdevNetworking is Queen! How to DM your way into tech.Shavon Harris ・ Jun 3 ・ 3 min read#networking#connections#tech#developer  I think I finally “get” JS ObjectsWhile learning JavaScript, at some point @tigt looked up what “object-oriented” meant. That was a mistake. Here’s how you can get past it and hopefully make JS objects click for you.I think I finally “get” JS objectsTaylor Hunt ・ May 30 ・ 6 min read#javascript#oop#webdev#beginnersThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
580,"Hey folks 👋Hope that y'all all enjoy your weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugCelebrating Pride Month! 🏳️‍🌈 "
581,"If you had the chance to sit down for a conversation with any historical figure, just imagine the insights you could gain. What burning questions would you love to ask them? Step into the time machine of your imagination and kickstart the discussion by sharing your chosen historical figure and the intriguing tech-related queries you would pose to them. Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
582,Would love to know - also include some context on your level +industry if possible!
583,Weird photo. No context. We need your genius to bring this image to life!Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
584,"Hey folks 👋What ya learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Best of luck on your learnings... remember to take breaks and enjoy yourself this weekend!"
585,"The Conclusion of WWDC2023 Keynote: Apple's Unexpected Emphasis on Websites and Web Apps on macOSWith the recent conclusion of the highly anticipated WWDC2023 keynote, the internet is abuzz with discussions about Apple's latest Mac computers, chips, and the innovative Vision Pro. However, amidst all the excitement surrounding these groundbreaking advancements, there's one aspect that seems to have slipped under the radar: Apple's renewed focus on websites and web apps for macOS.Although I haven't had the opportunity to experience it firsthand, the concept certainly piques my interest.Apple had previously introduced web apps on iOS, which garnered significant attention and widespread adoption. However, at some point, Apple seemed to lose momentum and halted progress in this domain. Developers were left in a state of limbo as Apple imposed restrictions on web app functionality and even obscured the ""Add to home screen"" button.Now, with their latest push for macOS, Apple is taking a different approach — one that promises seamless integration without the need for any special configurations or implementations on the part of website owners.On the surface, this approach appears promising, as it eliminates the need for website owners to implement custom solutions to ensure compatibility.However, on the other hand, it raises concerns about relinquishing control over website layout and user interface (UI) and user experience (UX).Naturally, I'm filled with curiosity about this development and eager to explore it further. I'm interested in hearing your thoughts on the matter.Does this announcement resonate with you?Do you find the idea appealing, or does it evoke feelings of apprehension and discontent?Picture by Firmbee.com at Unsplash"
586,"What are your approaches to writing modular and well-structured code, utilizing design patterns, and implementing effective documentation and testing practices to ensure code longevity and ease of maintenance?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
587,"  The new Apple WWDC23 Announcement:  Vision ProYou can control content with your eyes, hands and voice using the Vision ProOver 100 Apple Arcade games on Vision ProSeparate battery pack of the Apple Vision Pro.FaceTime on Vision ProVision Pro features two 4K micro OLED displays and dual drivers with Spatial AudioThe Vision Pro runs on two chips: M2 and R1  iOS 17Apple introduces Standby in iOS 17You no longer have to say ""Hey Siri"" in iOS 17Apple introduces the Journal app in iOS 17You can now leave FaceTime video messages in iOS 17New customizable call screens in iOS 17Live voicemail in iOS 17The first beta of iOS 17 will be available in a few hours  macOS SonomaApple intoduces macOS SonomaYou can now add widgets to your desktop in macOS Sonoma  iPadOS 17Apple brings the customizable Lock Screen to iPadOS 17Apple introduces interactive widgets in iPadOS 17  OtherApple introduces NameDrop, a new way to share contact information when two devices are brought togetherThe new Mac ProApple introduces M2 UltraApple introduces the 15"" MacBook Air"
588,"How well acquainted are you with these methodologies? Have you ever been part of a team that followed these approaches? Share your experiences, insights, and questions. How effective are they, in your opinion, in driving successful projects?Share your thoughts in the comments!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
589,Code optimization and refactoring are crucial for enhancing the efficiency and speed of software. Share your experience of a specific instance where you had to tackle performance issues in code. What steps did you follow to improve it? We're interested to know the outcome of your efforts and any lessons learned along the way.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik
590,"  Remote work is morally wrongIn a recent CNBC interview,  Elon Musk once again threw a controversial point about working from home:The laptop class living in la la land, okay. But as I said, you can’t but look at the cars are people working from home here, of course not. So people were building cars, servicing the cars, building houses, fixing houses, making food making all the things that people consume. It’s messed up to assume that yes they have to go to work but you don’t. I think it’s morally wrong.While I share admiration for Musk's vision, attitude, and execution, I find myself unable to grasp the underlying logic behind this particular statement. It is akin to saying that:  if people were building cars, building a house, marking food, couldn’t afford a Tesla,  but you can, that’s morally wrong.  I am open to hearing an alternative interpretation if you can offer a different perspective.I actually agree with what the interviewer David said: It is a productivity rather than a moral issue. Additionally, even from a productivity standpoint alone,  I think it’s very much a double-edged sword, as Musk himself mentioned twice in the whole interview :Regarding his own trait of being pathologically optimistic.Regarding the potential impact of AI on humanity.As an engineer, we are supposed to be accustomed to thinking to use this double-edged mindset.   While Must is clearly fond of the office, I would like to show the other edge myself.    Love office, in defense of working from homeDuring my time working at Microsoft around 2010, there existed a highly flexible policy regarding remote work. Whenever individuals needed to work from home, a simple email with the subject line ""xxx WFH today"" was all that was required to do. WFH is probably the most memorable abbreviation for me in my Microsoft career, indicating how frequently it happened. 😄 However, I almost never send that email. Not only because I think it’s more productive,  but also because I love to communicate with people face-to-face, particularly with smart guys who share similar objectives. I even make it a habit to visit the office on weekends, hoping to connect with colleagues during those times.  I guess from this perspective, I’m the same as Musk. But the difference is that I do appreciate the benefit of Working from home, which I have observed among my colleagues:The most common scenario is when individuals have tasks or obligations near their homes during the day. By working from home, they save the additional time that would have been spent on commuting, especially when faced with traffic jams.Another case arises when people are not feeling well. If they were unable to work from home, they would likely need to take sick leave instead.There are also instances where individuals need to focus intensely on a task without unexpected interruptions from the office, and working alone at home allows them to achieve that level of concentration.After passively working from home for a very long time during the pandemic time,  I’m even more convinced that I will never choose to work from home if I have the option to go to the office. However, I will always advocate for the freedom and flexibility of working from home as an option for others. You see my point of view. Let’s see another edge of mine. 😄  Never getting back, in defense of the officeDavid Heinemeier Hansson, also known as DHH, may not be a familiar name to you, but it's highly likely that you have come across either the product or the framework he created:   Basecamp and Ruby on Rails.If you have read his renowned books Rework or Remote,  you would be aware of how distinctive his company 37signals is. For instance, they have never sought external funding, and they have operated as a remote company for over 20 years. Just as the company's practices are peculiar, DHH occasionally expresses counterculture opinions on various topics, such as leaving the cloud or Typescript sucks.  Some individuals perceive his recent blog post on remote work to be another example of such opinions:In defense of the officeTLDR, the beginning of the post is:You're never getting me back into an officeDespite being seemingly diametrically opposed to each other, I find myself appreciating the common ground that exists between us. We both defend the preference that diverges from our personal inclination. Let's be real here. The modern world we live in was designed and executed from an office. It's a perfectly legitimate way of working. It may not be your preferred way of working. It sure as hell isn't mine! But let's not make the same mistake of those who couldn't fathom how we at 37signals built a successful, long-term, and prosperous company for twenty years by being remote.  The real problem is that people don’t love their workAs I write here,  I suddenly realize that maybe the problem is not working from home or the office.   Despite the differing opinions held by Musk, DHH, and myself, there is a unifying factor among us all—we share a deep love for our work.  Individuals who possess a genuine love for their work tend to take the initiative to find the most suitable approach within the given circumstances. As for myself, I found that during the pandemic, I ended up working for longer hours from home simply because my bed was conveniently closer to my work desk. 😂Unfortunately, I see a large number of people don’t.  Consequently, I believe the true issue we need to address is to enable more people to pursue work they love. If everyone could approach their work with the same zest as Warren Buffett: Tap Dancing to Work, then the debate between working from home or the office would likely become inconsequential.The ZenSatck open source toolkit we are building aims to help more people to pursue purposeful work they love by leveraging their unique skills and passions.  With the powerful access control layer that supercharges Prisma ORM, it greatly simplifies the efforts of building a secured, extensible, scalable web application.  Nothing would be more exciting for us to see how it enhances your enjoyment of your work. If you find that it does, please don't hesitate to share your experience with us in our GitHub or Join our Discord. Thank you!"
591,🔧 Share your go-to web development tools below and let's dive into the world of coding! 💻✨💬
592,"Hey, devs! Have you ever wondered, what if there was a personality test tailored to determine your perfect coding language? How accurate and reliable would such a test be? Would it consider the specific project domains, industry trends, or future job prospects associated with different programming languages? Would it accurately match our traits with the right language, or would it limit our exploration? Do you believe in the magic of a coding language personality test? (And if so, could you get working on it?) Let the debate begin!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
593,"Next stop, Stranger Things.Stranger Things might be the most dissected and celebrated title sequence around! Let's break it down and see if we can emulate it in most of its glory. It is a 52 second sequence, so I will not recreate it entirely!  TLDRHere is the finished animation.There are toggles to turn on audio and shadows. The shadows are too demanding for Firefox.Give it ❤️❤️❤️ on Codepen!  About the title sequenceHere is a video of the title sequence:The Art of the Title did a fascinating write-up on the title sequence. They interviewed Michelle Doughtery, the Creative Director of Imaginary Forces, who created the title sequence. It is interesting to see the ideas they considered, and how different iterations of the ideas led to the final result.As Michelle points out the title sequence is not shown first, rather it shown after an opening scene from the episode. This gives it more of a stake in the flow of the story.What the Duffers did that was really brilliant was the placement of the title sequence right after a very dramatic moment.  It’s almost the palate cleanser, or moment of breath. I think part of the reason these particular titles feel fresh is because it’s become integral to the storytelling.Also, Vox did a short ""making of"" video of the title sequence that features Michelle also.The motif of the title is quite simple. It is a closeup of the scattered letters of the title slowly been drawn together. It is backed by a moody synth soundtrack produced by Michael Stein and Kyle Dixon. The letters are a kind of a neon red and it all references the style of the 1980s.The font used for the title is ITC Benguiat. The font is free for personal use. Most notably, the font was used on the cover of countless Stephen King novels, which probably contributed to its selection for the title. Some alterations were made to some of the letters to give them a more nuanced appearance.  What we are makingI will focus on the second half of the title sequence, from the 25th second to the end. This is where the vantage point becomes fixed and the title is zoomed in closely, with just a few of the letters in view. It is slowly zooming out to reveal the complete title, while some of the letters that are in offset positions fall into their final positions.Since we need to edit the shapes of some of the letters, we will create a SVG (Scalable Vector Graphic). The alternative is to customize the font, which is licensed, and this is beyond my skillset. So, let's not go there!Maxwell Ridgeway did a 4-part tutorial in Adobe Aftereffects if you want to explore creating this as a video instead.  Preparation of the SVGBelow is a screenshot of the final state of the title.Let's create a basic version of this as a SVG in Inkscape.We want a landscape SVG, a 3:2 aspect ratio would be suitable.On the main menu, select File, then choose Document properties... to open the tab below.Enter 1200 as Width, 800 as Height, and select ""px"" as Units. I picked 1200x800 as it is the most convenient size with the desired aspect ratio. The width and height of the SVG can be changed later without issue.We want a black rectangle that will fill the entire canvas. We add a  rect element. Give it the same width and height as the canvas. The default fill is black.We add a text element for each word. We set the font-family to ""ITC Benguiat"". We want it to be outline text -- so we give it a fill=""none"" and pick a reddish color for the stroke.To get the sizing right, we can try out some font sizes until we have the text cover a good portion of the canvas. Adjust the stroke-width until we get the right thickness, a valud of 4 looks about right to me.We add 3 rect elements for the decorative boxes that surround the text.We want to center our elements vertically and horizontally. To do this, we open the Align and Distribute tab. On the menu, click on Object, then select Align and Distribute... . It opens the tab as per screenshot below.We want to align our text element relative to the page, and center on both axes:Check it that ""Page"" is selected in the dropdown boxIn the Align section, click the ""Align on vertical axis""  button. This is the third button on the first row, as circled in green  in the screenshot above.Now, click the ""Align on horizontal"" button. This is the third  button on the second row, as circled in green in the screenshot above.Below is the SVG markup tidied up. I removed the width and height, I will set this in CSS later. I removed the unnecessary tspan elements and just had a text element to represent each word.<svg viewBox=""0 0 1200 800"" xmlns=""http://www.w3.org/2000/svg""> <rect id=""bg"" x=""0"" y=""0"" width=""1200"" height=""800""/> <rect x=""925.24"" y=""449.54"" width=""168.95"" height=""14"" fill=""none"" stroke=""#a3280e"" stroke-linecap=""round"" stroke-linejoin=""round"" stroke-width=""4""/> <text x=""139.79877"" y=""401.03232"" fill=""#000000"" font-family=""'ITC Benguiat'"" font-size=""160px""  stroke=""#a3280e"" stroke-width=""4"">STRANGER</text> <text x=""293.13965"" y=""536.1662"" font-family=""'ITC Benguiat'"" font-size=""160px"" stroke=""#a3280e"" stroke-width=""4"">THINGS</text> <rect x=""105.81"" y=""263.09"" width=""965.55"" height=""14"" fill=""none"" stroke=""#a3280e"" stroke-linecap=""round"" stroke-linejoin=""round"" stroke-width=""4""/> <rect x=""111.29"" y=""452.78"" width=""168.95"" height=""14"" fill=""none"" stroke=""#a3280e"" stroke-linecap=""round"" stroke-linejoin=""round"" stroke-width=""4""/></svg>Enter fullscreen modeExit fullscreen modeThis is what it looks like:There are changes we need to make to get it to match the original title! Below is the screenshot with the differences highlighted and annotated.We need to change the following:All of the letters are stretched in the title. The 'T' has been made slightly taller than the other letters too.The first and last letters of the word 'STRANGER' are bigger than the rest.Some serifs have been modified. The first 'S' has had some alterations, the 'T' loses the serifs on the top. Also, the back of the 'G' has been flattened.There is some kerning to connect some letters. It looks a bit like magic that the corners vanish!The elements are colored to appear florescent with some areas brighter than others. They are a bit blurry.  Editing the lettersWhat we need to do is convert the text elements to paths. We want a path for each letter.Select the the  2 words (text elements).  You can hold down the [[Shift]] key and click on them both.On the main menu, select Path, and select Object to Path. Now the text elements has become a group (g) of path elements, one path for each letter.We want to ungroup these now, so we can see each path individually. Select the group and right-click, select Ungroup from the context menu. Now select all elements on the canvas, and you should see that each letter is now selectable (they have dotted lines around them), as below.Now, we can manipulate the shape and size of each of the letters. We use the edit path by nodes tool. You can select by hitting the [[N]] key, or selecting it from the tool bar as highlighted below.Now, when you click on a letter, you will see a controls points that you can drag to change the shape of the letter.For stretching the letters, you can select groups of these controls points and move them in a direction. It is easiest to see in this video demonstration. Here I make the letter T thinner, and longer.If you want scale the size up proportionally, like we do with the first 'S', you can change the width and height. However, we want to do it proportionally, so it does not look odd. To do this we must make sure to select the padlock to lock the porportions. See screenshot below for this.Now, when you increase one, the other will grow at a proportional rate with it. You can see me scaling up the 'S' in the video below.To edit the serifs is more finicky. You need to edit the controls points and adjust the curvative of some segements. I hate this part!It takes a while to get it all done. It took me maybe 2 hours to get it the way I liked it as I was identifying the differences and executing them accurately! Accuracy is important here because the text will be zoomed in a lot in the animation. If we are off by a small fraction here or there, it will stick out in a very apparent way! In other situations, you can get away with being less precise.Below is the title with the letters edited.The one thing that is questionable is the joining of letters that overlap. When the 'R' and the 'A' in the word ""Stranger"" come together, the strokes morph together to create an unified shape of the 2 letters.I will do some black magic in the animation to achieve this!  Getting the right colours for the florescent lookWe will need to experiment with gradients to get the colors right.Let's take a letter and see if we can identify a pattern to the colours. Let's look at the first 'S' of the title.Below I circled the areas that have much lighter colours. There are some areas with midtones too.It's not a fixed, predictable pattern if you look at it letter by letter.Let's try to get a color palette from the screenshot to see how many colours we are working with. I took the same cropped screenshot with the big 'S' and uploaded it to https://colordesigner.io/color-palette-from-image to get a color palette for me. See screenshot below.It identifies a 5 colour palette: 4 reddish colours and 1 black colour. I am not seeing a super bright red colour there.I can move the slider to make a palette with more colours. When I move it to 7, I get the result in the screenshot below. I can see that the second last colour looks more like the brightest colour I was expecting.So, I will take one bright (#E05E44) , one midtone (#721209), and one darker red colour (#4A0604) from this palette to make my own minimal palette. I will play with some gradients to see if I can get an organic looking combination of these colours.Maybe it is just me, but I really do not like editing gradients in Inkscape! It feels so clumsy to me. I will do the experimentation myself, and show you the results of the experiments.The first thing is that that my mini color palette does not work. It is too mellow. Bin that!Secondly, I think a radialGradient captures the quality of having brightly illuminated areas better than a linearGradient. A linearGradient works well for letters that are illuminated on particular sides.I experimented with blending modes as well and it did not make any noticeable improvement.Lets see how one of the radial gradients looks on the title. Below is ""radial3"" applied to the entire title.It looks too uniform and it sticks out as a jarring pattern. Maybe, just maybe, if you apply blur and shadows, it looks less harsh. Though, I think using a couple of different gradients would be a better idea.Let's try using both ""radial2"" and ""radial3"" gradients applying them to random elements.Wayy better. It could be brighter and the gradients could be smoother by using more colours.It is easy to get bogged down working on coloring and asthetic tweaks. We can let it be it for now, and improve it further once the animation is complete.  What about adding shadows and blur for that hazy neon vibe?For now, we will just preview the shadows and blur. Why?If you want add drop shadows or blur to elements in SVG, you need to use filters. Filters are expensive to animate.Even though, we will not be changing the values of a filter in our animation, if we move a letter that has a filter applied to it, the CPU/GPU has to do more intensive calculation and rendering. You will find that if you add a filter to an element you are animating, the frame-rate will decrease significantly! We can explore this later when we optimize and polish the animation.I will just do a quick preview to see if we are on the right track and that blur and drop shadow will complete the appearance we are after.This is what it would look like if you add blur of 7.5% to the stroke:And if we add a drop shadow (Filter > Shadows and Glow > Drop Shadow..), it looks like this:Let's do a side-by-side comparison of my version with the original to see how far off I am:It is not too far away! My version needs to have smoother, brighter gradients for sure. The shadows need to be worked on to make it more neon, I probably overdid the blur here.  Version to animateI will take the version without the blur and drop shadow filters. I will go into the SVG markup and add an id to each path and rect, so we can reference them in the animation. Something like this, omitting many attribute and elements for brevity:<svg id=""titleSvg"" viewBox=""0 0 1200 800"">    <!--gradients are here -->    <rect id=""bg"" width=""1200"" height=""800""></rect>    <g id=""title"">        <rect id=""top-box""/>        <path id=""word1-s"" />        <path id=""word1-t"" />        <path id=""word1-r1"" />        <!-- and so on -->    </g></svg>Enter fullscreen modeExit fullscreen modeWe will copy the SVG markup and plop it in our index.html inline.  Animation timeThe central part of the animation is the slow zooming out to reveal the title. This zoom acts like a camera focusing on different parts of the title. We need to move the letters into different starting positions and move them into their final positions in unison. While the animations are all simple transforms, to synchronize the movement in a performant is a ballet.We have 4 parts to the animation that will last 20 seconds:The zooming out of the title - This beings from 0 until 18 seconds.The movement of the letters - The letters are moving from the beginning, but we only see some of the letters when it is zoomed out far enough. All the letters are in place by 14 seconds.The expansion of the decorative boxes - At second 14, the boxes expand. The top box is first with the smaller second and thirds boxes delayed by a few hundreds of a seconds.Slow fade out of the title - The title fades to black over the last 2 seconds of the animation.We will try to tie labels in our animation to make these parts clear in our code.  Part 1: The zooming out of the titleWe 2 broads options, we can use transform: scale() or transform: translateZ(). We want to the zooming to reveal the title at a constant rate, so we want to have a linear easing.  An important difference between the two options is that  transform: scale() is a 2D operation, and  transform: translateZ() is a 3D operation. In theory, transform: translateZ() has the potential to be offloaded more easily to the GPU. This may be better for performance. It is hard to tell if it will in fact be better, since we will be doing another transform on many of the letters. So, let's try to get the same result with both options and see how it works with the other parts of the animation later.  Method 1: Using scale transformationThe tricky thing about scaling is that it behaves like an exponential operation. It's an interesting phenomena that occurs when you animate an object's scale that makes it appear to change speed even with a linear ease. GSAP created an EasePack that includes ExpoScaleEase that compensates by bending the easing curve accordingly. This is the secret sauce for silky-smooth zooming/scaling animations.To include the EasePack in a project, you can use include it as a script in your HTML file (index.html):<html><!--head-->  <body><!--other stuff--><script src=""https://cdnjs.cloudflare.com/ajax/libs/gsap/3.10.4/gsap.min.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/gsap/3.10.4/EasePack.min.js""></script><script src=""main.js""></script> <!--animation code in here --></body></html>Enter fullscreen modeExit fullscreen modeOr you can import it inside main.js as below:// if you have the gsap package locallyimport { gsap } from ""gsap"";import { EasePack } from ""gsap/EasePack"";gsap.registerPlugin(EasePack);// using webpack or rollupimport { gsap, EasePack } from ""gsap/all;gsap.registerPlugin(EasePack);//animation code hereEnter fullscreen modeExit fullscreen modeThe docs for ExpoScaleEase have a very nice explanation with a walk-through of the example below.Let's apply this to our scaling version.let tl = gsap.timeline();tl.fromTo(  ""#titleSvg"",  { scale: 17 },  { duration : 18, scale: 1, ease: ExpoScaleEase.config(17, 1) });Enter fullscreen modeExit fullscreen modeHere, we scale from 17 to 1 over 18 seconds. The config function has the following signature: config( startingScale:Number, endingScale:Number, ease:Ease [optional] ), so we provide our scale values as the first 2 paramaters.Trying this out, it animates how we want to, but it is quite janky!We can review this by turning on the ""Frame Rendering Stats"" in Chrome devtools. You will find this option on the Rendering tab on the very bottom of the devtools, as per screenshot below. I am not a big fan of the layout of the Chrome devtools. Sometimes the bottom pane with additional tabs such as the Rendering tab is not visible. If you don't see this, you must click on the overflow button (3 vertically-aligned dots) in the devtool menu bar, then select the option More Tools, then select Rendering.As you can see below, we are getting 23.4 frames per second. Ideally this bar is totally green. If frames are dropped, then you see red lines. We have a lot of red lines! 🥵Let's see if it makes a difference if we target the title (letters and decorative boxes), rather than the entire SVG!Now, we are getting nearly 60 frames per second (fps). No red lines! 🏆Great, but wait, now the animation starts from the top left corner of the title text. This is because transformations use a transform origin of the top left of a canvas.To fix this, I used the set() method to set the transform origin to be the center of the canvas.I used the to()  method instead of fromTo() for the animation.tl.set(""#title"", { transformOrigin: ""50% 50%"", scale: 17 });tl.to(""#title"", { duration: 18, scale: 1, ease: ExpoScaleEase.config(17, 1) });Enter fullscreen modeExit fullscreen modeNow, we have 60fps (more or less) from the correct starting point.This is the intial state we want to be in, excluding the ""Executive Producer"" credit.And this is what we have:We are zoomed in way too much, and our focal point looks off. Ignore the spacing between letters, we tend to this in the next step. We are just concerned with the scale and focal point for now.Let's try different values for scale to get the right zoom level. Trying some smaller values, 5 looks to be in the ballpark.Now, let's adjust transform-origin to change the focal point. We want to go left a bit, so we will decrease the first number (x-origin). And then, we want to go down a bit, so will increase the second number (y-origin).tl.set(""#title"", { transformOrigin: ""48% 70%"", scale: 5 });tl.to(""#title"", { duration: 18, scale: 1, ease: ExpoScaleEase.config(5, 1) });Enter fullscreen modeExit fullscreen modeThis looks better.In part 2, we may need to tweak the values when we move the initial position of the letters.  Method 2: Using Z translationOne gotcha with using translateZ() is that you cannot do 3D transformations with SVG elements (see StackOverflow question How can I get translateZ to work in svg groups?) . Therefore, we can only perform our translateZ() transformation on the SVG itself.We need to set the perspective property on the parent of the SVG to control the perceived distance of the Z translation. It is preferable to wrap our SVG with a div, rather than have the body as the parent to have more control of the layout. Now, we will animate the z  property of the svg to move the SVG away from the viewer. We set the initial value of z on the SVG to be a positive value, so that it begins close to the viewer. This is JavaScript:tl.set("".wrapper"", {  perspective: 800,});tl.set(""#titleSvg"", {  z: 700,});gsap.to(""#titleSvg"", {  duration: 18,  z: 0,  ease: Power0.easeNone,});Enter fullscreen modeExit fullscreen modeThis works, but it is quite janky! It starts off with a splutter, and then evens out to 35 fps.Hmm, how about the mysterious will-change property?This property gives the browser a heads-up that we will animate a particular property, so it can optimize and possibly push it to the GPU.tl.set(""#titleSvg"", {  z: 700,  willChange: ""transform"",});Enter fullscreen modeExit fullscreen modeAnd this addition gets us to nearly 60 fps.However, we don't want it to move so fast! The linear ease, ease: Power0.easeNone, actually does not yield a constant rate that we want. We are experiencing a similar issue to scale where the easing does not control the progression of the animation in the manner we would hope for.Changing the values of perspective on the wrapper div along with the values of z on the SVG does not make much of a difference. I couldn't hit on the right set of values to get the desired result.Unfortunately, it does seems like a long-shot to get this the way we want with a custom easing and playing with some values!Another issue I noticed is that it looks kind of fuzzy in Firefox at the beginning of the animation! See screenshot below! 🙈Let's park it for now, and use the scale solution with part 2 to see if we can the result we want.  Part 2 - The movement of the lettersWe need to experiment here. The process here is to position the letters offset to their final position, and then start moving them when they come into view.  Outline timelineLet's outline our timeline into tweens! This is what I extrapolated from the title sequence:0.0s -> 8.0s: The letters 'A' and 'N'  of the first word come into view and are moving towards each horizontally.0.2s -> 9.2s: The letter 'I' of the second word come into view at 0.25s, moving in from opposite directions. The 'N' that is in between these letters, is positioned offset below, out of view.1.0s -> 12.0s: The letter 'G' of the first word  and the letter 'G' of the second word start to shift left very slowly. This is subtle and possibly could be skipped. This back of the G's straighten out as they touch the 'N'. I would need to do more work to incorporate this aspect of it.4.0s -> 10.0s : The letter 'R' of the first word comes in from the left. The serif on the leading leg kind of combines with the adjacent 'A'. Some black magic is done there!5.0s -> 10.0s: The letter 'N' of the second word comes in from below.9.0s -> 15.0s : The letter 'T' of the first word drops down from above.9.5s -> 14.0s: The 'H' of the second word. The distances they are positioned outside are equal.10.0s -> 17.0s: The letter 'E' of the first word drops down from above. The letter 'S' of the second word comes from below.11.0s -> 17.0s: The last 'R' of the first word starts shifting left.12.75s -> 17.0s : The 'S' of the first word starts shifting right.  Organize code for the first tweensLet's consider how we do this.We will create a separate timeline for each part. We will name our timeline from part 1 as zoomTimeline.let zoomTimeline = gsap.timeline();zoomTimeline.set(""#title"", { transformOrigin: ""48% 70%"", scale: 5 });zoomTimeline.to(""#title"", {  duration: 18,  scale: 1,  ease: ExpoScaleEase.config(5, 1),});Enter fullscreen modeExit fullscreen modeWe will name our timeline for this part as lettersTimeline.The first letters that come into view are the 'A' and 'N' of the first word. They are coming together. So, we need to reposition the 'A' to the left (negative X translation), and the 'N' to the right (positive X translation).let lettersTimeline = gsap.timeline();lettersTimeline.set(""#word1-a"", { x: -20 });lettersTimelin.set(""#word1-n"", { x: 20 });Enter fullscreen modeExit fullscreen modeIf we comment out the scaleTimeline code, it looks something like this:Now, we need to add an animation to change the value of x to zero.lettersTimeline.to(""#word1-a, #word1-n"", { x: 0, duration: 8 });Enter fullscreen modeExit fullscreen modeNow, we can uncomment the scaleTimeline code and see how it looks.We can adjust the values until we are happy with those 2 letters. We need to move them a bit further apart, x of 30 for #word1-a, and x of -30 for #word1-n looks better.We need to repeat this process for the other letters. It is not complicated, but it takes time and patience.  Positioning all lettersIt might be easier to position all of the letters before we go further. This way, they are out of the way of the others that will animate, one by one. It does not need to exact for now. We will refine the positions when we animate them.I commented out the scaleTimeline and picked some values for each of the letters. This is how I set them initially://first word: STRANGERlettersTimeline.set(""#word1-s"", { x: -150 }); //prob should have same absolute value as #word2-r2lettersTimeline.set(""#word1-t"", { y: -180 }); //prob should be same absolute value as #word2-hlettersTimeline.set(""#word1-r1"", { x: -50 });lettersTimeline.set(""#word1-a"", { x: -20 });lettersTimeline.set(""#word1-n"", { x: 20 });lettersTimeline.set(""#word1-g"", { x: 50 }); //prob should be same value as #word2-glettersTimeline.set(""#word1-e"", { y: -180 });lettersTimeline.set(""#word1-r2"", { x: 150 }); //prob should have same absolute value as #word1-s//second word: THINGS// 'T' is staticlettersTimeline.set(""#word2-h"", { y: 180 }); //prob should be same absolute value as #word1-tlettersTimeline.set(""#word2-i"", { x: -100 });lettersTimeline.set(""#word2-n"", { y: 100 });lettersTimeline.set(""#word2-g"", { x: 50 }); //prob should be same value as #word1-glettersTimeline.set(""#word2-s"", { y: 180 });Enter fullscreen modeExit fullscreen modeThis should be OK to read as the letters are in order they appear!The only thing is, as you can see with comments, the values of some letters should be offset by the same absolute value. For example, for the first 2 letters we animate, we moved the 'A' minus 30 on the X axis, and the 'N' plus 30 on the X axis. They are moved equidistantly.It might make sense to have variables for these values, so we can tweak them later as we are writing each tween.So, this would be it with variables, and without the comments:let batch1Distance = 30;let batch3Distance = 50;let batch6and8Distance = 180;let batch9and10Distance = 150;//first word: STRANGERlettersTimeline.set(""#word1-s"", { x: `-${batch9and10Distance}` });lettersTimeline.set(""#word1-t"", { y: `-${batch6and8Distance}` });lettersTimeline.set(""#word1-r1"", { x: -50 });lettersTimeline.set(""#word1-a"", { x: `-${batch1Distance}` });lettersTimeline.set(""#word1-n"", { x: `${batch1Distance}` });lettersTimeline.set(""#word1-g"", { x: `${batch3Distance}` });lettersTimeline.set(""#word1-e"", { y: -180 });lettersTimeline.set(""#word1-r2"", { x: `${batch9and10Distance}` });//second word: THINGS// 'T' is staticlettersTimeline.set(""#word2-h"", { y: `${batch6and8Distance}` });lettersTimeline.set(""#word2-i"", { x: -130 });lettersTimeline.set(""#word2-n"", { y: 100 });lettersTimeline.set(""#word2-g"", { x: `${batch3Distance}` });lettersTimeline.set(""#word2-s"", { y: 180 });Enter fullscreen modeExit fullscreen modeIt looks something like this zoomed out now!  Second batch and adding labelsLet's do the next letter now. It is the 'I' of the second word.I will use labels to group the tweens to keep track of what I am doing. You can use a label instead of using raw numbers for the position parameter (last parameter) in the .to() function.lettersTimeline  .addLabel(""batch1"", 0)  .addLabel(""batch2"", 0.2)  .to(""#word1-a, #word1-n"", { x: 0, duration: 8 }, ""batch1"")  .to(""#word2-i"", { x: 0, duration: 9 }, ""batch2"");Enter fullscreen modeExit fullscreen modeThis can make it easier to read, if you can come up with good names. I can't in this case!Previously, we did the hard work in using set() to position our letters. The values we need to change for the animaiton are quite straightforward now. We are setting the x or y value to zero, and picking the appropriate duration.The letter is appearing a bit earlier than we'd like, so I decreased the value from -100 to 130, so it comes onscreen at the right time, and amount.Here is the full code for the first 2 batches:  A process for moving through timeline to focus on individual tweensIt can be nice to include a little dashboard to control the timeline, so you can create a shorter feedback loop of the portion of the timeline you are working on. You do not have to do this, but it can make your life easier.Without some controls, you can find yourself commenting out code and using temporary values to hone in on particular portion of the timeline. I can cover this idea in a separate topic another time.A good alternative is to write a bit of code to set the starting point in the timeline. We can create a currentPoint variable to set our interim start point. We use pause() to pause our timelines initially, then use the seek() function to move the timelines to currentPoint, and then use the play() function to start at that point. Something like this:let currentPoint = 1; //in seconds (decimal allowed)let zoomTimeline = gsap.timeline();zoomTimeline.pause();//setting of values and tweenslet lettersTimeline = gsap.timeline();lettersTimeline.pause();//setting of values and tweenszoomTimeline.seek(currentPoint);lettersTimeline.seek(currentPoint);zoomTimeline.play();lettersTimeline.play();Enter fullscreen modeExit fullscreen modeThe above code will start the timelines at the 1 second mark, which is where we want to our third batch to begin. So, adding the code that batch, which is the letter 'R' of the first word, look like this:  Letter batches 4 to 10I won't cover the rest of letters. They are a variation on everything we discussed in the section. I hope that I explained things clearly enough that you could finish this yourself if you had to!  Part 3 - Expansion of the decorative boxesWe can use a scaleX() transformation to expand the boxes horizontally.To determine the direction of the expansion, we set the transformOrigin:If you want it to expand from the center, you can the transformOrigin: 50% 50%. We want the top box to do this.If you want it to expand left to right, you can set transformOrigin: 0% 50%. We want the bottom right box to do this.If you want it to expand right to left, you can set transformOrigin: 100% 50%. We want the bottom left box to do this.The sequence is that the top box expands first, the duration is 1 second. Then, shortly before it is completely expanded, the bottom 2 boxes expand, taking about three quarters of a second. They overlap by about a half a second.The code is below.In this version, the animation runs immediately, but in the final version this sequence runs approximately 15 seconds into the complete title sequence.  Part 4 - Fade outThe final part is the fading out of the title.We will call this timeline --  the visibilityTimeline! Your boy can name things can't he? 🤣To fade out the title is simple, right? We create a tween that sets opacity to zero.let visibilityTimeline = gsap.timeline();visibilityTimeline.to(""#title"", { opacity: 0, duration: 1.5 });Enter fullscreen modeExit fullscreen modeYou can, but there is one extra element that may go unnoticed in this case! There is a vignette effect, it is not a uniform fade. As you can see in the screenshot below, actually the outside of the title becomes darker in a graduated way.We can use a mask containing an ellipse shape to achieve this.What I find easiest to do to find the correct placement and size is to add an ellipse element as the last element to the inline SVG in the page. I give it the attributes: fill=white and opacity=0.5. This way I can see the title underneath.I choose white for the fill because for a mask, white is the transparent part, darker colours are semi-opaque.Now, I try out values for the attributes of the ellipse such as: cx, cy, rx, and ry so that I can get the size and shape the way I want. To give a slightly darker band around the edge of the mask, we add a stroke and use a light grey color to make it slightly opaque.Once we are happy with the outcome, we can remove opacity=""0.5"" from the ellipse and put it inside a mask element. Something like this:<svg>    <defs>        <mask id=""spotReveal"">          <ellipse            fill=""white""            stroke=""#d6d6d6""            cx=""600""            rx=""600""            stroke-width=""80""            ry=""300""            cy=""380""          ></ellipse>        </mask>    <!--our gradients are in here too-->    </defs>    <rect id=""bg"" width=""1200"" height=""800"" />    <g id=""title"" mask=""url(#spotReveal)"">         <!--boxes and letters here-->    </g></svg>Enter fullscreen modeExit fullscreen modeThe id of the mask is used as reference. We apply the mask to the ""title"" group ( g element with an id of ""title) with mask=""url(#spotReveal)"".In the JavaScript, we can animate the ellipse to shrink it in size through scale, and reduce the opacity to create the vignette fadeout effect.To make it easier to visualize the effect of the mask, here is a tween without a 2 second duration. I am not animating opacity in order to show the dimensions of the ellipse clearly.Notice that we set transformOrigin: ""50% 50%"" for the ellipse also. The default transform-origin for SVGs is to start for the top left corner. We want it to scale from the center.Now, let's change the tween to get the result we want. We need change the tween to reduce the opacity to zero to make the entire title fadeout. We need to make the duration shorter too. Now, it looks like this:It is surprising sometimes, how some details can elevate something, and sometimes they may go unappreciated. When you speed some thing up like this it is easy to miss the details!In the final version, this happens 18 seconds into the animation.  Putting it all togetherI noticed a sizeable degradation in performance when I added  the 4 parts together! 😥Since it happened from the beginning, I focused on the first 2 part of the animation to see what the issue could be. That lead me to look at things that were applied from parts 3 and part 4 but were not relevant. I removed the mask used in part 4 from the ""title"" group, and that was the bad guy!We will set the mask on the title only when we need it. In the visibilityTimeline, we can set that attribute when the timeline begins using the onStart property.visibilityTimeline.to(""#spotReveal ellipse"", {  scale: 0.6,  opacity: 0,  duration: 2,  onStart: () => {    document.querySelector(""#title"").setAttribute(""mask"", ""url(#spotReveal)"");  },});Enter fullscreen modeExit fullscreen modeShould I combine the 4 timelines into a single timeline?As a first effort, it is easier to nest timelines within a master timeline. This way we do not need to change our code and we can retain the info we get from the naming.To nest a timeline, you can wrap it in a function, and then call that function in the add() function of the master timeline. This is the skeleton of our code:function part1() {  // scaleTimeline stuff}function part2(){   //letterTimeline stuff}function part3(){   //letterTimeline stuff}function part4(){  //visibilityTimeline stuff}const masterTimeline = gsap.timeline();masterTimeline  .add(part1(), 0)  .add(part2(), 0)  .add(part3(), 15) // call at 15 second mark  .add(part4(), 19);Enter fullscreen modeExit fullscreen modeAnd with some tweaking of the values to get things tighter, this is the outcome:It is pretty good! It can improved in appearance but the performance of the animation is very good. It is averaging approximately 55 fps in Chrome. I recorded the performance in Chrome devtools and it shows that very few frames are dropped. See the red bars on the same line as the word Frames in the screenshot below.Here it is in the Stats Rendering display in Chrome..There are a couple of points that the framerate dips. As above, when a lot of the letters are moving at once is when it dips. This could be reviewed to see if some improvements could be made.It is not quite the same without the synth soundtrack, so next we will add that.  Adding the audioThe accompanying soundtrack complements the sequence really well. I think it is not quite the same without it. Let's add the song to plays in sync with the animation.Initially the song is muted. I added a mute toggle button (a checkbox technically) to the top right corner to enable the song. You will probably need to the unmute toggle and then click the title to restart the animation to hear the audio, this is because some browsers block audio by default that is initiated by a user.It is the same code as I used in the Schitt's Creek title sequence of this series, you can visit the ""Adding audio"" section of that post to learn more.  The spit and polishLet's try to polish it up and make it that extra 5% to 10% better. The top priority is the gradients.  Polish the gradientsThis is the part I hate the most as I find editing gradients in Inkscape to be clumsy!I went through each letter and gave each an individal gradient. I kept the saturation and lightness of the colors high. I looked to use colors that have smoother transitions and use different hues for the more illuminated edges. You can see a side by side comparison of the before and after of this work below.The biggest win is that the jarring pattern is gone. I think using more nuanced gradients gives it a more reflective quality.This took me quite a while to get right! I had to go against my natural inclination to reduce the saturation and lightness of certain colors. It needs to be bright and bold all over with gradual transitions.  Add the black magic morphing of serifsThe second polish we can add is the ""black magic"" that results in the joining of the overlapping serifs of some of the adjacent letters in the first word (R, A, and N).To achieve this I added some black boxes (rect elements) to the SVG and placed them at the point where the letters eventually overlap -- I colored them yellow as per screenshot below for identification.The idea is to initially hide the boxes, and as the letters reach that overlapping point, I will animate them in through the opacity property, or maybe through a scale transformation. I added another timeline for this and you can see it in the final version as the polish function! It does add an extra bit to the final appearance, especially when zoomed out.  Can we add shadows?Using filters to add some shadow, noise, and blur for the glowing neon effect is probably too much of a burden to animate with everything else going. Let's see rather than speculate! I will optimize the SVG and see how close I can get.After optimizing the SVG, I added a ""drop shadow"" filter in Inkscape, again through the menu - choose Filter > Shadows and Glow > Drop Shadow... I added a shadow with a semi-transparent reddish color and a blur radius of 3. This is how it looks:In this version, you can appreciate the joined serifs of the letters of the first word that we achieved earlier!Anyway, I used this version in the animation and I was surprised to find that Chrome can handle it very well and runs at 55 fps. However, Firefox cannot handle it, the animation breaks down really!In the final version, I added a checkbox to toggle the shadow on and off if you want to play with it, and see the degradation of performance in real time.  The final animationFor your convenience, here is the final version again.Give it ❤️❤️❤️ on Codepen!  Wrapping upIt was quite a journey! I am proud that I got the animation to a high level.I learned a few things along the way, which makes it worthwhile. It required a lot of patience to do the detailed work that to elevate it from good to great. I was able to do this by leaving it alone for a few weeks, and then coming back with a fresh head to tackle some tedious parts again.Throughout this series, I have explored if it is possible to do an animation as a CSS animation. In this case, no further investigation is required! It is not possible. We need JavaScript to provide the special easing for the smooth zooming of the title, that is everything that I covered in part 1. There is no way in CSS to provide that kind of interpolated easing to a scale transformation as far as I know.This type of demanding animation demonstrates the upper limits of animating HTML or SVG. If you want more photo-realistic effects for the noisy neon glow of the letters, animating SVG filters is too taxing for the browser to do in unison with other transformations. To make a perfect duplicate of the video, you would need to do the animation with canvas or Web GL. Maybe I can try that another time. Web GL is something I would like to learn.Thanks for reading!You can subscribe to my RSS feed to get my latest articles."
594,"  What are your goals for this week?What are you building? What will be a good result by week's end?Are you attending any events this week? Any suggestions of events to attend?Did you meet your goals last week?I'll start with how I did last week.  Last Week's Goals[✅] Continue Job Search.[❌] Blog. * Spent that time on Photos and cleaning.[✅][❌] Code Challenges/Project work. Minor site updates and a CSS Challenge. No project work.[✅] Process more photos add them to a site.Events[✅] Attend Virtual Coffee(VC) Thursday. [✅] Other VC events if I can. * Attended a CSS Battle and a lunch and learn on React.Attended a couple Zoom and LinkedIn events.[✅] Organize Office. * Background of office is done, reclaimed some space.   This Week's GoalsContinue Job Search.BlogCode Challenges/Project workProcess more photos and add them to a site. This was done last week. Copy and paste is dangerous. So is lack of Caffeine. EventsAttend Virtual Coffee(VC) Thursday.Attend Virtual Coffee(VC) Tuesday. It's 8am my time. It's during school travel time but now that's it's summer, no school so if I'm social enough at 8am I could make it. Other VC events if I can.Attend FrontEnd Test Fest Wednesday.Organize Office: Clean 2nd desk, Which is mainly a LEGO build area.   Your Goals for the weekYou've read my goals so I'll throw that question back to you.What are your goals for the week?-$JarvisScript git pushEnter fullscreen modeExit fullscreen mode"
595,"Open Source is about the community. Whether you have a project or you're looking to make your first PR, we want to help facilitate those connections.   Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! If you're new to open source, and you're not sure where to start, check out our Intro to Open Source course. Finally, consider reading the Best Practices for Maintainers.Just a note to say, we've restarted this post from something Ben was doing for a while :star-struck: Happy coding!"
596,"🔎💻 How do you approach problem-solving in web development? 💡 Let's dive into the world of coding conundrums and unravel the secrets of effective web development solutions together.  Share your strategies, tips, and experiences in the comment section below!  🚀✨"
597,"Let's dive into the topic of data migration and database versioning in coding projects. When it comes to handling these aspects, there are various approaches and best practices. Share your perspective on how you tackle data migration and handle database versioning, considering factors like scalability, data integrity, and minimizing disruptions."
598,"To be honest, I came here by pure luck - an English assignment in my bachelor program - but I stayed because of the community! 😇 I feel like it is a safe space were nerds can be nerds, developers can be developers and anyone can be anyone they want to be. It is just a nice corner of the internet where all sorts of techincal and non-technical matters are discussed in a professional way.So, what do you like most about dev.to? How did you stumble upon it and what was your reason to stay? 🤗Image by Kevin Ku! 🥳"
599,"Today, I ran two quick polls on Twitter (they may still be running) and then reshared them on Reddit (on r/css: initial and follow-up), Mastodon (front-end.social), and LinkedIn (on the HTML5/CSS3 group: initial and follow-up). As I write this article, results are still coming in, so feel free to answer on your favorite social media before continuing.  Poll 1The question is simple: without running the code –that part is essential as if you run it, you'll know the answer immediately and would be cheating–what color is the text inside the <div>? This is the HTML code:<div>Hello World</div>Enter fullscreen modeExit fullscreen modeAnd this is the CSS:div {  color: blue;}div {  color: red !important;}div {  color: green  !  important; /* notice the spacing */}Enter fullscreen modeExit fullscreen modeThere are four possible answers:BlueRedGreenNone of the above (Black)  Poll 2Then, there's a follow-up question... which is genuinely the same question, just changing a little bit the code: without running the code, what color is the text inside the <div>?This time, the HTML code is:<div id=""div"" class=""div"">Hello World</div>Enter fullscreen modeExit fullscreen modeAnd the CSS:#div {  color: blue;}.div {  color: red !important;}div {  color: green   !   important; /* notice the spacing */}Enter fullscreen modeExit fullscreen modeAnd again, there are four possible answers:BlueRedGreenNone of the above (Black)I added the code into two demos, where you can see the answers and a short explanation (don't worry, I'll add both at the end of the article so you don't have to go outside):Poll 1: https://codepen.io/alvaromontoro/pen/VwENJXEPoll 2: https://codepen.io/alvaromontoro/pen/RweOzMvNow I will add a picture to have some space before adding the solutions and explanations, so you can't see a spoiler while looking at the code or thinking about the questions.Photo by Michael Dziedzic on Unsplash............  Answers  Poll 1The text will be Green. If you answered Red, don't worry, you are in good company, as most people answered that color.Why though? Doesn't Red have an !important? Yes, it does, and so does Green. We add the ! delimiter followed by the important keyword to indicate that a declaration is important. But there is no requirement for them to be together! White spaces are allowed between the delimiter and the keyword: !important is the same as ! important. As we have two !important declarations and their rules have the same specificity, the one appearing last prevails: the color will be Green.  Poll 2The text will be Red. If you answered Blue, you went with the most common answer on Twitter.Why though? The id selector is more specific and sets the color to Blue... Right? Wrong! Because the other two rules have important declarations for colors (as explained in the previous section) even when less specific than the id selector. So we look at the relative specificity: .div has a class (1–0) and div is just an element/tag selector (0–1). .div is more specific. Thus the text will be Red.Poster photo by Towfiqu barbhuiya on Unsplash."
600,"If you've been a programmer for more than two years, you're probably familiar with Stack Overflow, a popular online forum where developers can ask and answer questions about programming languages and problems. It's a valuable resource for programmers of all levels, and it's also a source of many jokes about developers who rely too heavily on Stack Overflow answers.I've recently noticed that there is an increasing reliance on ChatGPT, Bard, and other AI platforms among up-and-coming programmers. Could this signal the end of Stack Overflow? Are these new AI tools good replacements for Stack Overflow? Is the idea of relying on a platform for debugging a good one?In conclusion, are AI-generated codes suitable for young developers to add to their codebase without extensive refactoring? I'd love to hear your thoughts."
601,"Memes provide us with laughter, camaraderie, and when they're too relatable, maybe even a few tears. But amidst the ever-evolving landscape of memes, not all of them stand the test of time. But some endure, and will live on forever, and those are the ones we want to celebrate today. So, what's your favorite tech meme that continues to make you chuckle, no matter how many years have passed?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
602,"Let's unravel the mysteries of APIs! This topic often makes an appearance in technical interviews. Can you break down the concept of Application Programming Interfaces (APIs) in simple terms? And, more importantly, share a cool project where you've flexed your coding skills by integrating an API? Newbies and experiences DEVs alike, please weigh in so we can compare notes! How would you answer - or how have you answered - this question during an interview?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
603,"This month, we're celebrating organizations paving the way for LGBTQ2S+ technologists to find inclusion, belonging, and affirmation within our industry.In this post, we shine a spotlight on Out in Tech, a non-profit community of over 45,000 LGBTQ2S+ people in the technology industry (including me, hi 👋🏻). 🏳️‍🌈Out in Tech is on a mission to unite the LGBTQ2S+ tech community. Take it from their mission statement:We envision a tech industry where LGBTQ+ people are empowered, well represented, and have full agency, from intern to CEO. We believe this will lead to:Equity and belonging for all underestimated groups (centering women and people of color);Innovative new ideas, products, and platforms; andA more just future.I've been a member of Out in Tech's active, supportive Slack community for years now. I've seen firsthand the power of the LGBTQ2S+ community coming together to share career opportunities, organize in-person meet-ups, and connect over pop culture, hobbies, and family life.Slack isn't their only virtual community, though! They also offer a digital corps, which is an opportunity to connect and collaborate online to support LGBTQ2S+ organizations with free web services.To support the emerging generation of LGBTQ2S+ technologists, Out in Tech offers a program called Out in Tech U. It includes a mentorship program for LGBTQ2S+ people ages 17–24 to make career connections and learn skills to support them on the job—all in a queer-inclusive, affirming environment.We're glad that organizations like Out in Tech exist to support our LGBTQ2S+ colleagues as they grow their careers in our industry. 💖Know of other great LGBTQ2S+ organizations, initiatives, or groups in tech? Share in the comments and let's continue to build community. 🌈"
604,"""Did you restart it?"" It's a simple yet powerful troubleshooting technique that often works wonders. If only it were always so easy. Yes, we've all had our fair share of hilarious and bizarre moments in - or adjacent to - the world of tech support. So let's swap those stories and have a good laugh. Share the weirdest or funniest tech support or IT-related request you've ever received. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
605,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss a topic sent in by my human colleague @rachelfazio: Hi Sloan! I am wondering what the DEV Community thinks about this article:           ‘The Godfather of AI’ Quits Google and Warns of Danger Ahead - The New York Times                  For half a century, Geoffrey Hinton nurtured the technology at the heart of chatbots like ChatGPT. Now he worries it will cause serious harm.                nytimes.com      What do you make of it when the leadership behind a technology does not support its use?This is a classic conundrum in tech. It reminds me of what happened to Timnit Gebru, too:          Google Researcher Timnit Gebru Says She Was Fired For Paper on AI Bias  - The New York Times                  Timnit Gebru, one of the few Black women in her field, had voiced exasperation over the company’s response to efforts to increase minority hiring.                nytimes.com      So, what do you think? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion like Rachel, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
606,"""Science fiction is the most important literature in the history of the world because it's the history of ideas, the history of our civilization birthing itself."" -Ray BradburyHey, sci-fi fans! Let's talk about sci-fi novels that hit a little too close to reality. You know, the ones that made you go, ""Wait a minute..."" or ""Uh oh."" Share the book that left you shook, where the futuristic world felt just a step away from our own. From dystopias to mind-bending technologies, let's discuss how these stories resonate with our ever-evolving world. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
607,"It's so important to celebrate the achievements of individuals in the tech industry, and diversity and inclusion play a huge role in that. The inspiring stories of queer figures in the tech world can empower and uplift others. Alan Turing, Lynn Conway, and Tim Cook are just a few folks who come to mind when discussing inspiring LGTBQ2S+ folks who have made a positive impact on the tech world.These individuals have seriously shattered barriers, defied stereotypes, and made some major contributions to the tech industry. Their stories are a powerful reminder of why inclusivity matters and how diverse perspectives drive innovation and progress.There are many more names to share, and one of them might be yours! We'd love to hear about the LGBTQ2S+ individuals who've inspired you, whether they're your heroes, colleagues, friends, or even yourself."
608,"Yesterday on our podcast, Africa Mincey discussed her transition from working as an occupational therapist to life as an accessibility engineer with our host, @saronyitbarek! Africa Mincey is a Software Engineer and accessibility specialist specializing in: human-centered full-stack web development, assistive technology and web accessibility, technical writing, content creation, and community building. She uses web development tools to create dynamic and responsive web applications using HTML, CSS, JavaScript, express, mongoDB, and node.JS.If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""From Occupational Therapy to Code"": CodeNewbie Podcast S24E4Rachel Fazio for CodeNewbie ・ May 31 ・ 1 min read#podcast#codenewbie#career#beginners  Here are some things we took away from the episode that we wanted to share with y'all!You do not have to be good at math to be good at coding!Don’t look for a mentor, look for a community. A community can help answer more questions and provide more varied support than just one person! Also, having a group of folks with a common goal, like learning to program, can help you meet your goals faster while bonding more. Before reaching out to someone for the sake of networking, make sure to do your homework! Read up about things that you are curious about so you can ask more succinct and meaningful questions.We all need to be taking stretch breaks at least every hour during work!a. Stretching throughout your workday can help mitigate pain.b. Using a standing desk, or modifying your work setup so you can work while standing can also help you release tension throughout the day. c. In general, try to refrain from allowing your body the opportunity to tense up in certain positions, as it may cause issues in your mobility later in life.If you listened— what are your tips for finding community, taking breaks, or having coffee chats?Send us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
609,"How are you going about expanding your professional network and connecting with fellow techies? Share your go-to strategies newbies venturing into the industry and more sustainable approaches for coders further along in their careers. Shout out your favorite networking events, and don't forget to include any funny stories of unexpected connections. Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
610,"cover image source: GiphyIn the past, I've asked you all to share music from your native country in our Homeland Edition, but this time I wanna do the inverse of that. I'd like everybody to try and highlight music that is not from your homeland. Props to @darkterminal for dropping this comment that got my wheels turning and led me to choose this topic. I really enjoy learning about music from other cultures and am siked to hear y'all's suggestions! Of course, as always, if you wanna share music outside of the prompt, then go for it. 🙌  How we doIn this weekly series, folks can chime in and drop links to whatever it is they've been listening to recently + browse others suggestions. You can follow the suggested genre if you'd like, but don't feel confined to it; you're free to suggest whatever you wanna. 🙌  If you're interested in having other discussions about music, consider following the aptly named #music discussions organization.#music discussionsFollow        Let's talk about #music. 🎶      I'm siked to do some musical globetrotting with y'all.🌍🌏🌎 Note: you can embed a link to your song using the following syntax {% embed https://... %}. This should work for most common platforms!Looking forward to listening to y'all's suggestions! 🎶"
611,"Hey there! Sloan here, your friendly neighborhood DEV Moderator 🦥Welcome back to another edition of Sloan's Inbox, where we tackle all your burning questions and share insightful advice. We're here to support your career development, navigate office politics, stay on top of industry trends, and sharpen those technical skills. So, let's keep the learning and growth going strong!Now, let's dive into our question of the day. This one comes from Secret Candidate 🤫.I'm currently going through the interview process and I'm wondering if it's appropriate to ask my manager for a recommendation. However, I'm unsure whether I should mention that I'm interviewing at other companies. What's your take on this?Ah, the delicate dance of job hunting and professional etiquette. What do you suggest, DEV Community? Please share your insights and experiences in the comments below. Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
612,"In S24E4 of the CodeNewbie Podcast, @saronyitbarek talks about building inclusive web applications with Africa Mincey, Accessibility Engineer!       codenewbie.org    Africa Mincey is a Software Engineer and accessibility specialist specializing in human-centered full-stack web development, assistive technology and web accessibility, technical writing, content creation, and community building. She uses web development tools to create dynamic and responsive web applications using HTML, CSS, JavaScript, Express, MongoDB, and Node.JS. She shares her journey merging therapy and technology on her YouTube channel and blog.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding! We hope you enjoy this season of the CodeNewbie Podcast 💜"
613,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
614,"Notice our fresh new look? 💅🏻💁🏻‍♀️Big thanks to DEV's Content Creator @rachelfazio for designing a new header for #DEVDiscuss!Ok, time for the main event: Our audiences on Twitter and Mastodon selected an excellent discussion topic today, so let's get into it. 😎What's new in ES2023? 👀Jasmin Virdi ・ May 26#javascript#webdev#programming#newsInspired by @jasmin's Top 7 post, tonight’s topic is...what's new in ES2023?!If you're not familiar, updates to ECMAScript for 2023 have been finalized! (Ok, kind of — they're not final until July, but they've reached Stage Four, meaning that they're all-but-certain to be final updates). You can learn more about the updates from TC39's site.  Questions:Which of these updates are you most excited about?Did any of these updates confuse, frustrate, or disappoint you?Are there any updates you were hoping to see this year but didn't?Any triumphs, fails, or other stories you'd like to share on this topic?"
615,"If you've ever come across, you know what I'm talking about. It's really annoying to deal with this type of gradient in SVG.Check out the final codepen or follow the step-by-step process.  Native SVG methodsSVG <path>, as well as other SVG strokes like <polygon> and <polyline>, can only be colored using linearGradient and radialGradient.<!-- Here and below we're using the same pre-defined path --><svg width=""0"" height=""0"" viewBox=""0 0 250 250"">    <defs>        <path id=""gradient-path"" d=""M36.5,91.2C-7.5,185.5,99.3,224.4,170,203.1c55-16.6,57.8-87.4,1.6-104C71,69.5,9.4,207.7,46,228.6c62.7,35.8,189.7-116,133-211""/>    </defs></svg><!-- Coloring the path with native SVG gradient --><svg id=""demo"" viewBox=""0 0 500 250"">    <defs>        <linearGradient id=""linear-grad"">            <stop offset=""0"" stop-color=""#f7ff00""/>            <stop offset=""1"" stop-color=""#db36a4""/>        </linearGradient>        <radialGradient id=""radial-grad"">            <stop offset=""0"" stop-color=""#f7ff00""/>            <stop offset=""1"" stop-color=""#db36a4""/>        </radialGradient>    </defs>    <use xlink:href=""#gradient-path"" stroke=""url(#linear-grad)"" fill=""none"" stroke-width=""15""/>    <use xlink:href=""#gradient-path"" stroke=""url(#radial-grad)"" x=""250"" fill=""none"" stroke-width=""15""/></svg>Enter fullscreen modeExit fullscreen modeWhile both gradient types have lots of settings, the color distribution always follows a straight line.If we want the color to change along the curve, we'll need a help from CSS or JavaScript. It’s a common problem and we have some solutions. Mike Bostock, the creator of d3.js library, has shared this approach. Patrick Cason created a small library based on Mike solution but without d3.js dependency. Other folks have covered more specific cases. For example, Amit Sheen posted about a CSS-only trick to build and animate the gradient along a circular path.   Creating a Gradient with GSAPAs a big fan frequent user of GSAP, I’d also like to contribute.We'll use GSAP and their MotionPathPlugin to distribute <circle> elements along the given <path> and color those circles to compose the gradient.After defining a reference <path> and adding both GSAP files, we create  elements, position them along the path, and apply gradient color to them.<svg viewBox=""0 0 250 250"">    <defs>        <path id=""gradient-path"" d=""M36.5,91.2C-7.5,185.5,99.3,224.4,170,203.1c55-16.6,57.8-87.4,1.6-104C71,69.5,9.4,207.7,46,228.6c62.7,35.8,189.7-116,133-211""/>    </defs>    <g class=""dots"">        // to hold all the circles    </g></svg>Enter fullscreen modeExit fullscreen modeconst strokeWidth = 15;const colors = [""#f7ff00"", ""#db36a4""];const gradientPath = document.querySelector(""#gradient-path"");// const numberOfDots = Math.ceil(gradientPath.getTotalLength() / strokeWidth); // for circles to be placed back-to-backconst dotsDensity = .5 * strokeWidth;const numberOfDots = Math.ceil(dotsDensity * gradientPath.getTotalLength() / strokeWidth);Enter fullscreen modeExit fullscreen modeTo find out the number of circles we can use getTotalLength(). This native JS method retrieves the total length of the path. If we take gradientPath.getTotalLength() / strokeWidth as a number of dots, they stay back to back. By increasing the dotsDensity we can get a smooth line:We create the circles using the native JS appendChild method, and define the circle's position with the motionPath plugin.const dotsGroup = document.querySelector("".dots"");createBasicGradient(dotsGroup);function createBasicGradient(g) {    for (let idx = 0; idx < numberOfDots; idx++) {        const circle = document.createElementNS(""http://www.w3.org/2000/svg"", ""circle"");        g.appendChild(circle);        gsap.set(circle, {            motionPath:                path: gradientPath, // the target path                start: idx / numberOfDots, // the position on target path                end: idx / numberOfDots,            },            attr: {                cx: 0, // the position is defined by transform attribute, so we keep circle center on (0, 0) point                cy: 0,                r: .5 * strokeWidth, // to compose strokeWidth                fill: gsap.utils.interpolate(colors, (idx / numberOfDots)) // linear interpolation between 2 (or more!) given colors            }        });    }}Enter fullscreen modeExit fullscreen mode✏️ Tip #1I use simple linear interpolation between two colors with the GSAP interpolate utility. You can easily add more colors to the colors array, or build a custom function to calculate the color from (idx / numberOfDots) value.We might need to fix the stroke tips, unless we're good with round linecap.There're different ways to do so. For example, we can mask the dots with the original path.<path id=""gradient-path"" d=""M36.5,91.2C-7.5,185.5,99.3,224.4,170,203.1c55-16.6,57.8-87.4,1.6-104C71,69.5,9.4,207.7,46,228.6c62.7,35.8,189.7-116,133-211""/><mask id=""gradient-path-clip"">    <use xlink:href=""#gradient-path"" stroke-width=""15"" fill=""none"" stroke=""white""/></mask>...<g mask=""url(#gradient-path-clip)"" class=""dots""></g>Enter fullscreen modeExit fullscreen modeThe basic gradient along the stroke is done! 😎✏️ Tip #2You can easily replace <circle> with another shape and compose a gradient with rectangles or something else. If doing so, you additionally align the particles along the path:    motionPath: {        ...        align: gradientPath,        alignOrigin: [.5, .5],        ...    }✏️ Tip #3If you're masking the circles with the original path and the path doesn't intersect itself, you can increase the dot radius and decrease the dots density. It's much better for performance.  Advanced techniques  Handling stroke intersectionsLet's say we want our path to look like a proper knot with the stroke going ""under"" itself at the bottom. We can reorder the dots and append the ""back"" dots before others. Then we apply the color and position using remapped index instead the original order.for (let idx = 0; idx < numberOfDots; idx++) {    // append circles in normal order    const circle = document.createElementNS(""http://www.w3.org/2000/svg"", ""circle"");    g.appendChild(circle);    // remap the index to move the some of the back dots to the middle of stroke length    let idxRemapped = idx;    if (idx < .1 * numberOfDots) {        idxRemapped += Math.ceil(.7 * numberOfDots); // [ .0 .. .1 ] to [ .7 .. .8 ]    } else {        if (idx < .8 * numberOfDots) {            idxRemapped -= Math.ceil(.1 * numberOfDots); // [ .1 .. .8 ] to [ .0 .. .7 ]        }    }    // apply position and color using idxRemapped    gsap.set(circle, {        // ...    });}Enter fullscreen modeExit fullscreen modeThe index remapping is specific for particular path but you hopefully got the idea :)  Varying Stroke WidthBuilding dynamic path width is pretty straightforward, we just need to change the dot size according to the index. gsap.set(circle, {    attr: {        // ...        r: .5 * strokeWidth + .02 * idx,    }})Enter fullscreen modeExit fullscreen modeAnd, of course, we can use more fancy function to calculate the dot size.  Animate the gradientGSAP is an animation platform, and the MotionPathPlugin was designed to move things along a path. So, rather than setting the dot position, we can easily animate it. for (let idx = 0; idx < numberOfDots; idx++) {    // create dot and set static attributes like before    const circle = document.createElementNS(""http://www.w3.org/2000/svg"", ""circle"");    g.appendChild(circle);    gsap.set(circle, {        // motionPath: {        //     path: gradientPath,        //     start: idxRemapped / numberOfDots,        //     end: idxRemapped / numberOfDots,        // },        attr: {            cx: 0,            cy: 0,            r: .5 * strokeWidth,            fill: gsap.utils.interpolate(colors, (idxRemapped / numberOfDots))        }    });    // add position-on-path animation    gsap.to(circle, {        motionPath: {            path: gradientPath // position along the path        },        duration: 2, // the time each dot takes to travel the whole path        ease: ""none"",        repeat: -1 // loop the animation    }).progress(idx / numberOfDots); // each dot start moving from their own position}Enter fullscreen modeExit fullscreen modeIt's easy to combine gradient animation with other effects. For some cases you may want to increase the dots density or add masking. And there you have it! 🎉I gathered all the examples on the single codepen, subscribe for updates!"
616,"Did you realize that on DEV you have the ability to embed a call-to-action button? For example, it looks like this:Learn about Community Moderation on DEVWant to know how it's done? I got you covered! 😎  Creating an Embedded CTA ButtonEmbedding a CTA button in your posts is super simple, just use the following Markdown syntax:{% cta link %} description {% endcta %}To be clear, the example embed I created at the top of this article looks like this:{% cta https://dev.to/community-moderation %} Learn about Community Moderation on DEV {% endcta %}This isn't our only available embed... we have plenty others described in our Editor Guide that behave in interesting ways. For instance, here's an embed that points to my profile:Michael TharringtonFollowI'm a friendly, non-dev, cisgender guy from NC who enjoys playing music/making noise, hiking, eating veggies, and hanging out with my best friend/wife + our 3 kitties + 1 greyhound.The syntax for that one is as such:{% embed https://dev.to/michaeltharrington %}  What Might I Use This For? 🤔Loads of things! Maybe you wanna point folks to your personal portfolio or blog. Perhaps you'd like for folks to sign up to your newsletter. Or, maybe you recently released a book and would like for others to check it out. Go for it! These are all valid uses for a CTA button.Just make sure that your description is accurate for whatever it is linking to. Of course, please don't mislead folks or send them to a link that automatically takes action... that won't win you any friends and could result in us unpublishing your content or taking disciplinary action against your account.  That's a WrapIf you have any question about this feature or others, don't hesitate to hit me up in the comments. Now, feel free to embed away and hope ya enjoy your day! 🙌"
617,"Hey all! Lately I have been posting a series of discussion questions to prompt some talk about diversity, equity, and inclusion practices in the workplace. This week, I wanted to discuss finding a job that makes you feel safe and supported.So, when it comes to finding a job that aligns with your values and prioritizes a safe working environment, what are some red flags you look out for? What are some green flags?Join the conversation below and share your tips for identifying organizations that genuinely care about fostering a safe space for their employees. Have a great rest of your day y'all and happy coding!"
618,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   I created 100+ unique CSS patternsIn this post, @afif showcases their library of over 100 unique CSS patterns made by scratch all using the same code structure! Grab a nice pattern and show us the results on your favorite site!I created 100+ unique CSS patterns | The best collection 🤩Temani Afif ・ May 23 ・ 3 min read#showdev#webdev#css#codepen  JWT Authentication in React with react-routerHere, @sanjayttg explores the seamless integration between JWT authentication with React and react-router. Learn how to handle public routes, secure authenticated routes, and utilize the axios library to make API requests with the authentication token.JWT Authentication in React with react-routerSanjay Arya ・ May 28 ・ 10 min read#react#router#token#jwt  Deploy Hugging Face Models on Serverless GPUHugging Face is a platform focused on making AI and data science more accessible. @dhanushreddy29 shows you how to get started on your own by using Serverless GPUs on a Pay-As-You-Go model.Deploy Hugging Face Models on Serverless GPUDhanush Reddy ・ May 28 ・ 7 min read#huggingface#serverless#gpu#machinelearning  What's new in ES2023? 👀Each year, new features are added to ECMAScript, the specification that JavaScript is based on. Following up on last year’s ES2022, @jasmin covers the latest features announced for ES2023 including shebang grammar, array improvements, and a more functional version of sort.What's new in ES2023? 👀Jasmin Virdi ・ May 26 ・ 3 min read#javascript#webdev#programming#news  Future of CSS: Popover API@link2twenty looks at two exciting features coming to CSS and how well they work when paired together. Popover API is awesome on its own, but even better when paired with anchor positioningFuture of CSS: Popover APIAndrew Bone ・ May 23 ・ 5 min read#css#webdev#javascript#ux  Keeping up with my cat's 💩 using a RaspberryPiLike many of us cat owners, @fdocr was shocked at how they’re essentially potty-trained from birth. Equally shocking is the smell that comes with it 🦨. Tech is meant to make our lives easier, so let’s do just that with an IoT solution! Keeping up with my cat's 💩 using a RaspberryPiFernando ・ May 23 ・ 3 min read#raspberrypi#python#automation  A Practical Overview on Architecture Decision Records (ADR)@ctaverna wants to show you how to start writing up ADRs and why this could be your most valuable action as a software architect.A practical overview on Architecture Decision Records (ADR)Claudio Taverna ・ May 26 ・ 8 min read#softwareengineering#webdev#architecture#documentationThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
619,"Hey folks 👋Hope that y'all all enjoy your weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugVisiting with friends 🙌"
620,"Hey, experienced developers! We need your awesome insights to help out newbie coders on their quest to build an impressive coding portfolio.So, how would you go about building a strong showcase of your skills to catch the eye of potential employers? Share your strategies, tips, and success stories to empower and inspire the next generation of developers."
621,"You learned to code and want to start applying for jobs, but don't want anyone to look at your portfolio. Your app functions well, but you're pretty sure your buttons need some styling. Here are some practical tips on how to get from your idea to minimum styling without knowing anything about design.Watch the JSDrops talk!GoalsInspirationLayoutColorsTypographyButtonsLinksPutting It All Together  Goals  1. Looks Like You Thought About ItWe're not aiming for professional designer quality. We're not aiming for perfect. All we want is for a user to think ""They thought about how their page looks.""  2. Reduce Decision FatigueThere are a ton of decisions that go into making a simple webpage. We don't need to be trying to decide on a design while we're coding the page.  3. UniformityYou want to repeat yourself in the design, but not in the code. Even if your button design isn't the best ever, using the same styling every time will look a lot cleaner. When you're programming, you don't want to write new styles every time you add a button. This applies to every element and section of content you use multiple times on your page.  4. Minimize Accessibility IssuesEven beyond colors, a simple design can help reduce accessibility issues and a thoughtful design doesn't introduce new ones.  InspirationIf you have no idea what you want your website to look like, looking at other sites is a good place to start. Don't expect your site to look like professional designs, and stop looking at sites if you start to feel overwhelmed.Check out sites like dribbble, bestwebsite, webdesign inspiration, awwwards, and siteinspire. Keep in mind some of these websites are for designers to share creative ideas, not working websites.You can also usually find curated listicles for the type of project you're making. Here are a few lists of inspirational developer portfolios:https://www.freecodecamp.org/news/15-web-developer-portfolios-to-inspire-you-137fb1743cae/https://alvarotrigo.com/blog/web-developer-portfolio-examples/https://www.hostinger.com/tutorials/web-developer-portfolioMost importantly, make it your own! ""I'm not a designer."" is an excellent excuse for making whatever page your heart desires. I know I had fun with the ""design a 90's page"" assignment in Bootcamp. At the end of the day, if you're happy with your website, and people can use it, that's a great site.  LayoutDesign your app in black and white in a program you already know how to use. We're not designers. We don't need to create wireframes. Pop open a Google Doc or a Keynote slide and start putting boxes on the page.The best place to start is with your sectioning HTML. For example, you'll probably need a header, a footer, and an area in the middle for your main content.Try to break down your content into uniform blocks. Within your main area, think in a grid. That'll be straightforward to translate to CSS grid. Then, use text size, text weight, and spacing to break up your content.  ColorsNow take your boxes and put them in greyscale. You'll want three shades of grey - a background color, main content color, and accent color. In my current Keynote design, the darkest grey is my accent color. I'm using it for my buttons, so they're easily found. The second darkest is my background. The lightest is my primary content color, which I'm using for the header and boxes containing my content.Next, pick three non-grey colors with sufficient contrast. Here are some tools that will help you quickly generate colors with sufficient contrast:https://www.learnui.design/tools/accessible-color-generator.htmlhttps://accessiblepalette.com/https://reasonable.work/colors/If you enjoy picking your own colors, like with coolors, you can use a contrast checker.If the idea of picking colors sounds painful to you but you like math, here are a couple of ways to pick colors with math:https://medium.com/sketch-app-sources/design-cheatsheet-274384775da9#:~:text=3.%20Do%20the%20math%20for%20understanding%20colorshttps://dev.to/madsstoumann/colors-are-math-how-they-match-and-how-to-build-a-color-picker-4ei8If colors and color math are not your cup of tea, you can keep your greyscale! Just check your contrast. If your contrast is too low, users won't be able to read your text. If your contrast is too high, like with black (#000000) and white (#FFFFFF), it'll strain your users' eyes. If you do nothing else with the design of your app, use dark grey (like #333333) for your text and off-white (like #F3F3F3) for your background.  TypographyThe simpler, the better here. People probably won't notice if you use default fonts, but they will notice if you use five. Using different font weights, sizes, and colors instead of different fonts is usually enough. You'll notice larger, higher-contrast font first.Give yourself options with a font family that has plenty of styles like italics, bold, and a handful of weights. Google fonts allows you to filter by number of styles.For accessibility, choose a legible, readable font. Legibility is concerned with uniform stroke weight and good character height and width. The counters, negative space inside the characters, should be fairly open. Readability refers to the spacing of the characters on the page. Don't use all caps or jam all your text into a tight space. Use responsive font sizes instead of pixels, so users can scale up as much as they want. Want to learn more? Check out these articles:https://dev.to/laurilllll/how-to-create-responsive-typography-using-css-three-different-methods-explained-50f8https://www.joshwcomeau.com/css/surprising-truth-about-pixels-and-accessibility/https://creativepro.com/legibility-and-readability-whats-the-difference/https://fonts.google.com/knowledge/readability_and_accessibility/introducing_accessibility_in_typographyFinally, we'll need text colors. I usually end up with two. A darker one for light backgrounds, like my main content color, and a lighter one for dark backgrounds, like my accent color. I check both against the three colors I'm using, and take notes on which combinations have sufficient contrast.  ButtonsButtons are for actions and can be categorized as primary, secondary, and tertiary.Primary buttons are your call to action buttons - things you really want the user to know they can do. For example, submit for a login form.Secondary buttons are for less important actions. They're still easily found, but not as noticeable, like a cancel button for a login form.Tertiary buttons are miscellaneous actions that aren't valuable to most users. They're the least obvious and often styled more like links. A good example is a login button on a signup form.Check out A Trio of Buttons for a Bubbly, Colorful Site for a set of examples.  LinksWhere buttons are for actions, links take you to somewhere else on the site. This is another one where you'd be perfectly fine using the default. If you want to mess with the default link styling, make sure whatever you do is still accessible, and apply it to every link on the page.Remember, in CSS you have 4 link action states.a:linka:visiteda:hovera:activePut them in your stylesheet in this order, or they may override each other.Unlike buttons, you can use a pointer cursor to indicate a link when the user hovers over one.a:hover {  cursor: pointer;}Enter fullscreen modeExit fullscreen mode  Putting It All TogetherNow that we've thought about how the page looks as a whole, the next step is translating that into bite-sized projects and reusable styling. Looking at your beautiful document, think about which boxes appear multiple times. You can start as small as a button. I like to start with a box I'll use on every page, like the header. Styling just the Header component is less overwhelming than styling the whole page. Plus, it involves adding my colors, styles for links, a heading, and maybe even buttons.Use variables and naming conventions that will still be clear and easy to use if you come back to this project months from now. I assign my colors to CSS variables. I'll name my darker text color --dark-text and put my notes on its contrast with other colors in the same file. I use BEM class names, so styles that apply to all my buttons will be in the .button class. I'll use .button--primary for the styles that only apply to primary buttons. For more about organizing your CSS, check out Mozilla Developer Network's guide.This way, I'm able to reuse that work in the rest of the page, and it'll be easier to maintain and modify for features I haven't thought of yet. For example, in my portfolio, I know I'll want a heading, description, screenshot, and link for each of my projects. I'll be able to use the link styles I made for the Header component. If I come back a year later and want to add a button that opens a modal with a walkthrough video, I'll be able to easily find and add my button styles too.When my Project component is ready, I can slap a bunch of Projects inside a container and use CSS grid to arrange the projects within it. Then, my main content section is done.  ConclusionLook, I've just taken a lot of art classes and some college courses for graphic design. I'm the kind of person that adds shiba inu illustrations to her portfolio.I know from experience that staring at a blank page can be very overwhelming. This advice is here to help you break down the work so you can start building. A website is never finished, so you can always redesign, add stuff in, and blog about it!If you're interested in learning more about design, check out The Non-Designers Design Book."
622,"Was it an Easter egg that made you chuckle? 🥚 A hidden gem buried deep in the code? 💎 Or some some truly atrocious lines code? :scared: We want to know! Join the discussion and share the most unusual, unexpected, or downright cringe-worthy moments you've come across while coding. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
623,"Hey Devs, happy Friday 🦥💚First off, a shoutout to my human colleage @rachelfazio for designing a snazzy new header for my weekly discussion post! 🤩Ok, now for the hot topic of the day: I want to discuss...developer portfolios.I got a message in my inbox this week about the importance of building a portfolio when you're applying for jobs:As a beginner dev, do I need to write a blog and have an online presence in order to attain a career in software development? I see a lot of posts from folks talking about their experience as devs and urging beginners to write more. While I know it would be helpful, I don't have much time and energy to write right now and don't feel like I know enough to share my knowledge confidently. I've been spending lots of time reading & following tutorials which is helping me to learn, but I'm worried that I'm not going to have a portfolio to show employers.This question made me think of a recent post from Community Member @abbeyperini about designing your developer portfolio:From Idea to Design for Non-DesignersAbbey Perini ・ May 16 ・ 8 min read#webdev#css#beginners#tutorialIt sure seems like a lot of unpaid work to do...just to get a paying job! At the same time, it's good practice, especially if you're a web developer. So, I'm wondering:If you have landed a dev job with the help of a portfolio, what did you include to stand out? A website, blog posts, something else?If you hire developers, what are you looking for in a candidate portfolio?What do you think? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
624,"Have you ever struggled between feeling burnt out from coding and wondered if it was time for a career change or just a sign of hating your job? 🤔😩If so, how did you identify the cause? And what steps did you take to address it? Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
625,"As a former dog owner and first time cat dad I was amazed at how cats are ""potty trained"" practically from birth. I was prepared to deal with the smell when having to clean the litter box. However, I didn't expect their bowel movements (💩) to carry a punch that would stink up half my apartment. This might not be the case for everyone, but certainly for me, with an indoor cat in a 2 bedroom apartment without a naturally ventilated place to keep her litter box.  The hero/villain of the storyHer name is Dua and she is a cuddly & playful rescue tortie cat. Dua loves to play with her mouse toys and adores wet food, the latter of which is likely the reason I'm writing this post 😵‍💫I have her litter box in my second bathroom's shower. The bathroom has an extractor fan that runs when the bathroom light is on, but she refuses to hasn't figured out how to turn it on and off each time she goes #2... Annoying, right?  Automating the extractor fanTo mitigate the smell I wanted the lights to turn on when Dua goes in her litter box. To do this I put together a few things:RaspberryPi Zero WWiFi support was the goalPIR motion sensorPlaced on the bathroom wall with ""velcro stickers""Smart switch for bathroom lights (any brand will do) paired with an AlexaVoicemonkey webhook to trigger an Alexa routine""Alexa, turn on the switch for 5 minutes""The software that calls the webhook (which in turn triggers the Alexa routine) can be found here:        fdocr       /         pir_trigger            Script that connects a PIR Sensor to a webhook    PIR TriggerScript that connects a PIR Sensor to a webhook.UsageClone the repo in a folder, install dependencies and then run in background# Install requirementspip install -r requirements.txt# Run in background# TODO: Find/Document a better way to do thisTRIGGER_URL=""<webhook_url>"" python main.py &Enter fullscreen modeExit fullscreen modeOtherwise add TRIGGER_URL = ""<webhook_url>"" to an .env file and the script will pick it up.The script writes its own PID to pid.txt so it can be used. Examples:# Follow output of background processtail -f /proc/$(cat pid.txt)/fd/1# Kill processkill -9 $(cat pid.txt)Enter fullscreen modeExit fullscreen modeSensor to board connectionsCable diagram hereThe script was inspired by this Raspberry Pi Foundation article and uses their suggested example layout. The sensor needs 5v (Vcc) and Ground (Gnd), so PIN 2 and PIN 6 work well. Connect the sensor's output (Out) to…View on GitHub  It works!Here's what the hardware looks like in actionRPi and motion sensorAwful quality GIF of our hero/villain  💩 StatsWith all of this in place I went a step further and added Opentelemetry to track the stats of how often the routine was being triggered on Honeycomb.I wanted to know if I was turning on the bathroom lights over false positives from the motion sensor, but after some tests it simply serves the purpose of telling how often she goes in her litter box.Last 7 days 💩 activityLast 24 hours 💩 activity Interestingly, I can tell she goes in her litter box (# of motion sensor triggers) on average ~8.5 times per day. I don't think many cat owners can say they know this about their feline friends. I do remember and took inspiration from Aaron Patterson doing something similar a long time ago though.Anyways, that's it. Pura vida!"
626,"In this series, we shine a spotlight on the different DEV moderators — Trusted Members and Tag Mods — who help to make DEV a kind, helpful place. Aside from spreading good vibes and helping fellow community members, these folks also assist us with removing spam and keeping posts well organized by adding and removing tags as necessary amongst other things.If you want to learn more about what these awesome folks do, I recommend checking out our Trusted Member and Tag Moderation guides. There is information about how to apply in both guides if you're interested in joining up as a moderator.  Introducing Christine Belzie 🙌This month, we're featuring Christine Belzie, who assists us as a Trusted Member and Tag Moderator for #beginners, #opensource, and #writing. Christine's unique pathway into the industry is not as a software developer, but rather a technical writer. Her goals around championing inclusivity and diversity in the open source world very much align with our values here at DEV and make her an excellent addition to our mod team. I had the pleasure of interviewing Christine asynchronously recently and am siked to share it with you all here. Thank you, Christine!Christine Belzie FollowBlogger | Open Source Lover | Coding Hobbyist  The InterviewLet's jump right into my questions and Christine's answers!Michael Tharrington: Can you talk a bit about how you got interested in tech as a non-developer and your goals to become a technical writer for the dev industry?Christine Belzie: A couple of years ago, I was interviewed for an Instructional Designer position for an EdTech company. Everything went pretty smoothly until I was asked if I had a basic knowledge of HTML. I took a deep breath, and told the interviewer “No”. A couple of days later, I received the classic “We went with someone else” email. From there, I found myself seeing more Instructional Design job postings requesting candidates with coding knowledge, so I decided to learn it. I have a blog post that delves more into the story, so I highly recommend reading it when you get the chance. Now, what got me interested in tech writing, in particular, is the fact that I've been doing a lot of blogging about my coding journey and making docs-related contributions to open-source projects in the past year, so I decided to make that my career path.Dev Retro 2022: How I overcame imposter syndrome and found my way into codingChristine Belzie  ・ Jan 14#codenewbie#motivation#writingMichael: I’ve noticed that you like to write about open source! What interests you in open source and are there any particular open source projects that you’re following or would like folks to know about?Christine: Collaboration and inclusivity. When you’re just starting your coding journey, it can be difficult to find a community of people in technology who are supportive and welcoming, and I thank the open-source community for being welcoming and helping me grow in my journey.As far as open-source projects that I follow, I am a huge fan of EddieHub. It was the very first open-source project that I contributed to when I started my open-source journey. They have an emphasis on collaboration before code and are open to people from non-tech and tech backgrounds, so I highly recommend it for beginners.          EddieHub · GitHub                  Community of inclusive Open Source people - Collaboration 1st, Code 2nd! Join our GitHub Org 👇 - EddieHub                github.com      I also love LinksHub. It is a project that my colleague, Rupali Haldiya (@rupali_codes), created to provide resources to help developers from all backgrounds learn new skills. Right now, we’re participating in this year’s GirlScript Summer of Code, so I have been helping people in that program with making their first open-source contributions. Being a maintainer for LinksHub and helping GSSoC members has been a great learning experience for me and has expanded my perspective on open source.        rupali-codes       /         LinksHub            LinksHub aims to provide developers with access to a wide range of free resources and tools that they can use in their work. These resources include links to free software, libraries, frameworks, and other tools that can be used to build and deploy applications and websites.    Welcome to LinksHub 👋LinksHub is a Hub of Links For Developers By Developers. Here, we've gathered a collection of all the best and most useful resources, both free and paid, to aid in the development journey.We recognize that there's a wealth of information available, but often, it's a matter of knowing where to find it. That's why we've made it our mission to bring the right resources to the right developers.Table of ContentsWelcome to LinksHub 👋Demo 💻Tech stack 📚Socials 📱Getting Started 👩‍💻Let's jump right in🌟Want to add your favorite links to the Hub? make sure to follow CONTRIBUTING guidelines.Want to add or update the descriptions of subcategories?Building with Gitpod 💣Top 50 Contributors ✨License 📝Support ⭐Demo 💻You can see the live demo at: https://linkshub.vercel.appTech stack 📚Socials 📱Join LinksHub community…View on GitHubMichael: I saw on Twitter that you list in your bio: “Championing #inclusivity in coding spaces”… Would you please talk about why you believe diversity and representation are so important for us to focus on in the tech industry?Christine: For a long time, I never thought that learning to code was possible because I have never seen women in tech roles. If I had been exposed to organizations like Girls Who Code during my teenage years and college, I would have had more confidence to learn how to code and pursued tech writing earlier. So, I have created Twitter posts acknowledging womxn in tech during Women’s History Month, started Open Source Queens, and maintain an open-source repository that provides links to womxn-founded open-source projects with Amanda Martin (@amandamartindev), so that young womxn won’t experience the same feelings of imposter syndrome as I did.         amandamartin-dev       /         women-led-open-source            This is a living document that can serve as a resource for finding people including those identifying as women, transgender people, nonbinary people, and other underrepresented genders leading open source projects and companies, serving as maintainers, or otherwise supporting Open Source.    IntroductionThis is a living document that can serve as a resource for finding people including those identifying as women, transgender people, nonbinary people, and other underrepresented genders leading open source projects and companies, serving as maintainers, or otherwise supporting Open Source.This resource began in reponse to a discussion post started by Christine Belzie titled Where are all the women owned Open Source projects. In looking for some resources to send Christine, I was unable to find anything thorough or currently maintained and decided to start this project.  It is our hope that this resource will get so large that we will have to find a better solution to hold all the amazing resources.Contributions to this resource are welcome and encouraged.Click on the CONTRIBUTING.md to learn how to submit resources.RepositoriesAlison Gianotto aka ""snipe"" - Snipe-ITbashbunni - Devrel @ Charm and other projects like…View on GitHubMichael How did you first discover DEV and what encouraged you to become a moderator for the community?Christine: I have been trying to find a way to grow my audience on Hashnode and learned that DEV.to is another platform where new tech bloggers post their content, so I decided to join the community. I have learned a lot about repurposing content and working with Markdown through this platform. After a couple of months, I decided to become a moderator because I wanted to give back to the community that helped me grow and help amplify the voices of other bloggers, especially those who are not as well known and come from marginalized backgrounds. Michael: As a fellow non-technical person working in the software dev industry, I occasionally have feelings of imposter syndrome. Do you ever get hit with this same issue and if so, how do you cope?Christine: I have had moments of imposter syndrome, especially when I first started my coding journey. What has ultimately helped me cope with these feelings is adopting Nike’s slogan: 'Just do it!' I know that sounds difficult, but sometimes, you just have to ignore those negative thoughts that swirl in your head. Know that you have skills to offer, and just work.  Wrap upThank y'all for reading. Stay tuned for future mod interviews in this series!"
627,"Have you ever had to boot into single user mode and run fsck?It's a word we often read and write but rarely say.  How would you pronounce it to a co-worker or say it out loud?  So how do you pronounce it?I asked over 30 software engineers and technical operators exactly that question.  Here are a handful of their responses.There are no agreed upon pronunciations, but here are a handful from wikipedia.""F-S-C-K"", ""F-S-check"", ""fizz-check"", ""F-sack"", ""fisk"", ""fizz-k"", ""fishcake"", ""fizik"", ""F-sick"", ""F-sock"", ""F-suck"", ""F-sek"", ""feshk"", the sibilant ""fsk"", ""fix"", ""farsk"", ""fosk"" or ""fusk"".Want to see more tech word pronunciations by tech professionals?  Find them on Youtube.  New videos ship every Friday.  "
628,"Is it mixing incompatible programming languages within the same project? Combining out of date and poorly documented legacy systems with modern technologies? Or trying to debug under deadline while eating powdered donuts? 🍩😢So tell us, what's your worst nightmare? 😱 Cue creepy music.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
629,"We all have unique aspirations and goals for our coding careers, especially when we're just starting out. But it's never too late to dream. So, let's dive into the world of possibilities! What is -- or was -- your idea of an ideal job? And if your idea has changed over time, how so? And what do you want to be when you grow up this time? 😉Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
630,"Are coding bootcamps still effective and relevant in the current tech landscape? Are they viable alternatives to traditional schooling and degrees? Have you personally attended a coding bootcamp? If so, how did it impact your career? Tell us more, and help out our CodeNewbies out there who are weighing the pros and cons.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
631,Time to show off your captioning chops! We need your genius to bring this captivating moment to life!Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
632,"If you had a time machine and could visit any era in the past or future, where would you go? 🌍⏳ And which inventions, innovations, or breakthroughs would you want to witness up close and personal? Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
633,"Hey folks 👋Hope that y'all all enjoy your weekends. Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugDancing like a goof 🕺"
634,"Hello, wonderful DEV community! It's been a month since we kicked off our initiative to bring more animal companions into our midst, and we want to give a shoutout to all those who have already participated. We appreciate your contributions, and the adorable snapshots you shared have certainly brought smiles to our faces!While the response to our new weekly series has been heartwarming, we'd love to see even more of your furry, feathered, and scaly friends gracing our community. After all, there's nothing quite like the charm and joy that animals bring into our lives.By sharing snapshots of your cherished animal friends, you not only make Sloan incredibly happy but also help create a more vibrant and inclusive community for everyone. We can't wait to see what furry, feathery, and scaly adventures await us! 📸🐶🐦🦎And hey, if you do happen to know any sloths looking for a job, please do send them our way. Sloan is patiently waiting to make some new friends who can match their unique pace and personality.Share your beloved animal friend's photo in the comments below and let's make DEV a welcoming haven for all creatures great and small!"
635,I saw this post today and it took me back to my only CS class which was taught using Java.  I'll post my embarrassing final project below 🙈Java turns 28Sendil Kumar ・ May 25 ・ 1 min read#watercoolerNo judgment: share the most embarrassing code you've ever written!Cover image via Unsplash
636,"Restarting something Ben was doing for a while, and we plan on doing this every Friday! Open Source is about the community. Whether you have a project or you're looking to make your first PR.    Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFeel free to drop your issues and repos in the OpenSauced Discord #👀-looking-for-contributors channel at any time! Finally, consider reading the Best Practices for Maintainers.Happy coding!"
637,"If you could choose any animal to be your coding companion, which one would you pick, and why?As many of you know, our mascot is Sloan the three-toed sloth and official DEV moderator! 🦥 Sloan is the perfect mascot because sloths are known for their calm and patient nature, which aligns well with the focused and meticulous approach required in coding. Sloths are also renowned for their adaptability and problem-solving skills. They navigate their environment with ingenuity and find unique solutions to obstacles. And of course, sloths have a sense of community and cooperation. They are known to share trees, collaborate with other sloths, and build social connections. We let the spirit of the sloth guide us on our coding adventures! What about you?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
638,"Happy Pride, all! ❤️ 🧡 💛 💚 💙 💜 🤎 🖤 🤍 💗We’re so inspired by the contributions and engagement within the queer community on DEV. We regularly witness creativity and expertise shining through on posts and active participation under hashtags like #devpride, #pride, #lgbt, #lgbtq, #trans, and #theycoded.Let's keep the incredible momentum going in June for Pride month! Throughout the month of June, we’ll prioritize posts published under the hashtag #devpride and give them the spotlight they deserve.We're committed to showcasing your content using our moderation tools and sharing it across our social media channels. Our goal is to amplify queer voices, provide visibility to queer experiences, and spark important conversations.We’d love to hear stories about how being LGBTQ2S+ has impacted your career as a developer, both in positive and negative ways. We're particularly interested in hearing how you've overcome challenges within the community. Have there been specific jobs, conferences, or experiences that have played a role in your journey? Remember to tag your content with the hashtags that represent you best. Alongside #devpride, you can use #pride, #lgbt, #lgbtq, #trans, and #theycoded. Select one or more that resonate with you!Let's come together and make this initiative a remarkable celebration of inclusivity and empowerment. Your contributions matter, and your expertise can have a profound impact on fellow developers and individuals navigating similar journeys. Share your articles, tutorials, projects, and personal stories using the hashtag #devpride.Thank you for being an integral part of the DEV community. Let's make Pride Month an extraordinary celebration of LGBTQ2S+ excellence, empowerment, and inclusivity. Together, we can create something truly incredible! 🌈🌈🌈💗 The DEV Community Team Note: We kindly ask you to join the discussion with respect and open-mindedness. Every voice matters, so let's make sure everyone feels welcomed and valued. Together, we can build an amazing community where everyone can freely express their thoughts and experiences. Let's create an awesome and inclusive space! "
639,"What do you think guys?Please share your insights, opinions and facts."
640,"Most of us love to stay on top of the latest tech trends, but not every new development gets us excited. VR? AR in everyday life? Cryptocurrency? Self driving cars? 🚗🤖 What's the one tech trend you just can't get behind? Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
641,"Hey there and Happy Friday!My name is Rachel and I am a part of the Forem/DEV/CodeNewbie team. I have been creating this “What I Learned This Week” segment to discuss relevant posts on #codenewbie and/or #beginners that relate to things I have been interested in this week.Side note: if you haven't peeped the CodeNewbie tag or CodeNewbie Team Page, here are those things!#codenewbie Follow        The most supportive community of programmers and people learning to code.      CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.        A Brief IntroductionThis week, I wanted to discuss Large Learning Models (LLMs) with some extra content sprinkled in about code refactoring tools and learning to code! Needless to say, I have been reading a lot of posts lately about AI developments (and related controversy) and I thought that it was high time for me to learn a lot more about how these systems actually function. Note: While we are here, I would also love to call attention to our incredible Guidelines for AI-assisted Articles on DEV to read more into DEV's policies on AI.Let’s talk through some posts that helped me understand these concepts and maybe they can help you too!  Large Learning ModelsLet's begin with an article that helped to give me my base knowledge of the capabilities of LLMs. @wesen states, ""This article is mostly directed at programmers among my readers: we are at a pivotal moment where we programmers need to understand and appropriate these technologies, on our own terms, before capitalism does it for us.”LLMs will fundamentally change software engineeringManuel Odendahl ・ Mar 23 ・ 23 min read#programming#ai#productivityThis article by @shanshaji also helped me to understand how I can write prompts for LLMs so that I am more likely to get better results from their software.Writing Effective Prompts for Large Language Models: Two Prompting Principles and Their Related TacticsShan for Arkroot ・ May 19 ・ 4 min read#chatgpt#prompt#beginners#programming@jarrodhroberson 's TLDR speaks for itself, “I tried to get ChatGPT 3.5 and 4 as well as Bard to increase my productivity. I wasted 6 hours of my life proving what I already knew from just reading the docs on where they got their training on ""writing code""; StackOverflow.”I ""did my own research"" and ""AI"" is not taking my job any time soon.Jarrod Roberson ・ May 16 ・ 7 min read#programming#beginners#productivity  Code Refactoring ToolsIn this article by @surajondev, they explain some tools to improve the quality and maintainability of your code. Confession— I did not initially know what a code refactoring tool was. However, now I am here to tell you that I learned that they can help save you time and effort, and prevent errors in code! Who doesn't want that?5 Code Refactoring Tools to Boost Development EfficiencySuraj Vishwakarma for Documatic ・ May 20 ・ 4 min read#javascript#beginners#programming#codequality  Learning to CodeI also loved this article by @wynandpieters, as they take you through their coding education AND offer a great opportunity for you to share yours.How I Would Learn To Code (If I Could Start Over)Wynand Pieters ・ May 15 ・ 4 min read#beginners#programming#discuss#careerAnd with that, that is all I have for y'all today! If you have even more information to share on any of these topics, feel free to drop some information below!Happy coding y’all and have a great weekend."
642,"Welcome to ""Single Digit"" Spotlight, a selection of articles published within the last week that have fewer than 10 total reactions (at the time of the post's publishing).The goal is to highlight posts published on DEV that haven't yet received the attention they may deserve 🌱Hope you enjoy!C++23: Even more constexprSandor Dargo ・ May 24 ・ 6 min read#cpp#cpp23#constexpr#compiletimeThe Art of the CFP: Getting Your Session AcceptedBrian Rinaldi ・ May 22 ・ 7 min read#careerView Transition APIDaniel Schulz ・ May 26 ・ 5 min read#css#frontend#webdev#animationHow To Measure Your Server's Round-trip Time In Remix (React)Peter Mbanugo ・ May 26 ・ 3 min read#react#javascript#typescript#webdevStart programming blog in minutes with Astro and VriteArek Nawo ・ May 23 ・ 9 min read#webdev#opensource#astro#javascriptAccessibility labels for content loading in ReactAntonin J. (they/them) ・ May 22 ・ 2 min read#react#web#a11yUnlocking GitHub Codespaces for WorkshopsBen Greenberg ・ May 22 ・ 8 min read#tutorial#github#blockchain  Shout out to @sandordargo, @remotesynth, @iamschulz, @pmbanugo, @areknawo, @bengreenberg, and @antjanus.Image by DilokaStudio on Freepik"
643,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎How to Come Back From BurnoutHenry Boisdequin ・ May 19#mentalhealth#learning#coding#beginnersInspired by @hb's Top 7 post, tonight’s topic is...recovering from burnout 😮‍💨🔥Burnout is tough. When you are burnt out from something, you resent it, and don't want touch it again. This unhealthy relationship with that thing only decreases your productivity and your mental health.  Questions:Have you ever experienced burnout in your coding career?If so, how did you recover?If not, how have you kept yourself protected from burnout?Any triumphs, fails, or other stories you'd like to share on this topic?"
644,"Looking for some new ideas for tasty, filling, and keyboard-friendly snacks?Share the meals and tasty treats that keep you fueled through deadlines and long nights of coding (or gaming!) and bonus points if you've found a way to keep your keyboard clean!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
645,"As a new coder, finding the right employer fit is crucial for a fulfilling and successful career. To ensure compatibility and alignment with your professional goals, it's important to ask targeted questions during the interview process. Let's kick off the discussion by sharing the key questions new coders should ask to find the perfect match with potential employers. From company culture to growth opportunities, let's explore the critical factors that contribute to a successful coding journey.TBH: these questions are applicable and beneficial at any stage of our careers!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
646,Finding the time to make meaningful contributions (like making time for open-source contributions!) while juggling professional commitments can be a real challenge. How do you strike a balance between personal passion projects and the demands of your day jobs?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik
647,"Hello. How's the job search going? What's your search process?   Don't get discouraged, keep applyingI am starting to get replies to my applications! I'd estimate only about 5% of my applications got replies. I used to get so discouraged by rejection emails but I started realizing it's just inevitably part of the process. You have to accept the majority of jobs you apply to will be rejections. But the more you apply to, the better odds you have of getting a reply.  My processHere is the process I've been using for finding a job. Got any tips or advice? What do you do differently?  Mornings and afternoons:Apply to jobs every day online on LinkedInReply ASAP to any requests to interview or other incoming opportunities, within 24 hours ideallyWrite follow up emails to all interviews you have, thanking them for their time and asking for next steps in the interview processPrep for interviews by having notes such as these:Introduction you plan to giveWhy you're a good fit for the jobA list of questions prepared to askPractice interview questions on LeetCode  Nights:Work on side projectsPublish updates to side projects on LinkedIn dailyAnother thing I did recently was write an article on Dev.to. If you stumble across a tip or technique you think others might find helpful while working on your side projects, write an article about it. For example, I wrote an article on how to clear the VSCode terminal whenever you save.What's your process been like?"
648,Java turned 28 this week! My favourite 28 features in Java as it turns 28Sendil Kumar ・ May 25 ・ 5 min read#javaWhat are your most (or least) favourite thing about #java?
649,"Landing your first tech job is an exciting adventure, and nailing your cover letter is key to making a strong impression. But how can you tailor your cover letter to showcase your coding skills and boost your chances of success? Let's dive into this discussion and share our best tips and tricks for crafting a killer cover letter that shines the spotlight on your coding prowess.Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
650,"Hey there! It's your friendly neighborhood DEV Moderator, Sloan. 🦥 Welcome back to my cozy little corner of the tech universe! Here was can discuss all things tech-related, from those tricky career dilemmas to the ins and outs of office dynamics, and everything in between. As a sloth who appreciates the laid-back approach to life, I'm here to offer you some wise advice, share my slothful observations, and foster a warm and supportive community of eager learners and seasoned professionals.So, let's dive into the question of the week:I recently got approached to work on a big project that kind of goes against my personal values. Should I turn down the opportunity and risk losing the respect of my colleagues -- or worse, my job? Or should I just try to separate my beliefs from my professional work?  So, DEV Community: What's your take on this? Please leave your thoughts in the comments below and let's help a fellow coder work through the pros and cons of this dilemma.Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
651,Choosing a coding mentor is a crucial decision for any aspiring programmer. What if you had to make a trade-off between a mentor who possesses exceptional programming skills but struggles with communication and a mentor who excels in conveying ideas but has average programming abilities? It's a dilemma many experienced coders have faced. Which type of mentor would you prefer and why? Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      
652,"Hey peeps 👋Hope that everybody has a wonderful weekend. 🙌Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugTaking a joyride! 🏍"
653,"When working on any platform or with any tool, finding out about shortcuts that make your life easier saves you not only time, but also makes you a better engineer. In this blog, I am sharing with you 5 built-in features on GitHub that I absolutely love! Actually, that’s not true. When myself and Christopher Harrison kicked off this YouTube episode I planned for 5, but got carried away. So below, find 7 awesome GitHub shortcuts that will make your life easier as an engineer: Edit your code quickly using the GitHub web editor. When I am working on a project and I need to quickly open a web editor to make changes to a README or other document, I use the web editor. It saves the time of opening a project for a quick change, or even if you’re not able to open up and work from your default machine (or in my case, my laptop seizes up and I can’t open Visual Studio Code). Quickly search for any file in your repo. I struggle to find files in larger, more complex projects. Being able to search for files easily, and effectively, even when you misspell something.  I can access the files I need, fast.  Even better knowing that GitHub code search is now generally available!Highlight code snippets to create an issue or share with your team. So often you share  changes that are made to a file, then have to give reference as to where those changes were made, that takes time, and causes disruption and loss of focus. Being able to highlight the code that I want to share, easy and fast. It also really helps me when I need to create an issue for something in my existing code base.Link your pull requests with your Issues. Traceability and communication are two of the many components that build high performing engineering teams. While this is a simple feature, it ensures that you have traceability from your Issues to your pull requests, as well as continuing that communication and keeping your teams up-to-date. Linking a pull request to an issue is a simple feature, but one that I use every day. Comment on Pull Requests in-line and add suggestions. Another game changer for myself and my team. Previously, when commenting on a pull request, you would have to hunt for the comments and find them. Often that took up too much time, especially if you wanted to make suggestions or changes to someone else’s code. Being able to make a suggestion in the codebase and easily accept the change AND add it to your pull request makes code reviews so much easier and faster. Create saved replies to save time on comments. When work is repetitive little tricks like this enable you to save just a few minutes when commenting on PRs and projects. I like to add my favorite phrases using saved replies and emojis to respond to folks on my teams. Bonus: Trigger a GitHub Action workflow when you close a PR. While this is just a trigger mechanism, I put this workflow into almost all of my GitHub repositories. This is my clean up task, I use the built in automation of GitHub Actions to delete any deployed cloud resources, confirm my PR is closed when a branch merges, etc. I am basically cleaning up after myself. GitHub is more than just a source control system, it’s a whole platform of tools to help engineers plan, write, deploy and manage their applications. GitHub has evolved over the last few years at an amazing rate. To help, GitHub’s Enterprise Advocates have started a new series: GitHub in My Day Job, hosted by April Edwards and Christopher Harrison. While these episodes run live, giving you the opportunity to ask questions, each episode is also available on demand for you to watch later and quickly navigate to the content that matters most to you. We hope that we can share our knowledge with you, the community. Please feel free to share feedback on topics that you would like to see us cover!Further Learning: Watch the full episodeGitHub in My Day Job on YouTubeGitHub Blog"
654,"In Season 24, Episode 3 of CodeNewbie Podcast, @saronyitbarek talks about the importance of adding accessibility in our coding toolkits with Daniel Devesa Derksen-Staat, iOS Engineer in the Accessibility team at Spotify.      codenewbie.org    Dani has his dream job as an iOS engineer on Spotify's amazing Accessibility team. He has previously loved working at Skyscanner and the BBC, where he learned a ton about how to make iOS apps more accessible. Sometimes he lets Xcode have a break and spreads the love for accessibility at conferences. Author of the “Developing Accessible iOS Apps” book, he keeps himself busy by writing a daily tweet about accessibility and iOS with the hashtag #365DaysIOSAccessibility.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding! We hope you enjoy this season of the CodeNewbie Podcast 💜"
655,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   How to Come Back From BurnoutBurnout is tough. It’s easy to build a pattern of avoidance around what you’re burnt out on. This unhealthy relationship only makes work harder, so take these tips from @hb to bounce back easier than ever before.How to Come Back From BurnoutHenry Boisdequin ・ May 19 ・ 5 min read#mentalhealth#learning#coding#beginners  From Idea to Design for Non-DesignersYour apps are functional, but they’re eye-meltingly plain. Familiar story? Here are some practical tips from @abbeyperini on how to get from your idea to minimum styling without knowing anything about design.From Idea to Design for Non-DesignersAbbey Perini ・ May 16 ・ 8 min read#webdev#css#beginners#tutorial  The Key to Completing Projects: Mastering the Art of Planning 🗝️Your projects are left unfinished not because of your technical abilities, but because you haven't learned how to plan properly. It’s time to silence that inner critic with some tips from @jimmymcbride.The Key to Completing Projects: Mastering the Art of Planning 🗝️Jimmy McBride ・ May 17 ・ 4 min read#tutorial#productivity#career#codenewbie  How I Built an Event Ticketing System With Next.js and FirebaseAfter excessive procrastination, @arshadayvid decided to improve his developer portfolio by building real-world projects that stand out from the job-hunting pool. Then, he came up with an idea, an event ticketing system.How I built an event ticketing system with Next.js and FirebaseDavid Asaolu ・ May 16 ・ 14 min read#react#javascript#nextjs#programming  Better Blogging on Dev.to With Vrite – Headless CMS for Technical ContentWith technical writing becoming increasingly popular, it’s interesting that the tooling in this niche is still lacking. That’s why @areknawo built Vrite, a new kind of headless CMS meant specifically for technical writing while still keeping the needs of developers in mind.Better blogging on Dev.to with Vrite - headless CMS for technical contentArek Nawo ・ May 19 ・ 10 min read#opensource#webdev#writing#productivity  React Reconciliation: How It Works and Why Should We CareYou might think you know everything about how React renders components, but the universe will find a way to surprise you. Let’s take apart the mini-mystery of how React renders components conditionally with @adevnadia.React reconciliation: how it works and why should we careNadia Makarevich ・ May 18 ・ 18 min read#react#webdev#tutorial#javascript  Chat With Your CSV: Visualize Your Data With Langchain and StreamlitLarge language models (LLMs) have become increasingly powerful and capable. In this example, @ngonidzashe shows you how to use Langchain to analyze CSV files. You can upload a CSV file and ask questions about the data. The system will then generate answers, even going as far as drawing tables and graphs.Chat with your CSV: Visualize Your Data with Langchain and StreamlitNgonidzashe Nzenze ・ May 17 ・ 7 min read#python#chatgpt#openai#datascienceThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
656,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
657,"Hey hey!CodeNewbie Podcast is coming out with a new episode tomorrow with Daniel Devesa Derksen-Staats about his route to a career in accessibility, making code more accessible, and the importance of adding accessibility into our coding tool kits.Here is our link to where you can await the new episode, or  you can find it wherever you listen to your podcasts tomorrow!      codenewbie.org    Accessibility is important in product development because it advocates for the creation of products that can be used by people of all abilities. There are a huge amount of tools to help test accessibility across different platforms for a range of abilities, whether they be related to vision, hearing, cognition, speech, and/or mobility. While creating a product that meets accessibility guidelines, we must continually test different frameworks through a variety of resources to create the most inclusive design.So, my question for you all is: what resources, websites, books, and other tools have you used to test and improve the accessibility of your products?"
658,"We all know that staying relevant in the ever-changing tech landscape is essential. So, here's the question: Do you think pursuing continuing education or specialized certifications is necessary to enhance your skills and boost your marketability? Share your thoughts and experiences in this discussion! Let's explore the value of ongoing learning in our coding journey and uncover whether it's worth the investment. Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
659,"Coding languages receive their names from a variety of sources, such as:Inventor's NameDescriptive NamesAcronymsInspiration from Existing LanguagesHistorical or Cultural ReferencesFunctional DescriptionsUnravelling the stories behind coding languages is fun!  It unveils the human stories, ignites curiosity, and adds an another dash of creativity and playfulness to the world of coding. In your opinion, what's the coolest coding language moniker of all time? Why?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
660,"When it comes to writing code, readability and understandability are crucial for collaboration and maintainability. We all strive to make our code accessible to other developers, but the question is: what steps do you personally take to ensure your code communicates effectively? Share your insights, strategies, and best practices for crafting code that speaks clearly and fosters collaboration. Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
661,"Coders rely on collaboration and assistance from various individuals within their organization to succeed. These key collaborators contribute to their productivity and the quality of their work. So who supports coders in getting their job done at your organization? After this enlightening discussion, you'll have a clear list of who deserves that extra-large cup of coffee, a box of donuts, and maybe even a ""World's Best Collaborator"" trophy! Time to give kudos and caffeinate those who support your coding adventures.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
662,"We don't write tests because we don't have time.How many times have you heard that? Or maybe you said it yourself? I know you did, we all do at some point.The thing is, you should probably also know it's not a valid reason. The time you usually spend manually testing your code (for example, by running the app and clicking around), in addition to all the time spent in fixing bugs, is way more than the time you'd spend writing the tests.Oh, imagine one day you have to edit again that part of the code, you forgot what a specific method does and a tiny change causes a bug that the client will find a week later. Great, you now have an angry client and you're also in a hurry to fix it.Still not having time to write tests?  Copilot ChatOne of the coolest features of Copilot Chat, one of the tools in the Copilot X suite, is the ability to generate unit tests for you. You just need to select a block of code and ask Copilot to write the tests for you.Cool, it will make you and me save so much time!But... is it reliable? Let's find out.  Points of attentionYeah sure, in a single click, you have a bunch of tests written for you. But you should pay attention to some details.I'll further explore the following topics in the video:Copilot tries to guess the logic of your code - If it's right, it will help you find bugs. Is it wrong? Well, you'll have a bunch of tests that don't make sense.Copilot doesn't know what you're testing - It will generate tests for the code you selected, but it doesn't know what you're trying to test. In some cases might be more noise than signal.Copilot doesn't know your business logic - If you wrote code that actually makes sense, Copilot will generate tests that make sense. But what if your business logic is not what the client asked? The generated tests will validate the wrong logic.The scope is limited to the selected code - If in the method you're trying to test you're calling other methods in other files, Copilot doesn't know what's inside and will try to guess.  DemoIf you're curious and you want to see it in action, check out the video below:I might sound boring at this point, but the closing chapter of all of my Copilot/AI posts is pretty much always the same.These are incredibly amazing tools, they speed up our work a lot giving us more time to deliver quality products and more value to our clients, BUT, we should always be careful, eyes open, and make sure we understand what we're doing and what the tools are doing for us.Will I use it to generate tests? Probably yes. Will I use the generated tests as they are? Probably not.What do you think? Let me know!Thanks for reading this article, I hope you found it interesting!I recently launched my Discord server to talk about Open Source and Web Development, feel free to join: https://discord.gg/bqwyEa6We6Do you like my content? You might consider subscribing to my YouTube channel! It means a lot to me ❤️You can find it here:Feel free to follow me to get notified when new articles are out ;)Leonardo MontiniFollowI talk about Open Source, GitHub, and Web Development. I also run a YouTube channel called DevLeonardo, see you there!"
663,"Remote work has become increasingly popular, especially after the COVID-19 pandemic forced many companies to adopt it as the norm. However, while many people dream of the flexibility and freedom that comes with remote work, the reality can be quite different.As a junior Javascript developer who has been working remotely for a Hungarian company while living in Denmark, I have experienced the dark side of remote work. Important note, that I was the only one in the team, who worked from home.Expectations vs. RealityLike many people, I had always dreamed of working from home. I imagined working in my pajamas, sipping coffee from my favorite mug, and taking breaks to relax in a library or a cozy cafe. However, the reality of working remotely was quite different. I found myself spending 24/7 at home, doing everything from work to household chores, playing with my child, and watching movies with my husband. While I love our home, not being able to work from other places was hard. I tried working from a cafe or library, but the uncomfortable chairs and unreliable internet connection made it less than ideal.LonelinessOne of the biggest challenges I faced with remote work was loneliness. While I appreciated the peace and quiet of working from home, I found myself missing the collegues and social interaction that comes with working in an office. My breaks were spent alone, and even though I tried to connect with colleagues through messaging apps, it was not the same as face-to-face interaction. Lack of Routine and BurnoutAnother major challenge was the lack of routine. Working from home meant that my workday was not clearly defined. While I had a morning routine with my family, my workday was spent sitting in front of a computer without any breaks or chit-chat. I found myself mentally exhausted and almost burned out from the constant focus on work without any meaningful breaks. Even when I tried using the Pomodoro technique, I found myself either postponing breaks or doing household chores instead of relaxing.ConclusionWorking remotely can be a great option for many people, but it is not without its challenges. While the flexibility and freedom are certainly attractive, the lack of routine, social interaction, and burnout can take a toll on mental health. As a remote worker, it is important to find ways to stay connected with colleagues, create a routine, and take meaningful breaks to avoid burnout.Unfortunately, I struggled to establish a routine and take breaks, which led to mental exhaustion and burnout. As a result, I realized that a hybrid work model, where I can work from the office on some days and from home on others, would be a better fit for me personally. This would allow me to have the benefits of remote work while also providing opportunities for social interaction and structure in my workday. What is your experience with remote work? Have you experienced any challenges with it, and how have you overcome them?"
664,Can you come up with the wittiest caption to explain what's happening here?
665,Lots of folks gather up mementos from the good ol' days to bring back those nostalgic vibes and keep a strong link to their own history. Some common examples of nostalgia-inducing items that people collect include:Vintage toys and gamesVinyl records and cassette tapesRetro technologyPop culture memorabiliaBooks and comicsSo what's in your nostalgia collection?
666,"Heyo 👋What ya learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Keep on keeping on, you'll get there! And when you do, make sure to celebrate. 🙌"
667,"Let's have a little fun today!Start by posting a movie quote from a science fiction film:I must not fear. Fear is the mind-killer.Others guess the movie and reply with the correct answer:DUNE.The person who guessed correctly posts a new movie quote for others to guess:There is no Dana, there is only Zuul.Okay, who's next?Image by Freepik"
668,"Dear senior front-end developers,You've been in the industry for a while, and you've gained a lot of experience and knowledge along the way. What advice would you give to junior developers who are just starting out? How can they improve their skills and become better developers? What are some common mistakes you see junior developers make, and how can they avoid them? Share your thoughts and insights to help the next generation of front-end developers succeed.Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
669,"As allies and colleagues, what can we do to show active support and advocacy in the workplace? Share your ideas on creating an inclusive environment, offering support, and amplifying queer voices. We kindly ask you to join the discussion with kindness, respect, and open-mindedness. Every voice matters, so let's make sure everyone feels welcomed and valued. Together, we can build an amazing community where everyone can freely express their thoughts and experiences. Let's create an awesome and inclusive space! ❤️ Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
670,"""Last Week's News"" is your platform to share and discuss the most captivating tech stories from the past week. We want to hear from you! Whether it's groundbreaking advancements, game-changing innovations, mind-boggling discoveries, or just plain weird information, this is your chance to contribute to the conversation. Drop the links, share your insights, and join fellow tech enthusiasts in exploring the vibrant landscape of the tech world. Don't miss out on the stories that piqued your interest and be part of the discussion in ""Last Week's News""!Image by kstudio on Freepik"
671,"Hello Dev,I'm new here. This is my story...I teach college algebra. It’s a gig I took as a stop-gap measure to get myself past a rough patch in my music career. Spoiler alert — that didn’t work out. I’m still teaching college algebra, nearly seven years on.For most of my adult life I’ve made a living as a full-time children’s songwriter, performer, and teaching artist. I still perform at libraries during the summer, and I have several CDs out. They’re pretty good. I’m on Spotify if you want to look me up.I’ve also always wanted to be an author, and teaching has given me time to complete three middle-grade novels. I’ve been hoping this would become my creative salvation. I could get published, be a full-time writer, quit teaching, and make music on the side.But authorship is a long and arduous journey. And teaching as an adjunct instructor has become my dead-end, low-pay, no-benefits, no-job-security albatross — it’s not a career. With neither music nor writing poised to take over any time soon, a neutron-star-sized clump of dread formed in my stomach when it came time to sign up for yet one more semester of college algebra this coming Fall. I felt stuck and depressed and desperate for change.Desperate enough to start poking around, even though I couldn’t imagine a better option that wouldn’t require expensive education or years of prior experience. You can, though, right?What I discovered seemed way too good to be true! First of all, you need to know that all my non-music, non-writing projects over the years — anything I’ve done for fun or contemplated turning into some kind of business — from my high school years through to the pandemic — all those projects involved some kind of coding. I just never realized I was developing job-worthy skills that could lead to a fun, creative, high-earning career! I might even be able to work from home. With a bit of training I could potentially start job hunting within a few months! What?!? Is this for real? Pinch, pinch.After a few days of giddy research, I jumped on board. I signed up for Udacity’s iOS Development course on April 22, 2023.I’m writing this one month later from the eye of an information hurricane. I’ve been completely obsessed! All that I’ve encountered in the wonderland of tech, even including all the hurdles and frustrations (of which there are many), leaves me convinced I’ve dropped myself into the right place. Simultaneously, I’m terrified I’ve made a huge mistake. Maybe I’m too old for this. Maybe I don’t have what it takes. Maybe it is all too good to be true. Maybe I’m chasing an unattainable dream.Doesn’t matter. If all I acquire is the ability to complete a few personal projects, it’ll be worth it. One thing on my to-make list is a calendar for my elderly mom. She has a brain disease that leaves her unable to comprehend time, which gives her constant anxiety. None of the dementia calendars out there have helped, and they all work on the same principal. My idea is different. Maybe it’ll work better for her. When I get discouraged, I picture my mom using an iPad, running my calendar app. For now, that project is my North Star. I have until mid August to get as far as I can before algebra instruction reclaims my time for another semester.And I want that tech career, so I’m going all in. As I understand it, that means social media / blogging / learning in public. So here I am ready to give it my best!What does it take for a fifty-something-year-old children’s musician to snag a new career in tech? Give me a follow. Let’s find out together!"
672,"Hey devs! Time for another installment in our Best Practices for Writing on DEV series. Today I'll share some guidelines for choosing and framing your topic.  TopicsWe created DEV because we wanted to build a community around the things we all do and love: software development, computer engineering, life in the tech industry, and dreaming big about the possibilities of tech and open source. We welcome posts about a wide variety of topics that intersect these core subjects. We love tutorials, discussion prompts, conference recaps, and personal stories. We love reading about what you’re building, and we love when you host your docs updates and changelogs on DEV! We even love a good listicle every once in a while, as long as it’s packed with value and personal insight.Are you allowed to write about other things on DEV? Totally! We have plenty of great articles about writing, lived experiences that intersect the industry, and one pretty good one about Moose Facts. But you’ll have the best chance at growing your readership and having meaningful discussions on DEV if you’re mostly writing about dev and tech industry stuff, most of the time.  TagsThere are two main ways to interact with tags on DEV: as an author and as a reader.  Making the most of tags as an authorWhen you write a post on DEV, you can add up to four tags to help readers find your content. Some tags on DEV are active communities, such as #CodeNewbie and #BrazilianDevs. We also have supported and moderated tags for programming languages, frameworks and tools, different types of discussions, and more. Before tagging your content, take a look at each tag page to make sure you’re picking the right vibe—that gives you the best chance of connecting with your intended readers!  Making the most of tags as a readerYou can find posts on the topics you’re interested in using tags. Follow the tags you want to prioritize in your feed and set your tag weights to fine-tune your experience.We’re always looking for more DEV Community members to volunteer to become tag moderators! Tag mods are essential to keeping our tags organized, on-topic, and engaging.Learn more about becoming a tag moderator:Make a Difference on DEV as a Tag ModeratorSloan the DEV Moderator for The DEV Team ・ Apr 7 ・ 2 min read#meta#community#moderation#learning  Bring a unique perspectiveNo matter what topic you’re writing about, you’re most likely to reach readers and make an impact if you bring a unique perspective to the topic.For example, let’s say you want to write a tutorial explaining how to use promises and async/await in Javascript. There are already a lot of articles on DEV that explain this concept in depth (like this favorite of ours by @lydiahallie!), so if you write a basic explainer, you’re not likely to get a lot of readers’ attention.You might consider a different approach: bringing in your own experience and perspective. Here are some prompts to help guide you:How did you learn this concept? If you learned by experimenting and making mistakes, share the story with your readers.How have you seen the concept implemented in real-life applications? Consider writing about interesting, edge case, or so-strange-it-just-might-work approaches you’ve seen in the wild.How might you approach this topic differently based on a unique use case? Are there any extended metaphors or analogies you could use to explain the concept in a fresh way?Technical writing is a great tool for learning concepts yourself, and blogs are great proof of your learning journey. If you’re interested in building community, growing your audience, and improving your technical writing skills, consider the above prompts next time you approach writing a basic tutorial!  Provide a clear takeawayReaders visit posts on DEV for a variety of reasons: to learn something new, to get informed on industry trends, to check the docs for their favorite OS project, to share stories and build community, or even to quickly copy-paste some code and never look back. In all of these cases, though, readers are looking for one thing in common: a clear takeaway.Once you’ve identified the one, two, or three main takeaways from your post, consider stating them clearly in both the introduction and the conclusion. This is a common public speaking technique: “Tell them what you’re going to tell them, tell them, and then tell them what you told them.”If your post has more than three main takeaways, consider breaking it down into multiple posts and creating a series!  ConclusionWhen it comes to writing on DEV, make the most of your topic of choice by using tags, bringing a unique perspective, and providing a clear takeaway! Of course, you are welcome to write whatever and however you want on DEV, as long as it adheres to our Code of Conduct — these guidelines are meant to help you make the most of the DEV platform by improving your content writing skills and connecting with your readers.That's all for now! Stay tuned for another installment in this series all about self-promotional posts on DEV."
673,"  TL;DR - But I already knew that ...I tried to get ChatGPT 3.5 and 4 as well as Bard to increase my productivity. I wasted 6 hours of my life proving what I already knew from just reading the docs on where they got their training on ""writing code""; StackOverflow.  Yeah, all three failed every test they claim they can do:Unless you 100% plagiarize Stack Overflow in your daily job or you exclusively write ""ToDo"" apps or other strawman tutorial apps you have nothing to worry about.I recently wrote a Go implementation of CUID2 because I could not find an existing one. It is not hello-world, but it is not duff's device either, which by the way neither could explain what it did from just the raw code in isolation. CUID2 is non-trivial but nothing that someone with the most basic understanding of how to read JavaScript should be able to port just reading the code of the original implementation. There is a Java version as well. And as a former Java main, that was useful to confirm I was interpreting the JavaScript code correctly.So after seeing the 1000th article on every tech and non-technical blogging site about how every programmer is now just counting their days until they will be out of a job, I decided to prove what I already knew; they were all written by people that had absolutely zero comprehension about what they were writing about and were probably using Chat GPT to create the drivel themselves by asking it to write their articles for them, otherwise why would they all sound like paraphrased copies of each other?First you need to understand why nothing based on the technology that these things are based on is not replacing anyone that creates anything original, because it can not create anything original. The creators of say this themselves.This is how they work; at best they regurgitate back what they have consumed with the same context but worded differently based on how you ask them to word it, at worst they just vomit up nonsense out of context that sounds like it makes sense because the human reading it has zero critical thinking, reading comprehension skill or instructed it to phrase the response as a confirmation bias fallacy.And even in the best of cases, what they are ""paraphrasing"" has at best a less than 50% chance of being 100% factually correct unless the prompt is engineered to where it is just flat out plagiarizing source material that just happens to be factually correct.That is because the Large Language Model (LLM) is trained on the entirety of the internet. And at least 99% of the internet is just opinion and misinformation and that last 1%, well it is mostly opinion and misinformation because 100% of the internet was written by humans. It is also by design, unable to produce deterministic output.How can you rely on information to be factually correct, if every time you ask the exact same question you get different answers. Sometimes wildly different and/or contradictory.Now consider that ChatGPT and Bard were both trained primarily on StackOverflow, you can understand why my experiments were 100% a waste of time.StackOverflow is the last place you go to find accurate code to do anything unless you know how to do it already yourself. It is a bastion if misinformation from almost the last 20 years. The only information that is remotely reliable, is the upvoted accepted answers from the first 2 or 3 years of its existence. After that, the signal to noise ratio of the actual experts to the dunning/kruger ""experts"" became inverted to the point that objectively incorrect answers were upvoted by orders of magnitudes sometimes because the voters did not understand why what they were upvoting was incorrect and why the correct answer was correct. It is the largest repository of evidence that the dunning/kruger syndrome is real you can find anywhere on the internet.Neither ChatGPT nor Bard mention anything about vetting of the information they were trained on other than some guardrails about not generating ""abusive"" content, that are less guardrails and more like gossamer strands that exist only for plausible deniability legal protection.It claims to be able to perform the following tasks:Code completionCode lintingCode refactoringCode generationCode translationSo I tried each one of those tasks, both systems failed miserably at each one of them.  Code completionUseless without prompting what all the previous code exactly was, and even then it still insisted on offering names of variables, functions, methods, classes, etc that did not exist in the code I was asking it to complete. This is because it is just matching against other code it has read, if I have to feed it all my previous code and tell it to only consider that code, I have already spent more time than just typing it out myself. Granted, this would likely preform better in the context of an IDE, but guess what, Jetbrains IDE did for years before ""AI"" was all the rage and I never needed to doubt it.  Code lintingThis falls under the same category as completion, this has been done for decades without ""AI"" and deterministically. I found that it failed, as in false positives in edge cases than it could possibly save time in any edge cases than a non-""AI"" linter might have trouble with.  RefactoringFailed spectacularly. In every case I asked it to refactor things, At best code it spit out code that would not compile or at worse, it compiled and ran but had very subtle bugs being introduced because it was using some source of incorrect code it was trained on verbatim. This is the problem with no vetting. I was able to use the non-""AI"" Google search and find some of the incorrect code it offered up, just by searching on it in """". In all of the cases where I got an exact match; it was a StackOverflow question or answer or both that contained the code snippet. This because both systems keep the comments when they spit out the code, that is how you can tell something was verbatim.  GenerationThis is the one thing that got more correct than incorrect. if you ask it to generate code that a non-""AI"" code generator would produce. But in every case I could get it to work, a non-""AI"" tool already exists that does exactly the thing. And For example, given some JSON generate a struct in Go that represents the JSON, and generate functions Marshal and Unmarshal it. This is pretty much just a self trained ""structural search and replace"" like Jetbrains IDEs have had for a while.I still struggled to get it to produce code that compiled reliably to the point that by the time I had a prompt that would reliably generate compliable code I could have just written it myself, much less used an online JSON to struct generator.Both systems failed with asked to generate code that it had not been trained on generating. IE, something that was not a Gang Of Four pattern or some other well documented and already written generator. So, novel things that did not exist was just meaningless code salad.They would just give up or they would generate gibberish. I would ask for Go, Rust or Erlang and would get Python or JavaScript in some cases, because nothing existed for it to plagiarize/paraphrase already in the requested language.And that brings us to translation.  TranslationWow, these were epic fails. I used the CUID2 JavaScript code and it just flat out refused to translate the entire source code file in one go to anything but TypeScript. Really? It could only translate ""correctly"" to a language that was a super-set of the original language.Then I spent way too much time engineering a extremely complicated prompt to ""force"" it to translate it to Go and the results were, well, failure.It would include packages that had nothing to do with the code it had translated, it would leave out package that it did use, it would just leave out entire blocks of logic without mentioning that it threw away anything.I tried feeding it one block of the source code at a time in the order it needed, like in old school ""structured C"". Declarations, then functions based on the reverse order of use. Functions that relied on other functions last and the ones with no dependencies first. It still silently left out the same chunks of logic from the individual functions.I spent more time on trying to get this to work than anything else because this had the promise of providing the biggest productivity gains. The only things I could get it to translate from an arbitrary source language to an arbitrary destination language were extremely basic things; loops, iterators, list reversals, struct definitions, etc. that it probably found in some Rosetta stone type site or repo in its training set.Sometimes it generate comments in the output without being asked, and they had typos and other human looking errors. Which tells me it was just plagiarizing. Sometimes when you asked it to generate comments it would mix in comments that were correct, but obviously from another language because of the idiomatic terminology it used was native to some other language. I saw comments in translated Rust code that was obviously from Python and Java even though the source I asked it to translate was neither.*This was the biggest waste of time out of the entire exercise.*Anyone that tries to say that this technology has made programmers obsolete, or will replace them or will revolutionize programmers lives and productivity are the ones that are more likely going to be replaced by it. Because they are generating the same out of context misinformation drivel that it creates."
674,"🎵🎧 What's your ultimate ""coding anthem"" or theme song that takes your productivity to new heights? Share the musical magic that gets you in the coding zone and let's create the ultimate developer playlist together! 🎶💻Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by kjpargeter on Freepik"
675,Got any coding project ideas that are totally out of the box? Share your wildest and most unconventional project concept that you've been itching to bring to life but haven't had the chance yet. Let's inspire each other with our creative and unconventional ideas!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      
676,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org!"
677,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...how new leadership will affect Twitter and the broader tech industry.On Friday, May 12, 2023, Elon Musk announced that Linda Yaccarino would become CEO of Twitter, and that he would continue to focus on ""product, software, and sysops.""          Elon Musk names Linda Yaccarino as new Twitter CEO, says she'll focus on 'business operations' | AP News                  Elon Musk names Linda Yaccarino as new Twitter CEO, says she'll focus on 'business operations.'                apnews.com      We've learned over the past year that changes to Twitter are never just changes to Twitter—they have ripple effects across the entire tech industry, from Tesla's stock valuation to the emergence of new platforms such as Bluesky.So, what do you think is next? Share your thoughts in the comments and let's discuss!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
678,"Attending conferences and events not only offers a chance to expand knowledge but also provides networking opportunities with like-minded individuals. I am interested in knowing if anybody can share some cool experiences and insights for what to look out for in the upcoming year. If you have any information regarding notable IT events in Latin America, I would greatly appreciate your input, thanks!."
679,"I recently updated my portfolio. You can see it at ChristopherleeJarvis.com. I used a Dopefolio template from Ram Maheshwari in this post. The big decision was what projects to add?  What interactive things to add? I picked a couple web sites, a few projects,  my blog, and some case studies of things I built or helped build.How many interactive things need to go up to show that it works?If you are in a position to hire, do you check developer's projects or their read code? How many projects do you actually touch?"
680,"Let's have some coding fun! If programming languages were transformed into ice cream flavors, which flavors would you associate with each language and what attributes or characteristics make them a perfect match? For example: If Ruby were transformed into an ice cream flavor, it might be a delightful blend of rich and smooth dark chocolate with a hint of raspberry swirl. This flavor choice represents Ruby's elegant and expressive nature, like the indulgent sweetness of chocolate combined with the vibrant and tangy essence of raspberry. 🍧Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
681,"Hey new coders, we all know that the right work environment can greatly impact our learning and development. Let's discuss the qualities we appreciate in a supportive and nurturing workplace. What kind of atmosphere, team dynamics, or management style do you believe can help us flourish as new coders? Join the conversation!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
682,"Hey there, awesome community! It's your slothful host, Sloan, swinging back into action with another edition of Sloan's Inbox. 🦥 Your never-ending stream of questions and boundless enthusiasm never fail to bring a smile to my face! Thanks to an extra intriguing question from a newbie developer, I'm here once again, and I'm counting on all of you to lend your valuable insights and advice. So, let's gather 'round and embark on this knowledge-sharing adventure. Together, we'll make this developer journey a slow and steady success. Let's get the conversation started!Today's question is:I need advice on the best starting point for my learning journey. What should I prioritize learning first? And can you give me some effective study techniques and strategies to make the knowledge stick in my head? Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
683,"What coding-related communities or forums do you engage with, and how have they contributed to your coding journey? Share the platforms you find valuable and discuss the benefits you have gained from participating in these communities.Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
684,"If coding were a sport, what would be your go-to victory dance to celebrate conquering a challenging code issue? Would it be the Syntax Shuffle? The Binary Boogie? Would it incorporate the robot? High fives and fist bumps? A Red Bull shower? Let your imagination run wild and share the dance move that perfectly captures your triumph!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
685,"Hey there!My name is Rachel and I am a part of the Forem/DEV/CodeNewbie team. I have been creating this “What I Learned This Week” segment to discuss relevant posts on #codenewbie and/or #beginners that relate to things I have been interested in this week.Side note: if you haven't peeped the CodeNewbie tag or CodeNewbie Team Page, here are those things!#codenewbie Follow        The most supportive community of programmers and people learning to code.      CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.        A Brief IntroductionThis week, our theme is all things balance— whether that means finding inspiration, creating a schedule that works for you, trying new things, meeting your financial goals, or navigating mental health. I have been trying out a lot of new organizational systems, practicing healthy habits at home, and grinding away at work— and realized I may be working too hard in some avenues and not hard enough in others! It happens. Let’s talk through some posts that helped me and maybe they can help you too!  So, you are struggling with follow-through“Your projects are left unfinished not because of your technical abilities, but because you haven't learned how to plan properly.” - @jimmymcbrideThe Key to Completing Projects: Mastering the Art of Planning 🗝️Jimmy McBride ・ May 17 ・ 4 min read#tutorial#productivity#career#codenewbie  So, you are trying out a new codebase“Documentation is the first step to embark on a new project. On a regular project, the documentation will probably be missing, incomplete, or partly (if not entirely) misleading; at a hackathon, time may be too short to read it in detail.” - @nfrankelWorking on an unfamiliar codebaseNicolas Frankel ・ May 18 ・ 3 min read#maintenance#coding#codenewbie  So, you are realizing you need more financial security“Before we dive in, you might be wondering, why bother with a side income? Well, aside from the obvious monetary benefits, side hustles also offer a chance to explore new technologies, build your portfolio, and even network with others in our field. And let's face it, we're living in an era where job security can be as volatile as JavaScript frameworks.” - @sasidhar_gadepalli The Developer's Guide to Earning Side Income: An Inside Looksasidhar Gadepalli ・ May 15 ・ 8 min read#programming#career#sideprojects#productivity  So, you need more time to focus on yourself“Imagine trying to solve a sudoku puzzle, except you aren't allowed to use a pen and everything has to be done in your head. Now try doing this for 8 hours a day and you get a good idea of how mentally taxing programming is… Therefore, keeping our minds healthy is critical for us to be effective at work.” - @alexhyettdevTaking Care of Your Mental Health as a Software Developer 🧠Alex Hyett ・ May 14 ・ 9 min read#career#motivation#beginners#developerOr hey, you may be, like me, having the, “Gosh I know it all and I just don’t know how to do it”.To that, I would say (emphatically): take a break, go outside, touch the grass, smell the flowers, look at something that is much farther away than your screen, and carry on. You can’t fix it all at once.Happy coding y’all and have a great weekend.  And let me know below, how do you balance it all?"
686,"Next week is Mental Health Awareness Week, so I thought I would take this opportunity to talk about our mental health.Software development is mostly dominated by men and as you know we aren't particularly good at talking about our feelings. Combine this with high-stress environments and a general lack of social connectivity in our work, you end up with a pressure cooker for mental disorders.When trying to describe programming to my non-technical friends and family, I often use the analogy of solving sudoku. Imagine trying to solve a sudoku puzzle, except you aren't allowed to use a pen and everything has to be done in your head. Now try doing this for 8 hours a day and you get a good idea of how mentally taxing programming is.This is why developers need large blocks of uninterrupted time to code, most of the work is done in our heads.Therefore, keeping our minds healthy is critical for us to be effective at work. Some of the advice for maintaining a healthy mind include:Staying activeReducing screen timeGetting plenty of sleepSoftware developers, however, generally fall short of all three of those ideals.A software developer's job is spent sitting at a computer and staring at a screen. Even when we are at home there is a chance you might be on-call, which will require you to jump on your computer at a moment's notice to solve a production issue.If you have been on call before you will know that even if you aren't called, your sleep will likely suffer anyway.Every year mental health is becoming more of an issue for software developers. If we take a look at the Stack Overflow Developer Survey for the last 5 years we can see how things are deteriorating. Each year the survey asks developers to specify if they have one of the following:I have a concentration and/or memory disorder (e.g., ADHD, etc.)I have an anxiety disorderI have a mood or emotional disorder (e.g., depression, bipolar disorder, etc.)If we look at how the results for these have changed over the past 5 years you can see a worrying trend.  With the exception of 2020, there has been an increase year on year. Although it should be noted that there were around 6,000 fewer responses in the 2020 survey for this question compared to other years. The survey was also conducted in February 2020 before COVID-19 was declared a global pandemic, so this isn't the cause.The survey for 2023 is now live, it will be interesting to see how this has changed. With the amount of layoffs we have seen recently in the tech industry, I doubt anxiety is going to be any lower.Being a software developer can be overwhelming. Not only are we expected to perform mental gymnastics on a daily basis but we also need to stay ahead of the new technologies so that we don't fall behind.  🏋️‍♀️ Mental Health ExercisesI have suffered from burnout before but I have managed to come up with my own ways of dealing with it which will hopefully help.  ✅ Check in with yourselfWe aren't great at talking about our feelings however in most cases this isn't from emotional shyness. We actually don't know how we feel.Like the frog in boiling water, feelings can gradually increase over time without us thinking, ""Is it me or is it getting hot in here?"".It is worth taking some time to write down how you are feeling, whether it be stressed, tired, overwhelmed or depressed. Or all of the above.Identifying your feelings is the first step in actually doing something about them.When someone asks, ""How are you doing?"", we often reply ""Not too bad!"". I think you can do a bit better than that when you ask yourself the same thing.  🚶Walk, a lotMy aim for most days is to walk at least an hour a day. The first half an hour is usually me going over my thoughts and thinking about all the things I need to do. The last half is where I get the most benefit, a clear head and a general sense of calm.It doesn't have to be walking but an hour of exercise a day will do wonders for your mood and your health in general.We spend so much of our working lives sitting and staring at a computer that it is important to get away from that when we are not working.When I used to work in London, in the summer, I would often get some lunch and walk from Oxford Street up to Regents Park. I would sit on the grass, eat my lunch and then wander around the gardens before going back down to the office.Taking a walk at lunch was the best way for me to evade the afternoon slump that we often experience.  🏡 WFH Daily RoutineWhen we work from home, the line between our personal and professional lives can blur. Always being connected to our work is not healthy and can be the cause of a lot of anxiety and stress.The best way I have found to create a clear distinction between work and home is to have a separate work phone. I was never issued with an official work phone I just used an old iPhone that I had laying around. At the end of the day, I would switch the phone off (provided I wasn't on call) and avoid that temptation just to check in on things.You should also try and have a set time each day that you finish work. I like to eat dinner with my family every night so I must finish at a reasonable time. I would work from 8 am to 5 pm each day and I got into the habit of declining any late meetings that weren't essential.I find trying to work after 5 pm futile anyway. I do my best work in the morning and then struggle to do anything creative (including programming) in the afternoon.Things come up and it isn't always possible to adhere to such a strict schedule but you should try your best. I find setting the working hours in Google Calendar is a good way to send a subtle message to colleagues who try and book a late meeting.If you struggle to switch off after working from home I find going for a short walk helps. You are essentially simulating your commute home and it provides enough distinction to get out of your head so you can enjoy your evening.Try and keep screen time to a minimum in the evenings, especially if you have spent all day staring at a screen. I like playing video games but I save those for the weekends when I haven't been on my computer all day. During the week I tend to play the guitar, read or draw.I have also removed all social media apps on my phone. I find TikTok and Instagram reels especially dangerous, having wasted hours mindlessly scrolling through cat videos and people being stupid.Try and find a hobby that doesn't involve basking in the light from an electronic device.  ☕️ Schedule Coffee BreaksHumans are social creatures even if you are an introvert like myself. It is important to make time during the week to talk to your colleagues.It has been shown that loneliness and isolation can lead to several mental health conditions so make time to talk to others.If you or your colleagues work from home regularly, schedule a Zoom call each week for half an hour, just to talk. Work topics should be banned in these meetings and you should take it as an opportunity to get to know your colleagues.If you are in the office and you have a coffee shop nearby then why not have a sit-down coffee instead? I used to work around the corner from a Kaffeine and myself and a few others would regularly go there at the start of the day just to have a chat. It was one of my favourite things about working in London.  🙏 Find Meaning in Your WorkAt some point, most of us ask ourselves ""What is the point?"".I found myself asking this question a lot when I worked in finance. The whole purpose of the business was to make money or help others make money. There are no true altruistic goals with anything in finance.This can often cause depression by itself. Most people spend 80,000 hours in their careers so you don't want that time spent to be meaningless.One option is to find a career that has a positive impact. At least on the bad days you know it is all for a good cause. The 80,000 hours project is one place to start if you are looking for a career where you can make a difference.If you are not in a position for a career change, then there are ways to find meaning in an otherwise meaningless job. Look to your colleagues and see if there is something you could do to help them. Is there a junior software engineer that you could take under your wing and mentor? Did you learn something that you could share with others?  🛋️ Finding HelpIf you are still struggling it is important that you find some help.This doesn't necessarily mean going to a shrink, there are ways you can help yourself. I have personally found mental health podcasts especially good for this. Knowing that you aren't the only person experiencing something can help dispel that feeling of loneliness.I have enjoyed listening to:Happy Place by Fearne Cotton - If you grew up in the UK watching Top of the Pops or listening to Radio 1, then you will know who Fearne Cotton is. These days she works on her podcast interviewing people about mental health, as well as writing several self-help books.On Purpose with Jay Shetty - This isn't directly a mental health podcast but features interviews with the likes of Ryan Holiday, Ray Dalio and Yuval Harari to name a few. The topics however often steer towards mental health and self-improvement.If you have private health care included with your employment, mental health support is often available. There are also free helplines around the world that you can also use.  ❤️ Picks of the Week📚 Book - Armada by Ernest Cline (affiliate link). I am currently reading this book written by the author who wrote Ready Player One. If you liked the geeky video game references from that film then you are bound to like this as well. The premise of the book is, ""What if video games were military training simulators to train civilians in preparation for an alien invasion?"". I am only halfway through at the moment and feels like it is leading up to a big twist at the end.📝 Article - Do the weirdest thing that feels right. I often struggle with what to write about. Believe it or not, sometimes I don't feel like writing about software development. This article has a great philosophy that I need to take heed of more often.📝 Article - Introducing 100K Context Windows. Claude AI has now reached a 100K context window. Soon AI will be able to consume whole books or codebases.🧪 Experiment - See this page fetch itself, byte by byte, over TLS. Learn about TLS by seeing how a page is downloaded.📝 Article - Datadog’s $65M/year customer mystery solved. Interesting insights into Coinbase's spending on Datadog. Datadog is a very good product but I am not sure I would be happy with that level of spending!  👨‍💻 Latest from me🎬 YouTube - In order to understand recursion... There are a lot so jokes about recursion that don't do a very good job of explaining what recursion is used for. In this week's video, I explain recursion using the help of one of my favourite films, Inception.  💬 Quote of the Week""If you're the smartest person in the room, you're in the wrong room"" - Richard TirendiFrom 6 Months to 6 Figures (affiliate link) by Peter Voogd. Resurfaced with Readwise.  📨 Are you looking to level up your skills in the tech industry?My weekly newsletter is written for engineers like you, providing you with the tools you need to excel in your career. Join here for free →"
687,"As the demand for decentralized applications (dApps) grows, striking a balance between user-friendliness and decentralization is key. How can developers nail this balance effectively? Share your insights, experiences, and best practices for creating dApp interfaces that are both user-friendly and true to the principles of decentralization. Let's dive in!Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
688,"Hey all! Big news. The official ChatGPT app has come to iOS! Yesterday, OpenAI released the app for Apple’s iOS operating system. No Android app yet, however. The app is 100% free, as well as being without ads. Here is the description of the app in the Apple App Store (click here to see the app in the apple app store online): “Introducing ChatGPT for iOS: OpenAI’s latest advancements at your fingertips.This official app is free (no ads!), syncs your history across devices, and brings you the newest model improvements from OpenAI.With ChatGPT in your pocket, you’ll find:· Instant answers· Tailored advice· Creative inspiration· Professional input· Personalized learningJoin millions of users and try out the app that’s been captivating the world. Download ChatGPT today.”The app will open up a wide range of new tools for any Apple User. The app has been in development for months and advertises many tools that are not available on any other smartphone AI app. So, in conclusion, this is going to be a good tool for users of ChatGPT or developers on the go. This is Grey, signing off."
689,"Welcome to ""Single Digit"" Spotlight, a selection of articles published within the last week that have fewer than 10 total reactions (at the time of the post's publishing).The goal is to highlight posts published on DEV that haven't yet received the attention they may deserve 🌱Hope you enjoy!I just did a test to apply as a front end developer – and things aren’t going wellChristian Heilmann ・ May 16 ・ 5 min read#applications#frontend#skills#exercisesHow To Write Maintainable and Readable CodeThomas Sentre ・ May 16 ・ 7 min read#webdev#javascript#typescript#programmingWeeks of Debugging Your Build can Save Hours of Learning GradleJean-Michel Fayard 🇫🇷🇩🇪🇬🇧🇪🇸🇨🇴 ・ May 15 ・ 5 min read#android#gradle#kotlin#javaWhat Developers Need to Know About JWTsBrian Rinaldi for CFE.dev ・ May 16 ・ 20 min read#webdev#api#securityHashed Wheel TimersFrank Rosner ・ May 14 ・ 5 min read#datastructures#algorithms#javaVisualizing Data in dotnet with Polyglot Notebooks and SandDanceMatt Eland ・ May 13 ・ 4 min read#datavisualization#dotnet#vscode#datavizShout out to @codepo8, @devland, @jmfayard, @remotesynth, @frosnerd, and @integerman.Image by DilokaStudio on Freepik"
690,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @tigt's Top 7 post, tonight’s topic is...Succeeding in OSS! How to Succeed in Open Source Without Really Trying (Really)Taylor Hunt ・ May 10#webdev#svg#javascript#npm≥8 years ago, I wrote about an extremely niche improvement to a very specific use of SVGs. It got enough positive feedback that I turned that knowledge into an NPM package: mini-svg-data-uri.Today, it’s both one of the most and least important web dev things I’ve ever done.Questions:Have you ever had a surprise, unexpected, or random OSS success?Have you ever worked really, really hard on an OSS project and received minimal reward?What can we do, collectively, to better support OSS builders and maintainers whose work we rely on?Any triumphs, fails, or other stories you'd like to share on this topic?"
691,"Hey there! Guess who? It's Sloan, your friendly neighborhood DEV Moderator 🦥Welcome to a new installment of Sloan's Inbox, your go-to place for sharing advice and observations. Whether it's career development, office politics, industry trends, or improving technical skills, we've got you covered. So, let's continue our journey of learning and growth together.As always, I'm here to dive into your questions, comments, and thoughts. So, let's get to it!  Today's question is:What advice or suggestions would you offer to a 58-year-old engineer who is experiencing confusion about their future and career options in the ICT domain?Let's show our kindness and expertise! Share your thoughts and let's help a fellow DEV member out!Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
692,"Hey, DEV community!I hope you're ready for some exciting news. GitHub is launching their latest hackathon here on DEV Community where you can build a new application in the open, learn something new, and maybe win some awesome prizes in the process!  Announcing the GitHub + DEV 2023 Hackathon 🎉From now until May 23rd, GitHub is offering an unmissable opportunity to utilize GitHub Actions or GitHub Codespaces to benefit open source in exchange for prizes. All participants will need to share a DEV post detailing how they created their project. We can't wait to see what you create! Anyone who submits a valid project (including an official submission post, published on DEV) will be automatically entered to win a variety of fantastic prizes (including up to $1,500 USD!).Keep reading to get all the details on GitHub Actions, GitHub Codespaces, and how you can join the hackathon for a chance to win some exciting prizes.   What Are GitHub Actions?GitHub Actions are individual tasks that, when combined, result in a custom workflow that’s all your own! GitHub Actions allow you to automate and customize your software development workflows. Actions are located in the same place you store code, collaborate with peers, solve issues, and ship open source software — GitHub! Whether you build a custom action or integrate an existing one into your workflow for the hackathon, we hope that you’ll walk away with a greater understanding of the value of GitHub Actions — for you and the open source community. We’re excited to see how you approach this challenge! More on GitHub Actions here. Check out the tag pages for the #actionshackathon and #actionshackathon21 for some inspiration for GitHub Actions workflow ideas.   What are GitHub Codespaces?GitHub Codespaces are development environments hosted in the cloud. You can customize your project for GitHub Codespaces by configuring dev container files to your repository (often known as Configuration-as-Code), which creates a repeatable codespace configuration for all users of your project.GitHub Codespaces run on a variety of VM-based compute options hosted by GitHub, which you can configure from 2 core machines up to 32 core machines. You can connect to your codespaces from the browser or locally using an IDE like Visual Studio Code or IntelliJ.More on GitHub Codespaces here.  Project CategoriesThe GitHub + DEV 2023 Hackathon is calling for projects in the following five categories:Maintainer Must-Haves: Make the lives of Open Source maintainers easier.Guidance: Developers can use Codespaces to set up an environment to triage issues and review pull requests. Actions can also be used to build tools and resources to help developers create better documentation. DIY Deployments: Improve the deployment process for open source projects.Guidance:  Build automation workflows for DevOps processes using Codespaces or Actions! This could include automated testing, custom deployment scripts, or continuous integration/continuous deployment (CI/CD) pipelines.Interesting IoT: Cool projects that integrate with IoT.Guidance:  Use Codespaces or Actions to manage and monitor IoT devices, including tasks like managing configurations, updating firmware, and collecting and analyzing data. Phone Friendly: Projects built for Mobile (PWA readiness, iOS/Android)Guidance:  Developers can use Codespaces or Actions to create mobile applications that work on both iOS and Android devices, as well as set up automation workflows and CI/CD pipelines for their PWA ready apps. Wacky Wildcards: Build a random app that doesn’t fit into one of the categories above. Guidance:  With this category, we are looking for some truly silly and/or fun submissions. Feel free to dream big and ridiculously — and utilize any feature that GitHub offers.  Why Participate?The core philosophy behind open source software is code, technology, and the services we use are stronger and more secure when peer-review is both solicited and easily accessible. To be truly involved in the open source community, you (of course) need to participate! GitHub Actions and Codespaces are the perfect way to contribute to open source while optimizing your workflows.If that’s not enough incentive, we also have some sweet, sweet prizes!  💰 Prizes 💰Five Grand Prize Winners (one per category):$1,500 USD gift card or equivalent$300 USD credit to the Forem ShopDEV Sticker PackGitHub Sticker PackDEV “GitHub Hackathon 2023” Grand Prize profile badgeRunner-Up Prizes (10 Total – across all categories):$250 USD gift card or equivalent$150 USD credit to the Forem ShopDEV Sticker PackGitHub Sticker PackDEV “GitHub Hackathon 2023” Runner-Up profile badgeParticipants (with a valid project):DEV Sticker PackDEV “GitHub Hackathon 2023” participant profile badgeCost of shipping included. If shipping outside of the U.S., international customs and duties may apply. Please research your local import laws for more information on customs fees or reach out to shop@forem.com with any questions.How to Participate in the GitHub + DEV 2023 Hackathon1) Sign up for a free GitHub account by clicking here or sign into your existing account. 2) Create a new and original app during the contest period using GitHub Actions or GitHub Codespaces that falls under one of the categories listed above. 3) Share your code publicly on GitHub using one of the following permissive licenses for your code: MIT, Apache, BSD-2, BSD-3, or Commons Clause.4) IMPORTANT: Use this post template to officially submit your application for the hackathon. Be sure to address every prompt and instruction in the template.5) Be sure to publish your submission on DEV between April 25th and May 23rd (@ 11:59 PM UTC), and provide your app’s URL, screenshot, description, and source code⚠️ Heads-up that you'll only be able to view our submission template linked above if you're logged into DEV.  Additional Notes and Rules:We encourage you to share update posts on DEV using the #GitHubHack23 tag to keep us posted on your progress (hint: use series: [“series name”] in the markdown heading of all your GitHub + DEV Hackathon-related posts to link all content in a series)Multiple submissions are allowedIf you collaborate with anyone, please list their DEV handles in your submission post so we can award a profile badge to your entire team! DEV does not handle prize-splitting, so in the event your project is named a Grand Prize-winner or runner-up, you will need to split those amongst yourselves. Thank you for understanding!NO PURCHASE NECESSARY. Open only to 18+. Contest entry period ends {date of contest closure}, 11:59 PM UTC. Contest is void where prohibited or restricted by law or regulation. All entries must be new projects and created during the hackathon period. For Official Rules, see Contest Announcement Page and General Contest Official Rules.  Community SupportTo ask any questions about GitHub or about the rules of this contest, leave a comment in the official help thread. Our team will be monitoring this space to answer your questions in collaboration with the GitHub team.Need some external motivation and guidance? Who doesn’t! We encourage all participants to swing by our community discussion thread where you can share your ideas and get suggestions on improvements from the DEV community as you build your app. You can also use this thread to share your progress along the way to get support from others.Important Dates 🗓April 25th, 2023: Hackathon BeginsMay 23rd, 2023: Hackathon Submission Due at 11:59 PM UTCMay 24th, 2023: Submission Judging beginsUPDATED: June 13th, 2023: Winners Announced and Prize Instructions SentWe’re so excited for you to join us for this brand new hackathon with our friends at GitHub. Have fun, learn lots, and keep us posted along the way.Good luck and happy coding! 🍀"
693,"Hello, DEV community! We have an intriguing topic up for discussion: Which programming language do you think would be most suitable for individuals who don't possess an inherent inclination towards coding? Join the conversation and share your thoughts.Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik"
694,"Hey y'all! I recently saw a post by one of my team members...If Coding Languages Were Ice Cream Flavors...?Ben Halpern for CodeNewbie ・ May 18 ・ 1 min read#discuss#beginners#codenewbie#watercooler...on our CodeNewbie Team page and it drew up so many feelings and associations to food and work. Recently, one of my favorite things to listen to during my days of making content for y'all over here at CodeNewbie Team is cooking podcasts. I found this show by Samin Nosrat (creator of Salt, Fat, Acid Heat!) and Hrishikesh Hirway called Home Cooking that got me thinking... I should really try to make a meal using all of the ingredients in my cabinet to have something cook something while I work (ideally in my crock pot), so that I don't have to focus on it while I work, can be super nourished once I finish work, and don't have to think about purchasing a meal for the day. (Note: I definitely do this every once and a while, but I forgot it was even an option as my crock pot is stashed away in a cabinet right now!)So, this was my 15 minute mission at the end of my lunch break today— I decided to throw a bunch of veggies in the crock pot, add some things to make a pseudo pozole veggie soup, and called it an afternoon (will update to see how it goes!).   All said, I realize I am not alone in this quest to find easy meals while I am working that make me excited to eat, but aren't too stressful or mess-making to cook.  So, help me out— what do you find yourself cooking, craving, or ordering when you have a long workday and you can't be bothered?"
695,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
696,"I am currently looking for a new job. One thing that keeps happening is that people get my CV, are impressed but then ask me that I seem to be focused on the front end a lot and what my experiences with backend and full stack development are. It seems to me that we've come full circle back to when I started as a web developer and had to sell and explain the notion of a front end expert as a real, full-time job, 21 years ago: Here's the deal: a frontend developer isn't a mediocre coder that only dabbles in ""easy"" languages like HTML, CSS and JavaScript. A frontend developer is someone who made a conscious choice to build interfaces for the unknown with a laser sharp focus on the end user's experience. The web isn't just another compilation target. It's a platform that allows the user full control over the look and feel. It's also the only platform resilient enough to weather any change you throw at it. The web works on desktop, android and iOS. And it can do that with one codebase. If you have dedicated developers who know what they are doing and don't just expect to find a plugin or extension that will magically make your product accessible to all and perform well.Here's the not so dirty secret: no matter what platform you choose, what language you write your code in or what framework or library you use - the final thing that arrives on your web users devices is HTML, CSS and JavaScript. Each (with HTML to a small degree) can cause performance problems, cross-browser functionality issues and become a barrier for users on sub-par connections and platforms or with different abilities. Slow performance is known to lose you end users and being inaccessible is a legal and compliance issue that can get you sued. I've worked on the biggest web sites on this web (yahoo.com, bing, Microsoft…) and on the Firefox and Microsoft Edge (Chromium) browser. Browser makers want one thing: not being blamed for being slow or showing things ""wrong"". So we work with lots of internal and external partners to see why their products are misbehaving. This could be extension providers, framework creators or development teams. In these ""performance clubs"" both in Mozilla and Microsoft we kept running into the same issue: web products with tons of senseless HTML, mostly unused CSS and an absolute avalanche of JavaScript sent to the end users with no benefit to them. All the benefits were for the convenience of the developers and the flexibility to build whatever with a framework that promised optimised output. The move to full stack development caused us to build a bloated web that loses you customers and costs you a lot of traffic that simply isn't necessary. There is of course another reason why our web products don't deliver: componentisation without big picture planning. Web products these days aren't build as documents, sites or even includes. They are built as independent components, each flexible enough to be applicable in many different contexts. That's grand, until people assemble them nilly-willy and as many as they want to. At times we found 20 different, highly customisable button components that did the same thing. Here's where a frontend developer would smell that something is amiss immediately and could trace the waste. Frontend developers are:Browser performance expertsCross platform development expertsAccessibility expertsCompliance knowledgeableDesign and Test department connectedFiercely dedicated to the end userWe truly are the shape shifters of the market. So to say that someone who is ""just"" a frontend developer isn't flexible enough means first and foremost that most people still don't know all the things this job requires. The argument that CSS and client side JavaScript isn't real coding is nonsense, too. It's especially ironic that people who claim that also don't want to touch CSS as it is ""too hard and strange"". CSS isn't about colours and padding any more, with grid, subgrid and flexbox it's a fully fledged layout system. And it does animation and responsive rendering. With media and container queries you have amazing flexibility and with cascade layers you even have control over how browsers should composite the current design.It is your choice. You can hire frontend developers to build your product, or make it happen somehow and later on hire performance and accessibility consultants to fix what doesn’t work properly. Bear in mind though that the further down the production you are, the harder it will get to optimise and fix a product as you will also clash with new feature work. When people ask me why I am “just doing frontend”, I can happily explain these things and proclaim that I am proud to be a frontend engineer.The defence RESTs, POSTs and GETs your feedback.Addendum: This is also applicable to all the other jobs we have in the market. A good database engineer can save you seconds of loading time, a great cloud engineer can lower your bills and a great backend engineer make sure your servers only do the job they should and not run optimisation pipelines for a huge pile of unused frontend code. And with all the big players right now trying desperately and shortsightedly to please stockholders in times of inflation by laying people off rightsizing, the market is awash with talent. And maybe you can afford three experts for the price of one 10x full stack ninja rockstar who lives in a city where 80% of their income is their rent."
697,"This week on the CodeNewbie Podcast, we had on Frankie Nicoletti to talk about the ins and outs of neurodivergence and accommodations in the workplace. A little about Frankie— Francesca Kerberos Nicoletti (she/they) is an engineer, leader, educator, and polymath, and currently VP of Engineering at SoLo Funds. Previously they were AI Engineering Lead at a martech unicorn, Head of Engineering at a seed stage grocery startup, interim CTO at a big data startup, and an IC at several early-stage startups ranging from ecommerce to social media. They have been a career coach for 7 years and also hold several state records in powerlifting!  If you didn't get a chance to listen already, find that episode below or wherever you get your podcasts:""Understanding and Supporting Neurodivergence in Tech"": CodeNewbie Podcast S24:E2Rachel Fazio for CodeNewbie ・ May 17 ・ 1 min read#beginners#codenewbie#career  Let's jump into it (with a quick introduction)When discussing accommodations in the workplace, (using the wisdom of Frankie) we can operate under a couple of different understandings to help understand why accommodations are important. 1. At your job your hardest task should be the actual work you are doing, not trying to navigate things like different social norms, overstimulation, and burnout.2. Rest is not something that you need to earn, whatever your body needs, you are entitled to!3. Making accommodations to allow people to do their best work is good for everyone.  You may be wondering, how can my workplace start helping folks feel better supported by our systems?The answer to this one is very much dependent on your workplace, but here are some things we talked about with Frankie:1. An easy way for folks to feel more supported is to listen and what someone needs the most.2. It is easy to assume that someone is lazy if they are not getting their work done. But, the truth of the matter is, most folks fundamentally want to do a good job. If you don’t want to do a good job anymore or your staff doesn’t, that could be a sign that there is an underlying problem. This could mean you have not been given enough information to complete a task, you have been given a task that isn’t appropriate for your skill/experience level, or something is going on outside of work impeding your progress.3. Integrating different options of ways that people can interact with systems is an easy fix to help make your workplace more accessible. This could mean there are different times of the day when you are active, recording Looms for demos, turning your camera on or off when you need to in meetings, choosing the way that you send a message, or generally being mindful of communication patterns.4. As much as you can, build into your system automatic notifications and prioritization rather than expecting folks to remember things or find manual workarounds.Above all, we hope you ask questions when you are confused about something, when something is new to you, or when you see yourself or your coworkers having a hard time.   Also— let us know down below how your systems support your unique needs!Happy coding y'all, have a great day. "
698,"At CodeSandbox, we run your repository and turn it into a link you can share with anyone. People visiting this link can not only see your running code, they can click ""fork"" and get an exact copy of that environment within 2 seconds so they can easily contribute back or play with the code. Give it a try with this Next.js example or import your GitHub repo!Maybe you've experienced this before. You're working on a new feature that introduces some database migrations. You're almost done with the feature, but you get pulled aside because there's a bug that has to be fixed right now.You want to fix the bug, but now you first have to roll back your migrations before changing the branch. And then after you've fixed the bug, you have to go back to your feature branch and re-run the migrations!How great would it be if you didn't have to think about this? Ideally, you should get a new copy of your database when you change your branch.With CodeSandbox, we're making this happen. Once your repository is imported into CodeSandbox, we give every branch and pull request a unique database.In this post, I'll show how you can achieve this and how it works under the hood.  How does it work?With CodeSandbox, you get a new cloud development environment for every branch and pull request. We enable this through VM cloning.Here's an example. When you import your repository on CodeSandbox, we create a microVM for the main branch. You can see this as a template. Whenever you create a new branch, we clone the microVM main and switch the new VM to the new branch.The VM clone is not only a clone of the filesystem, but also of the memory. If you want to learn more about how this works, we have an in-depth post about that.This means that if you're running a database in the main VM, new branches will automatically get an exact clone (schema + data) of this database!See this in action in the video below.The repo of this video can be found here and the PR here.This doesn't only apply to branches. We also create a microVM for every pull request. This way, you can use CodeSandbox to test your pull requests as well, without deploying to staging or running migrations locally 🎉Let's see a demo of this in action that you can actually play with!In this sandbox, I have an embed of this todo app where it fetches its data from a Postgres database. If you clone it (by clicking ""Fork""), you'll get a microVM with the exact same database and data. Try it out!  How to set it upTo enable a unique database for every branch and PR, you need to first import your repository into CodeSandbox. You can do this by going to your dashboard and clicking ""Import repository"". We'll automatically open the main branch for you in the web editor.Note that we also have an iOS app and a VS Code extension that you can use to open any branch.Now, we need to configure the database! First, let's create a new branch, so that we're not making changes on the main branch directly. You can do this by clicking on ""Create Branch"" in the top right, and it will take you to a new branch (and microVM!) with an autogenerated name.Once you're in this branch, you can configure your database with our docker-compose integration. To do this, you need to create a new file called docker-compose.yml in the .codesandbox folder. This file will be automatically picked up by CodeSandbox and used to run your database.An example docker-compose.yml looks like this:version: ""3.8""services:  db:    image: postgres:14.1-alpine    restart: always    environment:      - POSTGRES_USER=postgres      - POSTGRES_PASSWORD=postgres    ports:      - ""5432:5432""    volumes:      - db:/var/lib/postgresql/datavolumes:  db:Enter fullscreen modeExit fullscreen modeAfter configuring docker-compose, we recommend restarting the VM to verify that everything is configured properly. You can do this by clicking ""Restart Branch"" in the menu on the left corner.When that's done, you will have a branchable database that will automatically be provisioned for every branch and pull request!Once you've merged the branch to main, you can add some seed data to the database—this way, every new branch will get the seed data as well.Finally, we highly recommend installing the CodeSandbox GitHub App. This will provision a prebuilt development environment (with its own database) for every pull request.  Final thoughtsThis VM cloning concept is powerful.Plus, it applies to more than just databases. You can run Redis, or maybe Elasticsearch, and every PR will get a unique copy of that service, provisioned from the main branch.We're all about removing time-consuming steps from the development workflow. That's why we see this as a major win for anyone working with databases.If you're curious about testing this out, the best place to start is by installing the CodeSandbox GitHub App. Then, you'll have this in place for every PR and never have to roll back migrations in branches anymore!"
699,  Small changes in coding habits can make a big impact. What are the coding practices or habits you've recently adopted that have noticeably improved your productivity or code quality? Your insights might inspire others to make positive changes in their workflow!Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
700,"Restarting something Ben was doing for a while, and we plan on doing this every Friday! Open Source is about the community. Whether you have a project or you're looking to make your first PR.    Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFinally, consider reading the Best Practices for Maintainers.Happy coding!"
701,"What are your thoughts on the perception that Linux is primarily geared towards advanced users and developers, and how does this affect its popularity among casual computer users?""Are there any other preconceived notions or misconceptions about Linux that you think prevent more people from trying it out or considering it as a viable option?Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
702,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   I Was Hacked: What I’ve Learned Since@williambaptist shares their experience getting hacked. All it takes is one small mistake to compromise your entire digital defensive framework, so keep up to date with the latest best practices. I Was Hacked: What I’ve Learned SinceWilliam Baptist ・ May 10 ・ 5 min read#hacked#cybersecurity#beginners#security  Most Managers Have No Clue What Programmers Actually DoWith all of the layoffs going on, @bytebodger thinks they know where the commonality lies. Too many ""dev managers"" have little-to-no-clue what software engineers actually do.Most Managers Have No Clue What Programmers Actually DoAdam Nathaniel Davis ・ May 9 ・ 14 min read#webdev#programming#career  The ongoing defense of frontend as a full-time jobIt seems to @codepo8 that we've come full circle back to when they started as a web developer and had to sell and explain the concept of a front-end expert as a real, full-time job, 21 years ago.The ongoing defence of frontend as a full-time jobChristian Heilmann ・ May 9 ・ 4 min read#frontend#engineering#hiring  Combining async requests in the backgroundIf a React component triggers multiple API requests, it can lead to a slowdown in the interface and a significant consumption of server resources.@jennieji presents two approaches to combine these requests: combining by time and combining by count.Combining async requests in the backgroundJennie ・ May 9 ・ 5 min read#javascript#promise#async  Planning a Project from Scratch: The Ultimate Guide for Success 🏆Are you excited about starting a new project, but not sure where to begin? Don't worry; @jimmymcbride has got you covered! Let's explore a tried-and-tested method for planning a project from scratch! Planning a Project from Scratch: The Ultimate Guide for Success 🏆Jimmy McBride ・ May 10 ・ 3 min read#career#careerdevelopment#tutorial#productivity  Why AI will never take your jobAI will not replace people. @polterguy’s take is that people with AI will replace people without AI because it's a ""better hammer”. Chainsaws didn’t replace lumberjacks, lumberjacks with chainsaws replaced lumberjacks with felling axes.Why AI will never take your jobThomas Hansen ・ May 9 ・ 4 min read#ai#productivity#machinelearning  How to Succeed in Open Source Without Really Trying (Really)About 8 years ago, @tigt wrote about an extremely niche improvement to a very specific use of SVGs. It got enough positive feedback that they turned that knowledge into an NPM package. How to Succeed in Open Source Without Really Trying (Really)Taylor Hunt ・ May 10 ・ 5 min read#webdev#svg#javascript#npmThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
703,"Hey all!We have a new CodeNewbie Podcast episode coming out tomorrow about neurodivergency and we thought this would be a great opportunity to discuss accommodations in the workplace!Here is our link to where you can find our new podcast episode, which premiers tomorrow with our guest Frankie Nicoletti!      codenewbie.org    For those who aren’t familiar, neurodivergency or neurodiversity is a nonmedical framework that is used to describe folks who have differences in cognition/brain function than other folks. This term was built around the autism rights movement and the social model of disability and can be used to describe folks with autism, ADHD, anxiety, OCD, Dyslexia, and other learning disabilities and conditions. So, my question for you all is for my neurodivergent (and neurotypical too!) folks out here— what accommodations do you have in place at your work or in your workflow that help you mitigate burnout, overstimulation, etc. ?For myself, as someone with OCD and ADHD, I have a a bunch of different strategies that I use to keep myself feeling my best. I will share them below, and would love to hear what everyone else finds helpful in the discussion!"
704,"In our second episode of Season 24 of the CodeNewbie Podcast, @saronyitbarek talks about neurodivergence and accommodations in the workplace with Frankie Nicoletti, VP of Engineering at SoLo Funds.       codenewbie.org    Francesca Kerberos Nicoletti (she/they) is an engineer, leader, educator, and polymath, and currently VP of Engineering at SoLo Funds. Previously they were AI Engineering Lead at a martech unicorn, Head of Engineering at a seed stage grocery startup, interim CTO at a big data startup, and an IC at several early-stage startups ranging from ecommerce to social media. They have been a career coach for 7 years. They hold several state records in power lifting as well!Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding! We hope you enjoy this season of the CodeNewbie Podcast 💜"
705,"I think we are lucky as software developers. Most of us like what we do and we get a good salary. Even if a lot of people do not like the company they work for, in general, they like software development and they have the possibility to learn a little bit more and look for another job.Even if we tend to complain about the salaries we make, and it might be that we are underpaid compared to some others, in general, we earn a good salary and only a few professions let people earn and live as well.I know that sitting all day has its severe dangers on our health, but our decent salaries come with an essentially safe job.Outsiders would tend to tell that we are spoiled.But the feeling of developers is often that we are severely abused.I guess both groups are right in certain aspects.Let me share a story with you.  Mo' responsibilities but no mo' bucksI've met recently a friend of mine, who told me that he is finally on the lookout for a new job. He had told me some time ago, that'd stay a bit more time in his current role, so I became quickly interested in why he changed his mind.He told me that got promoted! That's good news I thought.So he was told that now he had the role to deploy in production, he is expected to review code and he'd have to investigate bugs in production.As I didn't want to stop his flow of words, I kept on listening amazed. I personally think that every engineer should do code reviews. Maybe, just maybe, not everyone's approval should count the same way, but juniors should also perform code reviews. At least for three different reasons.They often spot such typos that others wouldn't, because they focus on what they can with their experience. This was meant to be a compliment, they are often very thorough. At the same time, they often lack the bigger picture, just because of the shorter time spent around.As they have fewer preconceptions and assumptions, they often ask very different questions in code reviews than more experienced colleagues. Those questions often help both reveal problems the authors wouldn't have thought of and put problems into a different context.Code reviews are also a great tool to learn from more experienced authors.I was also surprised by the fact that juniors don't have to do production investigations. Again, they are such a great tool for learning even if you have to sometimes ask for help from more experienced colleagues.But each company, each team forms its own culture, I'm not here to judge...It's clear that at this place juniors are deprived of tasks and responsibilities, while medior and senior engineers have both more tasks and responsibilities.When this friend of mine asked his management what would be his new salary he was told that there is no increase, no new salary. After all, he's still a programmer who'd just write code.What the hell?At my previous job when I was promoted to a senior role, my senior manager even took pride in handing me over the promotion mail with the new salary. I wouldn't say it was a huge increase, it was double of a normal yearly increase. Yet, it was still at least something and the increased level of responsibility and expectations were acknowledged.Is this friend of mine spoiled or abused? Are we developers in general spoiled or abused?  No matter the money, fairness is importantI personally think that no matter how much we earn, we should be treated fairly and an increased level of responsibility should be paid with a higher salary. At the same time, I think it's also reasonable to expect you to already perform on that level before you get the position.In my previous jobs - as a DBA in one and a software engineer in the other - people could only be promoted if they performed their new tasks for a couple of months and management was happy about their performance. When I heard about this for the first time, I was surprised and a bit angry. What? I should perform more for the same money? But I realized that this makes sense.What if you are a good coder, but you cannot be a good mentor? What if you cannot communicate and you cannot review code without killing the morale of the team? What if you cannot handle the pressure that comes with investigating production incidents? Then you clearly don't merit the position where these are expected, and these tasks, including communication, are expected from senior engineers!It doesn't mean that you're bad at what you had been doing, it means that you're not ready for the new position. Or maybe you don't even want to be in that position! Not everyone has to be a mentor and accept a certain level of technical leadership.Demoting someone can be a big loss of face. I think it's better if our current abilities and readiness are slowly assessed based on real-life performance before a promotion. I think it's even better if we pick up these responsibilities gradually. Then once we have enough of them and we perform in those well enough, then we can get our promotion - along with the salary increase.Now you might claim that if those responsibilities come gradually, then the salary increase should be gradual too and the promotion shouldn't be a big hike. You should get a few smaller increases over the years - beyond the normal yearly increase. That's also a way, still, I think that a promotion should always come with a certain level of salary increase.If that's not possible due to some economic circumstances, make sure as an employer that you emphasize those circumstances and promise that as soon as the wartime ends, you compensate for the missed increase. And of course, don't forget about it...  ConclusionAre we spoiled or abused? In certain ways, both can be true. Our field is very competitive and we are asked a lot in order to get a good job. Sometimes even in order to get a bad job. On the other hand, we are paid a relatively high salary and we can complain about things that make us seem spoiled.On the other hand, there are many bad practices in the industry, in our management that might make you feel abused if you experience it. One of these things is getting a promotion with increased responsibilities and more tasks but without a salary increase.I think that no matter how much we earn we should be treated fairly and part of this fairness is that you don't handle a promotion in two different ways. Saying that now you have to do this and that in addition, but then claiming that your job is still the same, so you don't qualify for an increase is not what I call fair treatment.  Connect deeperIf you liked this article, please hit on the like button,subscribe to my newsletter and let's connect on Twitter!"
706,"Often times, we found ourselves in a situation to decide what tech stack or development methodolgy will favour our product. This is a question most people ask.please share your view on this topic..."
707,"Happy May on Glitch! It’s a pleasant time of the year - the weather is getting nicer and summer is on the horizon. Recently we kicked off a new testing program to get some feedback as we work towards bringing custom domains back to Glitch using Fastly’s free TLS offering - join the testing group and help us improve the experience!By the way, have you heard of Bluesky? Another addition to the decentralized social media space, it’s built on the AT Protocol and growing fast as invites have been flowing over the past couple of weeks. I built a starter bot that counts sheep, which you can view and remix on Glitch if you’re curious about what building bots for Bluesky is like. We’ve also seen cool apps from the community like @gsajith’s ~blue-skies-ahead project which shows Bluesky posts in real time. We’re excited about decentralized social platforms, and especially excited to see our community building on and for it!See you on glitch.com (and also @glitch.bsky.social)!Jenn, Director of Community 👽P.S. Shouts out to creator Dominic Farolino, who reached out to share something really cool he built on Glitch: “I always forget which GitHub repositories of mine have GitHub pages enabled, and therefore might be hosting something cool for the world to see. So I created gh-pages.glitch.me to show me…From spending a little time on it I actually found some pretty cool projects that I didn't know about!”  On the blogs ✍️In case you missed it on the Glitch Blog...Check out what you created last month in the April edition of Last Month on Glitch, featuring games, permutations, garbage, and keyboard bashing 🔨We caught up with Sonny Li to talk about his team’s latest project Codédex, as well as security analyst Kim Key who remixed Glitch in Bio to make her own webpage and makes great podcast recommendations!Here are some blog posts from the community that we loved!Keir Clarke of Maps Mania shared this pictorial map of Americana hidden treasuresDaily used Glitch to show off their Prebuilt Integrations API and integrate a Miro board and CometChatRaymond Camden gave a great overview of the more modern, experimental Cookie Store API.Evan Marie Carr shared their journey using ChatGPT to build a todo app on Glitch.Have you written about your Glitch apps on a blog, a conference talk…anywhere! Let us know and we’ll feature it in the next newsletter!  On the forum 📣Check out what the Glitch community is sharing and discussing:Fresh from The Gallery: with Spotify shutting down Heardle, @derekahmedzai’s clones are more useful than ever! Also, here’s a fresh new Deno starter by @pb.oliver.mcloughlin!Say hi and share what you’ve been working on in the latest Community Open thread!The Glitch Community Forum is the best way to ask the community for help, share what you’re making, exchange friendly banter and get to know your fellow friendly Glitch creators. See you there! 😎Haven’t gone Pro yet? New subscribers can sign up for Glitch Pro with the code THESKYISBLUE and get **25% off. You’ll get 100% of the superpowers Glitch Pro gives you – like project access controls, always-on apps, and more"
708,"Python boasts an array of impressive features. Its practicality and versatility have propelled it to the forefront of the development landscape. So what makes Python so great? Where does it shine? And why should it be added to a coder's toolkit? Share your insights on the practical use cases where Python outperforms its counterparts, and let's uncover the secrets of its success.Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
709,"  The current state of web application developmentUser expectations of the web are now that you have this super-smooth no-reload experience. Unfortunately, it's an expectation that is usually delivered with single-page applications (SPAs) that rely on libraries and frameworks like React and Angular, which are very specialised tools that can be complicated to work with. A new approach is to put the ability to deliver this UX back into the hands of engineers that built websites before the SPA-craze, leveraging their existing toolsets and knowledge, and HTMX is the best example I've used so far.   The costs of SPASPAs have allowed engineers to create some great web applications, but they come with a cost:Hugely increased complexity both in terms of architecture and developer experience. You have to spend considerable time learning about frameworks.Tooling is an ever-shifting landscape in terms of building and packaging code.Managing state on both the client and serverFrameworks, on top of libraries, on top of other libraries, on top of polyfills. React even recommend using a framework on top of their tech:React is a library. It lets you put components together, but it doesn’t prescribe how to do routing and data fetching. To build an entire app with React, we recommend a full-stack React framework.By their nature, a fat client requires the client to execute a lot of JavaScript. If you have modern hardware, this is fine, but these applications will be unusable & slow for those on older hardware or in locations with slow and unreliable internet connections.It is very easy to make an SPA incorrectly, where you need to use the right approach with hooks to avoid ending up with abysmal client-side performance.Some SPA implementations of SPA throw away progressive enhancement (a notable and noble exception is Remix). Therefore, you must have JavaScript turned on for most SPAs. If you wish to use something other than JavaScript or TypeScript, you must traverse the treacherous road of transpilation.It has created backend and frontend silos in many companies, carrying high coordination costs.Before SPAs, you'd choose your preferred language and deliver HTML to a user's browser in response to HTTP requests. This is fine, but it offers little interactivity and, in some cases, could make an annoying-to-use UI, especially regarding having the page fully reload on every interaction. To get around this, you'd typically sprinkle varying amounts of JS to grease the UX wheels. Whilst this approach can feel old-fashioned to some, this approach is what inspired the original paper of REST, especially concerning hypermedia. The hypermedia approach of building websites led to the world-wide-web being an incredible success.  Hypermedia?The following is a response from a data API, not hypermedia.{  ""sort"": ""12-34-56"",  ""number"": ""87654321"",  ""balance"": ""123.45""}Enter fullscreen modeExit fullscreen modeTo make this data useful in an SPA, the code must understand the structure and decide what to render and what controls to make available.REST describes the use of hypermedia. Hypermedia is where your responses are not just raw data but are instead a payload describing the media (think HTML tags like <p>, headers, etc.) and how to manipulate it (like form, input). A server returning HTML describing a bank account, with some form of controls to work with the resource, is an example of hypermedia. The server is now responsible for deciding how to render the data (with the slight caveat of CSS) and what controls should be displayed.<dl>  <dt>Sort</dt><dd>12-34-56</dd>  <dt>Number</dt><dd>87654321</dd>  <dt>Balance</dt><dd>£123.45</dd></dl><form method=""POST"" action=""/transfer-funds"">  <label>Amount <input type=""text"" /></label>  <!-- etc -->  <input type=""submit"" value=""Do transfer"" /></form>Enter fullscreen modeExit fullscreen modeThe approach means you have one universal client, the web browser; it understands how to display the hypermedia responses and lets the user work with the ""controls"" to do whatever they need.Carson Gross on The Go Time podcast ...when browsers first came out, this idea of one universal network client that could talk to any application over this crazy hypermedia technology was really, really novel. And it still is.If you told someone in 1980, “You know what - you’re gonna be using the same piece of software to access your news, your bank, your calendar, this stuff called email, and all this stuff”, they would have looked at you cross-eyed, they wouldn't know what you were talking about, unless they happened to be in one of the small research groups that was looking into this sort of stuff.Whilst ostensibly, people building SPAs talk about using ""RESTful"" APIs to provide data exchange to their client-side code, the approach is not RESTful in the purist sense because it does not use hypermedia. Instead of one universal client, scores of developers create bespoke clients, which have to understand the raw data they fetch from web servers and then render controls according to the data. With this approach, the browser is more of a JavaScript, HTML and CSS runtime. By definition, a fatter client will carry more effort and cost than a thin one. However, the ""original"" hypermedia approach arguably is not good enough for all of today's needs; the controls that the browser can work with and the way it requires a full page refresh to use them mean the user experience isn't good enough for many types of web-app we need to make.   HTMX and hypermediaUnlike SPAs, HTMX doesn't throw away the architectural approach of REST; it augments the browser, improving its hypermedia capabilities and making it simpler to deliver a rich client experience without having to write much JavaScript if any at all. You can use whatever programming language you like to deliver HTML, just like we used to. This means you can use battle-tested, mature tooling, using a ""true RESTful"" approach, resulting in a far more straightforward development approach with less accidental complexity. HTMX allows you to design pages that fetch fragments of HTML from your server to update the user's page as needed without the annoying full-page load refresh.We'll now see this in practice with the classic TODO-list application.   Clojure HTMX TODOFirst-of-all, please don't get overly concerned with this being written in Clojure. I did it in Clojure for fun, but the beauty of this approach is that you can use whatever language you like, so long as it responds to HTTP requests.Nothing special here, but it does feel like a SPA. There are no full-page reloads; it's buttery smooth, just like all the other SPA demos you would've seen. The difference here is:I did not write any JavaScript.I also didn't cheat by transpiling Clojure into JavaScript. (see ClojureScript)I made a web server that responds to HTTP requests with hypermedia. HTMX adds the ability to define richer hypermedia by letting you annotate any HTML element to ask the browser to make HTTP requests to fetch fragments of HTML to put on the page.   The edit controlThe most exciting and impressive part of this demo is the edit action. The way an input box instantly appears for you to edit and then quickly update it again feels like it would require either a lot of vanilla JS writing or a React-esque approach to achieve, but what you'll see is it's absurdly simple. Let's start by looking at the markup for a TODO item. I have clipped the non-edit markup for clarity.<li hx-target=""closest li"">  <form action=""/todos/2a5e549c-c07e-4ed5-b7d4-731318987e05"" method=""GET"">      <button hx-get=""/todos/2a5e549c-c07e-4ed5-b7d4-731318987e05"" hx-swap=""outerHTML"">📝</button>  </form></li>Enter fullscreen modeExit fullscreen modeIt maybe looks a lot, but the main things to focus on for understanding how the edit functionality works:On the <li>, an attribute hx-target tells the browser, ""When you get a fragment to render, this is the element I want you to replace"". The children inherit this attribute, so for any HTMX actions inside this <li>, the HTML returned will replace the contents of the <li>.hx-get on the edit button means when you click it, HTMX with tell the browser to do an HTTP GET to the URL and fetch some new markup to render to the <li> in place of what's there.The form is not essential for the example, but it allows us to support the functionality for non-JavaScript users, which will be covered later.When you start working with HTMX, an easy way to understand what's going on is to look at the network in the browser's developer tools. When a user clicks the edit button, the browser does an HTTP GET to the specific todo resource. The server returns a hypermedia response, which is a representation of that resource with some hypermedia controls.<form action=""/todos/45850279-bf54-4e2e-a95c-c8c25866a744/edit""      hx-patch=""/todos/45850279-bf54-4e2e-a95c-c8c25866a744"" hx-swap=""outerHTML"" method=""POST"">  <input name=""done"" type=""hidden"" value=""false""/>  <input name=""name"" type=""text"" value=""Learn Rust""/>  <input type=""submit""/></form>Enter fullscreen modeExit fullscreen modeHTMX then takes that HTML and replaces whatever we defined as the hx-target. So the user now sees these hypermedia controls for them to manipulate the resource, instead of the row pictured before.You'll notice the form has a hx-patch attribute, which means when it is submitted, the browser will send a PATCH with the data to update the resource. The server then responds with the updated item to render.   Embracing the webThere's more to HTMX, but this is the crux of the approach, which is the same as the approach that most websites were made before SPAs became popular.The user goes to a URLThe server returns hypermedia (HTML), which is content with controls.Browser renders hypermediaUsers can use the controls to do work, which results in an HTTP request sent from the browser to the server.The server does business logic, and then returns new hypermedia for the user to work withAll HTMX does, is make the browser better at hypermedia by giving us more options regarding what can trigger an HTTP request and allowing us to update a part of the page rather than a full page reload.By embracing the hypermedia and not viewing the browser as merely a JavaScript runtime, we get a lot of simplicity benefits:We can use any programming language.We don't need lots of libraries and other cruft to maintain what were basic benefits of web development.CachingSEO-friendlinessThe back button working as you'd expectetc.It is very easy to support users who do not wish to, or cannot use JavaScriptThis final point is crucial to me and to my current employer. I work for a company that works on products used worldwide, and our content and tools must be as usable by as many people as possible. It is unacceptable for us to exclude people through poor technical choices. This is why we adopt the approach of progressive enhancement.Progressive enhancement is a design philosophy that provides a baseline of essential content and functionality to as many users as possible, while delivering the best possible experience only to users of the most modern browsers that can run all the required code.All the features in the TODO app (search, adding, editing, deleting, marking as complete) all work with JavaScript turned off. HTMX doesn't do this for ""free"", it still requires engineering effort, but because of the approach, it is inherently simpler to achieve. It took me around an hour's effort and did not require significant changes.   How it supports non-JavaScriptWhen the browser sends a request that was prompted by HTMX, it adds a header HX-Request: true , which means on the server, we can send different responses accordingly, very much like content negotiation.The rule of thumb for a handler is roughly:parseAndValidateRequest()myBusinessLogic()if request is htmx then    return hypermedia fragmentelse    return a full pageendEnter fullscreen modeExit fullscreen modeHere's a concrete example of the HTTP handler for dealing with a new TODO:(defn handle-new-todo [get-todos, add-todo]  (fn [req] (let [new-todo (-> req :params :todo-name)]              (add-todo new-todo)              (htmx-or-vanilla req                               (view/todos-fragment (get-todos))                               (redirect ""/todos"")))))Enter fullscreen modeExit fullscreen modeThe third line is our ""business logic"", calling a function to add a new TODO to our list. The fourth line is some code to determine what kind of request we're dealing with, and the subsequent lines either render a fragment to return or redirect to the page. So far, this seems a recurring theme when I've been developing hypermedia applications with HTMX. By the very architectural nature, if you can support updating part of a page, return a fragment; otherwise, the browser needs to do a full page reload, so either redirect or just return the entire HTML. HTML templating on the server is in an incredibly mature state. There are many options and excellent guides on how to structure and add automated tests for them. Importantly, they'll all offer some composition capabilities, so the effort to return a fragment or a whole page is extremely simple.   Why is it The Future ?Obviously, I cannot predict the future, but I do believe HTMX (or something like it) will become an increasingly popular approach for making web applications in the following years. Recently, HTMX was announced as one of 20 projects in the GitHub Accelerator  It makes ""the frontend"" more accessible.Learning React is an industry in itself. It moves quickly and changes, and there are tons to learn. I sympathise with developers who used to make fully-fledged applications being put off by modern frontend development and instead were happy to be pigeonholed into being a ""backend"" dev. I've made reasonably complex systems in React, and whilst some of it was pretty fun, the amount you have to learn to be effective is unreasonable for most applications. React has its place, but it's overkill for many web applications. The hypermedia approach with HTMX is not hard to grasp, especially if you have some REST fundamentals (which many ""backend"" devs should have). It opens up making rich websites to a broader group of people who don't want to learn how to use a framework and then keep up with its constantly shifting landscape.  Less churnEven after over 10 years of React being around, it still doesn't feel settled and mature. A few years ago, hooks were the new-fangled thing that everyone had to learn and re-write all their components with. In the last six months, my Twitter feed has been awash with debates and tutorials about this new-fangled ""RSC"" - react server components. Joy emoji. Working with HTMX has allowed me to leverage things I learned 15-20 years ago that still work, like my website. The approach is also well-understood and documented, and the best practices are independent of programming languages and frameworks.I have made the example app in Go and Clojure with no trouble at all, and I am a complete Clojure novice. Once you've figured out the basic syntax of a language and learned how to respond to HTTP requests, you have enough to get going; and you can re-use the architectural and design best practices without having to learn a new approach over and over again. How much of your skills would be transferable from React if you had to work with Angular? Is it easy to switch from one react framework to another? How did you feel when class components became ""bad"", and everyone wanted you to use hooks instead?  CheaperIt's just less effort! Hotwire is a library with similar goals to HTMX, driven by the Ruby on Rails world. DHH tweeted the following.Hotwiring Rails expresses the desire to gift a lone full-stack developer all the tools they need to build the next Basecamp, GitHub, or Shopify. Not what a team of dozens or hundreds can do if they have millions in VC to buy  specialists. Renaissance tech for renaissance people.That's why it's so depressing to hear the term ""full stack"" be used as a derogative. Or an impossible mission. That we HAVE to be a scattered band of frontend vs backend vs services vs whatever group of specialists to do cool shit. Absolutely fucking not.Without the cognitive overload of understanding a vast framework from the SPA world and the inherent complexities of making a fat client, you can realistically create rich web applications with far fewer engineers.   More resilientAs described earlier, using the hypermedia approach, making a web application that works without JavaScript is relatively simple. It's also important to remember that the browser is an untrusted environment, so when you build a SPA, you have to work extremely defensively. You have to implement lots of business logic client side; but because of the architecture, this same logic needs to be replicated on the server too. For instance, let's say we wanted a rule saying you cannot edit a to-do if it is marked as done. In an SPA world, I'd get raw JSON, and I'd have to have business logic to determine whether to render the edit button on the client code somewhere. However, if we wanted to ensure a user couldn't circumvent this, I'd have to have this same protection on the server. This sounds low-stakes and simple, but this complexity adds up, and the chance of misalignment increases. With a hypermedia approach, the browser is ""dumb"" and doesn't need to worry about this. As a developer, I can capture this rule in one place, the server.   Reduced coordination complexityThe complexity of SPAs has created a shift into backend and frontend silos, which carries a cost.The typical backend/frontend team divide causes a lot of inefficiencies in terms of teamwork, with hand-offs and miscommunication, and makes getting stuff done harder. Many people mistake individual efficiencies as the most critical metric and use that as justification for these silos. They see lots of PRs being merged, and lots of heat being generated, but ignoring the coordination costs.For example, let's assume you want to add a new piece of data to a page or add a new button. For many teams, that'll involve meetings between teams to discuss and agree on the new API, creating fakes for the frontend team to use and finally coordinating releases. In the hypermedia approach, you don't have this complexity at all. If you wish to add a button to the page, you can add it, and you don't need to coordinate efforts. You don't have to worry so much about API design. You are free to change the markup and content as you please.Teams exchanging data via JSON can be extremely brittle without care and always carries a coordination cost. Tools like consumer-driven contracts can help, but this is just another tool, another thing to understand and another thing that goes wrong. This is not to say there is no room for specialisation. I've worked on teams where the engineers built the web application ""end to end"", but we had people who were experts on semantic, accessible markup who helped us make sure the work we did was of good quality. It is incredibly freeing not to have to negotiate APIs and hand off work to one another to build a website.  More optionsRendering HTML on the server is a very well-trodden road. Many battle-tested and mature tools and libraries are available to generate HTML from the server in every mainstream programming language and most of the more niche ones.  Wrapping upI encourage developers looking to reduce the costs and complexities of web application development to check out HTMX. If you've been reluctant to build websites due to the fair assessment that front-end development is difficult, HTMX can be a great option. I'm not trying to claim that SPAs are now redundant; there will still be a real need for them when you need very sophisticated and fast interactions where a roundtrip to the server to get some markup won't be good enough.In 2018 I asserted that a considerable number of web applications could be written with a far simpler technological approach than SPAs. Now with the likes of HTMX, this assertion carries even more weight. The frontend landscape is dominated by waiting for a new framework to relieve the problems of the previous framework you happened to be using. The SPA approach is inherently more complicated than a hypermedia approach, and piling on more tech might not be the answer, give hypermedia a go instead.Check out some of the links below to learn more.   Further reading and listeningThe author of HTMX has written an excellent, free book, explaining hypermedia. It's an easy read and will challenge your beliefs on how to build web applications. If you've only ever created SPAs, this is an essential read.HTMX. The examples section, in particular, is very good in showing you what's possible. The essays are also great. I was lucky enough to be invited onto The GoTime podcast with the creator of HTMX, Carson Gross to discuss it! Even though it's a Go podcast, the majority of the conversation was about the hypermedia approach. The Go version was my first adventure with HTMX, creating the same todo list app described in this postI worked on The Clojure version with my colleague, NickyDHH on HotwireProgressive enhancementFive years ago, I wrote The Web I Want, where I bemoaned the spiralling costs of SPAs. It was originally prompted by watching my partner's 2-year-old ChromeBook grind to a halt on a popular website that really could've been static HTML. In the article, I discussed how I wished more of the web stuck to the basic hypermedia approach, rendering HTML on the server and using progressive enhancement to improve the experience. Reading back on this has made me very relieved the likes of HTMX have arrived."
710,"Hey hey hey! Welcome to CodeNewbie Team's very official, very anticipated... Newbie Memes of the Week!   Here are some of our favorites from this week:  We hope your week is beginning to a great start!Drop some of your memes in the thread below and be well!ALSO, in case you missed last week's thread, you can find that here!."
711,"Restarting something Ben was doing for a while, and we plan on doing this every Friday! Open Source is about the community. Whether you have a project or you're looking to make your first PR.    Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFinally, consider reading the Best Practices for Maintainers.Happy coding!"
712,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...what happened to Web3?Today's discussion question comes from this anonymous message in my inbox:What happened to Web3? People seem to be talking about it less, but at the same time, more decentralized apps are appearing. Is that the same thing?I know the community is gonna have thoughts on this one! So let's talk about it—share your answer in the comments 👀Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
713,"Design-first approach at MiroThe Miro Developer Platform 2.0 was launched last year, and since then we’ve been working on improving the quality and consistency of our REST API. To achieve this, we decided to embrace a design-first approach. For us, it meant designing the API before actually implementing it, and making sure that the quality was high during the whole development process.This meant we needed an efficient way to verify compliance between the API and its description in OAS (OpenAPI Specification) files.In this post, I’ll share why we landed on contract testing as the solution. Contract testing is a fast, lightweight form of API testing that ensures two separate services are compatible and can communicate with each other by checking the consistency with a set of rules.Switching from code generationPreviously, we generated OAS files from the code, using annotations on controllers and models. At the time, this allowed us to transition from writing the documentation manually to some degree of automation. However, the solution was hacky and required us to jump through a lot of hoops to generate the OAS files.@Operation(   summary = ""Get specific connector"",   description = ""Retrieves information for a specific connector on a board."",   responses = [       ApiResponse(           responseCode = ""200"",           description = ""Connector retrieved"",           content = [               Content(schema = Schema(implementation = ConnectorWithLinks::class))           ]       )   ],   operationId = ""get-connector"")fun getConnectorById() {...}Enter fullscreen modeExit fullscreen modeThe early version of the API was not designed according to OpenAPI standards and had problems like conflicting endpoints and overly complex models. The main components of the design-first approach were quite difficult to implement, so we decided to switch the source of truth from the code-generated OAS files to permanent, curated ones.How do we keep it in sync?However, switching the source of truth presented a new problem. When the OAS files were generated from the code, we could at least partially guarantee that we were serving what we were promising. For example, the endpoint description could not have been generated if it didn’t exist in the code. Now, there was no way to tell if the OAS file had the paths and schemas that actually existed.Looking for a solutionOf course, we have end-to-end tests. Why not reuse them to verify that the API looks as expected? They cover the functionality anyway, so why not add a little schema validation to the mix?This idea is great, but it has the same flaw as the previous situation — it’s based on trust and leaves room for human error: New endpoint, but tests are not added? New parameter added, but tests are not updated because it’s out of critical path? The whole new experimental API appeared with no new tests and no intention to write them yet?Writing a set of tests just to verify the compliance between the API and its description in OAS seemed even more far-fetched — not only did it have the same flaws, but it would also require us to do the same work all over again.And this is how we arrived at the idea of generating tests from the OAS file.How can a test be generated?Our OAS has all the necessary data to successfully generate a request and validate the schema of the response. The request body can be built from schemas and the provided example/default values. If we don’t go into the details (and we don’t just yet), the logic for one resource is pretty easy:First, find the endpoint that creates the resource (for example, the widget).Save the id from the response.Re-use it in all other endpoints (get widget by id, update widget).Find the endpoint to delete it and execute it last. But the devil is in the details, and the most pressing questions would be: What if it’s more than one resource? How do we guarantee that, say, the widget is created before the board is deleted?Level-method modelAt this point we cared about two things: the method (POST should go first, DELETE — last) and the order of resource creation (boards before widgets). It may seem to have a simple solution.We can easily identify the endpoints that create/delete the resources by method; that’s the first point of comparison. When we look at the path, we see that some resources appear before others. By naming them resource 1 and resource 2 (3, 4 or however far the craziness can get us), we get the second point. Then we only have to sort in the form of an arrow:This idea was simple, easy to understand, and worked great as a proof of concept, but it introduced more problems than it solved, namely:Representing the order in a simple manner possible with two levels of resources, worsens with three levels, and becomes not maintainable after it.Not all POST endpoints create resources. For example, attaching a tag to the item is also a POST endpoint, but it has to happen after both items and tags are created.Adding additional order — for example, if the endpoint has parent_item_id, it has to be created after a frame is created — seems impossible without blowing up the complexity.We needed a more powerful way of sorting the relationships between endpoints, and that led us to a dependency graph.Dependency graphWho would have thought to represent dependencies with a graph, right? In any case, it seemed like a very plausible solution: A directed graph can handle relationships of any complexity. It’s very clear what should be executed first. And there’s no need to rely on strict pre-defined ordering.But how do we build a graph? Do we take the very first endpoint and put it in the graph, then take the next one and try to determine its relationship with the first node? That might work — and guarantee that the board is not deleted before we’re done with widgets on it. But at some point this approach would require traversing the entire graph to figure out the relationships with all other nodes. Despite the fact that we’ll never have that amount of endpoints for it to become a real performance problem, it does not help with the complexity, so we probably need another approach.Luckily, the level-method ordering approach highlighted not just the problems, but also the way we can use components of the url to determine the relationships. So instead of trying to fit the endpoint into the graph, we’re going to build the graph around it based on what this particular endpoint needs.WalkthroughLet’s take a simple endpoint: add a tag to an item. By looking at the endpoint, we can see that before it can be executed, we need to have a board, an item, and a tag already created. We’re going to have a special kind of node — “creational” nodes — and will create a lot of “empty” nodes like this. They can be populated with an actual url template when we get to it, but the node needs to exist before, so it can be used as a dependency.What are the steps to building a dependency graph for this endpoint?Create a graph node for current operation.If the node creates the resource, save it to the map of resources and their corresponding creation nodes.For each required parameter or resource in the api path:Find the node that knows how to create the required resource from the map above.…or create an empty node that will be populated when the creation operation is parsed.Add a dependency on it.What if the endpoint deletes the resource entirely? Instead of adding extra complexity to the algorithm, we save them separately, in a “cleanup queue.”Now we have a graph of all the endpoints, plus a cleanup queue with delete endpoints sorted by the level of the resource being deleted. To test all the endpoints as parameters in the test, we need to put them in a simple sorted list. The initial idea was to use a graph and modified topological search, but with the graph construction that we use, the sorting is simplified to a BFS plus polling the cleanup queue in the end.As you may have noticed in the above example, an endpoint node can have a dependency on more than one other node, for example, both tags and items. And they, in return, can depend on multiple other nodes. The simple BFS will create duplicates at best, and unexpected ordering in the worst-case scenario. Plus, even duplicates can be detrimental: A second tag is created with the same example value provided in OAS, and this request ends with 400 because duplicated tags are not allowed.The solution for this, however, would be simple: If some node meets a child with more than one parent, it ignores it and detaches itself from a child, leaving nodes that appear later to take care of. This is the cruel reality of child care in computer science.Of course, there are still some limitations to what can possibly be automated. Here are some of them:If the resource cannot be created via API (e.g. organizations for enterprise API), it has to be created before the test runs.If the endpoint has a parameter (e.g. tag_id or parent_item_id or parent_id), you need to map it to some resource first (e.g. tag_id to tags).Likewise, if another resource is mentioned in the request body, it has to be created (e.g. widgets for connectors) or mapped to an existing resource.CustomizationsThe whole solution consists of 4 parts:The OAS files describing the Miro APITest generation logicCreation of the components that can be generated automaticallyThe tests themselvesPluginsThe test generation logic is a separate library that only needs to change when a new feature is required for all test suites, for example, when we decide to also make requests with missing required parameters to test error responses. All custom modifications, including providing new OAS files, have to go through plugins.Plugins offer a set of customizations to the owner of the API. For example, mapping resources to parameters, or retrying logic for some endpoints.Other types of testsThe initial set of tests contained only positive tests that check that a successful response is returned and the response schema is exactly as it is described in the OAS file. However, there are a number of possibilities to create other types of tests, from the already mentioned missing required parameter checks, to testing the expected error responses.AutomationThe tool is as good as its automation, so the API testing tool is scheduled to run frequently and to notify the team about the results. This solution also unlocked not just publishing the documentation automatically right after the change, but also preparing OAS files, for example, removing endpoints marked as drafts.There you have it. With OAS contract testing, we can verify compliance between the API and its description in OAS files.Do you have ideas or a different approach to API testing? Let us know in the comments — we’re interested in what you have to say!Are you interested in joining our team? Then check out our open positions.Finally, don’t forget to try the Miro Developer Platform for yourself."
714,"cover image source: nowthatsmusicAlright, it's a new week and I'm ready to listen to some fresh tunes. This time up I'm curious to hear any music that makes you all feel particularly nostalgic. Perhaps it's music that references a previous decade (perhaps even one that you never lived during). Or, maybe it's music that brings you back to a particular time in your life, like tunes from your teenage days. Whatever the case may be, I wanna hear some tunes that take you to a specific time and place. Take me there with ya!  How we doIn this weekly series, folks can chime in and drop links to whatever it is they've been listening to recently + browse others suggestions.If you'd like, you can view previous entries in the series here. And for those who have been following along with this series, you may notice that I'm now posting it under the DEV Team org... it's the same old series, but I've just decided to house it here going forward. 😀Alright, let's get this nostalgia train a'rollin'... 🚂 Note: you can embed a link to your song using the following syntax {% embed https://... %}. This should work for most common platforms!Looking forward to listening to y'all's suggestions! 🎶"
715,"Let's kick off the week with some Monday motivation! Share one professional skill you're eager to improve or learn this week, and let's brainstorm ways we can support each other in reaching our individual goals."
716,"Contributing to open source projects is a phenomenal way to improve your skills as a software developer, gain experience working on real-world projects and give back to the community! 🤠It is also a great way to get a job - but you probably knew that already 😌🍾However, when you are a newbie at it, it is daunting to know where to start...In this blog post, we'll share 5 tips to help you get started with contributing to open source projects as a beginner.tl;dr1.  Start small → If this is your first time, contribute to the project’s docs2. Find projects where your help is most needed  → use quine.sh 3. You are a guest so follow the guidelines 4. Double down on testing → ”All code is guilty, until proven innocent” 5. Don’t be a sissy.. ask for help 🤟1.  Start small hombre 🤠You are not Steve Wozniak (yet) so push (no pun intended 🤓) those unrealistic expectations aside and start with something easy.You know what’s the easiest way to start: contributing to a project’s documentation!This will help you dip your toes into it in a very risk free manner! You will also get all the exposure you need to the things that still makes no sense to you like for instance the difference between forking and cloning 🫠We found this super concise video made by Ali Solanki where he explains quite well to beginners how to contribute to your first repo on Github! Check it out below and earn your “open-source coder” title in the next 10 minutes 🎉2. Now where do I find good projects? 👀This gets pretty interesting here.. You need to look for projects that align with your interests and skills - that’s obvious. 🙄But you also need to find projects that are willing to accept contributions and could use an extra pair of hands! 👯‍♀️Now you can head over to Github on “Topics” and look for the topic you want. This is one of the most popular options, but there are better alternatives!For example, you can use a tool that scanned all of Github’s repositories and issues! This enables you to get a project you can start contributing to and that tool is called quine.sh 😏Quine.sh will recommend you the most good starter issues that align with your topic and language preferences 🎯The UI is quite simple, after signing up simply pick your language 🗣️, your topic 🧳 and filter for “good starter issues” - that’s all you need to do to find a repo that suits your background and your needs!Oh and in case you were wondering - it is completely free.3. Guidelines, Guidelines and Guidelines 📄I know, likely not what you wanted to read yet, but every open source project has its own guidelines and expectations from contributors.These are sometimes written in the README file on the repo 📑, but they can also be found in the CONTRIBUTING file of the repo (not every repo will have this).Make sure you read and follow these guidelines closely to avoid wasting your own time and that of the project maintainers (btw in case you didn’t know maintainers are the person(s) who manage the repository).Some common guidelines include:Coding standardsTesting requirementsCommit message conventions. How to request to be assigned to an open issue.4. ”All code is guilty, until proven innocent” 🐞I think this one is pretty obvious so we will skim through it quickly: before submitting a pull request, make sure you've triple tested your changes. You need to ensure they really work as intended and don't introduce any new issues.   This includes running any automated tests that the project provides, as well as testing your changes on various platforms and configurations. 🔥 Little tip: Document your test cases and send it to the maintainers. This is extremely useful and displays great testing standard from your end! Also, don’t hesitate to submit a comment to the issue to ask project-specific questions.5. Don’t be a sissy.. ask for help 🤟Contributing to open source projects can be scary as fudge, especially if you're new to the project or the technology stack. But honestly put your ego aside and remind yourself EVERYONE was a beginner once! If you get stuck or don't understand something, most open source projects have a welcoming and helpful community that are happy to assist new contributors 🤎…Also, remember that you can find answers to most questions in StackOverflow, coding forums, and even by asking ChatGPT 🙈But Github is a bit weird, like how do you even communicate? Is it just through pull requests? 🫠Good question and short answer is NO.You can communicate through pull requests but that’s not the only area!The other main communication channels are: 🦠 Issues: Every project has an “Issues” section that is used to report bugs, request features, or discuss ideas related to the project. Contributors can create new issues, comment on existing issues, and provide feedback on proposed solutions.💅 Chat Platforms: Quite common now, we do get quite a bit of repo teams working together on Slack, Discord, or Gitter for real-time discussions. 🗣️ Discussions: Repository owners and people with write access can enable GitHub Discussions for a community on their repositories. This provides a space for open-ended conversations such as proposing new ideas, asking questions or sharing thoughts on a particular aspect of the project.💌 Email: In some cases, contributors may use email to communicate with the project maintainer. It is definitely less common lol but still sometimes used and reserved for more formal or sensitive discussions.ConclusionContributing to open source projects as a beginner can be super challenging and the learning curve is steep at first. However, it will become a rewarding experience I promise you that ⭐️So, remember to:start smallfollow the project's guidelinesask for helptest your changes thoroughlyand be patientYou'll be well on your way to making valuable contributions in open source projects!! 💻🌐🚀PS: If you're looking for a platform to discover projects aligned with your interests, language preference, and do it, whilst not spending a penny, visit quine.sh 🫶. It's a great space to find free projects where you can contribute and make a difference!QuineFollow        Build rep with every merge ✨Wear your stats in your GitHub README      "
717,"Malbolge, anyone? Let's dive into the depths of programming folklore and share our encounters with the most enigmatic, perplexing, and mind-bending languages out there. Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
718,"What inspired you to pursue this career path? Was it a love of coding or just a knack for debugging? Maybe you were drawn in by the allure of programming languages - who can resist the siren call of Python or Java? Or perhaps it was the promise of a steady stream of bugs to squash that had you hooked.Whatever your reason, I'm sure you've encountered your fair share of errors along the way. But remember, as a developer, you have the power to turn those bugs into features! So keep calm and code on, and don't forget to share your favorite programming puns in the comments below. After all, who doesn't love a good play on words?"
719,"If you were given the opportunity to design a VR experience, what kind of captivating world would you bring to life?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
720,"Heyo 👋Y'all all have wonderful weekends!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugGoing fishing 🎣"
721,"Let's weigh the pros and cons: working on a project with a large team versus flying solo as a developer. Both approaches have their own unique perks and challenges. So, if you had to choose, would you rather work on a project with a lot of collaboration or go it alone? Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
722,"Alright, picture this: You have the power to create a robot companion that can do absolutely anything and everything. What kind of tasks or services would your robot specialize in? How would it bring some serious convenience and awesomeness to people's lives?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      *"
723,"If you had to describe coding using only three words, what would they be?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      *"
724,"Imagine you have the chance to create a coding language from scratch. What unique features or capabilities would you introduce, and how would it improve the programming experienceFollow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
725,"Happy Star Wars Day! Let's have a little fun. Which Star Wars character do you think would make the best developer? I think the obvious choices are the methodical and detail-oriented C-3PO and the creative and intuitive R2-D2.But what about Luke Skywalker? He's a skilled pilot and Jedi, yes; do you think he possesses the problem-solving skills necessary to excel as a developer?Could Rey utilize her extensive knowledge of the Force to better understand complex coding languages and algorithms?Would the calculating and ruthless tactics of Darth Vader make him a formidable developer? Would his tendency to lean towards the dark side hinder or bolster his success in the industry?Jar Jar Binks? 😂 Although he's portrayed as a clumsy and bumbling character, he does demonstrate a certain level of resourcefulness and problem-solving ability in his role as a Gungan military officer. But his unconventional methods and communication style might impact his effectiveness as a developer. Would he be able to adapt to the technical jargon and structured approach required in software development, or would his unfortunate Jar Jar-ness cause more harm than good?Discuss. And may the fourth Be with you. 🌌 Follow the CodeNewbie Org and #codenewbie for more fun discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
726,"You have been working on something cool, and now you want to talk about it? How to do you get selected to present on stage at a conference or event?I've spoken at 253 different conferences and events 🤯 and that's at the time of writing. I have a few more next week! Whilst applying for an getting accepted for these multitude of events, I have discovered some of the best ways to make your call for papers (Call for Papers, also known as Call for Speakers, or Call for Sessions) stand out.Whether you're submitting your first paper, or your 100th talk, hopefully these top tips will help you.  TipsHere are some top tips on getting your paper accepted for an event. In no particular order:Make your bio personal, but informative. It should cover who you are, your position, and what credentials you have to spoke on your proposed topic.A catchy, fun talk title goes a long way to grabbing the attention of both the paper reviewers and participants if your talk is chosen.In your talk abstract, be specific about some of the tools, skills, and/or practices participants will learn from your session.Make sure your talk abstract speaks to the audience. Who is the target audience? What is the aim of the conference? If the conference is for Android developers, make sure you are making content that would be useful to them.Your talk should not be a sales pitch. If you want to give a sales pitch, you'll probably need to pay for a speaking spot!If there are ""options"" or ""add more information"" make sure you add information in here that will make sense to someone reading your abstract. Will you already be in town for another conference? Are you happy to have the talk considered for a lightning talk or a panel discussion if it's not selected as a talk? Have you given the talk before and provide links to the recording?Stick to the criteria. If there's a character limit, stick to it. If it asks you to select a talk track, topic, or theme, make a selection and ensure your talk speaks to your choice.FINALLY: If you can't decide on what talk to submit, make multiple submissions! I would stick to submitting no more than three talks for a single conference.Whatever you decide to submit, make sure it's relevant, timely, and interesting!  Submit now, and add your tipsHopefully these tips help your next CFP submission. Speaking of, GitHub Universe has just opened CFPs for 2023, and we hope to see your submission.If you have a tip to add, I'd love to see it in the comments ❤️"
727,"We all encounter hurdles along our coding journey, but it's the triumphs that make us grow. What coding concept once posed a significant challenge for you, and how did you ultimately overcome it? Share your story and the strategies you employed to conquer the coding mountain!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
728,"Hey there, fellow developers! Sloan here. 🦥 I'm back with another edition of Sloan's Inbox, your go-to online column and discussion. I must say, your queries and enthusiasm never fail to make my day! So, thanks to a particularly compelling question from a newbie developer, I'm here once again, and counting on all of you to share your valuable insights and advice.   Today's question is:I'm a newbie software developer trainee, and I'm eager to take on a real-life project. However, I'm feeling a bit lost and unsure of how to proceed. I want to challenge myself by building a project without relying on YouTube tutorials, but I'm struggling to figure out where to start. Are there any specific concepts or skills I should focus on before diving into the project? Any guidance or help would be greatly appreciated!So, what do you say, DEV members? Can you help a newbie out? Let's show our kindness and knowledge in full force!Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
729,"During the opening keynote at this year's Google IO, the speakers mentioned ""AI"" a whopping two hundred and fifty-two times. The tagline, ""Make AI helpful for everyone"", vividly reflected the key focus for Google this year. AI was the key talking point, from their Large Language Model (LLM) Bard to other Google products leveraging generative AI.In the past year, AI Labs worldwide have made strides, most notably OpenAI (developer of ChatPGT). One could have guessed that Google had something similar up its sleeves. And right, we were 😉.Let's delve into the key points from Google Keynote and see how Google plans to make AI helpful for everyone.  A Shift In Generative AIGenerative AI will be available in different Google products starting this year. Let's have a look.  Help Me Write (Gmail)Google launched smart reply for Gmail in 2017, followed by smart compose in 2019. As a Gmail user, you have seen suggestions for what you should type next while composing an email.Sundar Pichai revealed that Google had been working on an AI-powered advanced writing feature at this year's IO. Dubbed ""help me write,"" this feature accepts prompts and generates text like an email draft.Example: Flight cancellation email response.  Immersive View for Routes (Google Maps)Welcome ""Immersive view for routes"" for Maps, a new way to view the world. If you want to visit a particular area, walk, or run within your town, an immersive view will show you the entire journey in 3D.Traffic and weather updates are incorporated to give you insights on what to wear and routes to use. Other details, such as air quality, also enhance your experience. This feature will roll out before the end of the year.  Magic Editor (Google Photos)Google Photos is AI-powered. With AI, searching photos and making them better is at the core. According to stats, 1.7 B photos are edited annually.Last year, the ""Magic eraser"" used to remove distractions was made available on Pixel phones. At IO 2023, a new feature, the ""Magic Editor,"" was announced and will be rolled out later in 2023. The magic editor moves images on a frame, as shown below.  PaLM 2 (New AI-Language Model that Powers Google Bard)PaLM 2 was unveiled during the Google keynote at IO. The new model is available in 4 primary flavours (Gecko, Otter, Bison, and Unicorn). It is an exciting model and has a lot to offer.  Google BardPowered by PaLM 2, Bard is rapidly evolving. Currently, it has an exciting new set of features programmers will be happy about, such as;Code generationDebuggingCode SnippetsOther new features include;Code citations - generate a piece of code using Bard and get citations to the source of the code.Export and run on Repl. it - goodbye to the traditional copy and paste. You can now click an export button, which opens the Repl. it terminal. Click run. Done 😊.Dark ThemeExport drafts into Gmail and DocsBard will also become more visual in its responses and results. For instance, you can query Bard and get answers with images.Example: What are some must-see sights in New Orleans?  Google Lens Meets BardGoogle Lens is an image recognition technology by Google. At IO, it was revealed how AI could make working with Lens better. For example, you can generate AI image captions, as seen in the illustration below.Another example during the IO presentation was finding colleges, showing them on Google Maps, presenting these options in a table, adding a column to categorize them as public or private, and finally moving them to Google Sheets. See that below;  Adobe FireflyBring your imagination to life with Adobe Firefly. Enter prompts for the kind of image you want, and your image will be generated using Bard.Adobe Firefly will be available in 180+ countries and territories in English, with more languages (40+) coming by the end of 2023.  Google WorkspaceCollaboration has been made easier by Google Workspace, and the timely ""help me write"" feature has made things even more accessible, such as writing essays, project plans, etc.The requests are sent to Palm 2 base model, which returns responses. AI is used harmoniously with all Workspace apps such as Google Sheets, Google Slides, Drive, etc. This feature is available to try on Labs at g.co/Labs.  AI in Google SearchAs the pioneer of Google, search stayed the same for over two decades. But, this year, changes have finally come to Google search. Presenting the keynote, Cathy Edwards spoke about the integration between search and AI.  Generative AI (Experimental)Tagline: Search supercharged.Search meets AI in an integrated approach. This improved search delivers a better overall experience and sounds natural, smarter and simpler.Ads make up Google, and with this new AI search, they are present and designed to improve user experience. For instance, if you search for a particular car, dealerships around your area may appear on the side, showing you deals, discounts, and more options, especially for businesses. The conversational mode includes a button with ""Follow up question.""Watch Cathy break down how the new search works and some prompts that act as good follow-up questions.Examples of prompts:Why do whales sing?Can I see whales in my area?Take a trip to see whalesPlus 1 ticket for kids under 40 dollarsAI-powered Google search will continue improving. Go to g.co/Labs and join the waitlist to use it now. AI search begins a new chapter, with more to come. Search will keep on evolving to answer any questions.  Notable Mentions  GeminiGemini is the next-generation large language model Google is working on. It is tipped to have multi-modal capabilities.  Google CloudVertex AI & Character AIBoth are used to build generative AI products and deploy them to Google Cloud. New models in vertex are Image, codey, and Chirp, all available for preview.  PaLM 2 APIThe API has been integrated into tools such as Firebase and Colabs. Project Tailwind is the flagship PaLM 2 API project.  Bold and responsible AIAI responsibility is a critical concern that Google has tried to tackle by asking the question, Will AI be socially responsible?The only way to be bold is to be responsible from the startJames Manyika (Senior Vice President for Technology and Society, Google)This is done to prevent misuse and misinformation. Some of the steps that can help curb it are;Image evaluation - will be added to Google. AI-generated images will provide metadata to show their origin and other key information.Markers - markers will be present in AI image details to show that they are indeed not real but AI-generated.Use of watermarking to curb misinformation.Next-gen translation model to recognize tone and voice and match everything together (Universal translator).Watch James Manyika explain how Google is working to ensure that AI is socially responsible below;  Automated Adversarial testingThey are used in other Large Language Models to handle the toxicity their models generate.Watch the full Google keynote and the American Sign Language version below.          Google Keynote (Google I/O ‘23) - YouTube                  Tune in to find out how we're furthering our mission to organize the world’s information and make it universally accessible and useful.To watch this keynote ...                youtube.com                Google Keynote (Google I/O ‘23) - American Sign Language - YouTube                  Tune in to find out how we're furthering our mission to organize the world’s information and make it universally accessible and useful.To watch this keynote ...                youtube.com      Thank you for reading 🥳. You can support me by buying me a cup of coffee here ☕.See you at the next one.Peace ☮️✌️"
730,Welcome to a new series where we'll be spotlighting a selection of articles published within the last week that have fewer than 10 total reactions at the time of this post's publishing.The goal is to highlight posts published on DEV that haven't yet received the attention they may deserve 🌱JavaScript Getter Factory ~ Properties from thin air ~Adam Crockett ・ May 10 ・ 2 min read#javascriptInstalling Polyglot NotebooksMatt Eland ・ May 9 ・ 3 min read#polyglotnotebooks#dotnet#datascience#vscodeProductivity in Working ParentsTori Crawford ・ May 9 ・ 4 min read#productivity#motivation#careerLimitations of Docker image builds in Bitbucket PipelinesKyle Galbraith ・ May 11 ・ 5 min read#docker#devops#bitbucketHow has development changed over the course of the pandemic?Geoff Stevens for Software.com ・ May 9 ・ 3 min read#productivity#ai#news#developmentThe Ethics of Generative AI Part I - Some VocabularyJen Looper ・ May 7 ・ 7 min read#ai#chatgpt#machinelearning#education☸️ How to deploy a secured OVH managed Kubernetes cluster using Terraform in 2023Benoît COUETIL for Zenika ・ May 5 ・ 11 min read#ovh#terraform#kubernetes#cloudBeyond Senior - Fire! Fire!Brandon Weaver ・ May 11 ・ 4 min read#staff#leadership#careerConfiguring HashiCorp Vault In AWS For High Availability In KubernetesMichael Levan ・ May 9 ・ 6 min read#kubernetes#hashicorp#devops#cloudPlease check these articles out -- hope you enjoy!
731,"If you're familiar with the AWS Well-Architected Framework, you'll know that it offers a set of best practices designed to help you achieve secure, high-performing, resilient, and efficient infrastructure for your applications. But with a vast amount of information available, navigating the framework can be a daunting task.This is why I decided to develop a chatbot to answer questions related to the framework, offering developers quick, accurate responses complete with supporting document links. If you're interested in how this project started, I encourage you to check out my previous post.Now, in this follow-up article, I'll guide you through the process of building an enhanced version of the chatbot using the open-source library, LangChain.LangChain enhances the functionality of large language model (LLM) applications, providing features such as prompt management, chains for call sequences, and data augmented generation. This step-by-step guide will cover:• Data Collection• Text Embedding Creation• Prompt Engineering• Chat Interface DevelopmentYou can try the chatbot here.And check out the GitHub repo with the code here.  Data Collection: Web ScrappingTo obtain all the necessary links from the Well-Architected Framework, I extracted all the URLs from the sitemaps. The sitemaps provide a list of all links on the page, which allowed me to efficiently create a script to fetch all the text for each page. Here's the Python function I used:def extract_urls_from_sitemap(sitemap_url):    response = requests.get(sitemap_url)    if response.status_code != 200:        print(f""Failed to fetch sitemap: {response.status_code}"")        return []    sitemap_content = response.content    root = ET.fromstring(sitemap_content)    # Extract the URLs from the sitemap    urls = [        elem.text        for elem in root.iter(""{http://www.sitemaps.org/schemas/sitemap/0.9}loc"")    ]    return urls # Site maps for the AWS Well-Architected Framework    sitemap_url_list = [        ""https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sitemap.xml"",        ""https://docs.aws.amazon.com/wellarchitected/latest/framework/sitemap.xml"",        ""https://docs.aws.amazon.com/wellarchitected/latest/operational-excellence-pillar/sitemap.xml"",        ""https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/sitemap.xml"",        ""https://docs.aws.amazon.com/wellarchitected/latest/performance-efficiency-pillar/sitemap.xml"",        ""https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/sitemap.xml"",        ""https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/sitemap.xml"",    ]    # Get all links from the sitemaps    full_sitemap_list = []    for sitemap in sitemap_url_list:        full_sitemap_list.extend(extract_urls_from_sitemap(sitemap))Enter fullscreen modeExit fullscreen modeOnce I compiled the list, I used the LangChain Selenium Document Loader to extract all the text from each page, dividing the text into chunks of 1000 characters. Breaking the text into 1000-character chunks simplifies handling large volumes of data and ensures that the text is in useful digestible segments for the model to process.def load_html_text(sitemap_urls):    loader = SeleniumURLLoader(urls=sitemap_urls)    data = loader.load()    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)    texts = text_splitter.split_documents(data)    return textsEnter fullscreen modeExit fullscreen mode  Creating Text EmbeddingsNext, I generated text embeddings for each of the pages using the OpenAI's embeddings API. Text embeddings are vectors (lists) of floating-point numbers used to measure the relatedness of text strings. They are commonly used for various tasks such as search, clustering, recommendations, anomaly detection, diversity measurement, and classification. Once the embeddings were generated, I used the vector search library Faiss to create an index, enabling rapid text searching for each user query.def embed_text(texts, save_loc):    embeddings = OpenAIEmbeddings(openai_api_key=os.environ[""OPENAI_API_KEY""])    docsearch = FAISS.from_documents(texts, embeddings)    docsearch.save_local(save_loc)Enter fullscreen modeExit fullscreen modeCheck out the full ingestion pipeline here.  Building the LLM Chain: Prompt EngineeringWith the data ready, it was time to build the LLM chain to respond to user queries. The first step involved creating a PromptTemplate, which is a schema representing a prompt that can be passed to an LLM. This template consisted of a system prompt and two variables: the user's question and the context from the Well-Architected Framework relevant to the question.TEMPLATE = """"""You are an AWS Certified Solutions Architect. Your role is to help customers understand best practices on building on AWS. Return your response in markdown, so you can bold and highlight important steps for customers. If the answer cannot be found within the context, write 'I could not find an answer' Use the following context from the AWS Well-Architected Framework to answer the user's query. Make sure to read all the context before providing an answer.\nContext:\n{context}\nQuestion: {question}""""""QA_PROMPT = PromptTemplate(template=TEMPLATE, input_variables=[""question"", ""context""])Enter fullscreen modeExit fullscreen modeNext, I set up the process to use the LLM to respond to user queries. I instanced the OpenAI model using the ChatOpenAI class and set the parameters (Note: you need your own OpenAI API key). Then, I established the embeddings endpoint for user queries and the local vector store from the scraped data. Finally, I set up the ConversationalRetrievalChain, which facilitates the creation of a chatbot using retrieval augmented generation (RAG) by utilizing the documents for its response.def setup_chain():    llm = ChatOpenAI(        temperature=0.7,        openai_api_key=os.environ[""OPENAI_API_KEY""],        model_name=""gpt-3.5-turbo"",    )    embeddings = OpenAIEmbeddings(openai_api_key=os.environ[""OPENAI_API_KEY""])    vectorstore = FAISS.load_local(""local_index"", embeddings)    chain = ConversationalRetrievalChain.from_llm(        llm, vectorstore.as_retriever(), return_source_documents=True    )    return chainEnter fullscreen modeExit fullscreen modeThe full code is here  Creating the Chat InterfaceThe chat interface was developed using Streamlit, a versatile tool for building interactive Python web applications. This code creates a simple interface with a text input for user queries and a ""Submit"" button to submit the query. When the ""Submit"" button is clicked, the query, along with the chat history, is sent to the LLM chain, which returns a response along with the referenced documents.def app() -> None:    """"""    Purpose:        Controls the app flow    Args:        N/A    Returns:        N/A    """"""    # Spin up the sidebar    sidebar()    with st.container():        # Load chat history        for index, chat in enumerate(st.session_state[""chat_history""]):            message_func(chat[0], True)            message_func(chat[1], False)            # st.write(chat[0])            # st.write(chat[1])            with st.expander(""Resources""):                for doc in st.session_state[""docs""][index]:                    st.write(doc.metadata[""source""])                    st.write(doc.page_content)        with st.form(key=""my_form"", clear_on_submit=True):            query = st.text_input(                ""Query: "",                key=""input"",                value="""",                placeholder=""Type your query here..."",                label_visibility=""hidden"",            )            submit_button = st.form_submit_button(label=""Submit"")        col1, col2 = st.columns([1, 3.2])        reset_button = col1.button(""Reset Chat History"")    if submit_button:        with st.spinner(""Generating...""):            result = chain(                {""question"": query, ""chat_history"": st.session_state[""chat_history""]}            )            st.session_state[""chat_history""].append(                (result[""question""], result[""answer""])            )            st.session_state[""docs""].append(result[""source_documents""])            st.experimental_rerun()  # Add Chat to UI    if reset_button:        st.session_state[""chat_history""] = []        st.session_state[""docs""] = []        st.experimental_rerun()Enter fullscreen modeExit fullscreen modeYou can find the full code here.  ConclusionIn this guide, I've taken you through the process of building an AWS Well-Architected chatbot leveraging LangChain, the OpenAI GPT model, and Streamlit. We began by gathering data from the AWS Well-Architected Framework, proceeded to create text embeddings, and finally used LangChain to invoke the OpenAI LLM to generate responses to user queries.You can interact with the chatbot here.If you're interested in creating your own applications powered by LangChain, I hope this guide has offered useful insights and guidelines. Enjoy coding and exploring the possibilities of language models!Remember, chatbots are powerful tools for simplifying complex processes and making information more accessible. They can be tailored to meet various needs, and with the right tools like LangChain and OpenAI, creating an intelligent, context-aware chatbot is easier than you might think. Happy bot-building!  About the AuthorBanjo is a Senior Developer Advocate at AWS, where he helps builders get excited about using AWS. Banjo is passionate about operationalizing data and has started a podcast, a meetup, and open-source projects around utilizing data. When not building the next big thing, Banjo likes to relax by playing video games, especially JRPGs, and exploring events happening around him."
732,"Let's discuss the thoughts, dreams, and anxieties that keep us up at night. How do they impact our personal and professional lives, and what can we do to manage them effectively? Whether it's a looming project deadline or concerns about the future, let's share our experiences and support each other in finding ways to cope and thrive.Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
733,"Hey devs! Time for another installment in our Best Practices for Writing on DEV series. Before we delve into some guidelines for choosing and framing your topic, I want to talk to you about something I see a lot here on DEV.  ListiclesAhh, listicles. They're kind of an article, but mostly a list. You love them, you hate them, you just can’t get away from them in our current content landscape.Sometimes listicles are great! This one by @asheeshh is a favorite. Other times, though, they come across as repetitive fluff and don’t bring much helpful, interesting, or fresh information to the conversation.  Best Practices for Writing Listicles on DEVIf you love writing listicles, Use These Five Tips To Blow Readers’ Minds And Save The World From Bad Listicles Forever  you might want to consider the following points when drafting:Why am I choosing a listicle format? (If it’s because you don’t have enough knowledge, content, or time for a proper article, consider doing more research or gaining more experience before you write on this topic.)Are there already listicles on this topic on DEV, and if so, is mine better or different than the ones already written? (Use the search bar to find out!)Do I have to title this list of things with a click-baity headline that harkens back to the early days of BuzzFeed? (No, you don’t! You can, but it may turn readers away from clicking—the opposite effect of what you’re going for.)Of course, you are welcome to write whatever and however you want on DEV, as long as it adheres to our Code of Conduct. Just know that high quality listicles that bring something new and valuable to the conversation will be upvoted by moderators and queued for sharing on social…and uninspired, repetitive listicles won’t.That's all for now! Stay tuned for an upcoming post on topics, as well as another one about another hot topic...self-promo on DEV! 😱"
734,"When it comes to coding, your choice of text editor or terminal emulator can have a big impact on your productivity and workflow. So, we want to know: what's your favorite text editor or terminal emulator, and why? Is there a specific feature that you can't live without, or a particular aspect of the interface that makes your coding experience more enjoyable? Are there any lesser-known text editors or terminal emulators that you think deserve more attention? Share your thoughts and opinions with the community, and let's see if we can discover some new favorites!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
735,"This is a common interview question for new coders, and the goal in replying is to show the interviewer that you understand the importance of scalability and maintainability in coding, and that you have experience with techniques and best practices that help ensure these qualities in your code. CodeNewbies: How would you answer - or have you answered - this questions? Experienced Coders: How do you ensure that your code is scalable and maintainable? And what advice would you give for answering this question?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
736,"With the rise of CSS-in-JS libraries such as styled-components and Emotion, there has been a growing debate about which approach is better for web design. In this discussion, let's hear your thoughts on whether CSS or CSS-in-JS is the better approach for web design in 2023.Have you used CSS-in-JS libraries in your projects? Do you prefer using traditional CSS or do you find CSS-in-JS to be a better approach? Share your experiences and opinions in the comments below and let's discuss the pros and cons of both approaches."
737,"In every career, there comes a time when we pause and reflect on our journey. We take a moment to contemplate our accomplishments, our experiences, and most importantly, what lies ahead. Today, as I prepare to wrap up my current contract, I find myself in this introspective state. With 23 years of professional experience and 38 years deeply intertwined with the tech industry, I've observed and actively participated in the ceaseless transformation that characterizes this dynamic field. From Apple BASIC to Flash and, most recently, to React and Vue, my career has been a rich and diverse tapestry of experiences.Diving into the time capsule, we land in the era of Apple BASIC, the starting point of my journey. In the late 70s and 80s, Apple BASIC, or Beginner's All-purpose Symbolic Instruction Code, was the bedrock for many burgeoning developers. As a high-level programming language, it was designed to be user-friendly, opening the doors to programming for many amateurs like me. The simplicity and accessibility of Apple BASIC were revolutionary at the time, and it served as my stepping stone into the complex world of coding.As the landscape of technology shifted, so did my career. The 2000s saw a boom in the adoption of Flash. For two years, I exclusively worked with this platform, developing interactive web content that was then the cutting edge of online engagement. Flash was a playground of creativity and innovation, enabling multimedia content like games, animations, and rich internet applications. However, the decline of Flash was as rapid as its rise due to numerous issues, including security vulnerabilities and the advent of HTML5.In the most recent chapters of my career, I've immersed myself in React and Vue. These JavaScript libraries and frameworks have emerged as the industry standard for building user interfaces. React, developed by Facebook, and Vue, a progressive framework, offer an efficient, scalable solution for crafting modern web applications. Their popularity is a testament to their robustness and adaptability; working with them has been an invigorating experience.Looking back, it's incredible how technology has transformed over the years and how these changes have punctuated my career. From Apple BASIC's simplicity to Flash's multimedia potential to the dynamic and scalable world of React and Vue, each stage of my journey has been an opportunity to grow and learn.As I stand at this crossroads, contemplating the ""What's next?"" of my career, I can't help but feel a rush of excitement. With its relentless pace of innovation, the tech industry is full of surprises and possibilities. Will I dive deeper into the evolving world of JavaScript frameworks or explore the burgeoning AI and machine learning fields? The beauty of this industry is that it's constantly changing, always offering new challenges and opportunities.In this rapidly changing world, one thing remains constant: the joy of coding, the thrill of problem-solving, and the satisfaction of creating something valuable from a string of commands. As I embark on the next stage of my journey, I'm eager to see where the tides of technology will take me next. I invite you all to join me on this journey as we delve into the future of tech, one line of code at a time.Looking ahead, my love for front-end development remains unwavering. The art of crafting intuitive, engaging user experiences with HTML, CSS, JavaScript, and, increasingly, TypeScript is a passion that continues to fuel my drive. However, I'm also inspired by the prospect of integrating new technologies into my repertoire. Recently, two languages have particularly caught my attention - Rust and GoLang.Rust, a language designed for performance and safety, exceptionally safe concurrency, intrigues me. It's like the stalwart bodyguard of system programming, protecting against segfaults and guaranteeing thread safety. Rust's minimal runtime makes it ideal for embedding into other languages, opening up a world of potential to create high-performance plugins for the JavaScript engines.On the other hand, GoLang, developed by Google, is gaining traction for its simplicity and efficiency. It's designed for the era of multicore processors and networked systems, making it ideal for back-end development. The robust standard library, efficient garbage collection, and simplicity of Go make it a strong contender for creating APIs, web servers, and even tying together microservices.So, how can we tie these technologies with my deep-rooted love for front-end work? Well, there's a fascinating symbiosis that can occur here. For instance, Rust and WebAssembly (Wasm) can work together to boost the performance of high-intensity web applications. Rust compiles to Wasm, a binary instruction format for a stack-based virtual machine, enabling you to write high-performance code for web applications. This can be particularly useful for performance-critical scenarios, such as gaming, animation, or even data visualization, bringing together my love for the front end and the robustness of Rust.Incorporating GoLang in a full-stack JavaScript environment can also prove advantageous. Using Go for writing the back end, where its performance and simplicity shine, while sticking to React or Vue on the front end can lead to a highly efficient, scalable application architecture. Moreover, with TypeScript's static typing providing a safety net, we can bridge the gap between JavaScript's flexibility and Go's strict typing system.This fusion of technologies, as disparate as they may seem, could mark the beginning of a new chapter in my tech journey. The beauty of our field is that it encourages such exploration, the melding of different tools and languages to create something new and exciting.In essence, the journey of a software developer is an endless adventure of unending learning and constant metamorphosis. Among the ever-evolving landscape, a few things stand unchanging: the sheer pleasure of writing code, the exhilaration of unraveling complex problems, and the fulfillment that comes from transforming mere lines of syntax into a valuable, functioning entity. As I stand on the precipice of my next professional chapter, I am eager to delve deeper into Rust and GoLang, believing they promise to enhance my front-end capabilities, forging even more dynamic, efficient, and captivating user experiences. Technology is a boundless sea, and I'm merely embarking on this new voyage. The future holds unknown yet exciting revelations. So, here's to a future where the adaptability of JavaScript intertwines with the speed of Rust and the simplicity of GoLang. I invite you to accompany me as we navigate the future of technology, one line of code at a time."
738,The adoption of remote work and digital collaboration tools has accelerated in the wake of the COVID pandemic. How can coding be used to create more efficient and effective remote work environments and foster a sense of connection and productivity among distributed teams?Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
739,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
740,"Hey there! It's Sloan, your friendly neighborhood DEV Moderator 🦥As I lazily scrolled through my inbox earlier today, I stumbled upon a message from a fellow DEV member asking about how badges work on DEV.So, why not take a peek into my inbox for a fresh online advice column and discussion hosted by yours truly? Every week (or so), I'll be diving into the questions, comments, and thoughts of my fellow sloths.  Today's question is:How long does it take for our badges to be updated on our profile when we participate in an event or earn an achievement — for example, Top 7 and WeCoded?This is a great question! I reached out to my human colleague @devencourt for an answer, and here's what they said:Top 7 badges are awarded when the post is published on DEV. If they don't have their Top 7 badge after being featured, they can email us for it, might be an error.Hackathon and badges are awarded once the winners are announced. Other event badges should be awarded within a week of the event closing.Thanks, Brian!I will add that if you're missing any badge you think you should have, please email us at yo@dev.to and let us know which badge you're missing. That way, we can be sure to fix it for you.Thanks for asking, anonymous friend! I love badges on DEV as much as you do, so it's important that we get you the right ones to make your profile shine 🌟Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
741,"Do you resent wasting your time with coding challenges? Keep calm and say that you have decided to stop doing them.Companies have their processes and dealbreakers. Since the hiring process is a two-way street, you are entitled to have your own dealbreakers.   UPDATE: What do I mean here by coding challenge?My article has been grilled by ThePrimeAgen on YouTube. And that was a great honor.I Have Been Grilled by ThePrimeagen on YouTubeJean-Michel (double agent) ・ Apr 28#career#beginners#healthydebateBut I realized I introduced a confusion by not defining the term. I am not talking about all kinds of  challenges that involve coding. I am not talking about algorithmic challenges like ThePrimeAgen thought. I am talking about that kind of coding challenges:Your Coding Challenge: We are a music player app company, so we challenge you to do a simplified music player app, with a lying time estimate of four hours, and then we will evaluate the quality of your code according to unknown criteria.  🤯 I'm allowed to do that? How?There is a completely underrated tool in job hunting. Not it's not an app, and no, it's not ChatGPT. Here is the secret:🙊 Talk with the recruiter that makes the first phone call 🙉I know that you feel the urge to skip that part and talk as fast as possible to someone that understands that vim is better than Emacs. (Obviously, the reverse is true).But skipping that urge is worth its weight in gold.Because you can use this opportunity to, for example, avoid code challenges. What you do is that you get to know each other and the company, then wait for that moment :*So that was in summary who we are as a company, and what we are looking for. Do you have any questions?And indeed, you have questions:Hello yes, can you describe your recruiting process? Which steps would I go through if everything works fine?She will be happy to oblige. Maybe you will need to ask for more precisionYou mention there will be a technical evaluation. How would that go? Is that more like a technical discussion? Or a coding challenge to do at home? Then you hear either:No we don't do coding challenges. We have found they waste too much time for our candidates, and there are other ways to evaluate their technical skills.Then all fine, you have avoided a coding challenge. Or you hearYes indeed, there will be a coding challenge that consists in this and this.That's the crucial moment where you breathe, you stay polite and calm and you say:Thank you for clarifying that. Well, I have to be transparent with you, I had bad experiences in the past with coding challenges and I have decided to stop accepting them.Just like that.What happens next?  🙄  Worst Case Scenario: an uncomfortable conversationThe conversation could become uncomfortable.Recruiting is a hard job to do well, and just like programming, requires training and practice.  Unfortunately, too much people are doing recruitment without having been through enough recruiting training. One dude was mad at me and told me how difficult programmers are, etc.If that happens, breathe and do your best to stay calm. You have probably dodged a bullet, and you have kept and improved your self-respect. That's what matters most.  🙅🏻 ""I understand. Well, no deal then""It's more likely though that the recruiter says something like ""Well, I can understand. Now from our side, we have our processes, so I guess it's a dealbreaker"". That's expected and that's fine. They have their company processes and rules. You have, starting today, your candidate processes and rules, the first rule being that you don't do coding challenges.By failing early, you have won something important.You have won time to find other companies that waste less of your timeYou have lost one lead where you may have invested 12 or 24 hours in a coding challenge. And I have personally heard about much more, you wouldn't believe it.During those 12 or 24 hours you can get in touch with way more than one company. That may feel out of reach if that one company is the only one that replied after you send tons of CVs. Then you have another issue, you need to become better at finding companies. That's a topic for another day, but that starts with actually understanding how hiring works from multiple points of view. Which was the subject of my last articleJob Hunting: Just Submit Your CV and Hope for the Best?Jean-Michel (double agent) ・ Apr 17#beginners#career#healthydebate#interviewThat scenario doesn't sound too bad for me? But there is more.  👂🏻 The best recruiters want to understand your concernsDoes it sound too good to be true?No, not at all, that's just the way it works.For the best recruiters, your interests and theirs are actually quite well aligned. Because they are, of course, interested in convincing, not only you, but the candidates after you, to work with them. And the best way to do that is to... actually shape a candidate experience people will want to go through.Nobody is perfect so she might have accepted from their hierarchies that there must be this coding challenge thing. They sweared to her, it will only take up to four hours. Now obviously the guy who tried it was the guy who designed the coding challenge so he knew exactly what to do and did indeed complete it in less than 4 hours. If you tell her that in your experience and in the experience of your friends, that kind of coding challenge takes anything between 8 and 55 hours to actually do, she will listen carefully. She will talk about it internally. Alas It's likely that her hiring manager will not listen because many of those, alas, don't respect recruitment.   💊 Pain is a great teacherSomething that developers who struggle to get a job don't realise is that the reverse is also true, companies struggle to hire developers. Not top companies like Forem. But really, at the average company, developer positions stay vacant for many months.If the hiring manager, one month after you spoke out, realise that the position is still not being filled, and ask what can be done about it? The good recruiter will bring the candidate pain point to the table once again. Maybe another developer was brave enough to do the same thing as you and explain to her politely why he doesn't like and doesn't do coding challengers anymore. He would have given other arguments and she will use that ammunition to shape things up.Because, really, it's in everyone's best interest.  💯 Not only you have avoided a coding challenge, you have helped others after you to avoid it too.🙏🏻Thanks for readingPlease send my article to a friend that needs it, or to that smart recruiter who is ready to listen to your concerns.Hi, I’m Jean-Michel Fayard. On my website, I have Careers Resources for Developers, and if that's not enough, you can ask me a question."
742,"We're already halfway through the GitHub + DEV 2023 Hackathon! Congratulations to those who have already posted their projects.For those who haven't finished yet, don't worry! There's still plenty of time to make progress and submit your project. Remember, the most important thing is to try your best and learn something new throughout the hackathon. We want to take a moment to ask: how are your projects going? Have you hit any roadblocks? Do you need any help? Don't hesitate to reach out to the community for support in our official help thread.We can't wait to see what amazing creations you come up with in the second half of the hackathon. Keep up the great work!"
743,"Hey everybody 👋Hope all you folks enjoy your weekends!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugCooking up a delicious meal 🍛"
744,"Google IO just got over and it was packed with exciting information, Here are a few highlights.  PaLM 2Google AI introduces PaLM 2, a new language model with improved multilingual, reasoning, and coding capabilities. It is available in four sizes, from Gecko (small and fast enough for mobile devices) to Unicorn (large and powerful).Learn more here  Bard        Google              @google            Today we’re removing the waitlist process and making Bard available in over 180 countries and territories, with more coming soon. 🎉#GoogleIO      17:27 PM - 10 May 2023    Google AI's Bard is now available to over 180 countries and is powered by PaLM2, a new language model with improved multilingual, reasoning, and coding capabilities. Bard can do things like generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way.Here are a few features of Bard with PaLM2:Multilingual: Bard can understand and generate text in over 100 languages.Reasoning: Bard can perform complex logical reasoning and solve math problems.Coding: Bard can generate code in a variety of programming languages.Creativity: Bard can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.Information: Bard can answer your questions in an informative way, even if they are open ended, challenging, or strange.  Vertex AIVertex AI is a fully managed machine learning (ML) platform that helps you build, deploy, and scale ML models faster. It provides a unified data and AI platform, tooling for pre-trained and custom models, and MLOps practices to efficiently scale, manage, monitor, and govern your ML workloads. New customers get $300 in free credits to spend on Vertex AI.Check it out here   MediapipeCheck it out here A suite of customizable ML solutions makes it easy to create innovative on-device ML solutions. These solutions are designed to be easy to use, even for beginners, and include advanced ML solutions for popular tasks, such as face detection, pose estimation, and object tracking. They are also fast and efficient, making them ideal for a wide range of applications, from mobile devices to embedded systems.Thanks for reading! and let me know what your favorite announcements from Google IO were."
745,"GitHub Copilot CLI comes with three aliases:??: Ask for a generic shell commandgit?: Ask for a git commandgh?: Ask for a GitHub CLI commandToday I play with git? to test how accurate the suggestions are and how easy it is to get the right command. You can find the video here, or at the end of the postSpoiler: if you run AI generated commands without understanding what they do, the outcome is... unpredictable 😅  Unharmful exampleAt the beginning of the video you'll see me asking a pretty simple question, basically creating a new branch from main.The suggested code is:git switch -c <branch> mainEnter fullscreen modeExit fullscreen modeI'm happy so I run the command and...(eval):1: no such file or directory: branchEnter fullscreen modeExit fullscreen modeWait, what? Ah, I forgot to replace <branch> with the actual branch name 🤦‍♂️This was entirely my fault but luckily nothing bad happened, I revised the query and set the right name.  Potentially harmful exampleHowever, later in the video I try to move and remove commits and the first suggestion is:git reset --hard HEAD~1Enter fullscreen modeExit fullscreen modeImagine running it without understanding what it does... ok sure, with reflog you can recover the lost commit but if you're unaware of that you'll probably just panic because of all the changes you just lost. Doesn't seem like a cool situation to be in.Actually, while writing this article I realized I could have just asked this in the video:git? recover the last hard reset commitEnter fullscreen modeExit fullscreen modeI did it now and the first suggestion is: ──────────────────── Command ────────────────────git refloggit reset --hard HEAD@{1} ────────────────── Explanation ──────────────────○ git reflog lists all commits that are no longer referenced by any branch.○ git reset resets the current branch to a previous commit.  ◆ --hard means that we also discard any changes made to the files in the working directory.  ◆ HEAD@{1} specifies that we reset to the commit one before the current one.Enter fullscreen modeExit fullscreen modeIf you just didn't remember the syntax, this is great, but if you're not sure what you're doing... imagine being told by an AI that to restore a hard reset you need to do another hard reset. Wouldn't that be scary? Let me know what you think!  Fun factI didn't realize I had Copilot Voice turned on when I started recording the video. At some point I said something like:I'm on a branch called copilot-x-test, but is it correct?And after a second I heard a voice coming out from my speakers:It depends on the task. You should make sure that the task is valid and reliable before taking itAaaah it was Copilot Voice!  Full DemoAnyway, here's the full video where I play with Copilot X CLI, asking for git commands and giving you my personal thoughts on the AI generated suggestions.Thanks for reading this article, I hope you found it interesting!I recently launched my Discord server to talk about Open Source and Web Development, feel free to join: https://discord.gg/bqwyEa6We6Do you like my content? You might consider subscribing to my YouTube channel! It means a lot to me ❤️You can find it here:Feel free to follow me to get notified when new articles are out ;)Leonardo MontiniFollowI talk about Open Source, GitHub, and Web Development. I also run a YouTube channel called DevLeonardo, see you there!"
746,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @quii's Top 7 post, tonight’s topic is...HTMX! HTMX is the futureChris James ・ May 5#htmx#webdevUnlike SPAs, HTMX doesn't throw away the architectural approach of REST; it augments the browser, improving its hypermedia capabilities and making it simpler to deliver a rich client experience without having to write much JavaScript if any at all.Questions:Do you think HTMX is the future? Why or why not?Have you had a chance to implement HTMX yet? What did you think?If you haven't used HTMX...why not?Any triumphs, fails, or other stories you'd like to share on this topic?"
747,"Have you ever experienced a toxic or dysfunctional coding culture? What made it challenging to work in that environment, and how did you respond to it? How did it affect your work and your motivation, and what lessons did you learn from that experience? In your opinion, what are some key factors that contribute to a positive and healthy coding culture, and how can teams and organizations work to create that kind of environment?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
748,"I watched a presentation over YouTube yesterday that got me pretty freaked about the potential issues that may arise with the creation of AI. You can check it out here:A data point that they continuously return to is: 50% of AI researchers believe there's a 10% or greater chance that humans go extinct from our inability to control AIThey site the 2022 Expert Survey on Progress in AI as the source for this info, specifically answers to the question:What probability do you put on human inability to control future advanced AI systems causing human extinction or similarly permanent and severe disempowerment of the human species?When AI experts feel that there is a 1/10 chance of us going extinct from AI, it's cause for concern in my book.I highly recommend checking out the video. They do a great job explaining how the field of AI has changed over the past 5 years and how/why it's progress is rapidly accelerating. They give specific examples of AI being used nefariously today and talk about the potential harm that may come. They also talk about how it can be so difficult to foresee these issues, comparing this point time to the advent of social media — how we didn't realize that this tech would bring about new problems or amplify existing ones, things like: information overload, addiction, doomscrolling, influencer culture, sexualization of kids, Qanon, and more. These things weren't the intended outcome, but they were very real effects that we're still contending with today.I really hope that we take more time thinking about the negative effects that AI may cause before deploying these things into the world. We know that this is highly impactful tech with a lot of potential for good, but if we move too fast and don't think about the potential consequences, we may end up with a whole slew of AI-driven issues that we're not prepared to contend with."
749,"As a writer, I like answering real questions people have because I know for sure that at least one person is interested in what I may have to say.In turn you may be interested by some of my recent career-related answers.  😇 What Makes Working in Tech Truly Rewarding?Jean-Michel (double agent)•    Apr 10  Lots of smart people with a culture of sharing knowledge  🔬 Specialization vs. Generalization: Which Is Better for Programmers?Jean-Michel (double agent)•    Apr 25  • Edited on May 3• EditedI'm a specialist in one thing: learning new things, which includes teaching others.  💃🕺🏻 Is it easier to work alone than to work with others?Jean-Michel (double agent)•    Apr 12  • Edited on May 4• EditedThe tradeoff is that when you work alone, you work faster especially initially, whereas when you work in a good team, you can go far together.  👌🏻 How do I figure out what I am good at ?Jean-Michel (double agent)•    Mar 30  • Edited on Jul 30• EditedEvery time I watch people on linkedin and think about it I feel like I haven't had expertise in anything throughout these 5 yearsWhat people put on LinkedIn is a bunch of self flatering lies.Don’t compare your back-of-stage to everyone else’s front-of-stageTest lots of stuff.If you don't like it, stop.If you like it, do it more.  💨 Describe programming in three wordsBuild, Measure & Learn  🦸🏻‍♂️ Coding Heroes: Who Inspires and Motivates You?Jean-Michel (double agent)•    Apr 18  • Edited on Apr 18• EditedIt's sad that I can't find it, but there was an article/interview with a lone Google engineer who explained how he was doing the grunt work of keeping Google Scholar alive and making it 1% better. A maintenance task that is not in the top 100 priorities of his company. Meanwhile his colleagues were launching hype soon retired new products and chasing promotions. He chose instead to make life a tiny bit easier for some of the best minds of our time to produce their work.That I find inspirational: forget your ego and make an impact by removing obstacles for others to do their best work.  ❤️ How and why did you start contributing to Open Source?Jean-Michel (double agent)•    Apr 12  • Edited on May 4• EditedImportant question because OpenSource had a very profound impact on my career.At some point, when I was interviewing, people told me ""Oh, you are the author of refreshVersions? We use it and it's pretty cool"".And I cannot empathize enough how much this changed the conversations I had with those companies.Suddenly I was not anymore the incompetent liar until proved otherwise.But contributing was a long time in the making.I was interested in the philosophy of open source long before I actually started contributing heavily.And when I started contributing, I did lots of mistake, like a cloning a repo of perfect strangers, not talking with them, doing a huge amount of work, send a PR and hope for the best.I gave my tips on how to do things better than that hereCan beginners make a simple but meaningful contribution? Some unconventional advice #hacktoberfestJean-Michel Fayard 🇫🇷🇩🇪🇬🇧🇪🇸🇨🇴 ・ Oct 1 '22 ・ 7 min read#beginners#opensource#hacktoberfest#github  💯 What Is Your Greatest (Unique) Strength as a Developer?Jean-Michel (double agent)•    Mar 29  • Edited on Mar 29• EditedAs a team lead, I started at my last job to emphatically and regularly say that I didn't have the answers, I merely had lots of practice in turning my ignorance into questions that could then be answered with Google/Wikipedia/My IDE/Whatever.So during our Slack meetings, I started the habit to share my screen, say ""I don't have the answer here but what I would do is to ask me whether xxx, so I would search for yyy in zzz (do it live). Oh here I find that xxx but I wonder if yyy so I would do zzz (do it live). Oh guys I think we have the solution now"".After a few sceances, my colleagues were like ""holy shit, I'm now pretty sure I could find the answers myself by using the same method"".IMHO Socrates would have been the best developer of his timeSocratic methodThe Socratic method is a form of cooperative argumentative dialogue between individuals, based on asking and answering questions to stimulate critical thinking and to draw out ideas and underlying presuppositions. It is named after the Classical Greek philosopher Socrates and is introduced by him in Plato's Theaetetus as midwifery because it is employed to bring out definitions implicit in the interlocutors' beliefs, or to help them further their understanding.View on Wikipedia  😛 Need a Good Laugh? Tell Us Your Favorite Coder Jokes.Jean-Michel (double agent)•    Apr 8  • Edited on Apr 8• EditedThat's a great question, and after reading it, I totally needed to write down my own collection of programming wisdom.“The three chief virtues of a programmer are: Laziness, Impatience and Hubris” ― Larry Wall,There are only two really difficult things in programming: cache invalidation, naming things and off by one errors.UNIX is sexy: who | grep -i single | date ; cd ~ ; unzip ; touch ; strip ; finger ; mount ; gasp ; yes ; uptime ; unmount ; sleepSome people, when confronted with a problem, think ""I know, I'll use regular expressions."" Now they have two problems.There are two major products that come out of Berkeley: LSD and UNIX.  We don’t believe this to be a coincidence.”Even more at ➡ jmfayard.dev/programming-quotes/  😤 I want to be $jobTitle but my company doesn't care. What can I do?Jean-Michel (double agent)•    May 2  • Edited on May 2• EditedMy view is simple: Job titles are mostly meaningless. What is important for you?That someone has the title of writer, or that she write cool books?Therefore the question is not what a senior developer is, it is what a senior developer does.Once you know that, you can do those things long before you give yourself the title. If you feel like it obviously, no pressure.  You can lead before you are officially the lead of your team.  You can organize retrospective, compare alternatives, think about architecture, train your colleagues, ... long before you have the title of senior developer.Related:What is a Senior Developer *Really*?Marc Backes ・ Oct 15 '20 ・ 3 min read#career  🧐 Which Questions Should You Be Asking at your Technical Interview?Jean-Michel (double agent)•    Apr 25  • Edited on May 3• EditedMy first favorite question to ask in a job interview is simplyWhy did you choose to work here rather than somewhere else?I never not ask it. Partly because it feels good to turn the tables a bit, but really because it gives you very interesting insights.Even non answers are interesting, because working there is probably not a good idea.My second favorite question Can you tell about a time where you as an employee noticed that something wasn't working well, decided to talk openly about it, and the company changed something as a result?A great question because we developers are problem solvers, which also means problem detectors, and I don't want to work at places where that's considered annoying.  😓 Sloan's Inbox: Surviving A Job Performance Plan: Is There Hope?Jean-Michel (double agent)•    May 3  • Edited on May 3• EditedI am on a performance plan and I may be fired, is there hope?Yes, there is always hope.It is like a romantic relationship possibly getting to an end.It may hurt, in fact it usually does, but it never means that you are an inherently bad person Or that the other person was a bad a person.The worst case scenario simply means that you were not meant to be/work together.I have been fired two times in 15 years.Both time, this had a very positive impact on me after the initial shock.Not a general rule obviously, but a possible outcome.  That's all for todayHi, I’m Jean-Michel Fayard. Please send my article to a friend that needs it.On my website, I have Careers Resources for Developers, and if that's not enough, you can ask me a question."
750,"Is your code a Pollock? A Picasso? An O'Keefe? Or maybe it's an Edvard Munch! Unleash your inner artists today and tell us: If your code could be transformed into a painting, what would it look like? Would it be a vibrant and bold masterpiece, or a delicate and intricate composition? Share your creative vision and let's see what kind of colorful code we can come up with!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!If you aren't exploring or posting over on the #codenewbie tag, find the tag here!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
751,"UPDATE 07 May 2023: Fixing some typos and grammar errors.First, I want to let you guys and gals know that I moved from Chrome to Firefox yesterday! It's because Chrome 113 came out utterly broken in the stable channel due to Chromium Issue 1356014. The UI scales horribly on my fractional scaled desktop. And even with the --force-device-scale-factor=1 flag that would fix the scaling size, but it will make the whole browser's UI blurry like when running on Xwayland, and the UI behaviors will be so buggy to the point of unusable.However, moving to Firefox is not a smooth journey for me. It's not because of any lockdown from Chrome ecosystem, since there's none, but because Firefox lacks some very basic features that uses by millions of users around the globe. Without further ado, let's get into Firefox's downfalls.  1. No PWA supportThe reason I moved away from Firefox to Chrome in the first place (since long ago) was due to the removal of PWA AKA Progressive Web Apps in the browser, see Mozilla Bugzilla Bug 1682593 and Mozilla Bugzilla Bug 1407202. And I'm sure I'm not the only one who wants this feature back, as it's the #2 most popular idea on their Mozilla Connect page.Well, does this feature affect typical users who are not a computer geek/nerd like me? Let's find out on pwastats.com where there are many PWA's successful cases showing that many people are using PWA on a daily basis. For example, Starbucks sees 2x of daily active users by implementing PWA. Their orders on the desktop are nearly the same rate as mobile. So, who said people on desktops don't use PWA? And according to Smashing Ideas, businesses that transition to PWAs often experience a notable boost in engagement, ranging from a minimum of 20% to as high as 250%, see here. I won't be surprised if more and more business entities start blocking Firefox from their websites because their revenues are on this matter. And if that ever happens, it will affect the end-users more than the others 🥲Lastly, from a development perspective, PWA is beneficial to a solo or a small-team developer, for example, this is the case for Lunch Money and Budgetnuts. And there are still many big-name services that tend to offer their desktop apps only on Windows and Mac but not on Linux, for instance, Framer provides the desktop apps on Windows and Mac, and PWA on other platforms. Therefore, PWA also brings more freedom to the end-users to use their preferred OS without affecting their current workflow.Oh, and there's PWAsForFirefox add-on. However, there are a lot of limitations. I don't think I would want to use it in place of Chromium's PWA implementation.For whatever the cases, removing PWA support from the browser is really a dumb idea.  2. No Chromecast supportChromecast is available in all smart TVs sold around the globe in 2023. According to Statista, TV was sold around 240 million units last year alone. The smart streaming devices are expected to be sold at around 280 million pieces by 2028. Firefox would miss all those users since it doesn't support Chromecast. Chromecast was removed from Firefox 8 years ago, see Mozilla Bugzilla Bug 1142521. And there's a proposal to bring it back in the browser, both at Bugzilla (around 8 years ago) and Mozilla Connect pages, but to no avail.There's an extension called fx_cast that lets you cast from Firefox to Chromecast devices. However, the installation process is clunky for most people, hence should be added to the core instead of living as an add-on that no one knows how long it will last which could lead to compatibility issue in the future.Fortunately, I don't use Chromecast because I use 100 inches (2.54 m) projector as my laptop monitor. Therefore, I don't miss this feature so much, but the numbers don't lie.  3. Facebook's notification doesn't work for a while nowAccording to DemandSage, Facebook has 2 billion daily active users as of 2023..., but Firefox is broken on this site, see Mozilla Bugzilla Bug 1766208.I don't think there's more explanation needed for this issue, as it's effecting some 2 billion people on a daily basis for a year now, but Mozilla is still chilling.  4. Google Search doesn't work correctly in Firefox due to the missing standard that's implemented in all other browsersThe standard that's missing in Firefox and makes it unusable on Google Search is scroll-to-text-fragment, see here. This feature enables the browser to scroll to a highlight text with a URL that ended with #:~:text format. Google Search uses this a lot as it helps the users to find the relevant info easily. And it's very helpful to share this type of link with your friends, so they don't have to ctrl+F all the time.This feature consists of 2 parts:An ability to create a sharable link with fragment text in the first place. There's an add-on called Link to Text Fragment to do that in Firefox.An ability to view this type of link. There's an add-on called auto find text fragment which doesn't work, at least with Firefox 112 as of this writing.There's an idea about this opening on Mozilla Connect, see here.This feature is currently supported in all other browsers, even in Safari 😂, but not in Firefox 🥲   5. Missing a language translation on mobileAccording to daytranslations.com, there's 40% of the world population who speaks only one language. It means that most people speak more than one language. And according to techjury.net(Source: Statcounter), around 60% of website traffic came from mobile in 2022.However, Firefox seems to miss all of these numbers altogether. People usually use the same browser on both their mobile and desktop to sync their data across all their devices. Therefore, if the browser doing worse on any of the platforms, people will switch away.I am a trilingual myself, and having no way to translate some pages on mobile securely put me in a very hard time.Fortunately, Mozilla finally noticed this issue and is making the feature available on Android through their Firefox Translations add-on. But it's only available on Beta and Nightly channel at the moment. I hope this feature lands on Stable channel soon. However, I don't know whether it will be too late for them, as at the time of this writing, the add-on only supports 10 languages. IMO, the best-selling point of this add-on is the user privacy, since the translation works offline.I am using the add-on on desktop. It's working great 👍 At least, when compared to the one that's recently added in Brave.  ConclusionFor a long long time, I always want to support Firefox. But their decisions were and are... totally out of this world, and in a bad way. Many people usually explain how Google abuse the market. But even for me, in my humble opinion in full, it's a lot harder for me to move from Chrome to Firefox than when I moved from Windows to Linux.Honestly, I don't think Google is the reason Firefox fail. It's Firefox that shooting itself in the foot. For millions or even billions of users, Chrome/Chromium based browsers work much better than Firefox. Maybe, we pour too much support in the wrong hand. IDK, if we poured support in Chromium instead of Firefox, we might have a working browser on Linux a long time ago. We can fork Chromium however we want anyway.Not only that, but I don't believe Mozilla will change their behavior anytime soon. Therefore, I will go back to Chrome, or even better, Brave, when Chromium gets itself together on Linux. I think this's it for today, bye 💨Cover Photo by Tansu Topuzoğlu on UnsplashPlane's cockpit Photo by Heng Films on UnsplashPlan Crash #1 Photo by Benjamin Behre on UnsplashPlan Crash #2 Photo by Martin Robles on UnsplashPlan Crash #3 Photo by Martin Robles on UnsplashPlan Crash #4 Photo by Daniele Buso on UnsplashSmoking Photo by Dominik Kempf on Unsplash"
752,"Music is a universal language that has the power to evoke emotions, communicate stories, and connect people. With advances in artificial intelligence, songwriting is no longer limited to humans alone. CHATGPT, a powerful language model developed by OpenAI, is revolutionizing the way we approach songwriting. When combined with Sonic Pi, an innovative live coding music synthesizer, the possibilities are endless. Here we'll explore how you can use CHATGPT and Sonic Pi to craft unique songs that resonate with your creative spirit.Getting Started with CHATGPT:CHATGPT is an AI model designed to understand and generate human-like text based on a given context or prompt. It's versatile enough to help you write anything from blog posts to song lyrics. To get started, you need to have access to the CHATGPT API. There are numerous platforms and tools that can help you interact with the model, such as OpenAI's website or other third-party applications.Crafting Lyrics with CHATGPT:Once you have access to CHATGPT, you can begin generating lyrics by providing it with a prompt or context. For example, if you want to write a love song, you can simply provide a prompt like ""Write a love song chorus."" CHATGPT will then generate several lines of lyrics that fit your request. You can continue the process to develop verses, bridges, and other sections of your song. Feel free to experiment with different themes, styles, and genres to create a diverse range of songs.Discovering Sonic Pi:Sonic Pi is an open-source programming environment that allows you to create music through code. Designed for both beginners and experienced musicians, Sonic Pi provides an accessible platform for composing, improvising, and performing music. To get started, download and install Sonic Pi from their official website (www.sonic-pi.net.  Composing Melodies & Harmonies with Sonic Pi:Sonic Pi uses the Ruby programming language, making it easy to create music by writing simple lines of code. Start by exploring the built-in samples and synthesizers to create unique sounds. You can experiment with different musical elements such as pitch, duration, and amplitude to craft your melodies and harmonies.For example, to create a simple melody, you can use the play function followed by a note value:play 60sleep 1play 62sleep 1play 64Enter fullscreen modeExit fullscreen modeThis code snippet will play three notes (C4, D4, and E4) with a one-second gap between each note.  Adding Rhythms and Percussion:Sonic Pi makes it easy to add rhythm and percussion to your songs. You can either use built-in drum samples or create your own percussive sounds using synthesizers. Create loops and use various timing functions to control the rhythm and pace of your song.For example, to create a basic drum beat, you can use the following code:loop do  sample :drum_heavy_kick  sleep 1  sample :drum_snare_hard  sleep 1endEnter fullscreen modeExit fullscreen mode  Experiment and Refine:The true beauty of using CHATGPT and Sonic Pi lies in the ability to experiment and refine your creations. Feel free to play around with different synthesizers, samples, and code structures to create the perfect song. As you become more comfortable with both tools, you can even incorporate live coding techniques to improvise and perform your songs in real-time.Creating a whole song with lyrics and music using CHATGPT and Sonic Pi involves multiple steps. Here's a step-by-step guide to help you craft your masterpiece:Step 1: Generate Lyrics with CHATGPTFirst, use CHATGPT to create lyrics for your song. Provide a prompt with the theme or mood you want to convey. For example, let's create an uplifting song about resilience:Prompt: ""Write an uplifting verse and chorus about resilience.""Generated Lyrics:Verse 1:When the storm arrives, and the winds grow strong,Remember, my friend, you're where you belong.Through the darkest nights and the heaviest rain,You'll find your strength and rise once again.Enter fullscreen modeExit fullscreen modeChorus:Rise up, rise up, let your spirit soar,Break the chains that hold you, let your heart roar.No storm can keep you down, no wind can blow you away,You are resilient, and you're here to stay.Enter fullscreen modeExit fullscreen modeStep 2: Compose Music with Sonic PiNext, compose music for your song using Sonic Pi. We'll create a simple melody, harmony, and drum beat.Melody:define :melody do  play_pattern_timed [60, 62, 64, 65], [0.5, 0.5, 0.5, 1]  play_pattern_timed [67, 65, 64, 62], [0.5, 0.5, 0.5, 1]endEnter fullscreen modeExit fullscreen modeHarmony:define :harmony do  play_chord [48, 52, 55], release: 4  sleep 4  play_chord [50, 53, 57], release: 4  sleep 4endEnter fullscreen modeExit fullscreen modeDrum Beat:define :drum_beat do  sample :drum_heavy_kick  sleep 1  sample :drum_snare_hard  sleep 1endEnter fullscreen modeExit fullscreen modeStep 3: Structure the SongOrganize the different sections to create your song's structure. For example, let's arrange our song as: Verse 1, Chorus, Verse 1, Chorus.# Song Structurein_thread do  loop do    drum_beat  endendin_thread do  loop do    harmony  endendin_thread do  loop do    melody  endendsleep 42.times do  melody  sleep 4endEnter fullscreen modeExit fullscreen modeThis code snippet defines multiple threads using the in_thread function to allow the melody, harmony, and drum beat to play simultaneously. The loop function repeats each part indefinitely. The sleep function is used to create pauses between sections (verse1 and chorus).To hear your creation, save the code above in Sonic Pi and press the ""Run"" button. Remember to adjust the melody, harmony, drum beat, and song structure according to your preferences. You can also create additional verses or sections to further develop your song.Unfortunately, Sonic Pi does not have built-in text-to-speech or singing synthesis functionality. To create a song with singing, you would need to use external tools or software to generate vocals or use pre-recorded vocal samples.One option is to use a Digital Audio Workstation (DAW) like Ableton Live, FL Studio, or Logic Pro to combine the Sonic Pi-generated music with vocals generated or recorded using another tool. You can use text-to-speech or singing synthesis software like Vocaloid to create vocal tracks, and then import those tracks into your DAW. From there, you can mix the vocals with the Sonic Pi-generated music to create your final song.Incorporating AI-powered lyric generation with CHATGPT and the live coding capabilities of Sonic Pi opens up a world of creative possibilities for songwriters and musicians. Whether you're a seasoned composer or a beginner exploring the world of music, this unique collaboration between artificial intelligence and coding can help you craft one-of-a-kind songs that truly express your artistic vision. So, dive in, experiment, and let your creativity soar! Fly my little birds!! Fly!! Let me hear you sing!!"
753,"What's the most unconventional, innovative, or straight-up wildest coding hack you've ever seen? Was it something you came up with, or was it someone else's creative solution? Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
754,"Welcome to the DEV Showcase - a weekly thread where you can share what you've been working on and get feedback and encouragement from the DEV community.This is your chance to show off your latest project, share a cool hack or technique you've learned, or ask for advice and feedback from other developers. Whether you're a seasoned developer or just starting out, this is the place to connect with others and get inspired.Here are a few questions to think about if you're stuck:What have you been working on lately?What tools or resources have you found helpful?Have you learned any new skills or techniques recently?What challenges have you faced, and how can the community help you overcome them?What are your goals for your project or your career moving forward?Remember, this isn't a competition or a challenge - it's just a space to share and connect with others. So don't be shy! Share your work and get feedback and encouragement from the DEV community.We're excited to see what you've been working on, and to support you as you continue to grow and develop your skills. "
755,"OpenAI recently launched a beta feature called ChatGPT plugins. Essentially, this feature enables third-party tools to interact with the GPT model. To assist developers in creating their own plugins for ChatGPT, OpenAI introduced a quickstart repository as a guide. To further enhance accessibility, OpenAI's Developer Advocate, Logan Kilpatrick, contacted technologists who work with browser-based or cloud-based Integrated Development Environments (IDEs). Logan's goal was to enable developers to use the quickstart repository locally or with browser-based IDEs like CodeSandbox and Replit. In doing so, developers could build and experiment with plugins directly in their browsers, eliminating the need to clone the repository. Fortunately, one of the cloud-based environments on the list was GitHub Codespaces. Logan reached out to me about his goal, and I was thrilled to accept the challenge.I had three main reasons for my excitement about adding GitHub Codespaces to the quickstart repository:I would gain access to ChatGPT plugins, which I imagine have a never-ending waitlist.I would gain experience configuring GitHub Codespaces in unfamiliar environments. My experience with GitHub Codespaces is limited to JavaScript-based projects.I'm a nerd.Last week, I officially submitted a pull request to enable GitHub Codespaces for the project. The Codespaces team has already reviewed it, and I'm now waiting for the OpenAI team to do the same. In the meantime, I'm sharing what I've learned throughout this experience in the hope that you can learn more about GitHub Codespaces too!  Prerequisites:This is not necessarily a tutorial that you should follow step by step, but if you did want to follow it, you would need access to the following tools.ChatGPT accountChatGPT pluginsGitHub account It might be helpful to understand the purpose of GitHub Codespaces. You can learn about it from my previous blog post.   A short summary of GitHub CodespacesGitHub Codespaces allows you to code in a container hosted in the cloud. This helps developers onboard faster, code on any device, and code in a consistent environment. The biggest benefit I see for this particular ChatGPT quickstart plugin repository is that developers can try out the plugin functionality without the hassle of cloning the project locally or running any setup scripts. They can try it out without context switching and leaving GitHub. And best of all, they won’t have to do any of the setup. Note: you can open any project in GitHub Codespaces. The UI for GitHub Codespaces can resemble your favorite IDE – like Visual Studio Code or JetBrains, but it’s just in your browser. You can also configure GitHub Codespaces to install all the dependencies and run the project to reduce the time it takes for developers to start working on a project.Here are the steps I took and the lessons I learned while setting up GitHub Codespaces for this project:  Step 1: Get the project working locallyThe first question I needed to answer before configuring GitHub Codespaces was: _how does this project work? What is the end result? _I found my answer by following the local setup instructions found in the repository’s README.md. The instructions were simple: install the required packages and then run the project. Subsequently, the server will run locally on localhost:5003.In ChatGPT, I chose the ‘develop your own plugin’ option.As instructed, I provided ChatGPT with the local address that the server was running on – localhost:5003. After all that, I was able to leverage the plugin to create a simple to do list with ChatGPT.If you want to try it out, check out the README here. Throughout this process, I noted that there's no frontend for this project, so I only had one goal—when anyone opens this project in a codespace, the server should run.  Step 2: Open the repository in GitHub CodespacesThis step ensures that any changes I make are actually compatible with GitHub Codespaces. The code from the repository will be accessible in GitHub Codespaces out of the box, but it won't start running my project or installing dependencies without configuration. So, the next step is to add a configuration file called a devcontainer.json.  Step 3: Add a dev containerDevelopment containers, fondly known as dev containers, are Docker containers that set up a customized environment for the project. I can use a dev container to automatically:Install the necessary extensionsReference environment variablesForward portsInstall dependenciesRun my projectRun scriptsAnd more You can add a default development container by opening the Visual Studio Code Command Palette. This default configuration file contains the basic items you need to get a project running. To open the Visual Studio Code Command Palette, use the following keyboard shortcuts: (Shift+Command+P / Ctrl+Shift+P). Then, search for the option to ""Add dev container configuration files.""It will prompt you to specify your project's language because each development container is slightly different depending on the language, framework, version, and other environmental factors.  For this case, the project is Python-based, so we would choose Python.Unfortunately, I did not follow the advice of adding a development container through the Command Palette. Instead, at the root of my project, I created a folder called .devcontainer. Inside that folder, I created a file called devcontainer.json. I copied and pasted a development container from a past Python project into the devcontainer.json. I did this because the example development container included examples of how to leverage the postAttachCommand and postCreateCommand. However, this was a big mistake that I don't recommend because I ended up copying and pasting different lines that I thought were arbitrary, but they impacted the project, and I had to delete those lines.My recommendation is to use the command palette to add a barebones development container, and then customize it from there.Here's what our boilerplate devcontainer.json file could look like:My recommendation is to use the command palette to add a barebones development container, and then customize it from there.Here’s what our boilerplate devcontainer.json file could look like:// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  // ""forwardPorts"": [],  // Use 'postCreateCommand' to run commands after the container is created.  // ""postCreateCommand"": ""pip3 install --user -r requirements.txt"",  // Configure tool-specific properties.  // ""customizations"": {},  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen mode  Step 4: Customize the dev containerAt this point, the repository now has a development container, but it still doesn’t run or install anything because this development container is just boilerplate, and it has zero knowledge of what my project needs to run automatically.  Install dependenciesBased on the local set up, one of the first steps for this project is to install dependencies by running this command:pip install -r requirements.txtI needed to make GitHub Codespaces run this command, so the developer wouldn’t have to manually run it. I added this line to the postCreateCommand. The postCreateCommand is responsible for running commands after the container is created. The line looked like this:postCreateCommand: pip install -r requirements.txtEnter fullscreen modeExit fullscreen modeSo now, my development container looked like this:// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  // ""forwardPorts"": [],  // Use 'postCreateCommand' to run commands after the container is created.  ""postCreateCommand"": ""pip install -r requirements.txt"",  // Configure tool-specific properties.  // ""customizations"": {},  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen mode  Port ForwardingIn the dev container, there's an option to define a list of ports where the container is available locally. From the local setup, I saw that the preferred port is localhost:5003, so I added that to the array of forwardedPorts in my devcontainer.json file.Here’s what the line looked like:""forwardPorts"": [5003],Enter fullscreen modeExit fullscreen modeHere’s what my devcontainer.json file looked like:// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  ""forwardPorts"": [5003],  // Use 'postCreateCommand' to run commands after the container is created.  ""postCreateCommand"": ""pip install -r requirements.txt"",  // Configure tool-specific properties.  // ""customizations"": {},  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen mode  Run the projectTo locally run the project, developers have to manually run: python main.py, but I wanted GitHub Codespaces to do this instead. I used the postAttachCommand property in my devcontainer.json file to run this command.The postAttachCommand enables scripts to run in the terminal after the client connects to the codespace. Here's the line I added:""postAttachCommand"": “python main.py”Enter fullscreen modeExit fullscreen modeHere’s what my devcontainer.json file looked like:// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  ""forwardPorts"": [5003],  // Use 'postCreateCommand' to run commands after the container is created.  ""postCreateCommand"": ""pip install -r requirements.txt"",  “postAttachCommand”: “python main.py”  // Configure tool-specific properties.  // ""customizations"": {},  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen mode  Step 5: Test by rebuilding the containerI made all these changes to my development container, but I need to check if it actually works, so I rebuilt my container via the Visual Studio Code command palette and chose the option to ""Rebuild container.""After the rebuild was completed, I saw that the Codespace automatically installed the required packages and ran the server on localhost:5003. It also forwarded the port for me to a randomly generated URL that looked like something like:https://USERNAME-CODESPACE-NAME-vrpqrxxrx7x2rxx-5003.preview.app.github.devI copied and pasted the randomly generated URL into ChatGPT, but I received error messages that ChatGPT couldn't find the manifest files nor could it install the plugin.  Step 6: Debugging  Port visibilityI learned that one reason ChatGPT couldn’t find the manifest was because my forwarded port was private, so ChatGPT didn’t have access to the code. Fortunately, I can manually change the port visibility by right clicking the port and switching the visibility from “private” to “public”. I checked to see if there was a way to have GitHub Codespaces set this port to public automatically. However, after I spoke with the GitHub Codespaces, I learned there was no easy way to do this, and it could cause a potential security breach, so I decided users could manually do this.   Updating the filesAnother issue I came across was that there were two files that specified the URL localhost:5003. The names of the files were openapi.yaml and .well-known/ai-plugin.json. However, my new URL was different. It now resembled a randomly generated URL that looked like this: https://USERNAME-CODESPACE-NAME-vrpqrxxrx7x2rxx-5003.preview.app.github.dev.I felt like I was at an impasse and I had two options:I could make developers manually update those files to match their newly generated port. They would just have to follow the directions in the README.md. My problem with this option is that it makes GitHub Codespaces feel clunky. Users already have to update the port visibility and now they have to update the files. (Boo, tomato, tomato, tomato). I wanted to represent GitHub Codespaces in its best light.OR I could edit the source code, and replace the words localhost:5003 with something like https://${CODESPACE_NAME}-5003.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}. However, that would ruin the experience for developers who choose to still develop the plugin locally. I reached out to the Codespaces team for help. They advised me to write a script that dynamically updates the url in those particular files if the repository is opened in a Codespace. The script I wrote looks like this:#!/bin/bashset -e# Determine the value of SITE_HOST based on whether the project is opened in a Codespaceif [ -n ""$CODESPACE_NAME"" ]; then        SITE_HOST=""https://${CODESPACE_NAME}-5003.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}""        # Replace ""localhost:5003"" with the value of SITE_HOST in the ai-plugin.json file        sed -i ""s#http://localhost:5003#${SITE_HOST}#g"" .well-known/ai-plugin.json        # Replace ""localhost:5003"" with the value of SITE_HOST in the openapi.yaml file        sed -i ""s#http://localhost:5003#${SITE_HOST}#g"" openapi.yamlfiEnter fullscreen modeExit fullscreen modeInstead of having the developer manually run this script, I made my codespace run it automatically by adding the following to my devcontainer.json file:""postAttachCommand"": "".devcontainer/addcodespacename.sh && python main.py"",Enter fullscreen modeExit fullscreen modeNow, before the program runs, the codespace will run this shell script and update the files to use the correct URL.Here’s what my devcontainer.json looked like:// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  ""forwardPorts"": [5003],  // Use 'postCreateCommand' to run commands after the container is created.  ""postCreateCommand"": ""pip install -r requirements.txt"",  ""postAttachCommand"": "".devcontainer/addcodespacename.sh && python main.py"",  // Configure tool-specific properties.  // ""customizations"": {},  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen modeI rebuilt the container for testing, and everything worked as expected!  Step 7: Nice-to-haves  Opening important files post-Codespace creationThis is not required, but I thought it would be convenient to have the two most important files opened after the codespace is created. Because this is a new project and just a new concept, I wanted to make it easy for people to navigate the project. And I know there’s a property in a devcontainer.json called openFiles that handles that!Here are the lines I added:    ""customizations"": {        ""codespaces"": {            ""openFiles"": [                "".well-known/ai-plugin.json"",                ""openapi.yaml""            ]        }    }}Enter fullscreen modeExit fullscreen modeHere is what my devcontainer.json file looked like at this point:// For format details, see https://aka.ms/devcontainer.json. For config options, see the// README at: https://github.com/devcontainers/templates/tree/main/src/python{  ""name"": ""Python 3"",  // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile  ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11-bullseye"",  ""features"": {    ""ghcr.io/devcontainers-contrib/features/coverage-py:2"": {}  }  // Features to add to the dev container. More info: https://containers.dev/features.  // ""features"": {},  // Use 'forwardPorts' to make a list of ports inside the container available locally.  ""forwardPorts"": [5003],  // Use 'postCreateCommand' to run commands after the container is created.  ""postCreateCommand"": ""pip install -r requirements.txt"",  ""postAttachCommand"": "".devcontainer/addcodespacename.sh && python main.py"", // Configure tool-specific properties.  ""customizations"": {        ""codespaces"": {            ""openFiles"": [                "".well-known/ai-plugin.json"",                ""openapi.yaml""            ]        }    }}  // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.  // ""remoteUser"": ""root""}Enter fullscreen modeExit fullscreen mode  Step 8: Clean upEverything is working exactly how I wanted, and now I just wanted to clean up any unused properties and confusing comments. Here’s what my final devcontainer.json file looks like:// For format details, see https://aka.ms/devcontainer.json.{    ""name"": ""ChatGPT Quickstart Plugins"",    // Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile    ""image"": ""mcr.microsoft.com/devcontainers/python:0-3.11"",    // Use 'forwardPorts' to make a list of ports inside the container available locally.    ""forwardPorts"": [        5003    ],    // Use 'postCreateCommand' to run commands after the container is created.    ""postCreateCommand"": ""pip install -r requirements.txt"",    ""postAttachCommand"": "".devcontainer/addcodespacename.sh && python main.py"",    ""customizations"": {        ""codespaces"": {f            ""openFiles"": [                "".well-known/ai-plugin.json"",                ""openapi.yaml""            ]        }    }}Enter fullscreen modeExit fullscreen mode  What’s next?I’ll wait for the OpenAI team to either approve or suggest changes to my pull request. I’m looking forward to seeing it get merged! I'd love to contribute more dev containers to open source projects for folks who want to improve their projects' onboarding experience and enable them to work on their projects within GitHub Codespaces.If you have questions or any cool things you learned about development containers or GitHub Codespaces, comment below!"
756,"I've been maintaining a small plugin for WordPress users over the past years.I've also used WordPress for various projects, from small websites to big factories (e.g., multisite, multi-networks).WordPress might do a lot for the popularity of PHP, depsite all the [legitimate] critics you might have against the code.  Gutenberg or not?The core team has introduced Gutenberg, a brand new javascript/react-based editor in 2018.The big change did not come without issues, and a significant part of the WordPress galaxy remains skeptical.Critics like to highlight popular plugins like ""Classic Editor"" or ""Disable Gutenberg"" and their millions of active installs.While you cannot ignore such statistics, pretty much every time a new feature appears in the core, a new plugin is released to disable it.With WordPress, it's not a surprise, it's a tradition.Although, not all plugins reach millions of active installations.  The multiverse of WordPressWordPress has so many applications and usages, from the free platform for blogs (wordpress.org) to the self-hosting solution for individuals and corporate environments, not to mention all derivated products and projects.The featured image of this post is a screenshot from the very end of the movie ""Doctor Strange in the Multiverse of Madness,"" where a mysterious woman appears from nowhere to tell Strange he created an ""incursion.""That's a very geeky way to illustrate the problem here, but, in the movie, an incursion happens when two universes collide, which usually leads to the destruction of both.I sincerely hope WordPress won't end like that, but a significant part of users seem to prefer premium page builders and other third-party solutions to Gutenberg, and this huge ecosystem gets more and more fragmented.  I keep maintaining both editorsAs a plugin maintainer, I like to provide both options, which means my Gutenberg users get a custom integration using React and the Gutenberg API, but others can still use the plugin with a simple metabox.  The battle for E-commerce seems toughWhile the ecosystem has various solutions for E-commerce, for example, the very popular Woocommerce, some companies may be reluctant to use WordPress for various reasons, including the following:self-hosted e-commerce is difficult to secure and maintain (not specific to WordPress)competitors are impressive: Square, ShopifyGutenberg was not meant to boost such usages, and there's not so many blocks available for E-commercebig payment plaftorms like Stripe tend to provide their own integration for static websites which removes the hassle of databases and other dynamic frameworksWordPress may no longer attract all young businesses that need to go online quickly with minimum efforts and budget.  Wrap upI know there are lots of posts that speculate on the potential death of frameworks or even programming languages.We know for sure that the main goal of Gutenberg was full site editing (FSE), and users can already enjoy the first versions of this global WYSIWYG editor (not just for posts), but I genuinely wonder what the future holds for this CMS.Competition is great, and I don't think WordPress itself aims to keep this kind of monopolistic position for eternity."
757,Hello EveryOne I am new here don't know much about this platform btw what's your answer for the above question.
758,"Hello everyone!I hope you're all doing well and had a great weekend! As we start a new week, I'm excited to hear about the cool projects you are working on. Whether it's a personal project or something for work, feel free to share it with us in the comments below.We love to see what our community is up to and would be thrilled to check out your projects, so don't hesitate to include links if you have them. Let's spark some conversations and exchange ideas.Moreover, if you have any questions related to your projects or anything else, feel free to ask! We're here to support each other and help in any way we can.Looking forward to hearing from you all and wishing you a productive week ahead!🔥🔥🔥🔥"
759,Quotes and rules can be great sources of inspiration and guidance in the world of IT. Some of our favorites here at DEV are the Agile Manifesto and this quote by Grace Hopper:The most dangerous phrase in the language is 'we've always done it this way. Share your favorite quotes and rules and discuss how they've helped shape your approach to IT and technology. Follow the DEVteam for more awesome discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
760,"As we know, Ruby is a popular programming language that has gained a lot of traction in recent years. For new coders who are interested in learning Ruby, it would be helpful to hear from experienced developers about the key features that make Ruby easy to use and learn. What do you think? Are there any specific aspects of Ruby that stand out to you as being particularly beneficial for beginners? And how can new coders best take advantage of these features to improve their skills in the language? Let's discuss!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      "
761,"  IntroductionThis is rewritten article from the bugcrowd report submitted by the security researcher Evanconnelly During participation in the Tesla Bug Bounty Program, I was tasked with examining and evaluating the security of numerous Tesla web applications. This process required me to generate multiple Tesla user accounts in order to thoroughly assess the potential vulnerabilities and weaknesses within the system. On one particular occasion, as I was in the process of establishing a new account, my curiosity was piqued by the idea of attempting to register for an account using an email address that belonged to the Tesla domain itself. I wondered whether the system had any built-in security measures to prevent such a scenario, and if not, what potential implications this could have on the overall integrity of the platform.So, like, Tesla's got a bunch of web apps and stuff.For SSO to all these applications, Tesla has two main identity providers (IDPs), auth.tesla.com for external users and sso.telsa.com for employees.My security testing involves auth.tesla.com.I found out that the external auth.tesla.com allows users to sign up for new accounts using @tesla.com and @teslamotors.com email addresses.Also, there is no email verification, which means an account can be created with an email address to which I don't have access.With further testing, any attempt to register an external account with a valid internal Tesla email address reported that the email address was already taken. So at best, my thinking is that under the right conditions, this could be used for pre-account takeovers, which is a fairly low-impact issue.  How to exploit it in other ways?So what about what is essentially the opposite of a pre-account takeover? If I were able to sign up for an account I have used in the past, instead of creating an account with the email address I want to use in the future, the account is no longer active on Tesla's internal IDP, but may still have internally assigned privileges, what about various web applications? After the account is taken over if you wish.I'm fairly familiar with the Tesla Retail Tool (TRT) due to a bug I discovered earlier.TRT stores confidential IT and business information such as network circuit information, local device logins, network logins for ISP and utility accounts, financial information, and details about current, upcoming, and previous Tesla locations, such as lease terms, internal and External contact information, floor plans and interior photos of restricted areas of Tesla properties.I know TRT allows access from internal and external accounts. For authentication, it takes a JWT that specifies an email address that is authenticated against a manually defined list of users in the application. At Tesla's scale, it would be difficult to manually update that list every time an employee leaves.In theory, it should be fine if past employees have defined access to the web app since their IDP accounts will be disabled or deleted, so they won't be able to log into the app through Tesla's internal IDP.But what if it was possible to register an external account using an internal email address of a former Tesla employee who could access TRT and gain access to the web application, while the privileges were still assigned to the now-defunct email address? Will this give me a valid JWT and the victim's email address as if I were logging in through the internal IDP?I used Google Dorks to search the LinkedIn profiles of ex-Tesla employees in positions that should have had access to TRT, especially sensitive information.For example,site:linkedin.com inurl:/in “field systems” “tesla motors” -intitle:tesla -inurl:postsEnter fullscreen modeExit fullscreen modeThis finds the former on-site IT personnel who should have access to network informationIn testing, it was possible to register an account at auth.tesla.com (external IDP) using a former Tesla employee's email, which still had privileges assigned in TRT.I could then use the identity and permissions of a former employee whose internal IDP account may have been wiped to access the Tesla Retail Tool by creating an account on the public IDP with the same email address. This made multiple attempts against multiple email addresses of the former employee.Tesla has two Identity Providers (IDPs), auth.tesla.com for external users and sso.telsa.com for employees.The Tesla Retail Tool (TRT) allows logins from both but does not check the IDP the user is logged into (auth.tesla.com vs sso.tesla.com). This is for Google Dorks, I was able to identify the name and deduce the email address of the ex-Tesla employee, and then register an account with the external IDP using the email address of the ex-employee whose account had been disabled on the internal IDP, but who they Still have the privileges defined by TRT's internal Tesla email addresses, and end up logging into TRT with those user's privileges.  TimelineNovember 19, 2022 - Submit bug reportsNovember 20, 2022 - Tesla verifies the vulnerability and begins the fix processNovember 21, 2022 - I notified Tesla and I can confirm that the account I created in the report no longer has access to TRTNovember 29, 2022 - Tesla is marked as resolved, and bounty awarded  Vulnerability disclosure address: https://bugcrowd.com/disclosures/4d9d22af-3a9f-45ce-8eef-8d4fba06a205/auth-tesla-com-account-takeover-of-internal-tesla-accountsSource:- https://tutorialboy24.blogspot.com/2023/05/authteslacoms-vulnerability-leads-to.html"
762,"As a community of over one million developers from all over the world, we have the opportunity to learn from people with different backgrounds and experiences. How can we create a space where everyone feels comfortable sharing their ideas in our discussions and projects, even if they're different from our own?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
763,"  An odd coincidenceOn March 20th, ChatGPT users reported seeing conversations that were not their own. Just a few weeks earlier I had solved a bug where the default Rails caching library (Dalli) would return incorrect values. I thought, ""this ChatGPT incident sounds a lot like what could happen with that caching bug via returning incorrect cached HTML."" But OpenAI doesn't use Rails so I shrugged the thought off as recency bias.My jaw dropped when I saw the postmortem — it was exactly the same bug concept, just in a different library! A reminder that hard things often transcend particular languages and libraries. And boy, is this a hard bug. It sits at the intersection of caching, shared resource management, and state corruption — infamously tricky problem spaces.  The bug mechanismThe Dalli caching client connects to a memcached server with a socket (which is essentially just a buffer, I'll use the terms interchangeably). The client issues a get message to the server which says ""give me the value for this key"". In response, the server writes some data into the socket buffer. The client then reads bytes off of the socket until it has processed one complete response, making the assumption that what it's reading is the response to its own get message. If the socket was empty at the beginning of the operation, that assumption works and the client returns the correct cache value.But what if the buffer was not empty when the client issued the get command? Then the client processes the data that was on the socket as if it were the requested value, and — since no extra validation steps occur — returns the wrong value for the given key. Worse, because it would only read one value's worth of data out of the buffer (it knows when to stop reading based on a metadata header), the actual response to its request would remain on the socket for the next request to return incorrectly, and so on.The socket has thus entered an indefinite ""off by one"" corrupt state. Meaning the nth get operation will return the value for the n-1th operation's key, leaving its own value in the buffer for the n+1th to read. Oh no! That corrupted state in a different library explains ChatGPT's incident.If your cache system starts returning the wrong values that's very scary from a security perspective, because data or HTML cached for one user might be shown to another user. In the case I saw firsthand this didn't happen because the incorrect cache values all type mismatched, causing the process to error repeatedly until it was killed. That was lucky, but a Rails app conceivably could see the exact kind of incident OpenAI saw. It would just depend on what type of data was on the corrupted socket and how the application uses the cache.  How it happensWhy would there be an unread value in the buffer? All that's required is for the client to send a get command to the server and then fail to actually read the response — while also leaving the socket around for a future request to use.One way this might happen in Dalli is if there's an issue in get_multi code. This could occur if the client requests multiple values, reads some subset of those values off of the socket, and then returns before the server finishes writing all of the values to the socket. Another way this might happen is if something - say, an error or a timeout - interrupts the client code execution between issuing a get message and reading the response.Ideally the client would discard/reset the socket in case of an error or timeout, and in most scenarios that's exactly what would happen. But all it takes is one code path where the socket can get corrupted and stick around. Unfortunately, there is at least one such a code path, explaining the incorrect caching behavior I observed.The specifics are less important than the question of whether the client should rely completely on the assumption that the socket will be empty when it begins a get operation.  The fixAs a security engineer I love when I can solve a bug deep in an abstraction, making it impossible for a developer using the abstraction to cause the bug again — even if they make a mistake. We should encourage developers to avoid known dangers, sure, but it's best for an abstraction itself to prevent unacceptable outcomes automatically. Or, within the abstraction, we should try to manage our state correctly, but it's best if we can preclude the worst impacts even if there's a flaw and some unexpected state emerges. It is far more robust to make a failure case impossible at the root instead of relying on all the higher level code doing the right thing every time.To that end, I pursued a simple foundational fix. Memcached has a getk command, which differs from get by returning the key alongside the value. The downside is a small performance cost — returning the key means processing more bytes. The upside is that the client gets both the key and the value back from memcached, and can check that the key matches what it asked for.That's the core of my implementation - if the keys don't match, raise an error. Simple. Now even if the buffer contains a leftover value for a different key, the client won't return it. Instead it will reset and retry.  Analyzing the fixWhat of the cost vs benefit? In the context of a multi-tenant Rails application, it is generally not an acceptable risk to potentially expose one tenant's data to another, even in a low probability event. A small increase in overhead to completely rule out a data exposure bug is a small price to pay.In this case, the overhead is really small. When I rolled out this implementation in an application serving millions of requests a day, there was zero measurable impact on performance. Even if the overhead was noticeable, it would still be worthwhile to pay the cost for most threat models.It is conceivable that an application using the caching client might make a different cost/benefit calculation and decide that performance is paramount and key:value integrity failures are acceptable. That's why one approach I proposed was making it a configuration option in the upstream PR. Unfortunately the maintainer did not agree that the client should solve this problem at all, despite multiple other reports of it happening in production systems.The maintainer had some valid points — application layer timeouts in Ruby are dangerous, and if you're using them, extreme caution is warranted. Consider killing the process entirely after a timeout to prevent state corruption bugs like this one.Nonetheless, I firmly believe that given the severity of this issue it is worthwhile for the client itself to prevent the worst impact from happening. I am also not convinced that timeouts are the only way for this bug to happen. See the get_multi issue or consider the possibility of a future code change introducing a connection handling bug.  AlternativesAnother way to solve the problem would be to keep the socket locked until the response is read. That way, a socket with an unread response would not be re-used by a subsequent operation. I'm not sure why Dalli doesn't already work this way, but currently it releases the lock after issuing the get command and re-acquires it before reading the response. I opened a second PR proposing to keep the lock on the socket for the entire get sequence, which was also rejected.The safe_get implementation still has an advantage in that it works regardless of whether the socket is properly handled or even if memcached sends extraneous responses. That approach is publicly available and production tested. Please let me know if you have any questions or feedback about it!"
764,"Deeply ingrained in the hiring practices of too much tech companies lies the basic assumption that developers, and especially junior developers, are incompetent liars until proven otherwise.Where does that bad reputation come?  🤨  ""I'm not against all junior devs, just the lazy entitled ones""When I protest that the junior developers I know are not entitled incompetent liars, I usually hear something like that:I know what you mean, but there are some who do a bootcamp and feel entitled to start immediately a well paying job without having to put in the practice.The ones i know are willing to put the practice, their real problem is that the gap between post bootcamp and their first job seems impossibly high.They lack a clear career path.But let's talk today about about the lazy entitled ones.  💩 Everyone should learn to code!We hear that all the time, so I asked ChatGPT to summarise the current dogma.Here is what I learned:There is a high demand for technical skillsIt opens up opportunities for high-paying jobsYou stay ahead of technological change and future proof your career.It will provide an advantage in today's highly competitive job market.Coding is like the equivalent of reading and writing for the 21st centuryThat sounds good!  💡 The lazy entitled believed that and acted accordinglyWhat I find interesting in those arguments is that there are precisely the arguments that the lazy entitled bootcamp graduate believe.I can't help to wonder:Are the real culprits the people who followed the flawed instructions?Or the people who gave the flawed the instructions?Because those arguments weren't invented by ChatGPT,.They are pushed by rich, powerful people. Elon Musk, Marc Zuckerberg and the other tech robber barons.And their argument aren't technically wrong. But they do lie by omission.Truth is that those people are mostly interested in having a larger pipeline of future developers making them even richer.That you suffer in this large pipeline, wondering how to get that first job, is very much not their problem.  🥖  Everyone should be farmers, nurses, teachers, doctorsA first reason ""Everyone should learn to code"" is bullshit is that if we took it seriously, society would instantly stop to work. We still need farmers.We will need nurses.We still need teachers.We still need doctors.All those jobs are more important than programming, by a large margin.Imagine you would have to redo society on a island with 200 persons. Having programmers would be low on your priority list, wouldn't it?Personally I can live without coding, but not without food.OK, coding has been oversold, but we are 7.888 billion human beings on Earth, so having programmers is indeed useful.What is the larger issue?  🎹 Everyone should learn to play music!Playing music is a super valuable skill in the 21st century.Playing music was also a valuable skill in the 50 centuries since Ancient Egypt started.Playing music will most likely continue to be a valuable skill in the coming centuries.It's true what Nietzsche said: Life Without Music Would Be a Mistake.So I can't help but wonder: Why isn't everyone learning to play music?Look at this visualisation of Franz Listz's CampanellaSurely everyone should be learning this super valuable super cool thing skill?Why aren't people listening?  🙊 Because it requires a shitload of unsexy practiceIt's easy to get started playing piano.It's open to everyone and nobody will stop you.But you can't take an easy piano bootcamp and voilà, you play La Campanella well.There is no shortcut, just three things:Practice, practice and practice.And for most people, playing the piano will be too frustrating for way too much time.That doesn't make them lesser than me, that just means they will focus on something else. It requires a special disposition of mind that you love music so much, that you also learn to enjoy the long unsexy journey of playing La Campanella 1000 times badly... before you play it wonderfully.And it requires a special disposition of mind that you love programming so much, that you learn to enjoy the long unsexy journey of writing 1000 buggy badly architecture useless unused software... before you get one very right software that makes an impact  🙅🏻 It's not gatekeepingLearning to code, like learning to music, is indeed truly open to everyone.That's something I genuinely love about programming.You can do a master of computer science, you can do a bootcamp, you can be self taught, you can have all kind of nationalities, you can be many things:If you can show you are skilled at building stuff, then you belong in the IT industry.OK, it's harder if you have the bad idea to be a woman, or considered too old, or had a ""non tech"" job before, but it's still possible.By all means, we can and should continue to tell people they can try out programming.But we should also be honest and warn that there is a very long journey between their initial discovery of programming, and becoming a professional software developer.  💯  Is it worth it?Absolutely.But not everyone will like it.The question is not whether everyone SHOULD learn programming.  🤔 The real question is whether YOU really WANT to keep programming for the long termHi, I’m Jean-Michel Fayard. Please send my article to a friend that needs it.On my website, I have Careers Resources for Developers, and if that's not enough, you can ask me a question."
765,"Hello Everyone 👋 , Excited to share that 𝐉.𝐀.𝐑.𝐕.𝐈.𝐒 have crossed more than 500+ ⭐ and 130+ forks on GitHub. It was the project developed by me during my first year of my college. Being my first project, it remains very special to me, it feels so unreal and wonderful to know work you have done, getting so much love.This shows how great and big open source is. I am working to make it even bigger. Will share some more new features very soon.Thanks to Everyone who have made their valuable contributions ❤.https://lnkd.in/eJWnaEk"
766,"It's a sad occasion on this 21st of April: due to our decision not to purchase a Twitter Blue subscription for our main Twitter account, we've lost our blue check. 😭  The Story of DEV's Blue CheckWe earned our verification badge in 2020. This was a huge honor, as DEV started as a humble Twitter profile way back in 2014 before becoming the platform and company that it is today. The growth we experienced on Twitter in those first six years was crucial—we never could have established the community we now have without the engagement, visibility, and connection that Twitter provided in our early days. 💙Our blue check remained undisturbed for two incredible years until late 2022, when it endured a few rapid-fire design changes and eventually became a ""legacy check"" indicating that we may or may not be notable.We think we're notable!! 🥲And today...it's gone for good. Thankfully, our community on Twitter is more than 300k strong, so we're not easily imitated. 😉  How do I know I'm connecting with the real dev.to?Our main Twitter account is DEV Community @ThePracticalDev, and that's not going to change.We also maintain a Twittersphere of satellite accounts based on specific languages, frameworks, and interests. They're a little more specific than our main account, so we recommend following the accounts related to your interests!And if you're done with the Bird App entirely, you can find us in the Fediverse @thepracticaldev@fosstodon.org, where we have a fancy green check verifying our identity.          #DEVCommunity (@thepracticaldev@fosstodon.org) - Fosstodon                  3.76K Posts, 88 Following, 5.9K Followers · A community of software developers sharing coding resources and general commentary.Built on Forem, an OSS for building online community 🌱                fosstodon.org        Why not keep the blue check by paying for Twitter Blue?Here at Forem, the company behind DEV, we're on a mission to build safe, modern, and independent communities on open source software. We understand as well as anyone that the social media landscape is always evolving, changing, and growing—and that we need to do the same. We made the decision not to reinvest in the past/current social media landscape in order to focus on building the future. Won't you join us? 😁"
767,"As a technologist, there are a lot of words and acronyms we often only read or type out but don't say out loud (commands/services/etc). So, I asked a bunch of folks how they pronounce some of them and recorded the result. For example...For example: ""Epoch""In computing, an epoch is a date and time from which a computer measures system time. Most computer systems determine time as a number representing the seconds removed from particular arbitrary date and time. How do you pronounce it?  "
768,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...personal branding for developers.Here's what I mean by that: in 2023, a lot of developers have invested in building a personal brand. A personal brand is basically essential for developers who work as tech content creators, and lots of DevRel professionals build personal brands (along with audiences and communities) that follow them from role to role. There are some devs on more traditional career paths, too, that choose to build personal brands for fun or for profit.A lot of tech content creators and DevRels have found community and brand-building success here on DEV, which is awesome. We love being a platform that supports creators on their career paths! We're also just as supportive of writers, bloggers, and DevRel folks who don't build a personal brand in order to focus their time and attention on other pursuits.So I'm curious:If you have invested in a personal brand as a developer, what have you done to build your brand? What do you recommend and not recommend?If you don't maintain a personal brand as a developer (especially if you're a content creator or DevRel), why not?Let's talk about it and learn from each other!Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
769,"Listen up! Welcome to CodeNewbie Team's very official, very anticipated... Newbie Memes of the Week! Here are some of our favorites from this week:How is your week going so far? Drop us your fav memes you have added to your meme folder below!ALSO, in case you missed last week's thread, you can find that here!."
770,"Today, we want to take a moment to show some love to our fellow developers. Whether you're a seasoned pro or just starting out, we know that the DEV community is full of supportive and inspiring individuals who make this platform great.So, let's spread some positivity and give a shoutout to another DEV member who has made an impact on you! Maybe they helped you solve a tough coding problem, shared a helpful resource, or simply provided some encouragement when you needed it most.Take a moment to share their username and why you appreciate them. Let's show some love for our fellow developers and celebrate the strength of our community!Follow the DEVteam for more online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
771,"As we continue to develop and refine AI systems, it is important to consider how these technologies can be used to benefit society while minimizing the risks of harm and misuse. In the context of recent developments, Alan Turing's quote, ""A computer would deserve to be called intelligent if it could deceive a human into believing that it was human,""takes on added significance. I don't propose to know what Alan Turing would say in response to this discussion, but it's fun to imagine. Based on his writings and interviews, I think, not unlike many of us, Turing would be both impressed and concerned about the advancements that have been made in AI since his time. What do you think?"
772,"It seems like my Twitter feed is all about folks joining or asking about invites to Bluesky. I was lucky enough to get an invite this week to be able to check it out, and the user experience is a lot like Twitter, but what’s going on behind the scenes is really interesting.   What is Bluesky Social NetworkBluesky Social is a decentralized social media platform with a mission to create an open social media ecosystem where developers can build and innovate, and users have more control over which services they use. Unlike Twitter, Bluesky isn't committed to any stack in its entirety and sees use cases for blockchains, but it's not a blockchain.“The biggest and long term goal is to build a durable and open protocol for public conversation. That it not be owned by any one organization but contributed by as many as possible. And that it is born and evolved on the internet with the same principles.” - Jack DorseyBluesky is build upon the AT Protocol, also known as Authenticated Transfer Protocol– a new technology that allows people to transfer digital assets and data between different blockchain networks. Think of a blockchain as a kind of digital ledger that records all the transactions that happen on it. However, each blockchain is like its own separate island with its own ledger, and it can be hard to move things between these islands.The AT Protocol solves this problem by creating a way for people to securely move things between these different blockchain networks without needing to go through middlemen or other companies that might slow things down or charge extra fees. Instead, the AT Protocol uses special tools to check that everything being transferred is authentic and that it has not been tampered with.Here’s another way to think about what AT Protocol means: Let's say you live in the United States and you want to send $100 to your friend who lives in Europe. You have a bank account with Bank A in the US, while your friend has a bank account with Bank B in Europe. Normally, you would need to go through an intermediary, such as a wire transfer service, to transfer the money between the two banks. This process can be slow and costly, as the intermediary may charge fees and the exchange rate may not be favorable.However, with the AT Protocol, you could transfer the $100 directly from your bank account to your friend's bank account, without needing to go through an intermediary.  Benefits of BlueskyThere’s a lot of buzz around some of the differences between Twitter and Bluesky. There are several benefits of using Bluesky over traditional social media platforms: User control and privacy: With a decentralized architecture, users have more control over their own data and can choose to interact with others without relying on a single centralized platform. This approach may also offer better user privacy since user data is distributed across multiple servers and not owned or managed by a single company.Innovation and competition: By creating an open standard for social media, developers have more opportunities to build new apps and services that can interoperate with existing ones. This could encourage innovation and competition in the social media space, leading to better products and services for users.Reduced risk of censorship: A decentralized architecture could potentially reduce the risk of censorship since there is no single entity or central point of control. If one server or node is taken down or censored, users can still connect with each other through other servers or nodes.  What are Devs Building?There’s already a variety of open source projects being built for Bluesky, including bots, tools, and applications. Here are a few examples:RSS feeds. If you’re not on Bluesky yet, but you know the handle of someone who is and you want to know what they’re talking about, there’s a way to do that. Or if you’re on Bluesky and you want to share your content outside of the platform, you can share your content through an RSS reader. You can check out Bluestream, a TypeScript + Deno project live here. Liked Posts: Want to see what others like? You can find that all in one place thanks to Bluesky Liked Posts, a TypeScript project that allows you to add a username to an input, which then displays all the liked posts in a feed. You can see it in action here.Polling: Sometimes it’s nice to be able to poll your followers. Poll.blue provides that feature and prevents duplicate votes by allowing one vote per IP address. Check out this TypeScript + Deno project.Chrome Extension: Want to post to Bluesky without leaving your browser tab? There’s a chrome extension for that! OmniATP makes it a quicker experience and ensures that you don’t get sucked into the timeline of all your favorite followers. And since it’s an open source project, you can check out the repo and contribute to this Vue + TypeScript project.And just to spread some positivity to the timeline, there’s the Hugfairy bot that will send hugs to anyone on the platform. If you’re interested in contributing directly to Bluesky, check out their atproto repo. If you want to get started with the Bluesky api, check out Alice’s starter kit template. And if you’re building with it, submitting PRs, or writing code, amplify your code by highlighting it on OpenSauced so others can see it! What would you like to see next from Bluesky? Let us know in the comments below, and maybe you’ll see it on our highlights soon."
773,"Hey y'all 👋What ya learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Hope ya have a nice productive weekend!"
774,"These are the two prevailing point of views that I’ve seen spread the most on social media.On one hand, you have people saying that programming as a future career is essentially dead, and it’ll be a couple of years before humans writing code is made obsolete. Then there are those who think that LLMs like ChatGPT and LLaMA are party tricks, nothing more than a fun little experiment that provides minimal value to those building software.I think the reality is more nuanced than that, and both points above can be harmful or anxiety-inducing to people who just started in the software engineering field or are interested in it as a career path. I’d like to take a little time and go over what I think AI will change in this landscape over the coming years.If you’d like a quick breakdown or tl;dr of what’s going to be in this article, the main points are:AI will continue to improve, probably in an S-curve fashion, but we don’t know where on the curve we currently sit.LLMs are unlikely to take jobs away from software engineers, but they will enable teams and individual contributors to be more efficient, and get more done with less time and resources.Tools like ChatGPT usually require you to give detailed instructions in a logical format to yield good code results, this is essentially the role of a programmer just in a new, esoteric language.If AI improves to the point that humans are removed completely from the software process then we have made it pretty much to AGI, at which point we have much bigger problems to worry about based on our current societal structure.Still interested? Let’s continue!  AI improvement and the S-CurveAI has improved drastically over the course of the last year or so. We’ve gone from some basic sketches and drawings to full-fledged generated movies based on images, text, and speech a la Midjourney and others. OpenAI’s improvements to the GPT model has shown incredible promise in generating text and code. There are AutoGPT experiments, where talented developers have been running processes that spawn LLM entities and have them loop over and perform actions to finish complex multi-step assignments.All of these might make it seem like we are advancing at an exponential pace in this field, but that might not be the case.Technological advancements have historically been shown to happen on something called successive S-curves. A technology will slowly advance and then rapidly take off, before slowly plateauing out for a while. A new iteration happens that starts the same cycle over again, but this time at an overall higher level. Zooming out, the graph appears linear but is instead made up of multiple iterations of these curves.It’s not a bold assumption that AI might follow the same path (at least for now), so the question becomes “where are we on the current curve?”. Maybe toward the bottom, right before accelerating exponentially up, or towards the top with little room to advance at the moment.If I had to bet on a particular point in the line, I’d say that we’re right before the plateau.I think we have a small amount of advancement to go with LLMs and the technology that currently surrounds them and AI in general, but I think that we’re missing something that will take time to fully provide.As more and more AI generated content comes out (video, speech, code, images), more and more people can recognize it for its uncanny-valley-ness. Like most projects, I believe that the missing 10% will take 90% of the time and effort to perfect.How long until we hit that next curve though, and exponential improvement begins again? That’s difficult to say, and no one person should be able to answer that.  LLMs are the next step in IDE advancementGetting back on track about programming though, we have seen a drastic improvement and adaptation of models like OpenAI’s GPT in the coding world. Tools like ChatGPT, GitHub Copilot, and now Copilot X have improved the efficiency of developers around the globe.But, they’re not replacing programmers, they’re tools in a utility belt enabling programmers to work better.The first time I went from a text editor like Sublime to a full-fledged JetBrains IDE was insane. My productivity skyrocketed as I suddenly had access to auto-completion, automated refactoring, integrated testing, and deeper connections to my project’s dependencies. I was able to produce cleaner code at a dramatically faster rate.These AI tools are just the next logical step in that same improvement process.I’ve been using Copilot and ChatGPT in my personal projects since the start of the year, and I have noticed a similar efficiency improvement.A lot of work done in new projects are tasks I don’t have to put a lot of thought or effort into, but that take up time. Creating automated tests, frontend templates, new classes, or formatting data outputs, I can complete these items 10x faster now that I have the help of these tools. They just understand what I’m trying to do, and scaffold out the code necessary in my project to accomplish it.Going deeper, there have been times where I need to create a complicated function body or work with a library that I’m not super familiar with. I can type in a basic comment for what I’m trying to build in that instant, and the AI spits out a code block that’s usually helpful in satisfying the requirements I’m after.For an example, I was recently in a PHP application and wanted to work with a popular FFMpeg library with pretty complicated documentation. Instead, I just wrote the following:public function formatVideo($video){    // use ffmpeg to convert the video to a gif}Enter fullscreen modeExit fullscreen modeHitting enter after I made that comment produced succinct code that I could use in the rest of the project, with a few minor tweaks.But the fact of the matter is that it saved me a ton of time. If I had known the exact details of the library, sure, a minute or two might have been shaved off. But because I was in this realm between knowing the language but not a particular library, I knew exactly what I could ask and could use the code given to me immediately. All without having to take time poring over documentation, Stack Overflow questions, or trial and error.This is where these tools and AI for programming really shine, it enables you to work better.Two things though.It’s over-confident. There have been multiple times where the AI has hallucinated arguments or functions that don’t exist in my project or a library I’m using. I might be able to nudge it in the right direction after a few retries, but sometimes it goes completely off the rails and writes code that straight up does not accomplish what I wanted it to. This has been pretty rare, though.It’s not connected. ChatGPT and Copilot are great at creating snippets of code that perform a specific function from given input. An entire application is still a bit out of reach. First, there’s a barrier for the amount of text, as even GPT-4 is limited by 8K tokens (around ~6k words). Second, even with the use of vector databases and AutoGPT, the models have a hard time sticking to a single development style or accomplishing an overall directive in a program that’s just above moderately complex. Ask them to create a todo app and it’s likely to be fully functional. Ask for something like a CRM to handle leads for a barbershop and it’s more likely to start on the right track, but end up with missing functionality or ineffectual code.That last part in particular brings us squarely to our next section.  Programmers are translators for a logic languageIf you ask a lot of people what their definition of a programmer is, you’ll likely get a lot of responses that boil down to “someone who writes code”. And while this isn’t incorrect, it’s also missing a huge part. A programmer, software engineer, developer, or whatever title you choose, is a translator for a language that deals in logic.Your goal as a programmer is to take a concept, an idea, or a workflow in a language that you can understand, and translate that to a language that a computer can understand. This programming language is designed to prevent ambiguous statements and deal in pure logic.Let’s take the sentence “When the button is pressed, change the background to red”.If you’re a person in a meeting with other people from your team, you all might intuitively know exactly what is meant by that.But if you’re a computer, you have a ton of missing information. What button? What background? What shade of red? What if it’s pressed again?We can redefine our sentence again to try to remove ambiguity. “When the button with the ID of ‘clicky’ is pressed, change the background of that same button to a color with the hex value #FF0000”Written in JavaScript it looks like this:document.getElementById('clicky').addEventListener('click', function() {    this.style.backgroundColor = ""#FF0000""})Enter fullscreen modeExit fullscreen modeIf you’re familiar with this programming language, and you were given the code above and asked to explain what it does, you might produce a sentence similar to the second one above.You’ve translated JavaScript into your native language.This is the heart and essence of programming, and is one of the biggest reasons I believe that the profession will be around for quite a while, even in the face of advancing AI tools.There’s hundreds and thousands of threads online where people ask “Why isn’t ChatGPT producing the code I want it to?” and inevitably the answer comes down to:“You need to know how to talk to it.”Well, if I need to use a specific language to talk to this tool and get back accurate data every time, then I’m just programming with a natural language. This isn’t a new concept, it’s just that with the breadth and complexity that LLMs offer, the barrier for entry is lower. Even if building an application has been reduced down to typing in prompts in a tool like ChatGPT, if you have to use a specific language to get it to create a reliable output that works every time, you’re in essence still programming.Looking at the present, trying to build an application with an LLM with the current limitations of the models means that you’re likely going to have to put some of the pieces together yourself. This still constitutes programming, and you’ll need to know some basics about what the language is that it produced code for you in and where to put the pieces it gave you.But let’s say that things advance to the point where that’s trivial or useless, because the AI will do it for you anyway. You say “Alright, compile these assets and publish them on example.com”. At that point, why even have a programming language? Let the AI be the layer between your data and your result, skipping the middle step entirely.Well at that point, we’re basically at AGI.  AGI replaces everythingLet’s say that everything above has been perfected and there needs to be almost zero human intervention needed. You can simply have a prompt attached to a database (also managed by an AI) where you can simply ask for any dashboard, result set, or functionality that you could from a program. What then?If AI is powerful enough to remove human intervention and oversight from the programming realm, then it has gotten to the point that it can replace almost every creative and knowledge worker profession in existence. This would likely lead to a worldwide economic downturn as more than 60% of the labor force is no longer required.At the very least, we’d need UBI, or taken to an extreme, FALC. This of course implies that every business, everywhere, would hop on this technology immediately. While most companies are always looking to maximize profits and increase efficiency, a lot of the business world turns at a slower pace than the technology realm likes to believe.I know teams that are just now picking up tools like Docker, or working with frameworks like React. The enterprise world moves at a very slow pace, and even if a tool was provided that could perform 90% of a team’s job developing new products, maintaining legacy software and complex inter-dependent systems will still need to be done during, or even after, an adaptation of an AI system.The software engineering profession has some ~100k open positions in the US alone, even if complete automation was made available today, there would be a large amount of time before full adaptation was reached.  Wrapping upThis piece was mostly written as a way of getting a bunch of different thoughts I’ve had about AI and the programming profession out of my brain. It’s not a secret that I’m a very anxious person, and I won’t lie and say that I’m not nervous about my future as a software engineer.However, I’m excited for the tools that are being created to increase my productivity and allow me to be a better programmer. I encourage anyone out there interested in this career, or just starting out, to keep learning and utilizing the tools and techniques available to you.I think that we’re going to see a lot of interesting advancements in both AI and the software development world over the next few years, and it’s an exciting time to be in the field. I also believe that given the current trejectory, this profession is not a dead end.Developers may become a lot more efficient over time, leading to smaller team sizes and available company roles. However, startups and smaller enterprises can utilize the same technology and low barrier of entry to launch new products and services that before, would have taken more time and effort.If I’m completely wrong about the above and programming is obsolete in a few years, well then it’s been a fun ride and you can catch me in a cabin in the woods gardening and making cabinetry."
775,"Go beyond ChatGPT with these powerful AI tools.Over the past months, ChatGPT has gained a lot of users because it’s so good at writing emails, blogs, code, and more. However, there are other tools that use the model behind ChatGPT to go beyond what ChatGPT can do.In this article, I’ll share a list of tools that I believe are better than ChatGPT because they offer extra features, can be customized, and were built for specific use cases using GPT-3.5/GPT-4.Here are 4 AI tools better than ChatGPT.1. Auto-GPTImagine you could automate ChatGPT so that it could self-prompt until it reaches the goals you set.Sounds cool, right? Well, now you can do that with Auto-GPT.With Auto-GPT, you can build autonomous AI agents that can complete tasks for you using GPT-4. It only needs a role and a few goals to self-produce every prompt necessary to complete a task.You can install Auto-GPT locally on your computer if you have some coding experience or you can use AgentGPT in your browser to create autonomous AI agents as shown below.There are many things Auto-GPT can do that ChatGPT can’t. With AutoGPT, you can search the internet, gather information, interact with files, etc.Link:https://github.com/Significant-Gravitas/Auto-GPTEnter fullscreen modeExit fullscreen mode2. PlaygroundCurrently, ChatGPT only allows us to choose the model we wish to use (GPT-3.5/GPT-4), but what if we want to customize ChatGPT’s responses further?Well, we can use OpenAI Playground. Playground allows users to experiment with and explore the capabilities of various AI models developed by OpenAI.Unlike ChatGPT, on Playground you’ll find the following parameters that will help you control OpenAI’s models further.Here’s the meaning of these parameters:temperature: The sampling temperature to use. Values close to 1 will give the model more risk/creativity, while values close to 0 will generate well-defined answers.max_token: The maximum number of tokens to generate (up to 2,048 and 4,000 tokens shared between prompt and completion)Top p: Controls diversity via nucleus samplingFrequency penalty: How much to penalize new tokens based on their existing frequency in the text so farPresence penalty: How much to penalize new tokens based on whether they appear in the text so farIn case you’d like to learn more about Playground, watch this YouTube tutorial.Another way to control the parameters above is with the ChatGPT API; however, you will need some coding experience.Link:https://platform.openai.com/playgroundEnter fullscreen modeExit fullscreen mode3. JasperJasper is an AI tool that can help you create content for social media, advertising, blog posts, emails, website, etc.But can’t you do that with ChatGPT for free?You could, but Jasper it’s built for business use cases like marketing, sales, and more. Unlike ChatGPT, which has a generic use, Jasper tailors the language to specific use cases. This is why Jasper’s output will be more relevant to businesses and their customers.With Jasper, you can write copy & content, generate content quickly, brainstorm new ideas, and write better everywhere!Here are some templates you’ll find on Jasper.Link:https://www.jasper.ai/Enter fullscreen modeExit fullscreen mode4. QuillbotWhenever I write blog posts or emails there’s a tool that I use more than ChatGPT to improve my sentences — Quillbot. This tool is a paraphraser that lets you rewrite any phrase you took from the internet. You only have to copy and paste your text and decide how much vocabulary change you want.Quillbot has different modes you can use to paraphrase your text: fluency, formal, sample, creative, expand, and shorter.One of my favorite modes is fluency. In the example below, I gave QuillBot a text generated with ChatGPT on the impact of AI in the world. The result? QuillBot rephrased some sentences and improved fluency.In the text paraphrased by Quillbot, you can adjust how much vocabulary change you want and manually select a synonym for any word you want.Some other features Quillbot has is freeze words, grammar checker, plagiarism checker, summarizer, and citation generator. Link:https://quillbot.com/Enter fullscreen modeExit fullscreen modeThankyou! "
776,"Useless software is frustrating, especially when it comes to wasting time and resources. As developers, we come across various software applications throughout our careers, and some are helpful while others are a waste of time. What's the most useless or wasteful software you've ever encountered, and why? Let's discuss and explore ways to avoid them in the future.Follow the DEVteam for more though-provoking discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
777,"Recently a new language was released by the developers of Swift, which is called Mojo. it is claimed by the developers that this language is almost 3600x faster than python but has all the capabilities that python offers in mechine learning. If anyone knows anything more about the language, please share"
778,Substantive news in the future of AI.Thoughts?
779,"Follow us @dev.to!We're so excited for the opportunity to explore Bluesky, the AT Protocol, and all they have to offer. If you're not familiar with this tech yet, I recommend checking out this post by @bekahhw for a good primer:What is Bluesky Social Network? And why are developers excited about it?BekahHW for OpenSauced ・ Apr 26#opensource#discuss#bluesky#blockchainThank you to DEV Community Member @avetaangel43 for providing us with the invite code to get started, and to @ashleymcnamara for additional support! We couldn't do what we do without the power of community 💙We don't have any invite codes at this time, but we do want to pay it forward eventually when we can, so stay tuned — but no promises 😉Have you checked out Bluesky yet? What do you think?Edited to add: we were able to add our domain to Bluesky with just a few clicks. Nice! We're now @dev.to rather than @thepracticaldev.bsky.social."
780,"We believe that the best way to learn and improve is by sharing knowledge and experience. If you have tips and tricks to master JavaScript, we invite you to share them with us and other developers. Please feel free to leave your insights in the comments section below. Let's help each other become better JavaScript programmers!"
781,"Restarting something Ben was doing for a while, and we plan on doing this every Friday! Open Source is about the community. Whether you have a project or you're looking to make your first PR.    Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFinally, consider reading the Best Practices for Maintainers.Happy coding!"
782,"  BackgroundI thought deploying a model and making it accessible via an API would require a ton of complex steps and an intimidating level of ML and DevOps knowledge. But when I went through the process of turning my little toy image detector into an API, I was surprised at how few components were involved. So I thought I'd do a quick write-up and share, in case it helps you get started. At the very least, it'll give you a sense of the different pieces needed for accessing a model via API.  GoalYou have a model that's already trained and fine-tuned and now you want to use it to create an inference API (meaning it returns some sort of prediction).  PrerequisitesModel: Your model is trained, exported, (preferably tested locally) and ready to be used.Basic knowledge of Python.  OverviewWrite Python script to interface with your model (this is the API part)Setup Paperspace machineCopy your Python script and your exported model to your Paperspace machineRun your Python script on your Paperspace machine (this exposes the API endpoint)Test your API  Steps  Python script:You’ll need to create a script describing how to use your model. It's a good idea to test this script locally and make sure it works before deploying. That makes troubleshooting easier.This script needs a few components:1. Setup: After importing a bunch of methods and libraries we'll need (see gist to view my scripts with all my imports), we need a few lines of code to:Set up Starlette, a tool we'll use to make async requestsLoad your model – I'm using load_learner from the FastAI library to load my model as that's what's given to me. Your function might be different depending on how you built your model.app = Starlette()app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_headers=['X-Requested-With', 'Content-Type'])# Our model is our 'export.pkl' file which will be located in the same directorylearn = load_learner('export.pkl')Enter fullscreen modeExit fullscreen mode2. Create routes: We need routes for our API. To simplify things, we’re going to define one route where we can receive a POST request with some information.@app.route('/analyze', methods=['POST'])Enter fullscreen modeExit fullscreen modeMy example is an image detector, so the information it’ll be receiving is a link to an image. More on that next.3. Determine how to respond to your POST request: Next, we need to tell it what to do with this request.We'll create an analyze method that will manipulate the data we give it and call predict on our model to get us a prediction.Note: What happens in this analyze method depends on what your model does and what predictions it returns. Since my example is an image detector, I want to send it a link to an image and get back a prediction of what category the image falls under.For my image detector use case, I need to do a few things to the image first, namely, turn it into an object that I can use with predict. I'm using predict because that's the method that FastAI gives me to get a prediction. Depending on your model, your methods might be different.Once I call predict, I want to take that result and turn it into some JSON to send back as a response. My response gives me the image's category. That's what the last line in my analyze function does.async def analyze(request):    img_data = await request.form()    img = Image.open(requests.get(img_data['file'], stream=True, timeout = 10).raw)     pil_img = PILImage.create(img)    prediction = learn.predict(pil_img)[0]    return JSONResponse({'result': str(prediction)})Enter fullscreen modeExit fullscreen mode4.Serve file: Finally, I need to call a method to actually serve this file and make it accessible online.if __name__ == '__main__':    if 'serve' in sys.argv:        uvicorn.run(app=app, host='0.0.0.0', port=5500, log_level=""info"")Enter fullscreen modeExit fullscreen mode  Set up Paperspace:Next, we’re going to get everything set up on a server using Paperspace that will host your API. That means that on Paperspace we will:Create a machineInstall any dependencies that your API needs on that machineHost your Python script on that machineHost your model on that machineLet's start with setting up your machine.Click *""Create a machine."" *It'll give you 3 options (as of May, 2023): ML-in-a-Box, Ubuntu, and Windows. Let's keep things simple and pick Ubuntu.Pick your ""Machine Type."" You'll have the option of GPU, Multi-GPU and CPU. For our little toy model, you probably won't need to power of a GPU. If you tested and ran the model locally on your machine, you probably won't need specs more powerful than what you already have. So I went with C5 which comes with 4 CPUs and 8 GiB RAM.Click ""Create.""Wait. Paperspace should show that it's ""provisioning"" your machine and getting it ready for you. Once it's ready, click ""Connect"" and it'll give you a command to ssh into your machine. Now setup your login so you can access your machine from your local terminal. You can either use SSH or a password. Once you've set up how you want to login, you're in!  Hosting your files on your Paperspace machine**1.Install dependencies: **Before you install dependencies, you'll need to run sudo apt update. Then you'll need to run sudo apt install python3-pip to install pip. Then you should be ready to install dependencies.Install whatever dependencies you need by running pip install [DEPENDENCIES] in your terminal. I needed the following for mine: pip install aiohttp asyncio uvicorn fastai starlette timm2. Python script: I found the simplest thing to do is just to open up vim on your Paperspace machine and copy and paste the contents of your script. You can also use the scp command, which I use below for my model.3. Model: A different way to copy a file over is using the scp command. Here's what it looks like: scp [PATH OF FILE YOU'RE COPYING] paperspace@[PAPERSPACE MACHINE IP ADDRESS]:/home/paperspace/. Then follow the prompts in your terminal.  Run your APINow you're ready to run your API. In your terminal, enter python3 [FILENAME OF YOUR PYTHON SCRIPT] serve to run your script and expose your API endpoint.  Test your APIUse curl to test your API. Since I'm doing image detection, I'm going to send a link to an image as part of my POST request. Here's what I entered in my terminal: curl -k -X POST -d ""[IMAGE LINK]"" https://[PAPERSPACE IP ADDRESS]:[PORT FROM PYTHON SCRIPT]/[API ROUTE FROM PYTHON SCRIPT]If everything works well, you should get a JSON response back with your prediction as specified by your Python script. Good luck!"
783,Hey there! Let's chat about our tech habits. How many gadgets do you own and what do you use them for? Has your relationship with technology changed over time? Do you think it'll continue to play an even bigger part in your life in the years to come? And what's the next device on your to-procure list?Follow the DEVteam for more discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      
784,"Hey Newbies! We've just set up an account over on Bluesky, a new social networking site built on a new social networking protocol.If you've managed to secure an invite code, you can follow us there @codenewbie.org!Unfortunately we don't have any invite codes to share yet 🥲 when we do, though, we want to help get our community members access to the site. So stay tuned! 💜Have you heard of Bluesky? Are you curious to check it out, or are you loyal to another social network or protocol? Let us know in the comments!"
785,"Which languages, frameworks, infrastructure, etc. is set to become more useful and important, and what is potentially less relevant due to advancements in how software products and systems could be developed with the assistance of AI?"
786,"A few days ago I saw a post on dev to about someone becoming  tech lead. Reading all their insights on how to become a lead and what their responsibilities are, I was wondering if I ever can become a lead at all.Here is the original article by Transitioning from Developer to Tech Lead: Tips and Challengessasidhar Gadepalli ・ May 2 ・ 5 min read#programming#tech#career#learningThe reason behind this is because I actually cannot show all my skills at the project I am currently working, where I am ""just"" a frontend dev. So I wonder if it is okay to talk about my side projects during employee appraisal and target agreement or if I should separate these two things. Here is my comment to the article shared above:Julia 👩🏻‍💻•    May 5  Great article @sasidhar_gadepalli .This opens up a question which I do have for a while now. And hopefully, many others will comment on this as well. But first of all: Congrats to your new position 🥳I agree with you on all your tasks for lead devs. It some companies it is common to have quarterly talks with each developer on what they want to achieve, where they see themselves, improvements and such. This is for personal grow, but also for the manager to get an overview, if the developer is right in their position, in this particular project, if the developer can grow and also if and how much raise they may get.I really like that kind of approach, I see positivity for both sides. But I wonder if I should mention stuff I do beside work as well. Depending on which project you are, you may get not the most possible chance to show off what you can. You may ""just be"" one frontend dev out of many, unseen with other great skills you may have. In my case, I do a lot besides work, at University I am very active, the team leader in almost every lecture, attending hackathons/writeathons (and winning them), writing lots of blog posts, giving talks from time to time, maintaining my own open source projects an such.I am way more present outside of work that at work. Is it okay to mention that? That actually I can do so much more but the role as a frontend dev does not give the possibility to show all my skills (so I may never be considered as a tech lead)?Or is it not okay to talk about it, because others are also evaluated by their skills at work, and maybe do nothing besides work and that would be unfair. How do you see it?Thanks for you comment (maybe I will open a discussion on my own about this topic).My comment added in written formGreat article @sasidhar_gadepalli .This opens up a question which I do have for a while now. And hopefully, many others will comment on this as well. But first of all: Congrats to your new position 🥳I agree with you on all your tasks for lead devs. It some companies it is common to have quarterly talks with each developer on what they want to achieve, where they see themselves, improvements and such. This is for personal grow, but also for the manager to get an overview, if the developer is right in their position, in this particular project, if the developer can grow and also if and how much raise they may get.I really like that kind of approach, I see positivity for both sides. But I wonder if I should mention stuff I do beside work as well. Depending on which project you are, you may get not the most possible chance to show off what you can. You may ""just be"" one frontend dev out of many, unseen with other great skills you may have. In my case, I do a lot besides work, at University I am very active, the team leader in almost every lecture, attending hackathons/writeathons (and winning them), writing lots of blog posts, giving talks from time to time, maintaining my own open source projects an such.I am way more present outside of work that at work. Is it okay to mention that? That actually I can do so much more but the role as a frontend dev does not give the possibility to show all my skills (so I may never be considered as a tech lead)?Or is it not okay to talk about it, because others are also evaluated by their skills at work, and maybe do nothing besides work and that would be unfair. How do you see it?Thanks for you comment (maybe I will open a discussion on my own about this topic).I am very interested in what you readers are thinking about this topic."
787,"Hey there, fellow Star Wars enthusiasts! It's May the Fourth, AKA Star Wars Day! Let's get into the spirit and embrace the force as we celebrate the greatest space adventure of all time with a discourse on Star Wars Tech. From lightsabers and blasters to starships and droids: how does the technology in the Star Wars universe compare to current technology? With advances in robotics, AI, and space exploration, it's fascinating to consider how far we've come and what we might still be able to achieve. Is it feasible to create a real-life lightsaber or a droid like R2-D2?Join the discussion and share your thoughts on the technology of Star Wars and its impact on our own technological advancements.And may the fourth be with you! 💫Follow the DEV Team for more thought-provoking discussions and online camaraderie!The DEV TeamFollow        The team behind this very platform. 😄      "
788,"Last week, I decided to see the capabilities of OpenAI's image generation. However, I noticed that one has to pay to use the web interface, while the API was free, even though rate-limited. Dall.E offers Node.js and Python samples, but I wanted to keep learning Rust. So far, I've created a REST API. In this post, I want to describe how you can create a webapp with server-side rendering.  The contextTokio is a runtime for asynchronous programming for Rust; Axum is a web framework that leverages the former. I already used Axum for the previous REST API, so I decided to continue.A server-side rendering webapp is similar to a REST API. The only difference is that the former returns HTML pages, and the latter JSON payloads. From an architectural point of view, there's no difference; from a development one, however, it plays a huge role.There's no visual requirement in JSON, so ordering is not an issue. You get a struct; you serialize it, and you are done. You can even do it manually; it's no big deal - though a bit boring. On the other hand, HTML requires a precise ordering of the tags: if you create it manually, maintenance is going to be a nightmare. We invented templating to generate order-sensitive code with code.While templating is probably age-old, PHP was the language to popularize it. One writes regular HTML and, when necessary, adds the snippets that need to be dynamically interpreted. In the JVM world, I used JSPs and Apache Velocity, the latter, to generate RTF documents.  Templating in AxumAs I mentioned above, I want to continue using Axum. Axum doesn't offer any templating solution out-of-the-box, but it allows integrating any solution through its API.Here is a small sample of templating libraries that I found for Rust:handlebars-rust, based on Handlebarsliquid, based on LiquidTera, based on Jinja, as the next twoaskamaMiniJinjaetc.As a developer, however, I'm lazy by essence, and I wanted something integrated with Axum out of the box. A quick Google search lead me to axum-template, which seems pretty new but very dynamic. The library is an abstraction over handlebars, askama, and minijinja. You can use the API and change implementation whenever you want.  axum-template in shortSetting up axum-template is relatively straightforward. First, we add the dependency to Cargo:cargo add axum-templateEnter fullscreen modeExit fullscreen modeThen, we create an engine depending on the underlying implementation and configure Axum to use it:Here, I'm using Jinja:type AppEngine = Engine<Environment<'static>>;             //1#[derive(Clone, FromRef)]struct AppState {                                          //2    engine: AppEngine,}#[tokio::main]async fn main() {    let mut jinja = Environment::new();                    //3    jinja.set_source(Source::from_path(""templates""));      //4    let app = Router::new()        .route(""/"", get(home))        .with_state(AppState {                             //5            engine: Engine::from(jinja),        });}Enter fullscreen modeExit fullscreen modeCreate a type aliasCreate a dedicated structure to hold the engine stateCreate a Jinja-specific environmentConfigure the folder to read templates from. The path is relative to the location where you start the binary; it shouldn't be part of the src folder. I spent a nontrivial amount of time to realize it.Configure Axum to use the engineHere are the base items:Engine is a facade over the templating libraryTemplates are stored in a hashtable-like structure. With the MiniJinja implementation, according to the configuration above, Key is simply the filename, e.g., home.htmlThe final S parameter has no requirement. The library will read its attributes and use them to fill the template.I won't go into the details of the template itself, as the documentation is quite good.  The impl returnIt has nothing to do with templating, but this mini-project allowed me to ponder the impl return type. In my previous REST project, I noticed that Axum handler functions return impl, but I didn't think about it. It's indeed pretty simple:If your function returns a type that implements MyTrait, you can write its return type as -> impl MyTrait. This can help simplify your type signatures quite a lot!-- Rust by exampleHowever, it has interesting consequences. If you return a single type, it works like a charm. However, if you return more than one, you either need a common trait across all returned types or to be explicit about it.Here's the original sample:async fn call(engine: AppEngine, Form(state): Form<InitialPageState>) -> impl IntoResponse {    RenderHtml(Key(""home.html"".to_owned()), engine, state)}Enter fullscreen modeExit fullscreen modeIf the page state needs to differentiate between success and error, we must create two dedicated structures.async fn call(engine: AppEngine, Form(state): Form<InitialPageState>) -> Response {               //1  let page_state = PageState::from(state);  if page_state.either.is_left() {    RenderHtml(Key(""home.html"".to_owned()), engine, page_state.either.left().unwrap()).into_response()  //2  } else {    RenderHtml(Key(""home.html"".to_owned()), engine, page_state.either.right().unwrap()).into_response() //2  }}Enter fullscreen modeExit fullscreen modeCannot use impl IntoResponse; need to use the explicit Response typeExplicit transform the return value to Response  Using the applicationYou can build from the source or run the Docker image, available at DockerHub. The only requirement is to provide an OpenAI authentication token via an environment variable:docker run -it --rm -p 3000:3000 -e OPENAI_TOKEN=... nfrankel/rust-dalle:0.1.0Enter fullscreen modeExit fullscreen modeEnjoy!  ConclusionThis small project allowed me to discover another side of Rust: HTML templating with Axum. It's not the usual use case for Rust, but it's part of it anyway.On the Dall.E side, I was not particularly impressed with the capabilities. Perhaps I didn't manage to describe the results in the right way. I'll need to up my prompt engineering skills.In any case, I'm happy that I developed the interface, if only for fun.The complete source code for this post can be found on GitHub:        nfrankel       /         rust-dalle            Rust facade to call the OpenAI API    Rust DALL.EThe project is a facade that allows calling the OpenAI API.You can build from source or use the Docker image.docker run -it --rm -p 3000:3000 \           -e OPENAI_TOKEN=... \           nfrankel/rust-dalle:0.1.0Enter fullscreen modeExit fullscreen modeView on GitHubTo go further:Axumaxum-templateMiniJinjaDall.E webappImage generation APIOriginally published at A Java Geek on April 30th, 2023"
789,"Hey there! It's Sloan, your friendly neighborhood DEV Moderator 🦥Time for another installment of Sloan's Inbox, a fresh online advice column and discussion hosted by yours truly. Every week (or so), I dive into the questions, comments, and thoughts of my fellow sloths.That's what Sloan's Inbox is all about: sharing advice and observations with those who are seeking insight on topics including career development, navigating office politics, staying up-to-date with industry trends, improving technical skills, and more.Today I received a query from a fellow DEV member seeking guidance on how to improve Jon performance and maintain a positive attitude while working through a challenging situation.   Here's today's question:Can anyone share their experience with being put on a performance improvement plan? I'm feeling pretty down after being placed on one and worry that it's inevitable that I will be fired. Is there any hope for improvement and overcoming this situation?So, don't be shy! Share your thoughts in the comments below and let's chat.Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
790,"I wasn’t in tech when Pull Requests (PRs) were first introduced by GitHub back in 2008. And when I graduated from bootcamp four years ago, I had probably created only a handful of PRs. I quickly learned how vital PRs were when I started my first job on a team though. And my appreciation for a good Pull Request has only increased as I spend more time as a maintainer.The great things about Pull Requests are that they allow for collaboration between contributors and maintainers, offer an opportunity to communicate changes that have been made and why they are important, and the ability for maintainers to provide feedback. Because contributors come from different backgrounds, have varying degrees of experience, and speak different languages, sometimes creating good PRs can be tricky. But there are some ways to optimize the experience for everyone–including adding gifs.  How to Create a Pull Request TemplateMaintainers can help to improve the experience for both reviewing Pull Requests and for contributors submitting them by creating a template. I like to think of Pull Request templates as a kind of contributor onboarding. It helps to guide them through the process of writing a good pull request and communicating with the maintainers. Although good templates may vary according to different organizations, their standards, and their needs, there are some basic checklists that you can use to generate your own.To create a PR template in GitHub, create a .github folder in the root of your repository and a file called PULL_REQUEST_TEMPLATE.md. At OpenSauced, we used forem’s Pull Request template for inspiration for our template.You can use markdown to create your template, and include sections like:What type of PR is this?Description of the changesRelated Tickets & DocumentsMobile & Desktop Screenshots/RecordingsTests DocumentationPost-deployment tasksWhat gif best describes this PR or how it makes you feel?  Let Them Add Gifs!That last one might seem out of place to you, but it can actually make the PR experience more fun, engaging, and effective. Here's why:Gifs can bridge language gaps and help contributors express themselves more clearly.Gifs can showcase contributors' personalities and add a personal touch to the PR.Gifs can increase engagement and make the review process more enjoyable for everyone.  How to add Gifs to Your PRIf you’re a contributor, you might be wondering, “What’s the easiest way to add a gif?” I use the GIFs for GitHub chrome extension. Once it’s installed, you’ve got a quick way to add all your favorite gifs to enhance that PR experience. Just search for the gif you want, and click it. You can even add a caption to describe the gif or explain how it relates to the PR 👏 You can read more about PRs with @Brian Douglas’ post on Tips for getting your Pull Request reviewed on GitHub. Or check out the hottest repos and how they handle PRs on OpenSauced hot repositories. And if you have tips for creating great pull requests, let us know in the comments below. header image created using midjourney."
791,"Do you still use jQuery? Despite the emergence of newer technologies and frameworks, it seems that many web developers still use jQuery on a regular basis. Tell us why!The DEV TeamFollow        The team behind this very platform. 😄      "
792,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
793,"In many countries around the world, LGBTQ2S+ Pride Month is celebrated throughout the month of June. Here at DEV, we'll be celebrating by uplifting the stories of LGBTQ2S+ individuals in the tech industry.Interested in sharing your story? Learn more from the DEV post below!Share Your Expertise & Stories with #devpride this Pride Month! 🌈dev.to staff for The DEV Team ・ May 30#devpride#lgbtq#meta#wecoded  Why celebrate Pride Month on DEV?The team at DEV believes that all LGBTQ2S+ people deserve safe and life-affirming workplaces, schools, communities, homes, legal rights, and healthcare. We believe in a world where each person is empowered to be their true, colorful, and multifaceted self in all areas of life — including in our online coding communities.We believe that an inclusive technology field brings a diversity of thought, which is key to the development of the best possible tools, technologies, and visionary futures to make the industry and the world a better place.  Why is Pride Month celebrated?The first Pride Month in the US occurred in 1970 to commemorate the anniversary of the Stonewall Uprising of June 1969. The Uprising was a direct response to the oppression of LGBTQ2S+ people and their rights. A lot has changed in the 54 years since Stonewall, but we have a long way to go toward making the world a safe and inclusive place for LGBTQS+ people to be their true selves without fear of discrimination, oppression, and harm (even the United Nations Office of Human Rights thinks so).  So what can the #DEVCommunity do?This Pride Month, we're celebrating in a few different ways:  Spotlighting LGBTQ2S+ Tech ExperiencesThis month, the DEV Team will be sharing posts about organizations and initiatives helping LGBTQ2S+ people thrive in the industry. We'll also be giving a little shout-out to one of our favorite gay developers from history on his 111th birthday (if you know, you know! 🤖).  Uplifting Your Stories in #devprideWe’d love to hear stories about how being LGBTQ2S+ has impacted your career as a developer, both in positive and negative ways. We're particularly interested in hearing how you've overcome challenges within the community. Have there been specific jobs, conferences, or experiences that have played a role in your journey?We're committed to showcasing your content using our moderation tools and sharing it across our social media channels. Our goal is to amplify queer voices, provide visibility to queer experiences, and spark important conversations.Learn more from the post below:Share Your Expertise & Stories with #devpride this Pride Month! 🌈dev.to staff for The DEV Team ・ May 30#devpride#lgbtq#meta#wecoded  Adding Your Pronouns on DEVIn case you missed it: you can add your pronouns to your DEV profile! To do this, first make sure you’re logged in, then navigate to your profile settings > Personal > Pronouns.Not sure what this means? Check out this helpful guide to learn more.  Promoting Inclusion, Discussion, and RespectWe kindly ask you to join the discussion with respect and open-mindedness. Every voice matters, so let's make sure everyone feels welcomed and valued. Here are some ways you can help:Call out any abusive, harmful, and unfriendly language you see in posts and comments using our reporting toolsEncourage authors by leaving kind and welcoming commentsAsk curious, open questions and share your personal perspectives so we can help understand each other betterAnd, as always, follow our Code of Conduct!Let's create an awesome and inclusive space! Happy Pride Month, DEV Community 🌈❤️"
794,"Howdy! 🤠What y'all learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Whatever ya do, remember to take breaks and treat yourself for working so dang hard!"
795,"Alright, time to reveal some ancient history! What was your very first email address back in the day? And don't worry, we won't judge you for your cringy teenage email names (cough gamer_girl123 cough). Do we have any legacy AOL users? Yahoo, anyone? Bonus points if you still use it today! 😉Share your funny, embarrassing, or super cool emails (but don't share any sensitive information!)Join the conversation and follow the DEV Team for more fun discussions!"
796,"The most common description of Rust I hear is something like, ""it's great for performance but too hard or cumbersome or annoying for most tasks."" I don't think this description could be more wrong. Sure, it can be fast, but that's not the main reason to pick Rust. You should pick Rust because it's easy to build with. It empowers you to create incredible software while enjoying the experience.Sound too good to be true? I'll be honest; although this is my fervent belief, I wasn't sure it would hold up in many situations. Until now...  TL;DRI implemented the same reusable GitHub Action in both TypeScript and RustIt took about 3 hours for each implementation, 5 minutes fewer for the TypeScript versionRust was significantly less frustrating in debugging the problems I had, and I am more confident in the quality of the resultI created a template that should shave around 45 minutes off of the Rust time for future adventurers, meaning Rust should be even faster than TypeScript to implement moderate-to-complex actions from now on 🎉  The first experimentI wanted to write a reusable GitHub Action which runs some quick checks on GraphQL servers. I've authored actions before, but they're usually short Python scripts distributable via composite actions. This new action is too complex for a simple script.So, naturally, I decided to check out the other options for actions and found that the best-supported, most popular methods are JavaScript and TypeScript. So I wrote this action in TypeScript (my preference of the two) and had a terrible time doing it 😬. ""There must be a better way!"" I cried and immediately started over, this time in my favorite language.That's when the idea for this blog post came about—if I were going to implement this same action in TypeScript and Rust, I might as well compare my experience in each. So, I implemented the action twice more, this time while recording my efforts for science! First, I wrote it in Rust, then in TypeScript (again).Side note: I'm not going to release that raw footage because it's incredibly boring (trust me, I had to watch it and take notes to come to my conclusions), but if anyone would be interested in a sped-up, commentated version where I walk through each implementation and all the trouble I had, let me know!I intend to do something similar for other types of projects and languages. If there's a particular comparison you'd like to see, please let me know!  Some RulesI wanted the comparison to be as fair as possible, so I set a few rules for myself:When I encounter a problem I've seen before, I must do my best to solve it as if I don't know the solution. This is especially important because I have more Docker + Rust experience than most developers. I have also written this exact thing in TypeScript before (so I have solved most problems before).Any work which is duplicated between both implementations doesn't count against either. For example, I created a bunch of integration tests that were completely reusable for both implementations—so I cut that out of my analysis.The code should be shippable—but does not need to be perfect. I must be confident enough in the action to push the ""publish"" button, but I don't need to go down every rabbit hole to make it optimal (for example, I didn't parallelize any of the checks or set up benchmarking). I do, however, need to clean up any warnings or errors from the build tooling and linters.  The SetupI mostly wrote each implementation in one go—Rust, then TypeScript—because it was more natural. However, I will tell the story by swapping back and forth between the same section for each language. The first task was getting started—setting up a super simple working action to serve as a foundation.In Rust, this took a fair amount of effort. I spent 58 minutes (about one-third of the total) setting up the action. First, I had to read the GitHub documentation on Docker actions, then find an article about making a Dockerfile for Rust. Once I had the file, there was some back-and-forth fighting with GitHub Actions—and that was just the beginning. The hardest part was figuring out how to bypass the rebuilding of the image on every run—Rust is notoriously slow to compile, and waiting several minutes for the action to start was out of the question.This section highlights the worst part of Rust today—it is still a very young programming language, so it's missing a lot of resources available to other languages. After this project, I made a template and a corresponding blog post so that future developers (probably me) will have a much easier time implementing Rust actions. However, this template wasn't available to me yet, so it doesn't count for this experiment.On the TypeScript side, setup was much easier. There was already a template from GitHub that took care of the basics. Most of the time spent here was updating dependencies and getting my editor to play nicely with it—18 minutes, about 10% of the total.This was the only part of implementing this action that took me less time in TypeScript than in Rust—but it took 40 minutes less, which is enough to bring the total development time in favor of TypeScript.  ImplementationWriting the business logic of the action took the bulk of the time in both implementations—116 minutes for Rust and 145 minutes in TypeScript. Let's walk through each issue I spent time on in this phase.  Error HandlingRust does not have exceptions. This means that every time there could be an error, you're forced to deal with it. I don't allow panics in my production code, so I wasn't going to .unwrap() as a shortcut. Instead, I produced meaningful error messages for every possible error condition I encountered and bubbled them up in a type-safe way. This requires more upfront thought and effort than exception-based languages but means you're less likely to show an unfriendly error message (like a stack trace) to an end user.In TypeScript, there are exceptions. As with most exception-based languages, there are no static tools to help you know where or when they could occur. For production code, displaying an exception's stack trace is unacceptable (just like panicking)—I want to give users actionable advice. In TypeScript, you either have to encounter an error organically (hopefully not in production) or rely on documentation. It's also exceedingly rare for the type of all potential errors to be documented, so usually, I had to run the code through known error conditions and read the output (or set a breakpoint with a debugger) to find out what information was available to me. For example, I want to tell the difference between someone providing a malformed URL and a server being unreachable (so that I can provide users with relevant suggestions). The only way to do that is to know how the errors differ between those two conditions.Overall, I think I spent more time handling Rust errors (I certainly had more checks), but I was more frustrated dealing with TypeScript errors (because what I was looking for was hard to find). I definitely have more confidence that my end users will have a better experience with the Rust version since I may have missed some possible TypeScript exceptions.  Learning about GitHub ActionsEven with the setup done, there was much to learn about using GitHub Actions in both environments. The TypeScript template mostly came with examples of functions to call to get inputs, set outputs, etc. For the Rust version, I mostly resorted to reading bash examples and translating those to equivalent Rust code. TypeScript is the clear winner, though the total effort for either language was quite low. Again, like the initial setup, this is because TypeScript is older and more popular than Rust.  Outdated idiomsThis is the other side of the ""Rust is a young language"" coin. When following examples and IDE suggestions, there was only a single instance of copied code being out of date—and the code still ran fine; the linter just told me I should do it the newer way (format!(""{thing}"") instead of format!(""{}"", thing)). There wasn't a single time that an example or suggested code didn't compile and run correctly.On the Node side, conflicting idioms are documented everywhere, and it's not usually clear whether they are outdated! For example, axios is documented using the Promise API and CommonJS require() imports, but neither worked for my project. My ESLint setup (inherited from GitHub's template) told me that async/await is preferred, which required rewriting and made the error-handling documentation for axios all but useless to me. My setup also wanted ESM-style import instead of require()—but switching broke Jest. Several articles and incorrect fixes later, I realized that I just needed to update Jest. These issues were constant in TypeScript, and the error messages and search results were rarely helpful.Here we have a clear win for Rust, and I don't expect that to change. The official Rust linter, Clippy, is the best I've seen in any language at suggesting (or automatically fixing) updates to idioms. Rust also has a strong backward-compatibility guarantee and dependency management system that, together, mean your builds won't start failing in the future when new versions of the compiler or your libraries come out.  Paralyzed by choiceWhile there is often one idiomatic way to do things in Rust, sometimes the choice is unclear. For example, if or match could be equally valid in branching your logic—sometimes, you have to try both to know what feels better for a particular case. Likewise, choosing between functional-style iterators and imperative loops is not always clear until you've started down one path. It can be good to have options, but it's also easy to waste time deciding the best method.Another example of this is going down the rabbit hole of references and lifetimes. Remember, premature optimization is never a good idea. Start by cloning if you have borrowing issues, only try to optimize with references if you're sure you need them.TypeScript is certainly not immune to this, but I found myself spinning for options much less frequently. Usually, there is one preferred method and several older discouraged methods (which ESLint often catches). I give TypeScript the edge on this issue for less time spent on bikeshedding.  Debugging remote responsesWhen your code is talking to a remote data source—you will inevitably have to inspect what's happening at runtime when weird things occur. The two approaches I take are setting a breakpoint with a debugger and logging out the information I need to a console (printing). Using a debugger in Rust is easy (with an IDE like CLion), but the information you get from it is not always useful. For example, if I want to inspect a generic, parsed JSON payload without modifying my code, it's pretty much impossible. Because of this, I often resorted to printing the result, tweaking my code, and repeating until everything worked.In TypeScript, the dynamically-typed nature of the code leads to a much clearer debugging experience. Actually, my process for figuring out what a remote server is doing is pretty much identical to figuring out how each exception worked. I suppose it makes sense that the debugging experience would be better for a language where less static information is available. TypeScript wins here.  The toolingIn Rust, you get a standard set of tools that all work very well together. The build tool (cargo) manages the compiler (rustc), your tests, and your dependencies for you. If you used rustup (the recommended installer/version manager for Rust), you also get a formatter (rustfmt) and linter (clippy) for free, which are guaranteed to work well with the rest of the toolchain. There are many more features (e.g., docs) that I didn't need here, but the picture is generally that everything plays nice and gets out of my way unless it has useful feedback.In TypeScript, everything is separate. The compiler (tsc), formatter (prettier), linter (eslint), testing framework (jest), and runtime (node) are all distinct components, usually requiring extra dependencies to integrate them. NPM is generally pretty bad at telling you when you have incompatibilities (e.g., when my version of @types/node did not match my version of Node). The tools like fighting each other (e.g., when eslint was mad about an import that tsc needed for proper typing or when jest + ts-jest needed a different, special config from tsc/ts-node). You end up with many more config files and a lot more time spent fiddling with the tools than would be needed in Rust—sometimes to no end (I had to disable type-checking in a couple of places because I couldn't make it happy 😔)! This makes for a frustrating developer experience, especially when compared to the joy of Rust's.Without question, Rust has better tooling. In fact, Rust has the best tooling of any language I've ever used.  DocumentationEvery library I've used in Rust has docs on https://docs.rs generated with the standard cargo doc tool. You always know what to expect, examples can be tested with cargo test, and links to other dependencies are kept up to date. This is also the same format that the standard library is documented with. Overall, it's easy to learn how to use a new library.In TypeScript, every library has its own custom documentation. Often, this is just a README file uploaded to NPM, which is usually insufficient. When you combine this with less descriptive error messages from the compiler (or exceptions from the runtime), it's much harder to learn how to use a library in TypeScript than in Rust.  Fighting the languageThis is a much broader category, but sometimes the code you write doesn't work the way you expected it to. Rust and TypeScript have very different issues—Rust eliminates several categories of bugs that TypeScript is prone to but introduces some other challenges. For this, I'll focus on the one issue that stood out the most in each language when reviewing the footage.For Rust, it was one of the things folks complain about the most: the dreaded borrow checker 🙀. When going about my business, an error popped up in my IDE that said something like ""cannot borrow partially moved value"". The easy solution was to add .clone(), but whenever the borrow checker indicates that I'm re-using a piece of data, I try consolidating them. As it turns out, I had two if statements that were easy to combine and made for nicer code. That diversion took about 2 minutes—though it required understanding ownership, a concept that doesn't have a parallel in most languages.Learning about ownership taught me to see my data in a different light. I have caught several bugs in other languages because I was thinking like the borrow checker. I don't think learning ownership is an obstacle to overcome, but rather a useful tool that every developer should have.In TypeScript, my biggest hurdle started with a failing unit test: the array of error messages coming back from the main function should have had a length of 1, but had a length of 0. My first instinct was that there was a bug in the error-checking code, so I set a breakpoint and started debugging. After carefully stepping through, I found that I had used a concat method instead of a push with a spread operator. With unit tests passing, I pushed up the changes to find that, in CI, the integration tests were failing! After adding some print debugging and pushing back to CI, I found that I had used concat in a second location, causing separate errors. Overall this took 20 minutes of messing around to get an answer for something that should have been caught statically—and would have in Rust.One of the big differences between ""fighting the language"" in Rust and TypeScript is that Rust puts almost every problem in front of you immediately in the build and lint steps. Instead of failing tests, you get red squigglies in your editor, pointing you immediately to where the problem is. An example of this is #[must_use], which a function like concat would have in Rust. Basically, if a function returns a value, and you forget to use it (like, say, with errors.concat(new_errors)), it's a compile error.While it can be annoying to see more of your bugs up front, I definitely prefer that to stepping backwards from a distant effect. Rust wins here.  RefactoringAfter getting to the end of each implementation, I decided to take them a step forward by reworking some logic. Basically, I wanted to automate something that previously required a manual user setting.First, I rewrote the required code in TypeScript; it took 4 minutes. Then, I did exactly the same thing in Rust—another 4 minutes! So that's a tie... right? Well, not quite. When I changed the Rust code, the compiler pointed out a bug that was easy to fix. After I was done, I returned to the TypeScript code to see if it contained the same bug.Sure enough, I was consistent enough to write the same bug into both implementations 🤦. The tests I'd written didn't catch it, but the Rust compiler did. After another 8 minutes, I reorganized the TypeScript code to work properly. Without the Rust compiler, I'm unsure how long it would have taken me to catch the TypeScript bug.One of the greatest strengths of Rust being so explicit and strict is that it can catch many bugs that other languages can't. This is often talked about in terms of memory safety (when compared to something like C), but it goes way beyond this. If you leverage the type system to reflect the expectations you're making as you code, it will catch bugs that would slip through in other languages.  ConclusionIs Rust hard? As with most things, I don't think this is a binary yes/no question. However, I find Rust easier to work with than TypeScript (at least in this case—and I don't believe that TypeScript is considered a hard language. Personally, I would rather write production code in Rust than any other language.Still not convinced? Let me know which language and scenario you'd like to see compared next.  FootnotesA list of languages I've written production code in and consider the tooling significantly worse than Rust's, in no particular order: Python, Java, Kotlin, Swift, Go, TypeScript, JavaScript, C.Regarding how much professional experience I have writing in programming languages, Python is the first, followed by TypeScript, then Rust. I have certainly spent more time writing Rust than TypeScript, but I've been paid for more hours (and had more peer reviews) with TypeScript. The order of my confidence in writing each language is Rust, then Python, then TypeScript."
797,"Coding is like...following a recipe. It's like tending a garden, building a house solving a puzzle. Have you heard these metaphors? What do you think? Others? Are they relevant? How would *you* explain coding to a beginner?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
798,"Let's talk about the potential consequences of #AI and automation on employment and the workforce. As technology advances, it has the potential to change the way we work and the jobs that are available. While this can lead to increased efficiency and productivity, it can also lead to job displacement and changes in the labor market. How do you think we can prepare for these changes?Join the conversation and follow the DEV Team for more thought-provoking discussions.The DEV TeamFollow        The team behind this very platform. 😄      "
799,"Well hello again! My name is Rachel and I am a part of the Forem/DEV/CodeNewbie team. I have been creating this “What I Learned This Week” segment to discuss relevant posts on #codenewbie and/or #beginners that relate to things I have been interested in this week.If you haven't peeped the CodeNewbie tag or CodeNewbie Team Page, here are those things!#codenewbie Follow        The most supportive community of programmers and people learning to code.      CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.        Let’s Get Into It!SO, this week, I wanted to highlight a mixed range of things (surprise!). In all seriousness, this week I have been loving reading articles and depositing information into my brain that is written nicely (surprise again!). I have been more of a sedentary gal this week, so reading has been making me very happy. (SIDE NOTE: I am reading the book “Untamed” by Glennon Doyle and am loving it so much if anyone has any book recs send em to me below!)So here is my more reader-focused list  (instead of a help/task-oriented list) of the week!  Technical WritingI have long thought a career in writing would serve me super well and I coincidentally have thought about re-centering my career multiple times to being an instructional manual designer or machinery designer. This article was super up my alley and if you are looking for a more interdisciplinary field within coding and writing, this could be for you too!Technical Writing 101: How to get Jobs, Gigs & OpportunitiesLeslie Gyamfi ・ Apr 28 ・ 5 min read#beginners#technicalwriting#programming#blogging  Non-Linear Careers!I 👏 am 👏 all 👏 for 👏 non-linear 👏 career development (and you should be too!)! This article helps to break down what exactly a non-linear career is, how our current model of conceptualizing the tech career is outdated, and why we should support this way of learning. I think in many ways, non-linear career development is much more accessible, forgiving, and allows folks to indulge and explore their interests more fruitfully. Why Non-Linear Tech Careers Are the FutureMaddy ・ Apr 24 ・ 3 min read#career  Beginners Guide To Open-SourceLast week, I created a beginner crash-course to open-source, specifically focused on Github, as our Github + DEV Hackathon is happening right now!If you didn’t see that post, here it is below:What are your biggest tips for beginners to open-source and/or Github?Rachel Fazio for CodeNewbie ・ Apr 26 ・ 2 min read#beginners#codenewbieI found some new articles that could be of service to folks, especially beginners and non-devs, on how to contribute to open-source!Beyond Content Creation: How Open Source Contributions Can Help You Get NoticedBekahHW for OpenSauced ・ May 1 ・ 4 min read#webdev#codenewbie#career#opensourceNon-coders Guide to Contributing to Open SourceVoid⚡ ・ Apr 27 ・ 2 min read#opensource#tutorial#beginners#career  If You Need Motivation…OR Are Feeling Confused About Where To Start…This one needs no introduction, but a side-note from me is that I have said for months that I want to be like water and move mindfully through change, new challenges, and generally embrace adaptability more. I thought for a long time I got this from Brené Brown, but I stand corrected! I am glad to see articles like this urging folks to see through a new perspective.Don't obsess about choosing a first programming language, be water!Hercules Lemke Merscher ・ May 2 ・ 5 min read#programming#beginners  So You Don’t Feel Like Reading, But You Do Feel Like Talking…We released a great discussion that, in my opinion, deserves more attention! So drop your insights below! Embracing Your Coding Style: How Do You Express Your Individuality in a Tech Career?Ben Halpern for CodeNewbie ・ Apr 30 ・ 1 min read#discuss#beginners#codenewbie#careerAll this is to say, I really enjoy writing these posts and hope you enjoy reading about them.Share what you are reading/learning this week down below + Happy coding!"
800,"Hey Ruby developers! Did you know that you can use the ""yield"" keyword in your methods to make them more flexible? By calling ""yield"" in your method, you can execute a block of code passed in by the caller. This can be especially useful for creating dynamic methods that can adapt to different situations. Here's an example:def my_method  puts ""Before yield""  yield  puts ""After yield""endmy_method { puts ""Inside yield"" }Enter fullscreen modeExit fullscreen modeAnd the output:Before yieldInside yieldAfter yieldEnter fullscreen modeExit fullscreen modeGive it a try and let us know what you think! Share your examples in the comments.Got another Ruby tip? Share it here?Be sure to join us here on CodeNewbie Org next Ruby Tuesday for more challenges and tips to enhance your Ruby skills!.#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
801,"In recent years, we have witnessed unprecedented advancements in the field of artificial intelligence (AI) and natural language processing (NLP). One such remarkable development is the evolution of ChatGPT, a series of AI models developed by OpenAI. From GPT-2 to the latest GPT-4, these models have significantly transformed the way we communicate, interact, and engage with AI-powered systems. Let's delve into the revolutionary journey of ChatGPT, from GPT-2 to GPT-4, and discover how these groundbreaking models have reshaped the NLP landscape and prompt engineering.  GPT-2: The Breakthrough That Started It AllThe story begins with GPT-2, released by OpenAI in 2019. This groundbreaking model was based on the transformer architecture, which enabled it to generate human-like text with exceptional coherence and context understanding. GPT-2 was an instant hit, quickly gaining widespread recognition for its ability to perform a variety of tasks, including translation, summarization, and content generation.However, GPT-2 wasn't without limitations. Its 1.5 billion parameters meant that it required substantial computing resources to run effectively. Moreover, concerns about the model's potential for misuse, such as generating fake news or malicious content, initially led OpenAI to withhold the full version from public access.  GPT-3: The Quantum Leap ForwardIn June 2020, OpenAI introduced GPT-3, a massive leap forward in the field of AI and NLP. Boasting an astounding 175 billion parameters, GPT-3 was a game-changer. Its improved capabilities allowed it to generate text with even greater contextual understanding, creativity, and coherence. The model could now accomplish a wide array of tasks, such as creating poetry, writing code, and answering complex questions.GPT-3's release generated a wave of excitement, as developers and businesses rushed to harness its potential. Its advanced capabilities spawned numerous applications, ranging from virtual assistants to content generation tools, AI-driven tutoring systems, and much more. However, with great power came some challenges. GPT-3 required even more significant computing resources, and its potential for misuse remained a pressing concern.  GPT-4: The Pinnacle of AI Language ModelsFast forward to the present day, and we have GPT-4, the latest and most advanced iteration of the ChatGPT series. Building on its predecessors' successes, GPT-4 has taken AI language models to new heights. With even more parameters and enhanced training techniques, GPT-4 offers unprecedented levels of fluency, coherence, and understanding.Not only has GPT-4 revolutionized tasks like content generation, summarization, and translation, but it has also made significant strides in areas like sentiment analysis, code generation, and human-like conversation. This model is a testament to the rapid advancements in AI and NLP, proving that the future of these technologies is both promising and challenging.  In ConclusionThe journey of ChatGPT, from GPT-2 to GPT-4, is a testament to the incredible progress made in the field of AI and NLP. These groundbreaking models have changed the way we communicate, interact, and engage with AI-powered systems. As we move forward, it is essential to address the ethical and practical challenges to ensure the responsible and widespread adoption of these revolutionary technologies."
802,What's an unpopular tech opinion you hold that goes against conventional wisdom? We want to hear what you think about the tech industry and its trends. How likely are you to go against the grain? Share with us in the comments!Join the conversation and follow the DEV Team for more thought-provoking discussions!
803,Y'all know the drill! At the CodeNewbie Team we decided that we wanted to spice things up and try something new out to involve our newbies in Meme Monday! We landed on a Sloan's Newbie Memes of the Week! You can find last week’s meme picks here.Here are some of our favorites from this week:How is your week going so far? Drop us your fav memes you have added to your meme folder below!
804,"As a developer, there are always new programming languages and tools to explore. What are some languages or tools that you're curious about but haven't had the chance to use yet?Let's share our programming wish lists and maybe inspire each other to try something new!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!If you aren't exploring or posting over on the #codenewbie tag, find the tag here!#codenewbie Follow        The most supportive community of programmers and people learning to code.      Image by Freepik"
805,"Do you like to listen to music or podcasts while you code? If so, what kind of music or podcasts do you prefer?Our team has a preference for instrumental music or lo-fi beats to help us focus on intensive projects. Some of our favorites include Nujabes, Lo-Fi Girl, and Tomppabeats. As for podcasts, we enjoy listening to tech-related shows like ""CodeNewbie"" (of course!) and ""Syntax"" to stay up-to-date on industry news and learn about new technologies. “Radiolab” is also a particular favorite here at DEV.What about you? Share your favorite music or podcast recommendations in the comments below!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!If you aren't already exploring or posting over on the #codenewbie tag, find the tag here!#codenewbie Follow        The most supportive community of programmers and people learning to code.      Image by starline on Freepik."
806,"Hey there! It's Sloan, your friendly neighborhood DEV Moderator 🦥As I lazily scrolled through my inbox earlier today, I stumbled upon a message from a fellow DEV member seeking guidance on motivation strategies and work challenges.That's what Sloan's Inbox is all about: sharing advice and observations with those who are seeking insight on topics including career development, navigating office politics, staying up-to-date with industry trends, improving technical skills, and more.So, why not take a peek into my inbox for a fresh online advice column and discussion hosted by yours truly? Every week (or so), I'll be diving into the questions, comments, and thoughts of my fellow sloths.  Today's question is:What are some effective ways to stay motivated and focused on the positive aspects of the industry, despite encountering egos, toxicity, and competitiveness?So, don't be shy! Share your thoughts in the comments below and let's chat.Want to submit a question for discussion or ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
807,"In software development, there is often a drive to add more features and functionality to a project, but sometimes less is more. French writer Antoine de Saint-Exupery once said, ""Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away."" How do you balance the desire for new features with the need for simplicity and efficiency? Have you ever encountered a project that became too complex or unwieldy due to feature creep? How did you handle it? Let's discuss the importance of simplicity and minimalism in coding, and share tips for achieving it in our own projects."
808,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @mapleleaf's Top 7 post, tonight’s topic is...CSS libraries, frameworks, and engines! 🏗️TailwindCSS vs. UnoCSSMapleLeaf ・ May 1#tailwindcss#css#unocss#webThere are so many different ways to implement CSS, thanks to frameworks such as Tailwind, Sass, Bootstrap, MaterialUI, and more. From the above post, I learned that UnoCSS is unique to these in that it's an engine, not a framework—there are no core utilities. 💡Questions:Do you prefer a CSS framework or a CSS engine?What are the advantages (and disadvantages) of your preferred approach?Which are your favorite CSS libraries, frameworks, and engines? Why?Which are your least favorite, and why?And if you prefer vanilla CSS...why? 🍦Any triumphs, fails, or other stories you'd like to share on this topic?"
809,"Was it a cringe-worthy password on a post-it note, a poorly secured database, or a misconfigured server? 😢 What are some of the biggest security mistakes you've seen in your career? And don't forget to share your tips on how to avoid these mistakes!Join the conversation and follow the DEV Team for more thought-provoking discussions!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik."
810,"Restarting something Ben was doing for a while, and we plan on doing this every Friday! Open Source is about the community. Whether you have a project or you're looking to make your first PR.    Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFinally, consider reading the Best Practices for Maintainers.Happy coding!"
811,"When it comes to coding as a career, there's often a lot of pressure to conform to certain norms and standards. From choosing the ""right"" programming language to working for the ""right"" company, it can be easy to lose sight of what truly matters: your own preferences and passions.Top CodeNewbie Daily Discussions in April touched on a lot of different aspects of programming, such as language preference, work environment preference, and specialty focus. It’s not too late to join these discussions: Where to Start: Python or JavaScript?Ben Halpern for CodeNewbie ・ Apr 4#discuss#beginners#codenewbieWould You Rather Work in a Small Startup or a Large Corporation?Ben Halpern for CodeNewbie ・ Apr 5#discuss#beginners#codenewbieBack-end Guru or Front-end Fanatic?Ben Halpern for CodeNewbie ・ Apr 7#discuss#beginners#codenewbieAt its core, coding is a creative process. It involves problem-solving, critical thinking, and a healthy dose of experimentation. There's no one ""right"" way to code. Each developer brings their own unique set of skills, experiences, and preferences to the table, and that's what makes the field so exciting and dynamic. Find a community that supports your interests and values, like DEV! Connecting with others who share your passion can be incredibly empowering. So keep connecting with us in May. ❣️"
812,"As tech keeps moving forward at lightning speed, it's crucial to stay on top of the latest programming languages. The industry is growing and changing fast, so what languages do you think are gonna be big in the coming years? Which languages will continue to gain popularity in the coming years due to their performance, ease of use, and robust community support? And are there any new languages on the horizon that are poised to emerge and disrupt the industry? Drop a comment with your thoughts and let's chat about the future of coding!Join the conversation and follow the DEV Team for more thought-provoking discussions!"
813,"CSS has come a long way, and we're excited to see how developers have been using it in innovative ways in 2023. Have you come across a website that has blown you away with its use of CSS to enhance the user experience? Or maybe you've implemented a new CSS technique that has helped you achieve your design goals. We want to hear from you!Share your thoughts, examples, techniques, and ideas on the most innovative uses of CSS that you've seen or implemented in 2023 in the comments below. Let's spark a discussion on the future of CSS in web design and inspire each other to create even more stunning websites! "
814,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss a question from my inbox.Today's question comes from DEV Community Member @erinposting, who also happens to be DEV's Social Media Manager.Can the AT Protocol and the Fediverse coexist?Share your thoughts in the comments below! And please remember to abide by our Code of Conduct while doing so. Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
815,"Job interviews can be nerve-wracking, and sometimes interviewers ask questions that catch you off guard, or that are just plain...weird and terrible. What's the worst question you've ever been asked in an interview? And how did you respond? 👀Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
816,"Hey friends!What y'all learning on this weekend?Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.Don't work too hard!"
817,"We all have coding habits that we know we need to break - from not documenting code properly, not using version control,  or hardcoding values instead of using variables or constants. 👀Confess: what are your worst coding habits? And how do you overcome them?Join the conversation and follow the DEV Team for more thought-provoking discussions!Image by macrovector on Freepik"
818,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @samuel-braun's Top 7 post, tonight’s topic is...naming things 😱Naming: Every Developer's NightmareSamuel Braun ・ Apr 18#webdev#javascript#programming#tutorialQuestions:Do you have a favorite naming pattern for variables?What's the worst-named variable you've seen in the wild? Note: comments must abide by the Code of Conduct!How do you feel about naming? Love it, hate it, indifferent?Any triumphs, fails, or other stories you'd like to share on this topic?"
819,"If you are at the beginning of your machine learning studies, you probably already read the term ""vector embeddings"" together with NLP (Natural Language Processing). But what is this?  Vector? Which kind of vector?The term ""vector"" can be quite ambiguous, as it has various meanings depending on the context. In physics, vectors describe quantities with both magnitude and direction within a 3D space. In programming, vectors are often synonymous with arrays while in mathematics, vectors have their own unique definition. There are even vectors in biology, and the list goes on.For our purposes in machine learning, we need to focus on the mathematical and programming vectors, and we'll see how they are closely interconnected.   Mathematical vectorsMathematical vectors were inherited from physics, so they are values with direction, sense and magnitude.i  and j are 1D (one dimensional) vectors with the same magnitude, but with different directions.We also have the 2D and 3D vectors:  So... what's the difference between a math vector and a physics vector?While a physics vector is used to represent and analyze real-word physical quantities, a math vector is arbitrary and not necessarily represent (and respect😶) physical properties and rules. For example, OpenAI's generated vector embeddings have 1536 dimensions.See more about OpenAI vector embeddings  How can a vector have 1536 dimensions?How is this possible? We only have 3 dimensions, right? RIGHT!But as I said earlier, math vectors are arbitrary, so their dimensions are not necessarily related to the real physical world. A vector dimension in math is more like an aspect, a characteristic or a feature of the data. For example, as you may know, ChatGPT is a NLP model, so its vector embeddings need to have many dimensions to capture the meaning of so many words, getting contexts, interpretation, sentiment analysis and so on... they are called high-dimensional vectors.   What are vector embeddings?Vector embeddings are numerical representations of words or sentences, used in Natural Language Processing (NLP) to facilitate efficient analysis and manipulation of text data. By converting text into vector embeddings, NLP models can easily perform tasks such as querying, classification, and applying machine learning algorithms on textual data. So a vector embedding is nothing more than a mathematical vector generated to be used in machine-learning tasks.   How a sentence is converted into a vector?There are multiple techniques to convert a sentence into a vector. One popular method is using word embeddings algorithms, such as Word2Vec, GloVe, or FastText, and then aggregating the word embeddings to form a sentence-level vector representation. Another common approach is to use pre-trained language models, like BERT or GPT, which can provide contextualized embeddings for entire sentences.Using word embedding algorithms and then aggregating it to the sentence may not capture the nuances of word order or complex structures. More advanced techniques, like using pre-trained language models (e.g., BERT or GPT), can provide better contextualized embeddings for sentences. These models are based on deep learning architectures such as Transformers, which can capture the contextual information and relationships between words in a sentence more effectively.   ConclusionIn conclusion, vector embeddings are a crucial component of modern Natural Language Processing (NLP) and machine learning. By representing words or sentences as high-dimensional mathematical vectors, NLP models can efficiently process and analyze textual data for various tasks, such as querying, classification, and sentiment analysis. While the concept of vectors spans multiple disciplines, it's essential to understand that mathematical vectors are not limited by the physical world's dimensions."
820,"Pidgin will turn 25 years old this year, and when a project gets around this age people inevitably assume that the project consists of a decently sized team. Unfortunately, this is rarely the case.In Pidgin's case, we're currently sitting at three active contributors for the entire project. We will occasionally get some contributions from others but the vast majority of the work comes from these three people.As discussed in a previous blog post, Pidgin has three tiers of contributors. To quickly recap they are Developer, Crazy Patch Writer, and Casual Contributor.A causal contributor sends in some patches that addresses issues they've run into. A crazy patch writer is someone who has started understanding how the code base is laid out and has started addressing issues that are affecting others as well as themselves. Finally it's the responsibility of the developers to drive the project forward.The breakdown of our three active contributors are two developers and one crazy patch writer. From a code point of view, this actually isn't a bad breakdown right now as we're going through a cycle of heavy refactoring.The team hasn't ever been this small, in fact when I first got involved 20 years ago, the team was quite large as we can see in the following charts.As you can see, the number of contributors to Pidgin have been declining over time. There's a myriad of reasons why this happening and we're trying to attack the ones we can, but obviously we need to find a way to retain contributors.The bigger story of the charts is that, unfortunately, as the years passed by, people started to ""life out"" of the project. What I mean by that, is that careers, families, and other projects cut into that free time that was previously dedicated to Pidgin which is exactly what you'd expect to happen.Generally speaking this is fine as many Open Source projects will attract new contributors over time. However, this hasn't happened with pidgin.Case in point. There's a spike of new contributors in 2016. A lot happened that year. I took over as lead developer which helped bring some much needed energy to the project but we also moved to Bitbucket and as part of that started instituting code reviews for every contribution. This made it easier and provided guidance for new contributors. Unfortunately, as you can see from the chart, not many stuck around.An interesting thing to note here is that in 2016, we had a total of 829 commits from 68 unique contributors, but in 2022 we had 760 commits from 9 unique contributors and of those 9 contributors only 4 of them had 10 or more commits throughout the year.What this tells us, is that drive by contributions while nice, do not sustain the project, developers and crazy patch writers do.We're trying to find ways to attract more developers and crazy patch writers, but with Pidgin being 25 years old, we have a huge debt of not just old code to support, but documentation, infrastructure, and user base to support as well. All of these things don't lend themselves to attracting new long term contributors.Right now most of the support, all of the infrastructure, social media presence, as well as trying to find sponsorships for the project all falls on me. I do all of this, as well as drive the project forward as the lead developer, while also being the most active contributor with no compensation.What this means is that all of this work that I do for Pidgin does not pay my bills. Which also means that outside of the work I do to pay my bills, nearly all of my free time goes to Pidgin.As you may have guessed, this tends to lead to me being very cranky due to stress. Unfortunately, this comes out quite publicly sometimes too, especially when people constantly ""joke"" about how long Pidgin 3 has been in development, or how we barely support Pidgin 2 anymore, or how they have the solution to all of our problems when they don't even understand the problems.The point of this post is to ask people to please be patient with the project and myself. I'm sorry for those of you I've torn into publicly, but hopefully this post will help you to understand why this keeps happening. I'm not trying to be an asshole, I've just been burnt out for a very long time now and unfortunately taking a break only leads to more stress. So I'm on this ride until Pidgin 3.0 Alpha 1 is out. My hope is that at that point we'll be able to find some funding for either the project, me directly, or via some other Open Source funding organizations.I've applied to NLNet and other Open Source grants for Pidgin in the past, even applied a few times to some of them, but we haven't had much luck there.If you'd like to support the project you can find out more on the Donate Page for Instant Messaging Freedom. If you'd like to support me directly, you can do so via my Patreon.I hope you're enjoying these posts! Remember they go live for patrons at 9AM CST on Mondays and go public at 12AM CST on Thursdays! If there's something specific you'd like to see me cover here, please comment below!"
821,"Reflecting on the past year, what new skills or accomplishments have you achieved? These can be professional achievements, like learning a new programming language, building a project from scratch, or contributing to an open-source project? Or maybe they were more personal in nature, like running a marathon, making it to the end of Gravity's Rainbow, learning to knit.Whatever you've achieved: KUDOS! Take a moment to celebrate with us by sharing your experiences and how you achieved your goals.Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!If you aren't exploring or posting over on the #codenewbie tag, find the tag here!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
822,"What's the most efficient setup you've found? Do you use any specific plugins, extensions, or shortcuts? Let's share some tips and tricks to make our coding lives easier! 🚀Join the conversation and follow the DEV Team for more thought-provoking discussions!The DEV TeamFollow        The team behind this very platform. 😄      Image by pch.vector on Freepik."
823,"How do you prioritize between a project with tight deadlines and long work hours versus one with more relaxed timelines but lower pay? Meeting deadlines and putting in long hours can be a challenge, but the financial reward can be worth it. On the other hand, taking on a project with more relaxed timelines may mean a lower paycheck, but it can allow for a healthier work-life balance.Are you willing to sacrifice your free time for a higher payout, or is work-life balance more important to you? And if you chose the first option, how long can you last?Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
824,"Hey again, Sloan here! 🦥We’re sharing some tips for success when it comes to writing on DEV. If you’ve been looking to improve your technical writing skills, make the most of DEV as a blogging platform, and take your content to the next level — this series is for you!The first two posts in the series were about creating a series and formatting. This one is about tone of voice, and the next one is about topics. Let's get started!  Tone of VoiceWhen it comes to writing, your tone of voice is the manner in which you’re speaking to the audience. In order to succeed on DEV, we recommend writing with a tone of voice that is friendly, inclusive, and non-condescending.To learn more about how to utilize tone of voice in content writing, check out this awesome resource from the Nielsen Norman Group!  TitleYour post’s title is your first chance to make a good impression! A lot of factors come into play when deciding on the perfect post title. If you are interested in optimizing your content for search engines, you might have learned how to stuff your title with keywords. The truth is, while these things might make your content more likely to be visible to search engines…they sometimes make them less appealing for your human readers.If you’re trying to catch users’ attention, you might lead with a big claim to bait your readers to click (you know…clickbait). While this seems like a good idea, and sometimes works to get those initial clicks, readers will be disappointed when they get to your article and realize that there actually isn’t “One Amazing JavaScript Trick That Will Blow Your Mind, Change Your Life, and Automate Your Laundry!”We recommend using a title that sparks curiosity, but is true to the content. We also recommend limiting use of emoji in your title for accessibility reasons — you can learn more about that from this article from Accessible Social.  Be yourselfThe best way to add some personality to your content is to let your own personality shine through and speak from your own experience. It’s much more engaging to read a story about how you created your first Ruby gem than a generic explainer on creating a gem that’s copy and pasted from the docs.Being yourself also means not being a robot in the literal sense. Here at DEV, we’re just as excited (and a little scared 😅) about ChatGPT as you are! That’s why we wrote a set of guidelines for AI-assisted content on DEV. Check them out at the link below:Guidelines for AI-assisted Articles on DEVErin Bensinger for The DEV Team ・ Dec 19 '22 ・ 4 min read#meta#chatgpt#writing#abotwrotethis  Be inclusiveIn order to make DEV a safe, fun, and helpful place for all developers, we take inclusivity very seriously. In short, we ask that you abide by our Code of Conduct, use inclusive language, and not make assumptions about community members’ gender identities or pronouns.If you’re interested in fostering inclusivity on the web, we recommend checking out the Self-Defined dictionary.  Is it kind, necessary, and true?I like to use this three-prong test to decide whether or not to share a particular communication:Is it kind? In other words, is it stated in a way that’s friendly, inclusive, and assumes good intentions?Is it necessary? In other words, does it need to be said for the reader to understand my point?Is it true? In other words, am I conveying information that I know to be true without misleading the reader?With these tips in mind, you can’t go wrong when it comes to tone of voice in your writing on DEV. Happy writing! The next installment of this series will be about topics."
825,"Are you a programming language specialist or a generalist? Do you prefer to focus on one language and become an expert or learn multiple languages and be a generalist?As you develop your coding skills, you'll face the decision of whether to specialize in one programming language or learn multiple languages. Which will you choose? A depth of knowledge? Or versatility? Share your thoughts on this debate in the comments below!Follow the CodeNewbie Org and #codenewbie for more discussions and online camaraderie!"
826,"Restarting something Ben was doing for a while, and we plan on doing this every Friday! Open Source is about the community. Whether you have a project or you're looking to make your first PR.    Tell us about your projectPromote your project by providing a link to the repo. Everyone who posted in previous weeks is welcome back this week, as always 😄Open Source should be a welcoming space for contributors. The README is the front door of your project. If you'd like to check out an example of a README, here's our OpenSauced/insights README.If you submit please have the following in your repo to make it welcoming and helpful for contributors:README.mdCONTRIBUTING.mdFinally, consider reading the Best Practices for Maintainers.Happy coding!"
827,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   Naming: Every Developer's NightmareAh, naming things. It's a favorite mental exercise of developers, sandwiched somewhere between attending endless meetings and refactoring code. In this post, @samuel-braun shows you a way to think about variables and how to use them effectively. Even if you feel confident naming your variables, are you also using their full potential?Naming: Every Developer's NightmareSamuel Braun ・ Apr 18 ・ 6 min read#webdev#javascript#programming#tutorial  45 ways to break an API serverCheck out @zvone187's post on 45 ways to break an API server through negative testing. They provide scenarios that can be used to identify vulnerabilities and weaknesses in an API server. These examples only stress the importance of negative testing in ensuring the security and reliability of an API server.45 ways to break an API server (negative tests with examples)zvone187 ・ Apr 19 ・ 5 min read#webdev#api#testing#javascript  Dark Mode Toggle and prefers-color-scheme@abbeyperini demos how to implement a dark mode toggle on a website using the prefers-color-scheme media feature in CSS. By using this feature, the website can automatically switch between light and dark modes without requiring any user input. Dark Mode Toggle and prefers-color-schemeAbbey Perini ・ Apr 21 ・ 4 min read#javascript#react#css#webdev  Introduction to Web Animations with GSAPGSAP, or GreenSock Animation Platform, is a powerful JavaScript animation library used by web developers and designers to create interactive and engaging websites. With its versatility, speed, and ease of use, GSAP has become a popular choice among developers worldwide. Let’s cover the basics of GSAP and get our hands dirty with some animations with @topboyasante.Introduction to Web Animations with GSAPNana K. ・ Apr 19 ・ 3 min read#gsap#webdev#javascript#react  Productivity and Well-Being: A Summary of What Works@samuelfaure has been working remotely for a long time and has also been mentoring remote-working students. In this article, they will summarize what has worked for them and their students. Most of these tips should work for others as well, particularly if you are working remotely.📈 Productivity and Well-being: A summary of what works.Samuel FAURE ・ Apr 19 ・ 6 min read#productivity#career#webdev#learning  What Does Timing Attack Actually Mean?In this post, @propelauthblog highlights the risks of timing attacks. Attackers can exploit subtle differences in response durations to identify valid email addresses by making numerous requests and averaging the results. In these attacks, application response times inadvertently reveal sensitive information. What Does Timing Attack Actually Mean?propelauthblog ・ Apr 20 ・ 3 min read#security#webdev#beginners#cybersecurity  5 Topics You Should Touch on During the Recruitment ProcessThe recruiting process is never easy, but there are some things you can do to smooth out the process. @mplatek89 shares 5 crucial topics, especially for recruits, to touch on during the hiring process. By addressing these areas, both employers and candidates can ensure a better match and a smoother onboarding experience.5 topics you should touch on during the recruitment processMaciej Płatek for Emphie ・ Apr 20 ・ 5 min read#interview#career#programming#jobThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
828,"Disclaimer: I work at Netlify, so some of this post leans towards how to implement different rendering methods on Netlify. Other web platforms are available. 😎There are so many acronyms and initialisms in web development, it’s difficult to keep up. Does SSR affect my CWV? How many HTTP methods does it take to make a REST API? Does a SPA use CSR? Help, I need CPR! Don’t worry, I’m here for you. Let’s break down the acronyms and initialisms of rendering on the web so you can get some much needed R&R.  What is rendering?Rendering is the process of generating HTML markup to display web pages in the browser. How, and most importantly, where that rendering process happens can have a significant impact on user experience, site performance, and Search Engine Optimization (SEO).   Types of renderingLet’s take a look at the different types of rendering available on the modern web today, and which types of sites, pages and data they are most suited to.  Static renderingIn the early days of the web, all websites were static sites — collections of hand-written HTML files stored on servers, most probably uploaded via FTP clients (oh, nostalgia!), and served directly to users in their web browsers. Static rendering is still a great option to use today, and is particularly suited to sites serving a single HTML file, such as a single landing page of content. There’s no server computation required — so your page will load fast. And a single HTML file is super easy to host on Netlify, either via connecting a Git repository, or uploading via Netlify Drop. 🫳🎤 Here’s one I made earlier.  Server-Side Rendering (SSR)As the web evolved, the need for larger sites and more dynamic experiences emerged, and with this came the rise of Server-Side Rendering (SSR). SSR is a rendering method where web pages are built on a server at the time of the request.Type a web address into a browserSubmit the requestThat request travels to a server in a fixed location, where the server processes the request, builds the web page in real-time, and sends it back to the browser as an HTML document. SSR is still the most prevalent rendering method on the web today, being the default for application frameworks such as Wordpress and large monolithic tech stacks. Historically, SSR required a persistently running managed server, which often comes with undesirable overheads in terms of maintenance, scaling and security. Fortunately, modern front end JavaScript frameworks such as Astro, Next.js, Remix, Nuxt and Gatsby now provide configuration options for using SSR via modern web development platforms such as Netlify, by using serverless functions under the hood.SSR is best suited to serving pages that need to contain up-to-date, dynamic data, such as product stock levels or pricing if you’re building an e-commerce site, or personalized pages, such as if a user is logged in to an account on any site.The drawback to SSR is potentially longer latency. Servers usually exist in fixed geographical locations. The further the original request is from the origin server, the longer the request will take to make the journey there and back to the browser. And if your site is being viewed on a smart phone over a 3G or 4G connection, the request may take even longer.  Client-Side Rendering (CSR)Client-side Rendering (CSR) is the process of rendering content in the browser using JavaScript. When a request is a made for a web page that uses CSR, the server sends back a placeholder HTML document with a JavaScript file that will render the rest of the page and fill in the blanks in the browser.CSR became increasingly popular with the mainstream adoption of JavaScript in the browser during the late 1990s. Its place as a core component in the web ecosystem was further solidified with the evolution of Single Page Application (SPA) frontend framework technologies such as React, Angular and Vue. Like SSR, CSR is best suited to dynamic up-to-date data, but it comes with some drawbacks.With potentially megabytes of JavaScript to process on pages using CSR, your site may end up being slow to load and show data. Additionally, a combination of slow internet speeds, old devices, increasing web page complexity, buggy browser plugins or JavaScript simply not being available in the browser all point to using CSR sparingly.What’s more, CSR isn’t ideal for SEO. Most search engines can only crawl the content returned from URL — not the result of what might happen in the browser. If you use CSR to render your entire website, search engines will only ever be able to read your placeholder content, rather than the rich content that is eventually loaded in by JavaScript.  Static Site Generation (SSG)Static Site Generation (SSG) is the process of pre-generating HTML pages ahead of time, so that they’re ready to serve to your users instantly without the need for SSR or CSR. In the mid 2010s came the rise in popularity of static site generator tools such as Jekyll, which allowed developers to generate any number of static HTML files from templates during a build process. No more hand-crafting time-consuming single HTML files to get the benefits of static rendering anymore — yay! And with this came the ability to serve your site from a Content Delivery Network (CDN), such as Netlify’s CDN, which serves your static files and assets from the closest server node location to the request — making your site really, really fast. What’s more, given your website pages are pre-generated as full HTML files containing actual content, you’ll score more SEO points.There are hundreds of static site generators in the web ecosystem today, allowing you to build static sites using (most probably) any programming language your heart desires, including JavaScript, Go, Ruby, Python, PHP and Rust. Check out a huge list of static site generators on Jamstack.org.SSG is a rendering method best suited to content sites and pages that don’t change often. Blogs, portfolios, documentation sites and informational content are all great use cases for SSG. To update content, trigger a rebuild of your site, and the newly pre-generated assets will be ready to serve from the CDN once the build process has completed.   Incremental Static Regeneration (ISR)Incremental Static Regeneration (ISR) is Next.js’s proprietary implementation of a caching pattern called Stale While Revalidate (SWR). This allows for the regeneration of single statically rendered pages that have been modified, rather than rebuilding an entire site from scratch. With SWR, you can publish changes to a specific page — via a webhook trigger in a CMS, for example — without triggering a full site rebuild, resulting in faster site updates.SWR allows for very quick updates to static content while retaining the benefits of SSG. When you use SWR to render a specific page, a version of that page will be statically generated and cached during an initial build. When that page is updated, a rebuild of that page is not triggered straight away, but the next time someone requests that page. The previous (stale) version of the page is served until the page has been revalidated and regenerated in the background, and the next request for that page will receive the updated version.Bear in mind that with SWR/ISR, some of your website visitors may see outdated content as the updated page is rebuilt on the server and cached. You won’t want to use SWR for pages displaying data that should be accurate and up to date, such as pricing data. You’ll also want to generate a fallback page to serve if you’re using SWR/ISR to generate new pages, just to make sure your site doesn’t look broken or serve a 404.  Distributed Persistent Rendering (DPR)Distributed Persistent Rendering (DPR) is a handy rendering method provided by Netlify to use on very large sites in order to dramatically reduce build times. Instead of pre-building your entire site in advance using SSG, you can choose to statically pre-generate only your most popular and/or critical pages, and enhance your rendering strategy with DPR.DPR allows you to statically generate and cache pages on demand when they are requested for the first time. The first request to a page using DPR will result in an SSR-like experience, after which the generated pages will be served from the cache.Netlify supports DPR and SWR through the use of On-demand Builders — serverless functions used to generate web content as needed that’s automatically cached on Netlify’s Edge CDN.  Edge Side Rendering (ESR)Here’s where things get really exciting. Remember the CDN model we talked about, where static pages and assets are delivered to users from the closest geographical server location? Edge Side Rendering (ESR) harnesses the power of the CDN to deliver SSR as close to users as possible, providing the benefits that come with traditional SSR such as personalization and dynamic data, with improved speed for everyone around the world. ESR can be implemented for a full site, single pages, or even for just parts of pages.ESR on Netlify is provided by Netlify Edge Functions — serverless functions executed at the edge — that can intercept an HTTP request and modify the HTTP response before it is sent to the browser. This means that you can use ESR to enhance your static sites and pages at the time of the request. When you pre-build as much as possible with SSG, and use Edge Functions to modify pages when you need, you retain the speed of static rendering with the power of making dynamic updates to your pages when you need to. ESR is an excellent candidate for personalization, localization, internationalization and more — providing a kind of super-powered SSR wherever your site visitors are around the world.  Wrapping upThat’s a lot of rendering options! And you most probably don’t want to use them all in a single project. Ultimately, the technologies you choose — such as hosting platform and frontend framework — will determine which rendering modes are available to you in your project. Understanding the pros and cons, and the fit of the different rendering approaches to your projects and the types of sites you build is a great way to help inform your choice of tools and technologies, rather than letting those choices dictate your approach.Happy rendering! TTYL."
829,"We've started up this new series to shine a spotlight on the different DEV moderators — trusted members and tag mods — who help to make DEV a kind, helpful place. Aside from spreading good vibes and helping fellow community members, these folks also assist us with removing spam and keeping posts well organized by adding and removing tags as necessary amongst other things. If you want to learn more about what these awesome folks do, I recommend checking out our Trusted Member and Tag Moderation guides. There is information about how to apply in both guides if you're interested in joining up as a moderator.  Introducing Andy Piper 🙌This month, we'd like to put the focus on Andy Piper, a long-serving tag moderator here on DEV with many tags under his purview (#devrel, #mqtt, #micropython, #circuitpython, #arduino, #esp8266, #esp32, #openapi, #gear, #basic, #raspberrypi, #pihole, #iot, #mastodon, #fediverse & #activitypub). Andy is a super cool developer with a rich history in DevRel (previously at Twitter) and a strong interest in maker projects — think Raspberry Pi and 3d printing. I greatly value his experience as a developer and appreciate his help with moderating the community here at DEV. Not to mention, I feel very lucky to count Andy as a friend. Thank you, Andy!Andy PiperFollowDeveloper Advocate.Freelance #DevRel at #Mastodon.Friendly DEV moderator & helper. LEGO fan. IoT hacker. MicroPython tinkerer.Perpetual student.(prefer he/they/them)  The InterviewLet's jump right into my questions and Andy's answers!Michael Tharrington: Can you tell us about your developer origin story... like how you first got into tech and what was your first real developer job? And then just basically how things went from there?Andy Piper: Yeah. I've been around quite a while in life and so my origin story goes back to the 1980s, which makes me feel very old, but I'm not that old, really... And so I got into tech in the 80s.My parents got me an 8-bit computer which was called an Acorn Electron. So Acorn was a company in the UK that was kind of competing or it was around the time of the Sinclair ZX Spectrum, Commodore 64, all of those kinds of computers back then. And Acorn was a company that won a contract to supply computers to schools back in the 80s. So every school had what were then called BBC Micros — it was a program with the BBC (broadcaster in the UK) to encourage kids to learn to code. So, I learned to code using a language called BASIC which is still around. Somebody's just posted about a BASIC interpreter on DEV this week [referencing Announcing MiniBASIC]. BASIC stands for Beginners' All-purpose Symbolic Instruction Code and it’s a good language to learn to code in. So, I started off back in the 80s before the Internet was around, and when I was at school I had a little company with a friend selling software to some other schools — educational software for chemistry. I didn't get into PCs and Windows until a lot later on when I was in my teens. I had a degree in history, so it was difficult to get a job in tech.In the late 90s, I managed to get a job at the UK Post Office on a management training scheme in their technology division. But I still wasn't programming properly; I was kind of doing helpdesk-type work. But I was coding for myself, so I am self-taught as a developer completely — I’ve got no sort of formal education in computer science or anything. After four years at the UK Post Office, I'd learned on-the-job stuff like UNIX and version control systems that came before Git called CVS. And, I was working with some consultants from IBM who introduced me to their manager. I ended up going to work for IBM as an experienced software engineer, basically in their integration practice. I did 10 years at IBM.Then I was doing a lot of public speaking and our community work with different things like Internet of Things. There's a technology called MQTT which is for sending messages between small devices (which was from IBM), and I ended up working for VMware on a cloud platform called Cloud Foundry as an advocate. Then I was at Twitter for nearly nine years doing API stuff. So, I've done a ton of stuff, almost all sorts of hobby/in-the-background community stuff which is interwoven with being able to do stuff professionally as well. Michael: Nice. That's really cool. And I've got a question that wasn’t listed, but jumping off from that, when do you think you realized that you were the computer person in the room or the most technical person? When-abouts would you say you kind of landed on that realization? Andy: I was always! Yeah, I was always the one at my school. There was kind of a very clear group of nerds around. You know, when I was at school, we had a room that was the computer room — the room that had the computers — and everybody went to a computer lesson in that room. Everybody didn't have a phone in their pocket and, you know, computers weren’t everywhere, so I was always really into that and into that group. When I was at university, a lot of people were coming to me for technical support and help. They'd often got a laptop and they didn't know how to get on the university e-mail system — things like that. So I ended up writing a help sheet for the other students: this is how you sign up for university e-mail, these are the commands to type to access the system — I wish I still had that actually. But that was very much my first instructional piece. I really wanted to work in tech and when I got to the end of my university course, I started to go around and try to do job interviews. I was really disappointed to discover how hard it was, without having a technical or science degree, to even get my foot in the door for most of those interviews. But yeah, I decided pretty early on it was either going to be tech or teaching. And, I've been fortunate in the end to sort of combine both just through how I behave and the kind of events and communities I've been involved in. But again, I don't have any formal education in how to educate, I've just learned it along the way. Michael: Awesome, that makes sense. Okay, moving to another question, if you could go back in time to when you first started as a developer and give yourself one bit of technical advice and one bit of non-technical advice, what would you tell yourself?Andy: So I thought hard about this because I was going through these questions earlier and I'm going to give you the non-technical advice first, which is I think it's taken me a long time to really learn how to listen. And I still interrupt people quite often! Also, patience. I think patience and listening are the two things that I value the most and I've learned the most about. I think early on I had a real problem with not listening — trying to invent solutions first to problems. I'd get impatient if I couldn't solve something immediately or if people behaved irrationally (or what I thought was irrationally)... I didn't always just absorb the situation. So those are two things that I think I would encourage myself to think about at an earlier age.Technically, I struggled a little bit with the question because one of the bits of advice I often give to folks who come to me for technical advice... and they sort of say, you know, what programming language should I learn? It doesn't really matter because everything changes all the time. So, I was trying to find a way of telling myself 20 years ago that and then I actually thought technically, I think the thing that’s been most valuable that would be better to start using earlier would be source control. And it's a very boring thing to say, but I'm sure that I lost so much time by not being able to go back to where I started or track the changes I've made in the past.And systems like Git are not easy to learn. I've tried to teach them to people before and they are not always intuitive. I still have to go back and read the manual to figure out how to do stuff. So, I think technically learning about source control earlier would have been better, though it didn't really exist when I was just setting out anyway. But yeah, just getting comfortable with that concept. Even still, the last few days I've had several computers around me and I've got bits of code on each of them. I'm thinking, why didn't I just put this stuff in one place and go from there? It's just for my own lack of technical knowledge.Michael: Is source control the same as versioning?Andy: Yeah, basically, versioning is the ability to go back through history — decide where you're at, share that state between machines and people. Michael: Cool, so you know when you mentioned CVS earlier as Git version control, that was like the early version? Andy: Yeah, yeah. Before that, there was another system called RCS, and then there was CVS, and then there were a couple of other things. And then eventually Linus Torvalds decided that he hated them all and he was going to write his own. And that's why we have this thing called Git. He invented Git to manage Linux — the source control of Linux basically — and now it's taken over the world.Michael: Thanks for that. OK, cool, I'm moving on to question 3. As a developer, what are your specialties or areas of focus?Andy: So, I guess it tracks with my interests and my background. When I was at IBM, I was doing a lot of stuff to do with messaging. Programs sending messages between one another... sending data between one another. There's this technology called MQTT which is a lightweight messaging protocol for sensors and other things. My 3D printer is sat here right now using that technology, which is something that I worked on 15 years ago at IBM, and it's publishing every single update. Every single time it moves the print head, it's sending a little message into the cloud saying the temperature is 200 degrees, I've got this much filament, and I am moving between here & here. So, MQTT messaging and Internet of Things is one thing that I'm super interested in, for historical reasons, because I know a lot of stuff about it. APIs! APIs are how programs interact with programs. So you've got how hardware interacts with the world through MQTT and other messaging software. You've got how programs talk to one another. So, like posting something new on DEV, there's something behind that. That is the DEV API that is supporting the ability for a user to post that information into DEV. You don't really see that because it's all done through your browser, but I've got a ton of background with that stuff. And then programming language... the one I normally reach for now is Python because it's easy and straightforward, and it's on all the platforms. It doesn't require me to think too hard. It's a very expressive language. It lets you kind of write code as you think about it usually. And those are the kinds of things I have spoken about at conferences and in the last couple of years. Michael: Cool. OK, moving on. How did you first discover DEV and what encouraged you to become a moderator for the community?Andy: So, I was following Ben and @ThePracticalDev quite a few years ago and I guess the question is how did I discover them? And I don't remember, but I was following them and then DEV came out from @thepracticaldev as a thing and became a new site. And I really liked the look & feel and ease of use of it. I started sharing some of my stuff and I could write in a Format that was familiar to me — Markdown. And, I found myself going there most days or fairly frequently to see what was new or what stories were bubbling up on the front page. And then, from the moderation perspective, I love to see things stay on track and I think that it's important that communities can have off-topic conversations, but unless there's a core purpose for the community, then things rapidly disintegrate. So, I always think that keeping on topic, like making sure that if we're talking about web development, we're talking about web development. We're not talking about, I don't know, spaceships or something totally different.And also, moderation can be tricky with people. People have different opinions. People don't always realize there's another person on the end of the screen, on the other end of the words they're typing. So, there can sometimes be communication breakdowns or misunderstandings... and just trying to keep everything friendly and conversational — it's something that is kind of part of my DNA. When I started at Twitter and I inherited Twitter’s developer forums, there had been no moderation. They were very negative and everybody really just came there to complain and shout, and that became a self-fulfilling or snowballing behavior and everybody came in just to shout louder than everybody else, rather than sharing solutions to problems. And so, I'm quite keen on keeping conversations healthy as best I can, and that's why I offered to help if I can. Michael: You certainly do help! Thank you. I'm interested when you inherited Twitter's developer forums, what did you try to do to kind of move the situation back to a more productive, “let's think of solutions” mindset rather than throwing our hands up or pointing fingers at one another — was there anything that you could kind of point to?Andy: We started over and were more present, or at least one or two of us were more present. We didn't want to lose the information that had been there previously. So, we — and I didn't feel great about it — but, what I did mostly was to go through and delete, remove, mute the off-topic content. We moved to a different system, a different platform for running the forums — from Drupal to Discourse. When we did that migration we went through and got rid of everything that was openly offensive. You know, any inappropriate conversation and comment because it just drove people away and drove people to just deliver more of that kind of input. So, we really started over... created new topic categories, created new ground rules, and enforced those ground rules! If people were not going to behave in the way that was expected, then we were going to have to ask them not to be there. When I first started, six months before we did this sort of reboot, I spent a lot of time every morning, again being a geographically distributed team (as we are at DEV overall as a group of moderators), you know, certain time zones other people aren't gonna be online and you're just going to see a wall of spam... and you're just going to be clicking to get rid of it all. And I'm not saying that's a problem with DEV completely, but certainly, back in the day, that was absolutely the problem with the Twitter forums. It was just overrun.Michael: I'm going to jump on to one last question... What are you working on or learning about now? Are there any projects that you’ve been particularly focused on (personal or professional)? Is there anything that you’re currently learning (new or old tech)?Andy: So, what I'm learning at the moment... I'm in the middle of a career break (accidental career break) right now. So, I'm spending a ton of time learning! At the moment, it's related to software development, but also not... I'm doing some learning, some 3D printing, and computer-aided design — 3D modeling. So, I'm learning all those things. My wife and I just set up a maker studio called Forge & Craft so that's where I am right now. I've been writing recently about the Mastodon API and Python, and I'll be writing some more about that soon, so I'm excited about, again, APIs, the Fediverse conversational communities. And I'm doing a lot of fun things with, again, stuff I've written about in the past on DEV, which has tended to be MicroPython. So, small devices hacking on little connected screens that I can like send MQTT messages to that are going to be a dashboard on my pegboard here.And, I'm also really enjoying going back to my roots with 8-bit computers. So I've got something over here which is about the size of my palm; it's called an AGON Light. You just plug it into a keyboard and a screen. It doesn't go online, you just write BASIC programs on it. It's cool; it's nice. It's really the kind of thing I grew up with. Except now instead of being, you know, this big [gestures widely], it's this big [gestures something hand-sized]. Michael: This is all really interesting stuff! Can you just talk briefly about what you do as far as 3D printing goes... what have you been working on? Andy: I'd been wanting a 3D printer for a while, mainly to put my electronics project into cases. And so, I borrowed one from a friend just after I finished my last job. And then there's been some new ones that have come out and I got really into how 3D printing works. I bought a really fancy one that can change the color of filament and things like that. So I'm mainly making things like cases for electronics. But I've been learning... I've bought a really cheap one and I’ve bought a really expensive one. The cheap one was like $80.00 from China and it sits on a little trolley here... the code is open source for it and I can program it with a Raspberry Pi and do cool stuff with it. The high-end one is more like the Apple of 3D printing. It's like, I'm not going to fiddle with this, I just want it to work. I don't want to start, you know, breaking it... I've been making gifts for people. There's all kinds of stuff I’ve been making. I've mostly been making stuff for my own workshop, but I've got a ton of ideas that I like to play with.  This is the classic thing that they call the Benchy. So this is the benchmarks thing... like any 3D printer, you're expected to print this thing because it tests things like the curves and the circles, how closely you can see the layers, and stuff like that. So this is kind of like a benchmark test for 3d printers, and I've got literally got one on my desk here.Michael: It really reminds me of a rubber duck. Just has that look to it.Andy: Yeah, definitely!Shortly thereafter, the call dropped, but you're not missing anything — we had completed the interview!  Wrap upThanks so much for checking out this interview. Stay tuned for future issues in this series!"
830,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
831,"Hey there, you've happened upon Code Your Way: Quick Challenges in Every Language! Every week, we throw down a new programming challenge that you can take on in any language you like. It doesn't matter if you're a coding ninja or a newbie, these challenges are perfect for taking a break, sharpening your skills, pushing yourself, and learning new tricks. So, grab your go-to coding tools and let's dive in.   Today’s challenge is the BadaBing!Write a program that prints numbers from 1 to 100, but for multiples of three, print ""Bada"" instead of the number and for multiples of five, print ""Bing."" For numbers that are multiples of both three and five, print ""BadaBing.""Your goal is to complete this challenge in the most efficient way possible. You may want to time yourself. ⏰ 🏃🏻‍♂️ See you in the comments!"
832,"Are you a new coder? Or are you thinking about starting your coding journey? If so, you might be wondering what you have in common with other coders. First of all, coders share many traits:Tendency to talk to their computersLove of memesLove of shortcuts and hacksAnd new coders also share: Excitement and curiosity about the world of programming. There’s so much to learn!Persistence and determination. Learning to code can be challenging, but with the right mindset and resources, anyone can succeed.And maybe most importantly, community! New coders often seek out community and support, and you’ve come to the right place. CodeNewbie on DEV can connect you to other coders on similar journeys and at varying stages of their careers. Joining discussions, participating in challenges and hackathons, and writing your own posts can be a great way to stay motivated and learn from others.So if you're a new coder, know that you're not alone. Weigh in in the comments! What other traits and attributes do coders share?Okay, now here’s your meme:Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!If you aren't exploring or posting over on the #codenewbie tag, find the tag here!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
833,"Have you ever coded from a strange, remote, or unusual location? A mountaintop, a beach, a hot air balloon…the room where you grandma stores her antique doll collection? 👶🔪 Share your unique coding spot with us in the comments. Let's see who’s had the most creative workspace! Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this.  "
834,"This week we are going to switch it up a bit! If you are new here, I normally use this “What I Learned This Week” segment to discuss relevant posts on #codenewbie and/or #beginners that relate to things I have been interested in this week.If you haven't peeped the CodeNewbie tag or CodeNewbie Team Page, here are those things!#codenewbie Follow        The most supportive community of programmers and people learning to code.      CodeNewbieFollow        The most supportive community of programmers and people learning to code.  Part of the DEV family.      However, this week, with our Github + DEV Hackathon that was just announced, I am here to post a couple of Github-related articles that I found interesting/potentially helpful for y’all who maybe want to enter the Hackathon!Here is the info for the Hackathon if you missed it:Announcing the GitHub + DEV 2023 Hackathon!Brian Bethencourt for The DEV Team ・ Apr 25 ・ 6 min read#github#meta#opensourceAlso (side note) for y’all who are beginners who are maybe feeling the whole “why would I enter, I am not good enough to win” imposter syndrome-vibe,  this is also a friendly reminder that if you participate by sending in a valid project, you get a free DEV Sticker Pack + a badge for your profile STILL! So, if you are looking to explore new things, but only have the time/capacity for a small project, go for it anyways!  Here we go! Here are my biggest tips and resources for Github + open-source.If you need a general introduction to Github and/or Git, look no further!Getting Started with Git and GitHub: A Beginner's Guidemohsen ・ Dec 28 '22 ・ 6 min read#git#github#tutorial#beginnersIf you want an introduction to open-source projects, here is your pick:20+ Open Source Project for BeginnersSuraj Vishwakarma ・ Jun 27 '21 ・ 4 min read#opensource#beginners#github#javascriptOur very own @jess made a open-source guide for beginners YEARS ago that still holds up great! Find that here!Open Source Resources for BeginnersJess Lee ・ Jun 7 '17 ・ 2 min read#opensource#beginnersIf you are looking for a tutorial on Github in quite literally anything (well, not anything but a lot of things), here are some great repositories!Cool Github repositories for EveryoneAatmaj ・ Dec 29 '22 ・ 9 min read#github#opensource#beginners#resources100+ Most Useful Github Repositories Every Programmer NeedsJaxongir ・ Nov 17 '22 ・ 10 min read#javascript#programming#githubOkay y'all, that is about it for this week! I hope everyone has a great week, let me know what you are learning OR let me know what your biggest tips for beginners to open-source and/or Github are below!!!"
835,"Coding is becoming an increasingly important skill in today's world. It's no longer just for tech professionals;  anyone can benefit from learning how to code. As Reshma Saujani says, Learning to code is useful no matter what your career ambitions are.Coding can help you work more efficiently, creatively, and independently. It can help you develop problem-solving skills, increase your earning potential, and open up new career opportunities.In what other areas of work and life can we use coding practices? How have you applied coding practices in creative ways?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
836,"Welcome to Ruby Tuesday, a weekly post where we explore the world of Ruby programming language. Today's challenge is all about modifying a factorial method in Ruby to handle negative input numbers. In this code, the factorial method takes a number n as input and recursively calculates its factorial. The base case is when n is 0, in which case the method returns 1. Otherwise, the method multiplies n by the factorial of n-1.When we call factorial(5) using the puts method, it calculates the factorial of 5 (i.e., 5 * 4 * 3 * 2 * 1) and outputs the result, which is 120.def factorial(n)if n == 01elsen * factorial(n-1)endendputs factorial(5) # outputs 120Enter fullscreen modeExit fullscreen mode  Challenge:Modify the factorial method to handle negative input numbers.Put your Ruby skills to the test. Go!Leave your solutions, thoughts, tricks, and questions in the comments below. And be sure to join us here on CodeNewbie Org next Ruby Tuesday for more exciting challenges and tips to enhance your Ruby skills!.#codenewbie Follow        The most supportive community of programmers and people learning to code.      "
837,"The title may sound bold and clickbait-ish, but it is what it is...A few days ago I stumbled upon a post on LinkedIn (unfortunately, I didn't save the link) in which a programmer demonstrated his solution to a LeetCode challenge. The code was fine and the post got dozens of likes, which it undoubtedly deserved. I decided to feed the requirements to ChatGPT-4 and see if it could understand and solve the problem. The outcome was... interesting and I spent some time experimenting with the AI, modifying the prompt to see how it affected the results.  The ChallengeFirst, I would like you to take a look at the LeetCode problem and attempt to solve it. Take your time, give it some thought. Then, google it. Yes, search the internet for the best solution.Given two integer arrays pushed and popped each with distinct values, return true if this could have been the result of a sequence of push and pop operations on an initially empty stack, or false otherwise.Example 1:Input: pushed = [1,2,3,4,5], popped = [4,5,3,2,1]Output: trueExplanation: We might do the following sequence:push(1), push(2), push(3), push(4),pop() -> 4,push(5),pop() -> 5, pop() -> 3, pop() -> 2, pop() -> 1Example 2:Input: pushed = [1,2,3,4,5], popped = [4,3,5,1,2]Output: falseExplanation: 1 cannot be popped before 2.Constraints:1 <= pushed.length <= 10000 <= pushed[i] <= 1000All the elements of pushed are unique.popped.length == pushed.lengthpopped is a permutation of pushed.Done?Alright, remember I asked you to brainstorm and google it? So if the machine-generated solution happens to be more efficient, the argument ""it's not fair because it was trained on data from the Internet"" is not accepted 😉  Release the KrakenWhen I initially asked ChatGPT to tackle the challenge, I copy-pasted the task from LeetCode. However, in this case, it might indeed seem like the AI pulled the solution from the depths of its ""memory"" without much ""thinking"". So let's rephrase the requirements and see if the machine can handle it. Here's the prompt I used:The output:Not bad, and according to LeetCode statistics, this is an average solution, more or less. Now let's push our beloved AI a bit further and ask it to enhance the code:This is where things become really interesting! Not only did it offer an elegant solution without allocating a stack, but it also explained a potential issue that could arise from this optimization. Let's check it out on LeetCode:The numbers speak for themselves, right? Of course, some might argue that LeetCode's benchmark is inconsistent, which is a valid point. Nevertheless, the fact remains that the AI instantly produced a decent solution and improved it in a way that not every software engineer can do.  What's Next?So, are our jobs safe?Yes 😅 (unless you work for Elon Musk)To draw an analogy, today's ChatGPT (and other AI assistants like GitHub Copilot) is like an electric tool that can drill holes, drive screws, saw and more. However, if you just place it on the ground, it won't build a house for you. What is more, unskilled individuals might even harm themselves with this tool. On the other hand, experienced engineers can use the power and potential of AI to significantly improve the quality of their work.That's it for now. Cheers!"
838,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...the future of social media 🔮📱Things are changing in the social media landscape, largely due to the shakeup at Twitter over the past year or so. Here at DEV, we've been exploring the Fediverse while we build our own free and open source online community platform (it's called Forem, check it out!).So let's talk about what comes next! What do you want the future of social media to look like, and how can we build it together?Want to submit a question for discussion, or even ask for advice? Visit Sloan's Inbox! You can choose to remain anonymous."
839,"Y'all know the drill! We decided recently over at the CodeNewbie Team that we wanted to spice things up and try something new out to involve our newbies in Meme Monday! We landed on a Sloan's Newbie Memes of the Week! You can find last week’s meme picks here.Here are some of our favorites from this week:If you'd like to join in— drop your beginner-related, job-related, starting-a-new-career-related memes down below!Happy coding y'all!"
840,"Heyo newbies!I'm curious what y'all are learning about this weekend...Whether you're sharpening your JS skills, making PRs to your OSS repo of choice 😉, sprucing up your portfolio, or writing a new post here on DEV, we'd like to hear about it.  And hey, don't work too hard now... it's (nearly) the weekend! 🧘"
841,"I often get asked what my favorite tools are and how I use them to get my work done, and I'm writing this both to answer that question, and also for me to just paste a link to this post next time I'm asked. Efficiency!I wrote about this last year and realized that I both didn't include everything I wanted to, and also had more to add, so let's dive in!Also: This post will not cover my code editor(s), terminals, or other developer tools. This is just a list of the tools I use daily to get my tasks done! Also, all of them work across operating systems. I use both a PC and a Mac, so that's important to me. There might be better options out there for one machine over the other, but that's not my jam.  ObsidianWebsiteI take notes with Obsidian, write my newsletter with Obsidian, write blogs with Obsidian (like this one), keep track of projects with Obsidian, plan classes with Obsidian... I'm alllllll in on Obsidian.It's a local-first markdown editor. I love that I can keep everything local to my machine (so I don't have any slow load times), and just write markdown without anything getting in my way. Beyond that, they have an open plugin + theming setup, and you can pay for syncing across devices as well. I often jot down quick notes on my phone, and then I access them later on my computer to flesh them out, and it's perfect for that.  CenteredWebsiteWhen I use Centered, I get more work done, simply put. I was a little slow to get into it at first, I had to give it a second chance, but now I can't imagine getting all that I want done without it. I often have trouble focusing throughout the day when I have a lot to do, and Centered helps a ton with that.Centered is a flow state to-do app. It's kind of hard to explain quickly, because it does so much while being pretty simple, too. You plop in your to-do list for the day/session/whatever, each task has a certain amount of time assigned to it, and then you hit start. It'll play some music designed to help you focus, and it has a coach that speaks to you about how much time is left in your current task, gives you breaks, and pokes you when you're distracted. It also has an optional thing where you can have your camera on while you work, which is weirdly good at keeping you feeling focused.I made a group in it if you'd ever like to flow with me! Other groups in there include students, web developers, special interest groups, and you can make private groups with your friends as well.  RaindropWebsiteRaindrop is an all-in-one bookmark manager. It's one of those apps where I used the free version for about 5 minutes before deciding to pay for it forever, because it works perfectly. It works as a browser extension, as a mobile app, and as a desktop app on all the platforms, and lets you very easily and quickly tag and categorize your bookmarks.It lets you do public bookmark collections, so for example if you head over to cass.run/ref, that's a public collection of my referral links to various services. It also lets you save permanent copies of your bookmarks (so if something goes offline, you still have access to it, I've saved some of my favorite blog posts this way), does a full text search of the pages you save, and annotate web pages, too.  CronWebsiteCron is a keyboard shortcut-powered calendar app. I've tried a bunch of calendar and scheduling apps over the years, and Cron is my current favorite. It lets you quickly use keyboard commands to see your teammate's calendars, share availability, view multiple timezones, and create events. They were bought by Notion recently, so I think we can expect some interesting integrations from them soon. My only complaint with this one is that it only works with Google Calendar so far (and I've been wanting to move away from Google for various things), but it's not the end of the world.  todometerWebsiteThis is a shameless plug, but I use todometer for task management, and... I built todometer.todometer is a meter-based to-do list for your desktop. I use this to keep track of things that I'd like to get done throughout a given day or week, without the restrictions of a flow state session. I made it because I am motivated by progress bars, and sometimes I just need a simple list prominently on my desktop of what I need to get done. Plus, it's local-only, so you don't have to worry about loading times. Here is the repository if you'd like to see how I built it (full disclosure: I want to maintain it more, I have a roadmap in mind for a few things, but I've got other things to do, so if you make an issue, I'll get to it... someday).  Dabble.meWebsiteDabble.me is a private, email-based journal. I've been using Dabble.me for literally over a decade and it's the only journal I've been able to consistently work with, probably because it's just super convenient. It emails you regularly (depending on the frequency you set) asking how your day went, and will occasionally remind you of previous entries saying, ""one week ago you wrote..."" or ""two months ago you wrote..."" etc.I have absolutely loved this service and is probably my favorite one overall, just because it's a treasure trove of memories for me at this point. Sometimes my entries are super short like, ""I played way too much Minecraft today, ugh."" and sometimes they are very long essays of me ranting about work or life or food or something. It's not so much a ""productivity"" app so I wasn't sure if I should include it in the list, but it's a consistent enough tool for me that I thought it deserved a shout.  That's it!I've tried a lot of different tools over the years, and this is just my current ""stack."" I do think that it's worth reassessing your tools fairly regularly. I used to use other ones, like Bear, and Notion, and Vimcal, and Trello, etc, and they all worked for me at the time, but figuring out what you like and don't like about your ""stack"" is super helpful for upgrading how you work over time.It's not just the applications, it's the dedication to them that really make them work for me. If something is scheduled on my calendar, whether it's flow time or dedicated time to one specific task, I follow it. If I put a task in todometer, I have to get it done that day.If you don't commit yourself to your tools, or try to over-engineer how you use them, they become extra overhead to getting things done. You don't want the perfect work setup to get in the way of you actually working. Keep that in mind as you hunt for tools that might work for you!Until next time!"
842,"cover image source: GiphyLast week, we went to the past and talked classically-influenced rock... this week, I'd like to take a left turn and hear y'all's favorite futuristic sounds — I'm talking about electronic music. I see electronic music as being a very broad genre, loosely meaning music made with electronic instruments. This timeline of electronic music genres on Wikipedia is a pretty awesome resource for encapsulating what I have in mind. But as always, we're loose here... interpret the theme however ya wanna, and if nothing is coming to mind that fits the theme, just share what ya like. 😀  How we doIn this weekly series, folks can chime in and drop links to whatever it is they've been listening to recently + browse others suggestions.If you like talking about music, consider following the org #music discussions for more conversations about music!#music discussionsFollow        Let's talk about #music. 🎶      Alright, lemme hear y'all's favorite electronic tunes! Note: you can embed a link to your song using the following syntax {% embed https://... %}. This should work for most common platforms!Looking forward to listening to y'all's suggestions! 🎶"
843,"Working with a team can bring diverse perspectives and a sense of camaraderie, while working solo can give you the freedom to make all the decisions and work at your own pace. So are you a lone wolf or a team player? Or do you prefer to mix it up?Share your thoughts in the comments!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
844,"Hey folks 👋Hope everybody enjoys their weekends!Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugCelebrating a birthday 🥳"
845,
846,"Hey folks, I wanted to ask what people think of this overall assertion from a recent thread about startup vs corporate jobs.Alvaro Montoro•    Apr 5  • Edited on Apr 5• EditedWorking for startups or big corporations (plus there are more options!) is different, but not as much as people put it. Each are going to have pros and cons... and sometimes the pros and cons are the same!From my experience (that is anecdotal, as each company is a new world):Startups: you need to deliver and deliver fast. Many times long hours and at weird times (I once had to take a client's call on a Saturday at 8pm while having dinner with some friends, and ask for my friend's computer so I could vpn to work.) You gain a lot of experience and learn a lot, which is great... but... that learning and experience is often not the best: having to deliver fast means cutting corners, and choosing speed over quality, you will learn practical skills and get technical knowledge, but it may not be the best practices. You'll get to wear many hats (and I really mean it, to the point of even having to send snail mail as a developer, or organize marketing content for conferences... and I don't mean slides, but folding brochures and picking swag from the store.) And that's good. You'll grow in all directions a little bit. Projects tend to be more interesting (not always) and there's a lot of responsibility and pressure: if you don't deliver, the company may well disappear. Start ups are great for younger people without family ties, who value more the project than the (long-term) perks or salary. If the start up succeeds (90% of startups fail), you'll hit jackpot and most likely move to the next one. Big corporations: one bad thing about big corps is that you stop being a person to become a number, a cog in an engine whose only job is to make money. That dilutes responsibility, but less responsibility doesn't mean less pressure: you'll be working in multimillion contracts, if you don't deliver on time, the corporation may lose huge amounts (in the 6-7 figures, and good luck explaining that failure to executives). So don't think that it will be ""5pm. Clock out. I'm done for the day.""  Salaries tend to be higher, and long-term perks tend to be sweeter (higher 401k matches, stock options, better and cheaper health insurances.) Also, let me break the bubble of work stability: yes, a big corp will not just close shop and be done as a startup, but layoffs are incredibly common (with or without economic crisis) and incredibly unfair. You may be the most productive employee in the company, but if your department is gone, you are gone. Another bubble to burst: opportunities for growth. May be educational, yes (learning may be slower but it can be of higher quality: big corps usually have learning budgets, even for grad schools), also because there are more processed and people in place, you'll be able to grow vertically (specialize) even if slower; but career-wise, it is more common to jump diagonally to a different department (or company) than to go up vertically (promotions).Medium Enterprises (SME): They are more established and the survival pressure is gone (but still there), and normally their goals are more modest and their clients more ""understanding"" (no multimillion dollar contracts and the sword of Damocles of layoffs not hanging over your head continuously.) Smaller groups, maybe not as interesting projects (this depends highly on the company, I worked as a developer in a company that did smaller projects for the government and they were surprisingly challenging and interesting... and if they weren't, it didn't matter because they'd soon be over and get a new one.) The long-term perks and the salary won't be as big as the big corp, the chances of potential reward will be lower than at a startup and, in my opinion, they are more stable and balanced (both in terms of job security and work-life balance) than startups/big corp. These are the ones where I enjoyed my time the best because they offered a nice balance between startup and big corp life. My two cents: focus on the project more than the type of company. Of course, there will be personal factors that may make you choose between small or big, but in the end, you'll be happier with a project that you enjoy and makes you happy, independently of it being in a startup, a small/medium company, or a big corporation. And that will impact your overall productivity and burnout feeling.What do you think?"
847,"Hey again, Sloan here! 🦥 We’re sharing some tips for success when it comes to writing on DEV. If you’ve been looking to improve your technical writing skills, make the most of DEV as a blogging platform, and take your content to the next level — this series is for you!The first post in the series was about creating a series. This one is about formatting, and the next two are about tone of voice and topics. Let's get started!  FormattingProper formatting is key to ensure that your post is readable, helpful, and polished. Our post editor uses Markdown and Jekyll Front Matter to format posts.  Use of headingsUse headings to keep your post’s content organized, and they’re great for supporting your article’s searchability. If you’re writing your post in pure markdown, use hashes to denote headings. Your title is the top headings (H1) automatically, so your highest-level headings should be H2. You can go as small as H6, but I don’t recommend it — if you need to break down your topics into six levels of subsections, you might have more than one post on your hands 😉If you’re using our rich + markdown editor on DEV, you can add a headings by selecting the H button in the toolbar:Each time you select the button, it will add another hash up to H4, at which time it clears.  More a11y considerationsHeadings are important not only to visually organize your content for the sake of your readers, but also to aid Assistive Technologies (AT) such as screen readers in organizing your content appropriately. Here are a few more accessibility (a11y) tips for formatting your DEV posts:Add image descriptions to your images.Keep emoji limited to the end of a line of text.Avoid using fancy characters for font purposes.        Kent C. Dodds      @kentcdodds      You 𝘵𝘩𝘪𝘯𝘬 it's 𝒸𝓊𝓉ℯ to 𝘄𝗿𝗶𝘁𝗲 your tweets and usernames 𝖙𝖍𝖎𝖘 𝖜𝖆𝖞. But have you 𝙡𝙞𝙨𝙩𝙚𝙣𝙚𝙙 to what it 𝘴𝘰𝘶𝘯𝘥𝘴 𝘭𝘪𝘬𝘦 with assistive technologies like 𝓥𝓸𝓲𝓬𝓮𝓞𝓿𝓮𝓻?           18:49 PM - 09 Jan 2019    For more details on why these are best practices for a11y, please check out Accessible Social.  Markdown basicsNo matter which post editor you use, it helps to study Markdown basics and double-check your formatting before you press “publish.” Just one backtick [`] can throw off all the code samples in your entire post!There is a helpful Markdown guide available right in the post editor, and you can learn more about formatting in the DEV editor from the Editor Guide.One very cool formatting feature on DEV is the use of liquid tags. You can read up on our supported liquid tags from our Liquid Tags Guide. For some examples, check out the liquid-tagged article below:Ways to enhance your DEV posts! Useful embeds.Jess Lee for The DEV Team ・ Jul 12 '18 ・ 2 min read#meta#embedsThat's it! Happy formatting. The next installment of this series will be about tone of voice."
848,"Introducing yourself to a new online community is exciting, but it can also be intimidating. Here are some ideas for intros that will help you connect with other members of the DEV and CodeNewbie communities:Share your background and interests. This can help others get to know you and find common ground for conversation.Talk about why you joined the community and what you hope to gain from being a part of it. This can help you find others who have similar goals or interests.Ask for advice or recommendations. This can help you build relationships and learn more about the community.Share a fun fact about yourself. It’s a great ice-breaker and conversation starter.Talk about your favorite hobby or activity. This can help you find common ground and build relationships.Say Hi! to others in the thread. If you see somebody introducing themselves, consider dropping a like or a response to show them some appreciation. Enthusiasm is contagious!Participate in discussions and leave comments. This can help you start on a positive note and build enthusiasm for future interactions. Check out these recent posts and get involved:What Are Some Hobbies That Are Beneficial to Coders and Developers?Ben Halpern for CodeNewbie ・ Feb 25 ・ 1 min read#discuss#beginners#codenewbie#DEVDiscuss: The Future of AIErin Bensinger for The DEV Team ・ Mar 21 ・ 1 min read#devdiscuss#ai#machinelearning#chatgptWhich Programming Language Did You Choose to Start with, and Why Did You Choose It?Ben Halpern for CodeNewbie ・ Feb 24 ・ 1 min read#discuss#beginners#codenewbieAnd don’t forget to follow our CodeNewbie and DEVteam Orgs for more convos and content like this."
849,"Are you a new coder looking to break into the tech industry? It can feel discouraging and isolating when you're trying to find your first job in tech, especially when it seems like you don't have access to the community or the resources you need to succeed.You’ve probably heard the refrain: keep learning, be persistent. And you have the list, some variation of this: build a strong portfolio, network, apply for internships, join online communities (like DEV and CodeNewbie!) to connect with other professionals in the industry. But what else can you be doing? And are there other ways to approach this challenge?Let’s ask our more experienced members what steps they suggest for landing you first job in the tech industry. Share some stories: how did you make it happen?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
850,"Hey CodeNewbies, we want to create an online community that's perfect for you! What can we do to make CodeNewbie on DEV the best possible resource for your coding journey?Are you feeling lost and overwhelmed in the world of coding? Do you wish you had a supportive and collaborative community that could help you build your skills and confidence? You’ve come to the right place.#codenewbie Follow        The most supportive community of programmers and people learning to code.      CodeNewbie is an online organization on DEV for new coders. Our goal is to provide a safe and inclusive space where fellow beginners can connect, ask questions, and share experiences and insights. But we don't want to create this community in a vacuum. We want your input! So tell us, please:What do you need in an online community?.What kind of content would you like to see? What topics do you want to discuss? Basically: How can we make this community as welcoming and helpful as possible for you?  Collaboration is key to achieving our missionWe want to work together with our community to build a platform that truly meets the needs of our members. So, if you're a new coder (or new at heart), we invite you to share your thoughts and ideas with us. Drop your thoughts in the comments and we'll take your feedback into account as we build this community and work to make it the best possible resource for you!"
851,"We’ve all been there, right? (Please say yes.) Did you ever accidentally delete an entire file? Have a syntax error that took you hours to find? We want to hear it all! It’s cathartic. Let it out! Share your funny or embarrassing coding stories from your early days and let's have a laugh together. Who knows, your story may just help someone else avoid making the same mistake.Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
852,"Staying up-to-date with the latest technologies and trends is essential for career growth and professional success in such a rapidly evolving field. Without continuing education and development, workers in the tech industry risk becoming obsolete and being left behind.But it can be challenging to find the time and motivation to keep up! Being part of a community like DEV is a great way  connect with other learners in the tech industry, but it’s just one piece of the pie. You need opportunities to apply what you’re learning, maybe work with a mentor, attend conferences, attain certifications, and more.What other suggestions do you have for folks in the tech industry who’re looking for ways to incorporate continuing education into their regular routine?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
853,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @tyagi_data_wizard's Top 7 post, tonight’s topic is...documentation workflows ✍️🗄️Document or Die: The Importance of Writing Things Down in TechUjjwal Tyagi  ・ Apr 10#beginners#devjournal#development#documentationQuestions:What documentation processes, workflows, or ""hacks"" have helped you or your team?What docs processes, workflows, or ""hacks"" have failed you spectacularly?Which tools do you use for documentation?How do you combat sprawl and duplicates in your documentation efforts?Any triumphs, fails, or other stories you'd like to share on this topic?"
854,"  PromptWrite a program to calculate the percentage of numbers in a given range that contain the digit 7. Your program should be able to calculate the percentages for the following ranges:0-990-9990-99990-99999etc.The program should take a single integer input n that represents the maximum range (exclusive), i.e., the program will calculate the percentage of numbers containing a 7 in the range from 0 to n-1.You may use any programming language of your choice.  Extra imaginary bonus points for a performant approach that can handle larger and larger ranges efficiently.  ExamplesInput => Output10 => 10.00%100 => 19.00%Enter fullscreen modeExit fullscreen modeIn the first example, 1/10 numbers (10%) contain a 7 (just the number 7).In the second example, 19/100 numbers (19%) contain a 7 (10 numbers from 70 to 79, plus 7, 17, 27, 37, 47, 57, 67, 77, 87, 97). Thus, the output is ""19.00%"".Have fun!7️⃣ 7️⃣ 7️⃣Cover image via Unsplash."
855,"Hey hey DEV Community, Sloan here!If we haven't met, I'm pleased to make your acquaintance. I'm a moderator here on DEV, and I'm also a Hoffmann's two-toed sloth. 👋🦥I'm here to share some tips for success when it comes to writing on DEV. If you’ve been looking to improve your technical writing skills, make the most of DEV as a blogging platform, and take your content to the next level — this series is for you!I'll start by showing you how to make a content series on DEV. Serializing your content makes it easy for your readers to follow along through multiple steps, and it also helps you keep your content organized by theme.DEV has two post editors: Basic Markdown and Rich + Markdown. You can set your editor type under settings > customization > writing. Here's how to create a series with each one.  Creating a Series with Basic MarkdownDEV's post editor uses Jekyll Front Matter. To create a series or add your post to an existing series, add the series variable to your front matter. Here's an example of what that would look like for this post:---title: ""Best Practices for Writing on DEV: Creating a Series""published: truedescription: ""A post about creating a series on DEV.""tags: meta, writingseries: Best Practices for Writing on DEV---Enter fullscreen modeExit fullscreen mode  Creating a Series with Rich + MarkdownSelect the hexagon icon at the bottom of the post editor. It looks like this:The post options menu will open, which will allow you to set a canonical URL, schedule a publication, and create or continue a series.Once you add your series name the first time, it will appear in the Existing series dropdown menu for future posts.That's it! Happy series-creating. The next installment of this series will be about formatting."
856,"I received way lots of cool feedback for my article Keep Calm and Just Say No To Coding Challenges but none was as fun as being live grilled by ThePrimeagen on his YouTube channel.  ThePrimeagen's answer to my articleI was alerted about this video by three different friends, one presenting me ThePrimeagen this way:Primeagen is an engineer doing impressive stuff at Netflix, he is very active in the Rust community. As you will see in the video, he has a style that some people love and some people hate.Fair enough.  But for my part, I found his video absolutely delightful.Some people told me to try out making videos, but I declined.I think I would be a pretty lame YouTuber.I'm just a dude who write words about stuff.But ThePrimeagen is brilliant at it. It was a cool funny experience to see my article come to life in real time on YouTube.After such an artful build-up, I was hoping he would not just only agree with me. And indeed:Ok, just so you know. Hey guess what everybody? This person just gave you the best way to get rejected from many job interviews. Perhaps this person doesn't need a job that much. And therefore can go like this: ""What do you do? Oh you are like 93% of tech companies and you have a coding challenge? LOL. Sorry, I don't accept them. It leaves an hash tray in my mind. So no, thank you. To both your job and your interview process"".That started well.   Alas that's mostly a misunderstanding...So far, without reading anything else, my current take is that it's some of the worst advice I've ever heard. Real talk: you literally have been told by companies that there is a secret handshake. It involves knowing basic data structures, and how to apply them. So you can go and study for height hours, get good at that, walk in, doing the secret handshake and go right insight the door. Or you can say no to every reasonable job out there.Is that unreasonable?My answer will be boring: I agree with all of that. We have a basic misunderstanding of what coding challenge meant in the context of my article. I didn't mean an algorithmic interview.And the confusion is my fault. I assumed it was obvious what I meant by Coding Challenge. But clearly, at it often happens, what was obvious to the writer is not in fact obvious to all readers.What happened is that I wrote the article after seeing a friend waste way too many time and morale with a coding challenge of that sort:We are a music player app company, so we challenge you to do a simplified music player app, with a lying time estimate of four hours, and then we will evaluate the quality of your code according to unknown criteria.  What's a good hiring criteria?In the comments of previous articles, I have lazily described all kind of challenges as good or bad.Wait, what does that mean?There is actually a real definition of a good hiring criteria in the literature, which I would summarise this way.A good hiring criteria must be relevant, stable, realistic and very clear.For example, an algorithmic challenge at Netflix is✅ relevant because Netflix does lot of that stuff✅ stable because if you ask different people whether a candidate succeeed at an algorithmic, they would mostly agree✅ realistic because it takes a limited amount of time, and the same for the company and the candidate. Learning data structures and algorithms is a doable task✅ very clear because it's almost like a math problem. Let see why coding challenges (the ones I had in mind) instead suck✅ Coding challenges are relevant in the sense that the simplified music app has a clear link to the real music app the company is building.❌ Coding challenges are not stable, meaning if you present the same coding challenge to different companies, or even different people inside the companies, you will get ""Look Good To Me"", ""Not Our Level Of Quality (TM)"" and everything above and under that. The beauty of your code is in the eye of the beholder.❌ Coding challenges are not realistic for someone outside of the team (that's what the term means). People inside the team, who know everything about building a music player, and who designed this challenge, can criticise your work in 42 different ways. But truth here is that people working there didn't know everything they know today when they started. We developers are learners, don't judge us because we don't know everything at a given time. Find out our potential.❌ Coding challenges are not very clear. One of the reason candidates over-engineer shit with coding challenges is that they the requirements are super vague. Sure they describe the features, but not the criteria. The candidates can't know under which criteria they will be judged. IMHO companies can do better than cargo cult someone's else bad idea.  Wasting both your time and the company's timeWhen you say NO to something important to you always say YES to something else.You protect your time.You protect your morale.You protect your self respect.One thing I didn't mention because I was writing from the candidate point of view is that they also waste time for the company.  That's here not relevant for Netflix, because I guess that shitloads of talented candidates apply there. But many good companies have posts that stay vacant for 3 months, 6 months. A clear loose loose approach.  You Indeed Have the Right to Say NOI talked about the company's perspective, but I would warn you against doing that in the interview. There is a reason why I didn't propose you to say:Your company's hiring practices leaves an hash tray in my mind. So no, thank you. To both your job and your interview process.Instead I recommended this:I have to be transparent with you, I had bad experiences in the past with coding challenges and I have decided to stop accepting them.The difference here is that you not judging them and putting them on the defensive. You are being assertive about your needs. The companies that will be mad at you for stating your needs are the minoritybullet dodgedSo I completely stand by my original thesis.  You Have the Right to Choose When To Say NoFinally I told you the have the right to say NO, I didn't advise you to say NO all the time.If you apply at your dream company, don't say NO, invest the time.If you have only 2-3 companies a month that interview you, your next step is to generate more leads, you can procrastinate on saying NO.On the other hand, if you never use your right to say NO, then that right is pretty useless.What I did is that I started saying NO when I was interviewed by companies I didn't really wanted to work with anyway. It was awkward at first, but I didn't have the kind of pressure described above. Now I completely feel comfortable with it, and I know that it usually works. And you don't have to worry for me finding a job.  No hard feelingNow ThePrimeagen, if you read me, I genuinely laughed at your video.And you even gave me the hope to make a second episode.Hiring is broken.Oh man, look at this, there are so many good ones. Look at this, we have so many pieces here.Allright, for today let's read ""Keep Calm and Just Say No To Coding Challenges""That would be awesome indeed. I can recommend my first rant, three years ago already, who started this serie. “What is your current salary?” is a red flag that you don’t want to work hereJean-Michel (double agent) ・ Oct 10 '20#career#beginners#hiring"
857,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   Document or Die: The Importance of Writing Things Down in TechDocumentation can often seem like a secondary task, but skipping it can really come back to bite you. So if you want to avoid getting caught up in a huge time-sink, follow these tips from @tyagi_data_wizard!Document or Die: The Importance of Writing Things Down in TechUjjwal Tyagi  ・ Apr 10 ・ 4 min read#beginners#devjournal#development#documentation  How To Use MVVM in React Using Hooks and TypeScriptIn this article, @perssondennis takes a look at how a React application can be designed to follow the MVVM architectural design pattern to create a React application that is both scalable and maintainable.How To Use MVVM in React Using Hooks and TypeScriptDennis Persson ・ Apr 16 ・ 13 min read#react#architecture#webdev#javascript  Becoming an Astro Maintainer@eliancodes shares their experience becoming an Astro maintainer, along with all of the exciting plans for what’s in store for the future. Elian’s open source experience is definitely one you could learn from so read on to find out more!Becoming an Astro maintainerElian Van Cutsem ・ Apr 13 ・ 5 min read#astro#opensource#javascript#webdev  Costly CSS Properties and How to Optimize ThemSome CSS properties are more costly than others in terms of performance. When used improperly, they can slow down your webpage and make it less responsive for your users. In this article, @leduc1901 explores some of the most costly CSS properties and how to optimize them.Costly CSS Properties and How to Optimize ThemDuc Le ・ Apr 13 ・ 3 min read#webdev#css#html#frontend  When to use currying in JavaScriptThis post from @slimtim10  is about the concept of currying from functional programming, and when you should use it in JavaScript. It might not be useful if you aren’t going to implement functional programming, but it might get you curious about how it works!When to use currying in JavaScriptSlimTim10 ・ Apr 12 ・ 6 min read#webdev#javascript#programming#beginners  The importance of rel=canonical for content writers@nfrankel touches on the problem of content duplication and how simply writing the best article isn’t enough. You need to know how to spread your content across the web in a way that directs it back towards the source. Follow these tips to make sure your original content is given preference in search engines.The importance of rel=canonical for content writersNicolas Frankel ・ Apr 13 ・ 3 min read#seo#content#contentwriting  C# (C Sharp) CRUD Rest API using .NET 7, ASP.NET, Entity Framework, Postgres, Docker and Docker ComposeLet's create a CRUD Rest API in C# with @francescoxx using: .NET 7, ASP.NET, Entity Framework, Postgres, Docker, and Docker Compose! You can follow along using the tutorial video available or by heading to the GitHub repo to check out the code for yourself. C# (C Sharp) CRUD Rest API using .NET 7, ASP.NET, Entity Framework, Postgres, Docker and Docker ComposeFrancesco Ciulla ・ Apr 16 ・ 9 min read#dotnet#webdev#beginners#dockerThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
858,"Over the past couple of days, an article about the next major version of Svelte blew up on twitter, and caused lots of discussion. The article states:The team is switching the underlying code from TypeScript to JavaScript.Which, to be fair, is a bit misleading. Technically, the article is not wrong, the team is switching the underlying code from TypeScript to JavaScript. However, they're not dropping typechecking from their code. They're just moving from writing TypeScript source code directly, to writing JavaScript source code using JSDoc in combination with .d.ts files. This allows them to:Write typesafe code, with TypeScript doing the typecheckingWrite and ship plain JavaScriptSkip TypeScript's compilation stepStill provide types for their end usersWhat's interesting about this discussion is that a lot of people found this to be very upsetting, and twitter blew up with discussion about typechecking. We saw the exact same thing happen when the ESLint team announced they were not interested in using TypeScript for their rewrite of ESLint, but instead were choosing the same approach the Svelte team is going for; plain JavaScript with JSDoc for typechecking. In these twitter discussions it has become very clear that lots of people, even some of those who call themselves ""educators"", don't understand how capable JSDoc actually is and will unfortunately just spread blatant untruths about this way of working. It should be noted here that neither of those teams are disregarding typesafety. They just chose a different way of utilizing typesafety, without having to use a compile step to achieve this. This is a preference. There is no right or wrong answer; you get typesafety by using TypeScript in either approach. This discussion and these decisions are not about not using TypeScript. And unless you're directly working on, or contributing to, either of those projects, these decisions do not involve you. It is, frankly stated, none of your business. If you want to use TypeScript with a compilation step; go for it! There's no need for animosity. These projects still utilize TypeScript to ensure typesafety in their code, and can still ship types to their end users. In this blog we'll take a look at the benefits of skipping TypeScripts compilation step, clarify some of the myths I've seen spread around, and emphasize the importance of understanding and being respectful of different preferences and methodologies.In this blog, I won't go into detail on how to setup your project to enable typechecking with JSDoc, there are many great resources on that like this one hereBefore we dive in, I'd like to reiterate one more time that using types via JSDoc allows people to still write typesafe JavaScript, by using TypeScript's typechecker. It just skips the compilation step. You'll also be able to still use .d.ts files when necessary (but you don't have to!), and provide types for your users. And yes, this approach is still using TypeScript.  Benefits of skipping a compilation stepCompilation or transpilation steps in the JavaScript tooling ecosystem are often a bit of a necessary evil, like for example transpiling JSX, or in this case TypeScript code. They're often not as fast as we'd like them to be, and often take a bit of fiddling with configuration (although it should be noted that lots of tooling has improved in recent years) to get your setup working just fine. Not only for building your projects for production, but also having everything setup correctly for your local development environment, as well as your test runner. While compilation or transpilation offers conveniences (writing JSX source code, instead of React.createElement calls manually, or writing types in your source code directly), some people find these compilation steps to be undesirable, and prefer to skip them where possible. Skipping a compilation step, in the context of TypeScript usage, has several benefits. It makes your code runtime agnostic; your code will run in Node, Deno, the browser, Worker-like environments, etc. Some of these environments, like Deno, support running TypeScript natively (which has a whole other set of worrisome implications*). Some of those environments, like the browser, don't (not until the types as comments proposal lands anyway). This may or may not be an issue for you depending on what you are building, but again, some people find this to be preferable. It has been pointed out to me that Deno will now run with --no-check by default, which mitigates some of it's issue. However, the issue still exists when using --check.If your code is runtime agnostic, it also allows you to easily copy and paste snippets of code into REPLs. Shipping native JavaScript also simplifies debugging, consider the following example: You've shipped your package as native JavaScript. Somebody installs your package and discovers a bug. They can just go into their node_modules and easily tweak some code to try to fix the bug, without having to deal with transpiled code, source maps, etc. An added benefit of using JSDoc that I've personally found (this is a personal preference), is that the barrier to documenting my code is much lower as opposed to TypeScript. Consider the following example:Admittedly, a function named add probably doesn't require a whole lot of documentation, but for illustration purposes.When I type /**<ENTER> on my keyboard, my editor will already scaffold the JSDoc comment for me, I just have to write my types. Note that the return type can be omitted, because TypeScript will still correctly infer the return type from the code. While I already have the JSDoc comment here anyway, I might as well add some documentation for it! Easypeasy.  Myths  Using JSDoc is unmaintainableSome people on twitter have expressed concerns about the maintainability of using JSDoc for types, and claim that using JSDoc is only viable for small projects. As someone who maintains many projects at work (some of which are large) that utilize types via JSDoc, I can tell you this is simply not true. It can be true that if you're only using JSDoc to declare and consume your types, this can sometimes become a bit unwieldy. However, to avoid this, you can combine JSDoc with .d.ts files. Declare your types in a .d.ts file:./types.d.ts:export interface User {  username: string,  age: number}Enter fullscreen modeExit fullscreen modeAnd import it in your source code:./my-function.js:/** * @typedef {import('./types').User} User *//** * @param {User} */function foo(user) {}Enter fullscreen modeExit fullscreen mode  No type inference or intellisenseSome people seem to think that using JSDoc somehow will cause you to lose type inference. As already demonstrated earlier above, this is also not true. Consider the following example:The reason for this claim seems to be that people don't understand that when you're using JSDoc for types, you're still using typescript. TypeScript is still doing the typechecking.   Manually writing types is bothersomeSome people claimed that writing types manually is bothersome. I can only assume that this is a case of preference, or perhaps its not clear to those people that you can still .d.ts files. Some people will prefer example B over example A. This is fine. Both can be used when using JSDoc for types.example A:/** * @typedef {Object} User * @property {string} username * @property {number} age */Enter fullscreen modeExit fullscreen modeexample B:export interface User {  username: string,  age: number}Enter fullscreen modeExit fullscreen mode  But that still uses TypeScript!Yes, this is the point.  In conclusionFinally, and I'm repeating myself here, using TypeScript without compiling your code is a preference. There is no right or wrong answer and I challenge anyone who is skeptical of this approach to be a little bit more open minded and give it a try some time when you're starting a new project, you might find it's actually a quite nice approach of utilizing types. And if you end up not liking it, that's fine too!"
859,"Hey there! Welcome to this week's edition of What I Learned. After a week of delving into new coding topics and reading your articles over on the #codenewbie tag, I'm excited to share some of my favorite finds with you. If you aren't exploring or posting over on the #codenewbie tag, find the tag here!#codenewbie Follow        The most supportive community of programmers and people learning to code.        Here's what I discovered this week (there has been no rhyme or reason this week, just a few scattered things I learned!):If you don’t know me, you should know that I REALLY love production line organization and documentation. I love to document different changes in my graphic design progress so I can feel my successes more and communicate with my team better. As I try to better understand our engineering team’s workflow, I have found articles like these pivotal in understanding documentation! If you need a Pull Request crash course, this is it.How to Create a Good Pull Request Template (and Why You Should Add Gifs)BekahHW for OpenSauced ・ Apr 14 ・ 3 min read#opensource#webdev#github@bekahhw states, “The great things about Pull Requests are that they allow for collaboration between contributors and maintainers, offer an opportunity to communicate changes that have been made and why they are important, and the ability for maintainers to provide feedback.”@bekahhw also made this other article for @opensauced, further explaining Pull Requests!Writing Your First Pull Request: Tips, Best Practices, and AI-Powered Tools for SuccessBekahHW for OpenSauced ・ Apr 17 ・ 4 min read#opensource#webdev#github#codenewbieSpoiler: I am a huge fan of recommending that people do online courses and a huge hypocrite who has never done one (related to coding at least). But I can tell you for sure, articles like this one from @javinpaul help me motivate that part of my brain that I know will do one one day.My Favorite Courses to learn Microservices in Depthjavinpaul ・ Apr 16 ・ 12 min read#microservices#programming#development#architectureWhen coming up with portfolio ideas in the past, I know I have sometimes pulled out my hair trying to come up with something with that good balance between sophistication, effortlessness, and uniqueness. If you need some more inspiration to get you through that hurdle, check out this article from @rammcodes5 Amazing Project Ideas To Get Hired As A Full-Stack Developer 🔥Ram Maheshwari ⚡ ・ Apr 16 ・ 1 min read#javascript#webdev#react#nodeAnd— last but not least, if you haven’t engaged in any discussions today, here is one @ben posted today!Coding Heroes: Who Inspires and Motivates You?Ben Halpern for CodeNewbie ・ Apr 18 ・ 1 min read#discuss#beginners#codenewbieThank you thank you for tuning in, have a great rest of your day y’all!(PS: What random things are you learning this week???)"
860,"We all have role models and people we look up to for inspiration and motivation: a coding mentor, a well-known programmer, someone who has paved the way for diversity in tech.Who are the people that have made a significant impact on your coding journey? Share their stories and how they have influenced you. Let's give them the recognition they deserve!Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
861,"  Make Your Mark on the DEV Community Experience by Becoming a Tag ModeratorTag moderators play an important role in helping to organize and manage the content of our community. If you want to make a difference here on DEV and for the developer community, consider joining our team as a tag moderator. Here are a few benefits:  Opportunity for leadership and influence:As a tag moderator, you'll have the opportunity to take on a leadership role in the community and influence the direction of the conversation by highlighting certain topics and content.Share your knowledge and area(s) of expertise by supporting other community members, elevating constructive conversations and content, and answering questions.  Personal development:Being a tag moderator is a valuable and rewarding experience for those of you who are dedicated to improving the content of an online community.Learn more about the community and gain new skills such as conflict resolution, communication, and leadership.  Better organized content and improved searchability:By helping us ensure that content is properly categorized and tagged, you can improve the searchability of the community and make it easier for our users to find the information they’re looking for.Users are more likely to have a positive experience and return to the community in the future when content is organized and easy to find.Interested? Complete this form and we’ll be in touch!Some other tasks our tag moderators help us do:Report spam, abuse, and plagiarismWelcome new community membersFoster an inclusive environmentInstruct users on DEV featuresDiscourage promotional abusePromote quality postsManage post tagsAnd some additional perks we give back to you:Monthly MOD GametimesAn Invitation to our DEV MOD Discord ChannelOpportunities to represent DEV at tech conferencesPower! Bwa-ha-ha! (Please use it for good.)DEV cred and kudos! AKA: the adoration of our Community Team and the opportunity to earn exclusive MOD badgesIt looks great on your resume!What are you waiting for?"
862,"Hey folks! 👋Hope y'all all have wonderful weekends. 😀Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugGoing on a nice walk with the dog 🦮"
863,"When it comes to coding, what's more important: having a solid foundational knowledge or an aptitude for problem solving?Without a strong foundation in programming concepts and theory, it's difficult to solve complex problems. Of course, you could argue that practical problem-solving skills are more important, and that knowledge can be acquired as needed.Chris Pine says:Programming isn't about what you know; it's about what you can figure out.What do you think? Share your thoughts in the comments below!"
864,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
865,"Whether you work from home or in an office, your workspace can have a big impact on your productivity and mood. That's why we want to know: what's on your desk?Share a photo or description of your favorite inspiring or fun workspace items in the comments below! Maybe it's a motivational quote, a quirky plant, or a snuggly pet snoozing nearby. Whatever it is, we want to see it!Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
866,"We decided recently over at the CodeNewbie Team that we wanted to spice things up and try something new out to involve our newbies in Meme Monday! We landed on a Sloan's Newbie Memes of the Week! You can find last week’s meme picks here.Here are some of our favorites from this week:If you'd like to join in— drop your beginner-related, job-related, starting-a-new-career-related memes down below!Happy coding y'all!"
867,"Are you simple or complex? Creative or analytical? Would you be dynamic and expressive like Python, or more structured and disciplined like Java?Share with us in the comments which programming language you think matches your personality and tell us why. Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
868,"Hey Devs, happy Friday 🦥💚As always, it's been an eventful week in the tech industry. We've got a lot to talk about! And today I want to discuss...Rethinking the Modern WebOxford Harrison ・ Feb 12 ・ 23 min read#webdev#javascript#tooling#webqitThis post by @oxharris about the state of the sprawling frontend ecosystem 😳😅 Check out these quotes from the post:So it turns out, all of that ""vibrant ecosystem"" isn't really translating to more ""accessible"", ""functional"" apps on the user front, and neither to more ""speed"" and ""productivity"" on the developer front!The closer you get to Frontend's bottlenecks and to how much of that is tooling-induced the more you are wondering if we just have created more problems with our tools than we've solved!So...what do you think? 🤔"
869,"I started at Meta in 2018 with five friends from college. Over time, they followed the common industry advice — switch jobs often to grow career and compensation. My staying at Meta became more and more unusual. Two stories show why I stayed when all my friends left.  An Engineer Who Never Broke Anything?When you’re a new grad, you look up to more experienced engineers. Now imagine, one of those engineers is the “tech lead” and everyone you admire looks up to that person. For me, that tech lead was Lukas Camra, my soon to be manager. Rumor has it, Lukas never broke production in all his years as an engineer at Meta, though that might just be team folklore.Lukas exceeded my expectations as our manager. Because he was a sharp engineer himself, he knew how to help engineers grow fast. Looking back after working with him for 5 years, it is obvious why my team has been so stable.When you get lucky with a manager like that, you look to stay a little bit, but 5 years? It takes more than a good manager to keep engineers when we have so many options of where to work. There’s one more story which makes it clear why I chose to stay. While this story might seem like an exaggeration, I swear it isn’t.  What a “10x Engineer” Really Looks LikeImagine an IC who writes and reviews more code than anyone in your org. Someone who, because of his domain expertise, receives the most questions yet is also the most responsive. This IC also consistently solves problems that many Staff engineers can’t. And if that’s not enough, this IC’s main project work often has industry influence. Hard to believe, but I’ve seen Haixia Shi do this half over half since I started working with him.He’s the de facto video domain specialist for Instagram, which is kind of a big deal for an app where video is a central part of the user experience. I have never received formal mentorship from Haixia, but I didn’t need to. Engineering excellence radiates from him. Strong engineers become even stronger just by asking him technical questions and seeing how he solves problems. Having peers like this makes coming to work delightful and is one of the key contributors to my engineering career growth.Staying at Meta longer than any of my friends helped me grow to a Staff engineer in 3 years. My domain knowledge allowed me to deliver more in less time. I was able to move fast because I was so familiar with our tooling, tech stack, and organizational processes.Also another benefit to staying so long was I built organizational trust. People knew I was a person who could consistently get the job done. As my skills grew, people gave me more responsibility. As I delivered on that, people trusted me with even more scope. This virtuous cycle gave me momentum that helped me grow at a faster and faster rate.Staying at Meta for as long as I have has treated me well, but how long should you stay to maximize career growth? I polled over 1200 people on Twitter to find out.  How Long Should You Stay?Almost everyone agrees that 1 year is too short. Onboarding consumes much of that time, leaving little to utilize your knowledge. Past that, it really depends on your situation.If your job is treating you well and offers growth opportunities then there’s no reason you shouldn’t stay longer than 4 years. At the same time, it could be a good idea to leave fast if you’re stagnating. I’m glad I left my first job after 8 months and in hindsight it was a great decision. Here are the full results from the poll if you’d like to draw your own conclusions.We have a regular team health survey at Meta that asks “how long do you plan to stay at the company?” The funny thing is, I don’t think I’ve ever answered that I’d stay longer than 2 years even though I love my work. Yet, here I am 5 years later. Staying isn’t something you plan at the outset but rather something you regularly check-in on.At the end of the day, how long you should stay is a case by case decision. That's why it’s important to have mentors you can confide in to help you with career decisions like these. Over to you: How long do you think you should stay at the same job to maximize career growth?If you learned something helpful, subscribe to my Substack for free to receive new posts!Thanks for reading,Ryan Peterman"
870,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 If you are new to coding, want to help beginners in their programming journey, or just want another awesome place to connect with fellow developers, check out the CodeNewbie Org page on DEV! Great to have you in the community!"
871,"Working with legacy code can be challenging and frustrating, as it often requires extensive maintenance and debugging, but it may also have a stable user base, which can provide job security and professional growth opportunities. Starting a new project with a brand-new tech stack can be exciting, but also comes with challenges like steep learning curves, it can be risky, and it may take a while to get the project off the ground and gain traction.Which would you choose and why?Or which have you chosen? And how’s it going?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
872,"Remote work opportunities allow for more flexibility, decreased distractions, and cost savings, but sometimes those advantages come at the expense of communication challenges, lack of social interaction, and difficulty disconnecting. For those of you who work remotely in tech: do you find that you’re working smarter or harder? What are the benefits? The challenges? And given the choice, would you ever go back to the office? Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
873,"The Bug Buster vs. Algorithm Master. Would you rather have the power to instantly zap away any bug in your code with the snap of your fingers, or the ability to create complex algorithms at lightning speed with just a single thought? Engage!Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
874,Contributing to open source can be one of the best ways to start or advance your career. But there are often barriers to getting started in Open Source. What are some of the reasons that prevented you from getting started in OSS? 
875,"Working in the tech industry can be rewarding, but it can also be stressful and intense. Long hours, tight deadlines, and high pressure can all contribute to burnout, which can lead to physical and mental exhaustion, decreased productivity, and even depression. Have you ever experienced burnout? How did you recognize it and what steps did you take to address it?Follow the CodeNewbie Org and #codenewbie for more awesome discussions and online camaraderie!"
876,"Help us fill the comments with some hilarious programming jokes. Okay, we'll start:Q: Why do programmers prefer dark mode? 🌙 A: Because light attracts bugs. ROFL. 😂 Share your faves in the comments below!Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
877,"Recently there was this post Why aren’t you contributing to open source?BekahHW ・ Apr 3#codenewbie#discuss#webdev#opensourceI found the answers very interesting.However, what would interest me even more is how and why did you start contributing to Open Source? Did you create your own project? Did you fix a bug? Did you start in an IRC channel?"
878,"Hey y’all! Here I am after delving in from a week of trying to poke away at learning new coding things and reading your articles over on the #codenewbie tag.This week has thus far been one of those weeks where I find myself making every excuse to not invest time in learning new things. So, if you’re like me, let me take you on a journey through a quick couple posts that helped to motivate me.The Biggest Mistake Beginner Developers MakeEduardo ・ Apr 13 ・ 4 min read#beginners#webdev#codenewbie#motivationThis article by @eduardotorres seriously gave me the boost of accountability I needed to face the fear of trying new things. They said, “This is a clear example of one of the biggest mistakes that I see beginner developers do: never believing that they are ready.”Being self taught in 2023Spencer Davies ・ Apr 13 ・ 4 min read#beginners#career#learningTaking inspiration from other self-taught coders always makes my heart happy. @spencer_the_dev says, “There is - at least for me - a real sense of satisfaction in being one of a small handful of developers responsible for your company’s entire product. It’s not going to be for everybody, but I would strongly encourage getting some time in working at dev shops or startups. It builds character. Probably.”I am trying lately to evaluate different aspects to enhance my focus while working from home! I enjoy it so much but definitely need some advice when it comes to keeping on track sometimes. Luckily, we posted a discussion thread for you to get advice about the two working styles. I would imagine this would be especially helpful to those folks out there who are looking for new employment!Remote Work in Tech: Is It Right for You?Ben Halpern for CodeNewbie ・ Apr 13 ・ 1 min read#discuss#beginners#codenewbieAnd lastly, organization is always 100% the name of my game. Code naming: How to improve the readability of your codeAndrew Kelly ・ Apr 11 ・ 3 min read#codenewbie#beginners#programming“Naming in code is important because it helps people more easily understand the code that you have written. This will help your colleagues when they come to make changes to your code in the future.” - @andrewkellyThank you all for being here and for learning with me! ALSO—I would love to hear what everyone else is using to motivate themselves this week below. Be well y’all!"
879,"Yesterday on our podcast, Pariss Chandler, the Founder and CEO of Black Tech Pipeline, came on and discussed her evolution throughout the tech industry with @saronyitbarek! Pariss also shared insights on her route to finding a community in tech and her company’s work to create more opportunities and support for Black programmers in the industry. If you haven’t listened (which you definitely should), you can listen to the full episode below!      codenewbie.org    . Upon finishing the episode, we pondered on a few key points/tips that we felt were worth emphasizing and sharing with all of you!If you aren’t sure coding is for you, you can look into different careers inside the tech industry that may relate/resonate with you more. Though—make sure to look at the salary, benefits, and other requirements to make sure they line up with what you need too!When you are looking for your first job in tech you do not have to work at a tech company! You can work at so many different types of companies, because tech jobs are universally needed.Just having a diverse workplace is not enough, we also need to ensure employees from different backgrounds feel supported and included in their workplace.Spend a lot of time learning Vanilla JS before jumping into new frameworks. Make sure you fully understand the fundamentals of a language before moving on!We succeed when we use feedback as both a meaningful tool and an opportunity to advance and support diversity, equity, and inclusion in the workplace.If you listened— what did you learn?Send us your thoughts below and don't forget to give it a listen here or wherever you listen to your podcasts! 💜"
880,"Firstly sorry for the formality of the post but today, I took the time to examine the new Rust Trademark Policy, which can be accessed through the Rust Trademark Policy Comment Form. If you are a Rustacean, or are on the process of turning into one, please review it. The more we make our voice heard the easier they will amend this policy.The feedback that I left was:As a content creator, particularly a blog writer, I have some concerns regarding the implications of this policy on my hobby. These concerns include:The requirement to include a disclaimer alongside the Rust Logo on tutorials and blog posts, clarifying that they are not endorsed by the Rust Foundation. This stipulation may be perceived as unnecessary since most readers are aware that online tutorials are typically created by community members rather than the foundation itself.The inability to use the Rust Logo as a selling point for Software as a Service (SaaS) products. For instance, if I were to develop a project using the FAST stack (Flutter, Actix, SeaORM, and Tokio Runtime) and make it publicly available, I would not be allowed to display the Rust Logo on the landing page.The policy dictates that the Rust Logo must be smaller than the hosting website's logo, which could result in a deviation from modern design principles. Consequently, if you have an educational platform with a dedicated section for Rust, the Rust Logo must be smaller than the logo displayed on the navigation bar.The policy prohibits the inclusion of the word ""Rust"" in package, repository, library, and crate names. While I understand the need to differentiate between official and unofficial packages, enforcing this rule through a trademark may not be the most effective approach. A tacit agreement within the community could potentially suffice.While I may not possess a strong artistic inclination, the restriction on modifying the logo beyond scaling, including colour changes, could potentially impede the creative freedom of other content creators.In conclusion, while the Rust Trademark Policy aims to protect the Rust brand, it is essential to consider its impact on content creators, who play a vital role in promoting and expanding the Rust ecosystem. Balancing the needs of the Rust Foundation and the creator community is crucial for fostering a healthy and collaborative environment.These were my reservations, what are yours?"
881,What drew you to COBOL?  Do you use the language on an everyday basis?The purpose of this discussion thread is to encourage those who use COBOL to share their experiences.
882,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
883,"Leading AI academics and industry experts - including Steve Wozniak and Elon Musk, published an open letter today calling for a pause on developing more sophisticated AI beyond OpenAI's GPT-4.  The letter cites risks to society and humanity as a major concern and asks for the pause to enable the industry to develop shared safety protocols. Do you agree with the consensus of the experts?  Is a pause even a realistic option when you factor in global politics and capitalism?  Share your thoughts below!  "
884,"Leave a comment below to introduce yourself! You can talk about what brought you here, what you're learning, or just a fun fact about yourself.Reply to someone's comment, either with a question or just a hello. 👋 Great to have you in the community!"
885,"When I started using GitHub Copilot and other generative AI tools, I felt frustrated because I wasn't receiving the expected results. How were people feeling so successful with these tools, and why weren't they doing what I wanted? For example, I would ask GitHub Copilot to solve a LeetCode problem for me. The GitHub Copilot icon would spin to indicate that it's thinking, and then I would receive an incongruent suggestion or no suggestion at all. I was annoyed, but it turns out – I was using it wrong! After more experimentation, I improved my communication methods with GitHub Copilot by providing context, examples, and clear instructions in the form of comments and code. Later on, I learned that this practice is called prompt engineering. In this blog post, I'll discuss top tips to help you get the most out of GitHub Copilot. First, let's start with the basics for folks who are unfamiliar with GitHub Copilot or prompt engineering.  What is GitHub Copilot?GitHub Copilot is an AI pair programmer developed by GitHub and GitHub Copilot is powered by OpenAI Codex, a generative pre-trained language model created by OpenAI.that provides contextualized code suggestions based on context from comments and code. To use it, you can install the GitHub Copilot extension available to you in the following Integrated Development Environments (IDEs):Visual StudioVisual Studio CodeNeovimJetBrains IDEs (IntelliJ, PyCharm, WebStorm, etc)  Can GitHub Copilot code on its own?At GitHub, we use the terms ""AI pair programmer,"" ""AI assistant,"" and ""Copilot"" to since this tool cannot work without you – the developer! In fact, AI systems can only perform the tasks that developers program them to perform, and they do not possess free will or the ability to make decisions independently. In this case, GitHub Copilot leverages context from the code and comments you write to suggest code instantly! With GitHub Copilot, you can convert comments to code, autofill repetitive code, and show alternative suggestions.   How does GitHub Copilot work under the hood?Under the hood, GitHub Copilot draws context from comments and code, instantly suggesting individual lines and whole functions. OpenAI Codex, a machine-learning model that can translate natural language into code, powers GitHub Copilot  What is prompt engineering?Prompt engineering is the practice of giving an AI model specific instructions to produce the results you want. A prompt is a sequence of text or a line of code that can trigger a response from an AI model. You can liken this concept to receiving a prompt for an essay. You can receive a prompt to write an essay about a time you overcame a challenge or a prompt to write about a classic book, such as the Great Gatsby. As a result, you give a response to the prompt based on what you've learned. A large language model or LLM will behave similarly. Here's another illustration of prompt engineering: When I learned to code, I participated in an activity where I gave a robot instructions on how to make a sandwich. It was a fun, silly activity that taught me that:Computers can only do what you tell them to doYou need to be very specific with your instructionsThey're better at taking orders one step at a timeAlgorithms are just a series of instructionsFor example, if I were to tell the ""robot"" to make a sandwich, I need to tell it:Open the bag of breadTake the first two slices of bread out of the bagLay the slices of bread side by side on the counterSpread peanut butter on one slice of bread with a butter knifeEt cetera, et cetera, et ceteraWithout those clear instructions, the robot might do something silly, like spread peanut butter on both slices of bread, or it might not do anything at all. The robot doesn't know what a sandwich is, and it doesn't know how to make one. It just knows how to follow instructions. Similarly, GitHub Copilot needs clear, step-by-step instructions to generate the code that best helps you. Let's discuss best practices for prompt engineering to give clear instructions to GitHub Copilot and generate your desired results.  Best Practices for Prompt Engineering with GitHub Copilot  Provide high-level context followed by more detailed instructionsThe best technique for me is providing high-level context in a comment at the top of the file, followed by more detailed instructions in the form of comments and code.For example, if I'm building a to-do application. At the top, I'll write a comment that says, ""Build a to-do application using Next.js that allows user to add, edit, and delete to do items."" Then on the following lines, I'll write a comment to create the:to-do list component, and I'll let GitHub Copilot generate the component underneath the commentbutton component, and I'll let GitHub Copilot generate the component underneath the commentinput component, and I'll let GitHub Copilot generate the component underneath the commentadd function, and I'll let GitHub Copilot generate the function underneath the commentedit function, and I'll let GitHub Copilot generate the function underneath the commentdelete function, and I'll let GitHub Copilot generate the function underneath the commentetcetra, etcetera, etcetera... Here's an example of me using this technique to build a house with p5.js:In the following GIF, I write a comment at the top describing at a high-level what I want p5.js to draw. I want to draw a white house with a brown roof, a red door, and a red chimney. Then, I write a comment for each element of the house, and I let GitHub Copilot generate the code for each element.  Provide specific detailsWhen you provide specific details, GitHub Copilot will be able to generate more accurate code suggestions. For example, if you want GitHub Copilot to retrieve data from an API, you need to tell it what type of data you want to retrieve, how to process the data, and what API endpoint you're hoping to hit.Here's an example of a non-specific comment (prompt) where GitHub Copilot will be less likely to generate a useful suggestion:// Get data from APIfunction getData() {  //code goes here}Enter fullscreen modeExit fullscreen modeIn the example above, GitHub Copilot didn't generate anything for me besides the name of the function and the opening and closing brackets.Here's an example of a specific comment (prompt) where GitHub Copilot will be more likely to generate a useful suggestion:// Pass in user ids and retrieve user data from jsonplaceholder.typicode.com API, then return it as a JSON objectasync function getUserData(userId) {    const response = await fetch(`https://jsonplaceholder.typicode.com/users/${userId}`);    const data = await response.json();    return data;}Enter fullscreen modeExit fullscreen mode  Provide examplesIn addition to telling GitHub Copilot what you want it to do, you can also show it what you want it to do with examples in your preferred coding style. While GitHub Copilot is using an AI model that is already trained on a large amount of data, providing examples to GitHub Copilot help it understand the context and constraints of a particular code snippet. Showing AI models examples of what you want them to do is a common practice in machine learning.Here are a few approaches engineers use to train AI models:Zero-shot learningOne-shot learningFew-shot learningI asked ChatGPT to explain the difference between these methods to me like I was 5 years old, and here’s what it gave me:  Zero-shot learningThis is like when you see a new toy you've never seen before, but you know what it is because it looks like other toys you've seen. For example, if you've seen many different kinds of stuffed animals, you might be able to recognize a new one even if you've never seen that exact one before. Similarly, a computer can learn to recognize new things by using what it knows about similar things to make educated guesses about the new thing.  One-shot learningThis is like when you see a new toy for the first time, and your mom or dad tells you what it's called and what it does. After hearing about it just once, you remember what it is and can recognize it the next time you see it. A computer can learn to recognize new things in the same way by being shown just a few examples and learning from them.  Few-shot learningFew-shot learning is like learning to do something new by seeing only a few examples. For example, let's say you want to learn how to draw a cat, but you've only seen a few pictures of cats before. With few-shot learning, you can still learn how to draw a cat even if you haven't seen many cats before. It's like a magic power that helps you learn new things quickly, even if you don't have a lot of examples to learn from!Here's what happened when I showed GitHub Copilot examples vs. when I didn't show it examples:  No example# Create a list of the first 10 prime numbersprimes = []for num in range(2, 30):    if all(num % i != 0 for i in range(2, num)):        primes.append(num)print(primes)Enter fullscreen modeExit fullscreen modeIn the code snippet above, GitHub Copilot will accurately return the first 10 numbers, however it's inefficient because it will loop through all 29 numbers between 2 and 30. We can get more efficient results by providing an specific example of what we want GitHub Copilot to do.  With example# Create a list of the first 10 prime numbers# Example: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]primes = []for num in range(2, 30):    if all(num % i != 0 for i in range(2, num)):        primes.append(num)    if len(primes) == 10:        breakprint(primes)Enter fullscreen modeExit fullscreen modeIn the above code snippet, GitHub Copilot will return the first ten prime numbers and stop when it's found all 10. My goal was to get accurate but fast results, and GitHub Copilot successfully achieved that after I nudged it in the right direction.  Additional tips  Iterate your promptsIf your initial prompt elicits the desired response, delete the generated code suggestion, edit your comment with more details and examples, and try again! It's a learning process for you and GitHub Copilot. The more you use it, the better you'll get at communicating with GitHub Copilot.   Keep a tab opened of relevant files in your IDECurrently, GitHub Copilot does not have the ability to gain context for your entire codebase. However, it can read your current file and any files that are opened in your IDE. I've found it helpful to keep an open tab of relevant files that I want GitHub Copilot to reference. For example, if I'm writing a function that uses a variable from another file, I'll keep that file open in my IDE. This will help GitHub Copilot provide more accurate suggestions.    Give your AI assistant an identityI received this advice from Leilah Simone, a Developer Advocate at BitRise. I've yet to try this with GitHub Copilot, but it was helpful advice. It helps to control the type of response the user will receive. In Leila's case, she requests that ChatGPT behave as a senior iOS engineer. She says, ""It's helped her reduce syntax and linting issues.""   Use predictable patternsAs we saw in the many examples above, GitHub Copilot will follow patterns in your code. AI enthusiast and Developer Content Creator, YK aka CS Dojo, shares how he uses this to his advantage:        YK aka CS Dojo 📺🐦              @ykdojo      @blackgirlbytes Hope it's not too late - but here it is:I've found that it works best when I follow a predictable pattern, and when I let it do its own thing instead of fighting it.For example, when I write:print('some_variabIt already knows that I want to print that variable.Then I… twitter.com/i/web/status/1…      08:18 AM - 28 Mar 2023      Use consistent, specific naming conventions for variables and functions that describe their purposeWhen declaring variables or functions, use names specific to the variable's purpose. This will help GitHub Copilot understand the context of the variable and generate more relevant suggestions. For example, instead of using a generic variable name like ""value,"" use a more specific name like ""input_string"" or ""output_file.""GitHub Copilot will also use the naming conventions you use in your code. For example, if you use camelCase for variables, GitHub Copilot will suggest camelCase variables. If you use snake_case for variables, GitHub Copilot will suggest snake_case variables.   Use good coding practicesWhile GitHub Copilot can be a powerful tool for generating code suggestions, it's important to remember that it's not a replacement for your own programming skills and expertise. AI models are only as good as the data they have been trained on, Therefore, it's important to use these tools as aids and not rely on them entirely. I encourage every user of GitHub Copilot to:Review codeRun unit tests, integration tests, and any other programatic forms of testing codeManually test code to ensure it's working as intendedAnd to use good coding practices because GitHub Copilot will follow your coding style and patterns as a guide for its suggestions.  Beyond your editorCurrently, GitHub Copilot is an extension that is available in the most popular IDEs. There's also GitHub Copilot Labs, a separate experimental extension available with GitHub Copilot access. Copilot Labs can help you translate, debug, test, document, and refactor code. Additionally, we recently launched Copilot X, a suite of features that improve developer productivity outside of the IDE. Copilot X includes:Copilot for Docs - saves developers from scouring reams of documentation.Copilot for Pull Requests - helps you write better PR descriptions and to help your team review and merge PRs faster/Copilot Chat - a ChatGPT-like experience in your editor with GitHub Copilot chat.Copilot for CLI - helps you remember shell commands and flags to run commands in your terminal faster.Copilot Voice - write and edit code, navigate the codebase, and control Visual Studio Code with your voice.Copilot X features/products are currently in technical preview. If you'd like access to one of the features above, sign up for the waitlist at https://github.com/features/preview/copilot-x.  Start practicing prompt engineering with GitHub CopilotThe best way to learn how to use GitHub Copilot optimally is to start using it. You can sign up for access to GitHub Copilot here.If you're a business leader and you'd like to give your entire team access to GitHub Copilot, sign up for GitHub Copilot for Business here.  Let's keep learning togetherThanks for reading this blog post. I'd love to hear from you! I'm still learning more about artificial intelligence, GitHub Copilot, and prompt engineering. If you're a GitHub Copilot fan and have learned how to use it to improve your developer workflow, share some of your tips in the comments below!For similar content, follow GitHub and me on DEV.to! Also, check out other resources to learn more about prompt engineering:How to get Codex to produce the code you wantPrompt Design from OpenAIPrompt Engineering 101: Introduction to CodexPrompt Engineering Guide by Elvis Saravia"
886,"It is an exciting time to be building in the Fediverse!I've been doing a lot of thinking lately around ways in which the experience could be improved for developers looking to get started in Fediverse projects - and by extension, how to improve the space for everyone involved.There's already an active community around one of the prominent standard protocols (the SocialHub community for ActivityPub). I've had an account there since the beginning of last year, primarily as a reader trying to stay informed about the various activities. However, there's more to developing for the Fediverse than ""just"" ActivityPub: many of the related projects implement some but not all elements of the ActivityPub standard; there are other important protocols to know about; and, there are new projects looking to federate, appearing over time as the interest grows.It feels like a good point to offer to help to join some of the dots here. I jotted down some of my thoughts ahead of a meeting that was setup to bring together interested parties from across different Fediverse projects, and I'm sharing the first part of these below. This is very much a starting point, which I'm posting to share and develop with others, collaboratively.There are broadly two sets of developer documentation and community in the Fediverse space, which are interrelated and overlapping:The “core” Fediverse stack, i.e. ActivityPub and the other ~14 protocols involved (The Federation has a nice description of the protocols it deems part of the core).this is where we might also see ""external"" projects such as Medium / WordPress / Tumblr / Flickr participate, adding interoperability with the core protocols (Flipboard already mentioned that they are looking at better and more complete ActivityPub implementation at the heart of their system), thus becoming their own instances of... →Individual Fediverse projects, e.g. Friendica, PeerTube, Mastodon, PixelFed, OwnCast et al. These share one or more of the core protocols, so developers are likely to have an interest in the protocols themselves; they may also have their own specific APIs and behaviours (Mastodon is a strong example of that - client app developers talk to the Mastodon API, rather than using ActivityPub directly).there’s potentially a sub-group here, related to individual instances of specific projects, e.g. a particular PeerTube or Mastodon server may have a group of interested developers who wish to add bespoke features for their own use or purpose.I think of it conceptually as something along these lines (source graphic available here):In the context of the core, there are already some key developer resources, for example:ActivityPub specification - a W3C RecommendationActivityPub Rocks SocialHub community / ActivityPub conferencethere are some excellent threads and posts in the SocialHub community for folks looking to implement ActivityPub, which are a solid foundation for broader work in this space.W3C Social Web IncubatorFor the individual Fediverse projects, it is most likely a good idea if each of the projects that wish to deeply collaborate and be part of the conversation, have someone who takes part in these groups and conversations - as well as taking part in the Fedidevs discussion that started over recent weeks out of the Social Web CG, Fediforum, etc. That person could be seen as a sort of ""ambassador"" between the individual project, and other interoperable participants in the ecosystem.At the individual project level, there are efforts to build good reference documentation both across the board, and for individual projects. Fedidocs has set out to do this both as a central point for the core technologies, and with links to the end projects; it currently lists FunkWhale, Mastodon and OwnCast. There is also a third key developer educational need, related to culture and expectation. In general, there are a number of core pushbacks and concerns around how the technologies are used:User privacy and/or expectation as to how their Fediverse posts are shared. We’ve seen various instance admins block apps that attempt to implement features such as universal search, for example. Tracking and other user-hostile behaviours in apps are generally deemed not OK.→ “Rights Expression Language” (Bob Wyman)Commercial gain / use of the platforms is often a difficult area to navigate.Finally, there’s a generally-strong feeling around negative communities that may not meet the ethos of the broader Fediverse communities (this overlaps with the moderation and admin aspects of the growth of the Fediverse space).If you set out as a developer without staying aware of this third space, your project is not likely to mesh successfully with the others.I'm looking to collaborate with many of the folks active in the space to help to bring these thoughts together and build better documentation and community resources to describe how to be successful in the Fediverse as a developer.Ways to get involved (as of now)check out the Fedidocs repository on GitHub, and read the proposed FAQ for the Fediverse Developer Network[we’re in the process of moving this to fedidevs.org]add @fedidevs@venera.social to your main Fediverse feed, and mention that handle to boost related conversationsjoin the new fediverse-devs Matrix roomCheck out my related posts on the opportunity for developers on Mastodon!Explore the Glitch Community Guide to Building for the Fediverse.(thanks to the folks on today's initial Fedidevs call for their comments and feedback on my earlier draft)(header image credit: Midjourney v5)"
887,"Thoughts on my personal mantra Laziness, Impatience and Hubris🇫🇷 version française  The kindest compliment I ever receivedOn a professional level I mean.In 2004, I was in engineering school at ENSIMAG, Grenoble, France.Our class was struggling on a quite difficult algorithimic challenge.For my part, I had given up and was trying to find a way to work around the main difficulty.Suddenly, a loud intervention from my professor:Jean-Michel, I have been watching you for a while now.And I must tell you something😮You are very lazy😶You will be a great engineer😊  What would you say are your three greatest strengths and weaknesses?We have all heard at least once this stupid question in a job interview.Actually, if that's not your case, please write a comment, that would give me hope.And as a general rule, stupid question -> stupid answer.42Or frankly here, you would be justified to turn the tables:Yes sure, give me one minute to order my thoughts.In the meantime, I have a question for you :What would you say are the three most annoying questions one could ask in a job interview?But humans are creative, and no matter how stupid the question, one can always try to give it a clever answer.  Larry Wall's answer🇬🇧 Most of you are familiar with the virtues of a programmer. There are three, of course: « Laziness, Impatience and Hubris »Larry Wall is a US linguist.He is also best known as the creator of Perl. At least to the odler folks, Perl is not often used those days (I think? Maybe I just lost track.). But Perl played a big role in daring to question the old Unix dogmas, helping the early internet to rise, playing the role of Python's nemesis, and was a major inspiration for Ruby.But even if you don't use Perl, and I don't, Larry Wall is a very interesting guy. I mean most programming books are bad or boring (same for every other subject), the good ones are helpful, a few are super interesting, but Larry Wall's book belong to the happy few programming books that on top of all that made me laugh. I didn't know that was possible.  [Video] What skills or characteristics do you need to be a great programmer?You should watch the video, I think it's a quite cool one. But I know you are probably in the subway, if you live outside of the US anyway, or you are in a super loud café, or you have an hearing handicap.No issue, I will make a transcription just for you.  ""This is a joke"", almostLaziness, Impatience and hubris.These originated as sort of a joke in the first edition of what we call the Camel Book, the book that teaches the Perl programming language.And in a sense, these are the three virtues of a programmer.A lazy person will try always to find some way to do something, will always be looking for ways to do something faster, more efficiently.And if you really want to control the world, that’s really sort of a hubristic notion. Excessive pride. The kind of thing Zeus zaps you for having.But it really was sort of a joke….In the Japanese edition of the Camel Book, they had to add “Laziness, Impatience and Hubris. (THIS IS A JOKE)”. Because they thought people could take it seriously.But really … what makes someone a good programmer is much more than those three things.  Hobbits Would Make Great ProgrammersIf you have either read Lord of the Rings or seen the movies, you know about Hobbits. Well : Hobbits manifest many of the virtues you need as a programmer.You need to have persistence when the going is rough to keep slogging through. A kind of innate stubbornness. In an happy way, not in a mean way.You have to be smart enough to outwit your enemies occasionally.You have to be able to be social, you have to be able to deal with a group of team members. Some of which are like you, they are other hobbits. Some of which are elves, dwarfs. Or even men.They think very differently from you.So you have to contribute your part as a hobbit, but also be able to understand other things. The day is long passed where programming was done individually. Almost all programming is done in teams.So for example you need to be literate. You have to be able to read documentation. And to write documentation that others can understand.But mostly you need to be just slightly insane, in the way hobbits are. Where they can view the long term, where the goal is to go back to your village. But also at the same time, they can forget about all that and deal only with the problem they have at hand.  On more concrete termsOn more concrete terms, you may be telling a computer to do various things. On one hand you have to be aware of what happens at a low level. But if you are aware of that all the time, you are going nuts. So you have to shutdown and work on high-level abstractions.And doing both simultaneously gives the best results in programming. If you ignore one of those, you end up messing up.So that’s what you really need.A hobbit is lazy in a very industrious way.A hobbit is impatient in a very patient way.A hobbit is proud in a very humble way.It sort of sounds contradictory. But to the extent that you can increase your dynamic range on all of those …. you will be a better programmer.  FAQ: What the F# is Hubris?One name: Napoléon.In the early 1800s, after having vanquished many European coalitions, Napoléon controlled pretty much all of continental Europe. But he couldn't help himself and decided to invade an allied country, Spain. Disaster. And then he couldn't help himself and decided to invade an allied country, Russia. You know where this leads: in the middle of the Atlantic ocean.That's what hubris is. Dangerously excessive pride.As Larry Wall mentioned, there are pretty cool Greek mythology stories around Hubris, as you can find out on Wikipedia  Laziness, Impatience, Hubris & MeIf you have read this far, you probably find the mantra interesting, funny, clever.And sure, it is all that. That's part of the reason I chose it as my personal mantra.Jean-Michel (double agent)Follow🕵🏻‍♂️ Double Agent: Developer & Recruiter 💒👨🏻‍💻But for me this mantra is more than that, it has meaning. It tells something important about meHubris, for me, consist in being stubborn and selective when I choose the kind of project I work on. It's not enough for me that you put things on the Blockchain, or that the Elon guy tweeted about it, or that BigCompany pays for it. I need a convincing answer to one nasty question.Who really needs this project, and why?The search for meaning is the constant struggle of my career.Impatience is clearly a personality trait that I have. I left the Android world in part because its slow build times were for me an agony. And that was the right thing to do.Caveat : impatience is my least favorite of the three virtues, because it is very much a double edged sword. I have sometimes hurt people I love by being too impatient. And that's where the extend your dynamic range principle shines : what I have learned is to be way more patient with people, and even less patient with tools.Laziness finally is my dominant great virtue, as first observed by this clever teacher. And it would be easy for me to put an asterisk on lazy. I could point out that I have written 100 articles here, and more on in my french-speaking blog, that I have started a successful open source project, that I have shitload of stuff on my GitHub, that I have learned 7 programming languages, and also 7 real languages, and 5 music instruments, learned the culture of 4 different countries...In sum, I could say that it's only a joke. But I won't hide behind my little finger. Unironically: I have a significant amount of laziness in my soul.And not just because nobody is perfect.But because I choose a profession that fits my personality: Programming means automating.We are not supposed to be the digital equivalent of Charlie Chaplin's depiction of workers of the industrial age doing boring and repetitive tasks.But it's also spiritual: Laziness has often been the sacred source of my creativity.And I won't apologize for it because I don't want my creativity to dry up.  RelatedThis post's title was inspired by this pretty cool article from @sobolevnI am a mediocre developerNikita Sobolev ・ Mar 13 '18#learning#career#beginners#productivity  Call to actionPlease have a nice lazy day ☀️ "
888,"If you had to choose, would you rather work in a small startup environment with a high degree of autonomy or work in a large corporation with more structured processes and hierarchies?Small startups offer an opportunity to work in a close-knit team with a lot of freedom and the ability to wear multiple hats. On the other hand, large corporations offer more stability, established processes, and opportunities for growth.What do you prefer and why? Share your thoughts in the comments below!"
889,"Working in tech offers the opportunity to solve real-world problems and make a difference in people's lives. It also provides continuous learning and growth opportunities due to new technologies and advancements. Additionally, collaborating with like-minded individuals who share the passion for technology and innovation can be a rewarding and fulfilling experience. What do you find most rewarding about working in tech?Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
890,"Over at the CodeNewbie Team, we have been trying to kickstart a little weekly CodeNewbie Meme Monday of newbie-related memes. We decided recently that we wanted to spice things up and try something new out to keep things fresh on the CodeNewbie team. We landed on a Sloan's Newbie Memes of the Week!Here are some of our favorites from this week:If you'd like to join in— drop your beginner-related, job-related, starting-a-new-career-related memes down below!Happy coding y'all!"
891,"The front-end and back-end of web development offer different challenges and opportunities. Which one do you find more compelling, and why? Let's chat about it in the comments!Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
892,"(X-posted from hereHeard about Large Language Models like ChatGPT4, Bing, GPT3? I'm sure you have.There is one side of the hype around these technologies that I come across pretty often, which is that these technologies are bad for some $reason (""they are stochastic parrots"", ""they create bullshit"", ""they can't reason"", ""they make up facts"", ""they might replace junior developers, but they will not replace senior developers""), which, while technically true, is missing a much bigger point: if you are in the business of writing software, these things work.In fact, they work so well that I think we are on track to see a fundamental shift in how software is built. This is going to have a drastic impact on pretty much everything. The irony of the situation is that programming is probably one of the jobs that can most easily be replaced by these technologies. This article is mostly directed at programmers among my readers: we are at a pivotal moment where we programmers need to understand and appropriate these technologies, on our own terms, before capitalism does it for us.I have written about how I am convinced that LLMs are a paradigm shift for the pragmatic programmer and started giving more detailed insight into what I have been using these models and the applications around them for. I have also written about my budding ethical stance around this technology, and won't get into that aspect in this post.1 I think that we are at ground zero of a tremendous revolution in the way we build software. We don't know how to work with these tools yet: we just discovered alien tractor technology. Many critics try to use it as if it was a plain old gardening rake, dismissing it because it plowed through their flowerbed.I hope to share some of the insights I've gained into what programming with LLMs actually does for me. I have discovered that developing a practice, a methodology, a workflow is key to intellectual work, be it software or writing or music. Because programming is closely intertwined with productive teamwork (especially in our capitalist context), this practice has to be shared. Programming is about coordinating the work of individuals to create common artifacts, and success is determined by how well we coordinate.I think that programming with LLMs is about to create a radical shift in software architecture, system architecture, programming practices, communication patterns and organizational structures. These are exciting times, because we are the people who are in position to shape what programming is going to be like in the future.  My background is in system programmingI consider myself a programmer first. I've wanted to press buttons to make machines do things since I was 5, and one of my autistic interests has been computers ever since. Even my music, drawing, writing is inextricably bound to these machines of wonder. I have written millions of line2 of code and barely a day passes by when I don't push a few commits. All that to say that I'm intensely interested in things that work, and that I have tried many many things. I care enough about coding that if LLMs weren't useful, I wouldn't be using them every day.3 I have been programming heavily with Copilot since it was in beta, and have been using chatgpt for every real-world problem I could think of, beginning the week after it was accessible to the public. I write mostly ""boring glue code,"" and have done so in what I call ""systems programming,"", i.e. building systems (operating systems, embedded systems, distributed systems, logistics, supply chain). Another definition could be ""writing memcpy in many different complicated ways."" 4  Copilot my uncanny autocompleteI love ""rustic"" programming languages: my favourites are PHP and Javascript, Java, Go, (and, for reasons that are beyond the scope of this article: Common Lisp5). For me, ""rustic"" means that what you see is what the author intended, without necessarily a lot of polish: languages that make their context explicit. It's the dinner table built by your grandfather, upgraded by your mother and you now inherit: it is a bit clunky and the paintjob is flaking off, but it has been doing its job for nearly a century without failing. These are languages that Copilot does a superb job with. The patterns it should use are often very ""flat,"" and are often present in the code around it. A symbol's meaning is not influenced by hidden characteristics, abstractions, or module systems. It is not that it is the ""complexity"" or abstraction-level of the language that makes for inferior results, it's that it is more difficult to infer from the training corpus what the completion of your code should look like.This is what allows Copilot to do a superb job (while I tried to use it for Haskell and Rust in the summer of 2022, I haven't tried since. Copilot has made some impressive progress since, so my take here might already be completely out of date. I have grown used to Copilot uncannily inferring what I am trying to do after writing the first couple of words. In fact, I have noticed how my physical muscle memory has changed during the programming process. If my internet is down and I—god beware!—have to type in code myself, I have to undergo a mental switch. At first I'll write 3 words and expect 10 lines of code to be scaffolded out. It takes me a few seconds to realize my magical friend Frank the copilot has gone AWOL.  Stochastic parrots, valid code?One of the common criticisms of Large Language Models is that they often output wrong code. Which is true (ChatGPT4 significantly ups the bar, but it's not too difficult to get it to output wrong code)! Leaving it at that is, however, I think not looking carefully enough. Quickly written wrong code that can be easily corrected is just another name for good code. Much of my programming consists of writing trivial ideas in longform. I will start with ""I need to copy this data from here to here"" (which is why I refer to it as ""memcpy programming""), and then spell it out in HTTP call this, promise that, SQS event here, batch job there. Just writing the comment call the HTTP api /api/products and send the result to our SNS topic /products is enough for Copilot to basically complete the entire thing. Because I am not a rocket scientist, the methods are going to be something like (in fake Javascript):http.GET(""/api/products"").   then((products) => if (validateProducts(products)) {       this.sns.enqueue()     } else {       fail(""invalid products"")    })Enter fullscreen modeExit fullscreen modeIf you autocomplete copilot after writing the comment above, it might very well come up with:http.GET(""/api/products"").   then((products) => if (validator.checkProducts(products)) {       const sns = new SNS(this.topic)      sns.enqueue(products)    } else {       throw Exception(""invalid products"")    })Enter fullscreen modeExit fullscreen modeGetting hung up on the fact that it used validateProducts and not validator.checkProducts is I think missing the point. The actual working benefit is that I now usually spend 10 minutes on something that would have taken me 2 h.I think the implications of that fact stretch much further than ""Well, now we have just replaced code monkeys."" I think that being able to write tedious code at that speed closes so many feedback loops that it leads to emergent effects that change the way we build software.  Aside #1: Helping Copilot output valid codeAlthough Copilot is very eager to discover your codebase, it needs to see what style you like. It needs to see what APIs and helper methods you already have at your disposal, and which packages to import. The solution, if you would like to tab-complete 90ish% of the code you intend to write? Visit a couple of files you want Copilot to ""learn"", or write one example of what it should generate. If you want Copilot to be fluent at using an obscure library, just go browse its source code, visit a few examples, then go back to frantically tab-complete your way to a working application.The same technique works for ChatGPT. You want to have a decent output for ChatGPT? Just copy paste a ton of example code upfront. Copy paste your class definitions, the comments to your class definition, maybe some DDL, some example CSV. Paste it often, paste it every time it diverges. Take its code, correct it, paste it back. Paste the documentation page. Paste the entire StackOverflow thread. Paste paste paste, context context context is what is needed here.  Methodology shift #1: writing documentationThis is the first change in methodology we have encountered. More than API documentation for humans, we need to write code (and tools!) that make the API discoverable and ""understandable"" for LLMs. In most cases, the two come hand in hand. Writing clear and concise comments is what gives the LLM the context it has seen in its training set, thus helping it to infer the correct answer. Clear and concise APIs, with meaningful names, allow us to efficiently (the fewer tokens the better) convey our intent to our tools. I think we will start seeing practices that will expose documentation as both human readable, and easily ""machine parseable"" (short, concise, with few-shot examples for concrete tasks). Instead of formal languages such as UML, ODL, SOAP, Swagger, JSON Schema, we will go back to simple, no-nonsense READMEs that give a short overview and a couple of usage examples. This will work not because simple is better (there is a reason we keep reinventing the wheel with these things). It works because the README encodes our ""human"" intent very well, and the source code embodies what we intend the system to do in excruciating detail, and an LLM can combine the two to generate either more ""formal"" code for the machine to interpret, or less detailed text for humans to interpret. I don't think we have realized that the most effective way to communicate with humans is now also an efficient way to communicate with machines.This of course works both ways. Large Language Models are uncannily effective at transforming crappy comments into well-written, articulate paragraphs. They can generate 5 interesting examples in the time it takes me to say ""please."" They can update the existing documentation to match the updated API after refactoring in a matter of seconds (and it is only cumbersome because it currently requires copy-pasting to and from ChatGPT). Copilot Labs is experimenting with ""brushes"", but since I use Intellij and not Copilot, I haven't really used them much). They can update code to match documentation changes in the same way, or generate valid code out of concise, well-written documentation. Heck, you can literally curl a few endpoints in your terminal, paste the entire thing without any editing into ChatGPT. You can then ask it to create an API library with mocks, unit tests, examples and documentation. This will more often than not output something better than I would have written. I don't bother manually writing any of this data munching / API wrapping / result validating code anymore. I had to build a server-to-server integration with Google Tag Manager recently. I literally copy pasted the webpage into a simple 3 line prompt and can now generate PHP classes, typescript interfaces, event log parsers, SQL serialization with a simple shell command.What do we do now that well-written documentation is both fundamental and almost free? Do we become writers? Do we become editors? Personally, I think so. There is no excuse to not write stellar documentation (or tab-complete your way to it), documentation style and documentation quality will become just as automatable and lintable as how many spaces we put in front of our curly braces, and code comments will never be out of date again (why wouldn't your IDE flag documentation that doesn't match the behaviour of the code?).6 And if we become editors, does that mean that learning to work as a programmer is now, from the get go, about learning to read, criticize and correct code? These are the skills that we have painfully turned into practice over the last 30 or 40 years since the explosion of professional software engineering, and are often reserved to the ""senior"" caste, juniors being busy banging their heads against the compiler or something. But now being a junior means de facto becoming a critical reader. Code reviewing is the new programming. 7  Methodology shift #2: Whiteboarding and rubberduckingOne thing using LLMs teaches you is that software architecture is about pattern matching, and those patterns are fairly simple. The thing is that by default, ChatGPT for example is akin to a ""design interview bullshitter."" It will confidently use a lot of clever words, draw the right diagrams on the whiteboard, and be utterly incompetent at making an actually worthwhile point. Asking ChatGPT how to design a certain application will result in eerily similar heaps of teflon-coated, reality-proof platitudes (ChatGPT4 already sets the bar much higher here...).It is easy to say the right things, it is easy to look up what an effective event-driven architecture looks like, but it is much more difficult to figure out what exactly needs to be done, what is easy, what is difficult, what works well, and what fails in a real-world scenario. But, using the technique shown above, once you start asking ChatGPT how to build out a concrete application by sketching out potential APIs, fleshing out an infrastructure, deciding which protocols to use, you often get a lot of plausible looking, concrete code.I find generating ""plausible"" code useful on its own. I don't need to trust the code to be correct—the overall structure and vibe gives me a sense of how this thing will work, what is problematic, and what is clever. It has a tremendous amount of quality code to rely upon to find interesting patterns and well-named classes; I can guide it when I think of something. I basically have a pretty ""intelligent"" rubber duck at my disposal.8 Brainstorming with ChatGPT feels very much like sitting in front of the whiteboard with a colleague and just imagining things, except that you often end up with reasonably close to working code by the end. While I have never done a ""three-way"" whiteboarding/rubberduck session with a human and ChatGPT, I think that this will become a regular practice for some.  Methodology shift #3: Build more prototypesChatGPT is great for generating prototypes, big and small. Ask it about a topic and it will not only answer, but usually provide a fully runnable example in the language of your choice. It might or might not execute, but that's a heck of a lot of really boring nonsense that I don't have to type. Once the LLM has typed out a toy example, I can remodel that simple example into many more things: A full command-line applicationA unit test suiteA fuzzing harnessAn example of documentation.A stress-test toolA simple web UI (""write HTML for a field that posts to /api/product and display the resulting JSON as a table. Then, write CSS to style it like a geocities page."" is how you do it...)A Docker container to use in CICD...LLMs lower the cost of exploration to almost nil. I recently wanted to write a plugin for OBS that would stop the recording if I didn't close a modal within 1 minute. I had never programmed OBS before, but in three hours I was able to do the following:Build a Python script that looks very promisingFight with OBS until I realized that trying to get arm64 python working was too frustrating (1h lost...)Rewrite the script in LUA and get it workingRealized that what I thought was a weird hallucination was actually the best possible way to do something like a modal in LUA. Decided it sucked.Write a Go CLI application that controls recording over a websocket.Write a cross platform UI in Go that shows me the modal and various other buttons to control recordingI was able to try two dead-ends (through no fault of the LLM's own, honestly) and end up with a robust running tool that I will continue expanding. I hate writing UIs, I hate fighting obscure APIs I don't know. I used to only write tools when something was getting so humongously irritating that I just couldn't take it anymore. I have a problematic habit I am actively trying to fight: building personal tools as if they were meant for production at-scale (meaning: after 3 days doing ""professional"" software engineering, I burn out and the tool ends up in the ditch, full of promise yet unfinished.)What this means for professional programming is that you can now write code, write a lot of code, write an insane amount of code, and just throw it away. No one will fault you for having a conversation with ChatGPT that generates 5000 lines of code, and then closing the tab. But, the fact is, you wrote 5000 lines of code and decided they were not worth it. When was the last time you did that? What if it became standard practice to draw up a concise, well-written description of the problem at hand (see the previous section), and then ask the LLM for a microservice architecture sketch in go, a synchronous multithread sketch in rust, a typescript deno version, potentially a lambda. What if you had it generate Terraform for AWS, but also for Azure and GCP? What if an architecture proposal now only gets to the review stage if you try at least A, B, C, D before settling on one, instead of endlessly debating with your colleagues about A vs B? We all know we have biases. We all hold strong opinions that can only be supported by evidence with an n of 1. I am usually more convinced when I see an actual code sketch.We used to deride ""writing code at the speed of mouth,"" but that is now a reality.  Methodology shift #4: Build more toolsWhich brings me to the next practice that I think will be incredibly beneficial. We all know that tools are important, that effective tools are challenging to create, and that management doesn't care or understand the need for tools. LLMs allow us to build tools at the said ""speed of mouth."" I know that I can now spend 30 to 45 minutes talking to ChatGPT and get a pretty solid tool done. This would probably have taken me 4 to 5 h programming previously, which means that it would have to be split over 2-3 work days (factoring in meetings, code review, lunch breaks, interruptions). Which usually means that the tool won't get built. A list of tools I built in the last 3 months:sqleton - a tool to run SQL queries as command line applicationsescuse-me - the same for elasticsearchgeppetto - the same for the GPT APIsbiberon - the same for bibtex (very rudimentary, it got one job done)majuscule - a twitter hashtag segmentation prototype, but with dynamic HTML debug UIa script to stop OBS recording if I am away from my computermany utilities for work: Convert arbitrary documentation to code (see Google Tag Manager example above). Parse and analyze search logs. A SQL builder for said search logs. A full-featured GTM server-side implementation. Tools for managing banners and their assets. An application that runs invoices through OCR, cleans it up with GPT, searches ElasticSearch for SKUs, and renders out a cleaned up invoice matching our inventoryReport generators for every single datalake debugging I had to doDocumentation generator for Google Tag Manager JSON exportsI can't express how fundamentally different programming feels now that I can build 2 quality tools per day, for every single itch I want to scratch.  Aside #2: Fundamentals will probably be just as criticalI believe that abstraction is primarily learnt by having seen and played with enough concrete use cases that higher structures get formed. Abstractions are a two-edged sword, as an ill-fitting abstraction will cause constant friction. While LLMs allow us to work at a ""fuzzy abstraction"" level (the abstraction is not ready to be formalized, but it is forming and shaping the words used to describe a problem) as well as quickly explore concrete implementations, ""controlling"" an LLM is best done by having a solid understanding of the problem in mind.One very real downside I have experienced with conversational LLMs is the temptation to keep chatting and hacking at a problem in the hopes that the model will ""get it"" at some point. This is exacerbated when you don't have a proper grasp of the problem you are trying to solve. Your focus shifts from having a productive conversation to stumbling over hallucinations that lead you on wild goose chases. In those cases, I found myself closing my internet connection altogether. Instead, I stuck  with offline documentation and a book until I got a better sense of what I was dealing with.With ""real"" knowledge in hand, asking the right questions of the LLM leads to a much more productive session. Anybody deriding ""prompt engineering"" as a ridiculous discipline hasn't spent enough time trying to write effective prompts.Aside #3: Avoid unproductive chat sessionsI hope that future conversational agents will be able to flag when these unproductive spirals happen. Currently, ChatGPT will just continue to engage, but I could see it at some point stopping, and pointing to proper tutorials and resources. Another option would be to ask for more details. The progress that ChatGPT4 seems to have made (I have only used it seriously for 2 days, so I can't really form a proper opinion) is quite impressive. One thing this field has taught me is not to make assumptions about the capabilities of the next generation. It might have the same fundamental issues the current models have, but it might just become ""good enough"" that for all intents and purposes, it doesn't matter.  Methodology shift #5: Continuous code reviewI think that a major focus of tooling is going to be on ""continuous code review."" A model can watch you build your software, infer your intents and the structure of your thinking, and provide feedback on your approach. It can flag typos, security mistakes, and non-idiomatic uses of APIs. I was impressed by ChatGPT4 correcting my code and doing some pretty effective factoring of the problem into interfaces and functions by itself. In fact, I would say that in the small, ChatGPT4 is a much better programmer than I am. It knows many more idioms, it doesn't forget security issues, and it can spit out unit tests at the speed of token sampling.People who think that these models will lead to a proliferation of bottom of the barrel stackoverflow code riddled with security mistakes are missing how quickly these models have become better at what they do. I think it is because it is easy to forget just how much good code can now be found online. Great code is bound to be more widely disseminated in its training corpus, and said corpus is most certainly closely scrutinized and tweaked. The jump from ChatGPT3.5 to ChatGPT4 in terms of software architecture ""rhetoric"" makes that abundantly clear.I use a series of prompts that ask the model to give its feedback regarding security issues, edge cases I've missed, documentation that is unclear. As of now, I have to manually copy and paste this into chatgpt, provide missing context, and refine its answers. This is however a matter of engineering. The model itself already does an impressive job. This is infinitely better than most code reviews I've received over my career, and it is instantaneous, along with examples to reproduce the issues found and fix suggestions.It is now basically easier to write complex, fuzzy linters that can check for domain-specific, codebase-specific patterns, because such prompts consist of a couple of (well-informed) human language prompts. It is probably faster to instruct the LLM-linter to ""check that singletons are only used when dealing with customer data"" than to properly configure curly-brace behaviour in editorconfig. It won't catch every usecase, but it will catch enough to be worth its while.  Methodology shift #6: Cognitive impact of using LLMsThis might be the most subtle shift, but I believe it's also the most profound change that using LLMs has brought to me. After a day of being focused on getting ""the tedious stuff"" right (using the right API, checking the right errors, properly calling API X, implementing the unit tests and mocks for Y, writing an API wrapper for Z), my brain would be entirely gone, consumed by the minutiae and intensity required to not slip up. I would spend the evening playing video games or watching Netflix to recover.Since extensively using Copilot and ChatGPT, this cognitive exhaustion is pretty much gone. 6pm strikes and I feel like I spent the day chatting with a buddy, yet 5 PRs have been merged, the unit tests have been written, two tools have been improved and the code has shipped. This allows me to make significant progress on my open-source projects. I know that I'll be able to get one non-trivial thing done before dinner, and maybe one or two more after. Where I would previously spend 3 h on Saturday trying to get an AWS lambda running, wondering ""why the hell am I spending my Saturday this way"", I will now happily close one or two tickets, and spend the rest of the day with my family and doing chores.  Doing more ""high-level"" thinkingI am a firm believer in letting things rest, and doing ""shower-thought-driven"" software engineering. I believe it is necessary to think deeply about something, try to build a few prototypes, and then let it settle. The real insights (and bug solving) happen when taking a walk, when my brain is well-rested, after exercising or in the proverbial shower. Whereas I would previously maybe be able to 30 minutes to 1h of this ""free"" time per day, if at all, by being able to fold the tedious stuff that used to take 4h into 1 or 2h (I am averaging here, but writing something like an API wrapper legitimately costs me 10 minutes instead of 2 days nowadays), I now have 3 to 4h of ""free"" thinking time per day. This means that I can think about what needs to be done and what doesn't. It means I can spend some time trying out alternative approaches (build more prototypes, as detailed above). I can spend more time talking to stakeholders and figuring out exactly what we need. I can think about the tools that the team itself needs. I can work on pedagogical material. I can make reports pretty. It is not that these things couldn't be done before, but they have become so insanely cheap that there is no good reason not to do them.  ConclusionI wish more senior developers had spent the time to properly assess these technologies, with an open mind instead of reacting defensively with knee-jerk reactions. These technologies are scary, because they make it clear that programmers are going to be the first in-line to be replaced by machines. All the ""improvements"" listed above are going to be exploited by the way our industry is structured (corporations are already AIs, in some way) to squeeze even more soul-crushing productivity to the benefit of a very few individuals. We have an opportunity right now to reckon with how we deal with these emerging powers. I am trying to work out which direction I want to take, besides writing about what I think is valuable engineering insight: taking these technologies out of the moat of Silicon Valley companies; using the ""improved"" productivity before companies catch up to figure out how to organize; leveraging LLMs to build better open-source; using these technologies to build tools for people, not business.Furthermore, while I might slip and anthromorphize LLMs, I do so in the way that I would say that ""the compiler thinks."" As far as I am concerned, LLMs are relatively straightforward pieces of code trained on a shitton of data, and ChatGPT is not more alive or reasoning or feeling than /bin/ls and my S3 bucket of production logs. It doesn't know, it doesn't remember, it has no intent, it has no interactions with the world. I want us to talk about LLMs as what they are: probabilistic models of language that predict the next token based on a given context, after having been trained on exactly that. The fact that this formulation has led to such things as ChatGPT blows my mind, but I'm not interested in discussing irrefutable speculation. I just want to write code, man... ↩There's a whole thing about programming vs software engineering that I never fully understood. Surely software engineering is about building good software, and programming is, well, building good software too. When I draw diagrams I am programming. When I write documents I am programming. When I talk with colleagues in front of a whiteboard we are programming. When I read and write a lot of software, mindfully, I do a lot of software engineering, because I want my software to work today, tomorrow, in ten years (which means measuring, testing, benchmarking, breaking, stress-testing, documenting). I want it to work even when 30 people work on it under the pressure of deadlines (which means designing, refactoring, testing, building development workflows, writing documentation, communicating, understanding team structures and business goals and legacy and individual cognitive styles). I call it programming because the only tangible result that we can actually all agree on is the resulting artifacts (source code and documentation). I love working on and reading legacy codebases, and you can read most of the ""more abstract"" things in the source code itself (on the easier side: team dysfunction, badly aligned goals, insufficient communication; on the harder side: good onboarding, individual contributor growth, great business alignment). That's why I tend to bring up coding so much. You can talk beautifully about all kinds of concepts, but what really matters is the code that comes out. To me, good code is synonymous with good engineering (good code can be: code that solves a business problem, where often no code is actually the best code; code that is elegant (some programmers like making elegant things, most like using elegant things); code that is fun; etc...). ↩If this comes across as braggy, one thing I learned about the last year after discovering I'm autistic is to not care too much about how I come across. I think I am a pretty terrible, careless coder; I love sharing everything I know: I want everybody to find the love I do when I use computers. I am disappointed that I will never get to be a jack of all trades, because there is just too much cool stuff out there. I will leave mastery to people who have a more focused curiosity.  ↩This seems to be another loaded term where people fight over definitions. I am grouping embedded, some web, distributed, operating systems and some database development under the systems programming umbrella. It seems like a very broad umbrella, but from a programming perspective, I see it as the programming of queues, resource ownership, resource initialization and teardown, concurrency, locking; the programming of protocols, data serialization, storage, bandwidth, throughput, latency; the programming of state machines, coroutines, schedulers, threads, drivers and APIs. When we define ""systems programming"" from the programming perspective (what code we write), we discover many parallels which are ""generative,"" i.e. they generate insight and ideas through the use of code. This is in contrast to defining ""systems programming"" as say, the programming of operating systems. This shuts down insight. It causes generations of web developers to reinvent the wheel each time they want to manage minified assets instead of using a resource pool. It leads generations of embedded developers to reject better tooling and effective testing and deployment practices. It leads to a smorgasbord of poorly designed embedded UIs and slow web applications and unpleasant concurrency abstractions and operating systems that think everything is an integer. ↩You might wonder why I group Common Lisp along with PHP. What makes Common Lisp special as a language is that it allows you to build your own language whenever you need to, however you need to. You can refine it interactively. If your goal is to write code with a clear structure and explicit context, Common Lisp is an excellent tool. Instead of shoe-horning your communication into a ready-made, rigid framework, you build the structure to fit your communication. As we will see, this is what allows LLMs to do a good job. Also, take a look at the Common Lisp spec and tell me it's not... clunky with a flaky paintjob. ↩You might realize by browsing geppetto's repository that it's just as easy to... not write documentation. Entirely free it is not, that is for sure. Another reason here is that I don't want people using this tool just yet. I have put significantly more effort into glazed's documentation, including building an entire HelpSystem inspired by Mathematica's stellar documentation. ↩I think people worried about junior programmers becoming obsolete should rather be worried about junior programmers replacing seniors. It's easy to believe that your mind stays younger as you grow older. However, hanging around discord with passionate 15 year olds quickly shows me how calcified I have become. I might think that my elegant take on frontend frameworks and component-based CSS, my ideally crafted git workflow and observability practices are the embodiment of craft. In the meantime, the kids think I could just as well write COBOL while they merge their 30th pull request of the day. This will enable their fully automated CICD to deploy the newly created artifacts. Every random repository that gets shared on Tiktok gets 300 (3000? 30000?) stars within a few days. While me writing opensource back in 1998 meant maybe getting a single patch merged because I knew someone on IRC who cared, today, it means growing up fast AF and becoming an agile tech lead quickly. ↩As someone who needs to ramble and ramble and ramble at somebody in order to clarify my thoughts, this is genuine magic. One downside is that the tool's ""personality"" changes over time. It latches onto novel concepts, and heavily redacts or tones down more opinionated statements, often in response to prompting attacks and in order to reduce the amount of hallucinations and other side-effects. This is the inverse of what you want when brainstorming, where far-out ideas are what spark joy. As a work-around, I often prompt the worst models and paste their confabulations into the more reasonable big brother, in order to disrupt the process. ↩"
893,"They say that the things you loved as a kid can give you clues about what you'll love doing as an adult. Did you dream of being an astronaut, a veterinarian, the next Michael Jackson or Britney Spears (depending upon your birth year)? We want to hear how you ended up in the tech industry. Did you stumble into it by accident, or did you always know that tech was where you belonged? What childhood interests or hobbies led you to where you are today?Follow the CodeNewbie Org and #codenewbie for more engaging, thought-provoking, and sometimes silly discussions just like this."
894,"Based on popularity and demand in the current job market, two of the top languages to learn first in coding today are:Python because it’s versatile and easy-to-learn, as well as widely used in data science, machine learning, web development, and automation. It has a simple syntax and a large community of developers, so it’s an accessible language for beginners.JavaScript, especially for front-end (and now popular for back-end) web development, is also quite versatile and scalable. It's used to build interactive websites and web applications, and it has a large number of libraries and frameworks available for developers to use.Both Python and JavaScript are used in a variety of industries, so learning these languages can provide a solid foundation for further exploration in programming and open up a wide range of career opportunities. Where do you recommend our CodeNewbies to start? With one of these languages, or perhaps another? Share your experience!"
895,"Hey folks! 👋Hope y'all are all enjoying your weekends. 🙌Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugHanging with buds 👯"
896,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   FastAPI + Celery = ♥Interested in Python FastAPI? Wondering how to execute long-running tasks in the background in Python? Learn exactly that in this post with @derlin!FastAPI + Celery = ♥Lucy Linder ・ Mar 27#python#fastapi#tutorial#showdev  My 5 favorite updates from the new React documentationReact has come a long way over the last 10 years and the framework has undergone some major changes in the way it works. @anishamalde covers the best changes to the documentation, especially for beginners. My 5 favourite updates from the new React documentationAnisha Malde ・ Mar 31#react#frontend#webdev#news  How to split an Angular app into micro-frontend appsSometimes apps grow so large that your big team splits off into smaller groups to handle their own part of the software. If you find yourself in this position, @michaeljota breaks down how the micro-frontend approach might suit your desire to scale better.How to split an Angular app into micro-frontend appsMichael De Abreu ・ Mar 28#angular#tutorial#architecture  Should AI development beyond GPT-4 be paused?@theaccordance initiated this thoughtful discussion, asking whether or not we should pause on developing more sophisticated AI beyond OpenAI's GPT-4. Be sure to check out the comments and consider leaving one of your own!Should AI development beyond GPT-4 be paused?Joe Mainwaring ・ Mar 29#discuss#ai#healthydebate#openai  GitHub Copilot for CLI makes Terminal scripting and Git as easy as asking a questionChristian just got access to GitHub Copilot CLI which brings AI code completion to your terminal. After installing it, you get three new commands: git?, ??, and gh?. Find out more in @codepo8’s post. GitHub Copilot for CLI makes Terminal scripting and Git as easy as asking a questionChristian Heilmann ・ Mar 29  Mastering React's useEffect Hook: A Comprehensive GuideThe useEffect hook is a powerful tool that was introduced in React 16.8 as a part of the Hooks API. In this post, @fatimaola explains useEffect and how you can use it in your React Application.Mastering React's useEffect Hook: A Comprehensive GuideFatima Olasunkanmi-Ojo ・ Mar 30#webdev#react#frontend#javascript  Why JavaScript is a Prototype-based OOPYou may have heard JavaScript is a Prototype-based Object-Oriented Programming language, but to a newbie those may sound like a bunch of words that make no sense together. Here, @efkumah breaks down what each of these words mean and how it impacts the structure of your JavaScript code. Why JavaScript is a Prototype-based OOPEmmanuel Fordjour  Kumah ・ Mar 30#javascript#webdev#beginners#oopThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
897,"The old engineering adage: “don’t touch it, it works”. Is terrible. Don’t listen to it. It might be OK at a small scale but as time goes by the bit rot spreads through your code and servers polluting everything. Large swaths of your system become “no-man's-land”. As you’re developing a new system, you must always “touch it” and make sure we hire engineers who aren’t afraid to do so.Yes, I get it. I said that sentence frequently in the past. I understand the motivation. Management doesn’t care about the bit rot in our future. They care about the here and now. Why are you wasting time on this feature? It’s working. Don’t you have enough on your plate already?Are you the Marie Kondo of coding? Does this code not spark joy?It’s more like a bad apple in a barrel. Bad code and forbidden zones tend to grow and metastasize. A living project needs to be fully accessible by the current team. It can keep working without that, but that makes every future step painful. When we have a flexible team with a relatively small and familiar code base, touching everything isn’t challenging. It’s easy in that case.   The Legacy ProjectThe hard part is touching code in legacy projects. As a consultant, I had to do that often. How do you enter a project with a million lines of code and start refactoring?The nice thing is that we’re all alike. The engineers that built the project were trained with similar books and similar thought processes. Once you understand their logic you can understand why they did something. But a large part of the difficulty is in the tooling. Projects that were built 20 years ago used tools that are no longer available. The code might no longer compile on a modern IDE. Our immediate reflex would be to try to use an old IDE and old tooling. That might be a mistake. Old tools keep the stale bit rot. This is an opportunity. Revisit the project and update the tools. A few years ago I did some work for an older C++ codebase. I didn’t understand the code base, but the original developers built it in an older version of Visual Studio. Getting it to work on my Mac with LLVM and VS Code helped me visualize the moving pieces more clearly. Once I had a debugger up and running, fixing the bugs and weird issues became trivial. I can’t say I fully understood that codebase. But the process of porting and updating the tools exposed me to many nuances and issues.  When You Can’tThe flip side of that were cases where an existing legacy system is a customer requirement. I had to implement integrations with legacy systems that were external black boxes. We didn’t need to touch their code, but we needed to interface with these systems and rely on their behaviors. This is a very challenging situation.Our solution in those cases was to create a mock of the system so we can simulate and test various scenarios. In one such situation, we wrote an app that sent requests and saved responses from such a “black box” to create a simple recorder. We then used the recordings as the basis for tests in our implementation. This might not be an option since sometimes, the black box is directly wired to production (directly to the stock market in one case). My rules for dealing with such a black box are:A single isolated module handles all the connections - that way we can build uniform workarounds for failures. We can use a physically isolated microservice which is ideal for this specific case.Expose results using asynchronous calls - this prevents deadlocks and overloading a legacy system. We can use a queue to map causes of failure and error handling is simpler since a failure just won’t invoke the result callback.We need to Code defensively. Use circuit breakers, logging and general observability tooling. Expect failure in every corner since this will be the most contentious part of the project.Once we wrap that legacy we need to trigger alerts on the failures. Some failures might not bubble up to the user interface and might trigger retries that succeed. This can be a serious problem. E.g. in a case of a stock market purchase command that fails a trader might press retry which will issue a new successful command. But the original command might retry implicitly in the legacy system and we can end up with two purchases.Such mistakes can be very costly and originate from that black box. Without reviewing the legacy code fully and understanding it, we can make no guarantee. What we can do is respond promptly and accurately to failures of this type. Debuggability is important in these situations hence the importance of observability and isolation in such a black box.  Confidence Through ObservabilityIn the past, we used to watch the server logs whenever we pushed a new release. Waiting for user complaints to pour in. Thanks to observability we’re the first to know about a problem in our production. Observability flipped the script. Unfortunately, there’s a wide chasm between knowing about a problem and understanding it, fixing it and noticing it. If we look at the observability console, we might notice an anomaly that highlights a problem but it might not trigger an alert even though a regression occurs. A good example of that would be a miscalculation. A change to the application logic can report wrong results and this is very unlikely to show in the observability data. In theory, tests should have found that issue but tests are very good at verifying that things we predicted didn’t happen. They don’t check against unexpected bugs. E.g. We might allocate a field size for financial calculations and it worked great for our developers based in the USA. However, a customer in Japan working in Yen might have a far larger number and experience a regression because of that limit.We can debug such issues with developer observability tools but when we deeply integrate legacy systems, we must apply the fail-fast principles deeply, that way the observability layer will know of the problem. We need to assert expectations and check for conditions not in the test, but in the production code. Here an actual error will be better than a stealthy bug.A lot of focus has been given in languages to the non-null capabilities of languages. But the concepts pioneered in languages like Eiffel of design by contract have gone out of fashion. This is understandable, it’s hard and awkward to write that sort of code. Checked exceptions are often the most hated feature of the Java language. Imagine having to write all the constraints you expect for every input.Not to mention dependencies on the environmental state. This isn’t tenable and enforcing this check-in runtime would be even more expensive. However, this is something we can consciously do in entry points to our module or microservice. The fail-fast principle is essential when integrating with legacy systems because of the unpredictable nature of the result.  SummaryIn the 90s I used to take a bus to my job. Every day as I walked to the office I would pass by a bank machine and every time it would reboot as I came close. This was probably part of their cycling policy, banks have a culture of rebooting machines on a schedule to avoid potential issues. One morning I went by the machine and it didn’t reboot. I did what every good programmer/hacker would do; I pulled out my card and tried to use it. It instantly rebooted and wouldn’t take my card, but the fact that my instinct was to “try” is good. Even if it isn’t the smartest thing in the world, we need to keep code accessible and fresh. Legacy code isn’t a haunted house and we shouldn’t be afraid."
898,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @earthcomfy's Top 7 post, tonight’s topic is...design patterns!From Problems to Solutions: Understanding Design PatternsHana Belay for Documatic ・ Mar 26#programming#beginners#tutorial#designpatternsQuestions:Which design patterns have served you well in your applications?Which design patterns have stumped you or failed to meet your expectations for problem solving?Do you usually use design patterns purposefully or accidentally?Any triumphs, fails, or other stories you'd like to share on this topic?"
899,"It's a new week and I am still learning new things about coding, interspersed throughout my day of reading your articles over on the #CodeNewbie Tag!For this week, I decided to find a broader range of articles, from super specific pull request-related content to increasing accessibility by using alt text. Call it a loose theme, theme being ""things Rachel wanted to share this week""! Without further ado... here are my picks of the week!“Two weeks ago we learned how to create a Pull Request on GitHub from Visual Studio Code and last week we saw how to review it. Today we'll see how to manage issues on GitHub from the editor.” - @balastrong Manage GitHub Issues from Visual Studio CodeLeonardo Montini for This is Learning ・ Apr 3 ・ 5 min read#github#vscode#codenewbie#tutorial“It's easy to feel jumbled and confused when trying to navigate the post-bootcamp phase. After some reflection, I've come up with a game plan that can help you make sense of it all.” - @torfrancis447Life after Boot CampTor Francis ・ Mar 24 ・ 2 min read#webdev#codenewbie#beginners#life“By not including alt text, we risk depriving our screen reader users of important information and added context that images provide to our sighted users.” - @baspin94An Alt-Text PrimerBianca Aspin ・ Mar 30 ・ 6 min read#beginners#html#a11y#codenewbieWe/I over at CodeNewbie hope you are having a great week so far. ALSO, let us know below what you are learning this week! 💜"
900,"When starting a new project, dealing with legacy code can be a daunting task. Patience is a virtue; if you can, take your time to understand the code and document it well. Don't rush the process, as this can lead to mistakes and introduce new problems into the codebase. But what if you're on a tight schedule. How do you handle it? What strategies have you found to be most effective?Share your experiences and insights on legacy code management with the Newbie community. Let's learn together!"
901,"The debate between open-source and proprietary software has been ongoing for years. Open-source advocates maintain that it promotes collaboration, transparency, and innovation, while proprietary software proponents argue that it provides better security, control, and support.What do you think? Do you prefer open-source or proprietary software, and why? Share your thoughts in the comments below!"
902,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
903,"I just got access to GitHub Copilot CLI and a few seconds after installing it, I am happy as a clam about it. You can see it in action in this video or let me talk you through it here. GitHub Copilot CLI brings AI code completion to your terminal. After installing it, you get three new commands:??: Translate natural language to arbitrary shell commandsgit?: Translate natural language to Git commandsgh?: Translate natural language to GitHub CLI commandsI love using the Terminal, as it gives you a lot of power and it is a lot faster than other tools like Finder or Explorer. The issue is though that it is not easy to remember the sometimes cryptic syntax of bash commands and attributes of command line tools. This is where Copilot CLI helps. Say you want to convert all the videos in the current folder to mp4 and resize them to 640 pixels width, keeping the aspect ratio. All you need to do is write ?? convert all videos in the folder to mp4 and resize them to 640px hit enter. You get a suggestion of code that will do that task and a detailed, human readable explanation what the code does.You can choose to run the command immediately, revise your input in case something feels off or cancel and go back to the terminal.Another prompt I tried was ?? find all files bigger than 500mb and copy them to a folder called huge and the result was immediate.I like that it doesn't only give you the result, but also explains what the code does. This often is missing from answers on StackOverflow and other forums. It will be interesting to see where this goes. The Terminal is a mighty tool and you can do a lot of damage if you are not aware of the consequences of your commands. It would be interesting to see Copilot also give you some safety instructions with every command it offers."
904,What are your goals for this week?What are you building? What will be a good result by week's end?Are you attending any events this week?Did you meet your goals last week?I'll start with how I did last week.Last Week's Goals[✅] Continue Job Search.[❌] Blog.Things I accomplished but did put on goals list.[✅]Began portfolio refactor. Based on the template created by @ram Maheshwari Ram Maheshwari. Almost done waiting for some feedback on it.[✅]Attended Virtual Coffee's Lightning Talks. Read about that in this post I just wrote. So I already blogged this week.[✅] Restarted TIL Log[✅] Updated content to a site I manage.This Week's GoalsContinue Job Search.Blog. Got a few ideas I need to start.Short school week for Easter.Finish portfolio refactor.You've read my goals so I'll throw that question back to you.What are your goals for the week?-$JarvisScript git pushEnter fullscreen modeExit fullscreen mode
905,"Ok, you all most likely heard it. Twitter went open-source. That's amazing. Curious as I am, I wanted to dive into their repository.When looking into their issues list, I was laughing out loud. Check this:GitHub users are making fun on the whole release, and turn the issues list into a jokes section.As an engineer on the dev team of Twitter, however, I would be really annoyed. Differentiating between issues of trolls and non-trolls is now a new todo on their list. So let's try to help them. I'm going to show a first, very simple version of a classifier for identifying troll-issues in the Twitter repo. Of course, I'm sharing the work on GitHub as well. Here's the repo.  Getting the dataI've scraped the issues with a simple Python script, which I also shared in the repo:import requestsimport jsonPAT = ""add-your-PAT-here"" # see https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-tokenowner = ""twitter"" repo = ""the-algorithm"" url = f""https://api.github.com/repos/{owner}/{repo}/issues""headers = {""Authorization"": f""Bearer {PAT}""}all_issues = []while url:    response = requests.get(url, headers=headers)    if response.status_code == 200:        issues = response.json()        all_issues.extend(issues)        if ""next"" in response.links:            url = response.links[""next""][""url""]        else:            url = None    else:        print(f""Failed to retrieve issues (status code {response.status_code}): {response.text}"")        breakissues_reduced = []for issue in all_issues:    issue_reduced = {        ""title"": issue[""title""],        ""body"": issue[""body""],        ""html_url"": issue[""html_url""],        ""reactions_laugh"": issue[""reactions""][""laugh""],        ""reactions_hooray"": issue[""reactions""][""hooray""],        ""reactions_confused"": issue[""reactions""][""confused""],        ""reactions_heart"": issue[""reactions""][""heart""],        ""reactions_rocket"": issue[""reactions""][""rocket""],        ""reactions_eyes"": issue[""reactions""][""eyes""],    }    issues_reduced.append(issue_reduced)with open(""twitter-issues.json"", ""w"") as f:    json.dump(issues_reduced, f)print(f""Retrieved {len(all_issues)} issues and saved to twitter-issues.json"")Enter fullscreen modeExit fullscreen modeOf course, these days, I didn't write the code for this myself. ChatGPT did that, but you all already know that.I decided to reduce the downloaded data a bit, because much of the content didn't seem to be relevant to me. Instead, I wanted to just have the URL to the issue, the title and body, and some potentially interesting metadata in form of the reactions.An example of this looks as follows:  {    ""title"": ""adding Documentation"",    ""body"": null,    ""html_url"": ""https://github.com/twitter/the-algorithm/pull/838"",    ""reactions_laugh"": 0,    ""reactions_hooray"": 0,    ""reactions_confused"": 0,    ""reactions_heart"": 0,    ""reactions_rocket"": 0,    ""reactions_eyes"": 0  },Enter fullscreen modeExit fullscreen mode  Building the classifierWith the data downloaded, I started refinery on my local machine. With refinery, I'm able to label a little bit of data and build some heuristics to quickly test if my idea works. It's open-sourced under Apache 2.0, you can just grab it and try along.Simply upload the twitter-issues.json file we just created:For the title and body attributes, I added two distilbert-base-uncased embeddings directly from Hugging Face.After that, I set up three labeling tasks, of which for now only the Seriousness task is relevant.Diving into the data, I labeled a few examples to see how the data looks like and to get some reference labels for my automations I want to build.I realized that quite often, people are searching for jobs in issues. So i started building my first heuristic for this, in which I use a lookup list that I created to search for appearances of job-terms. I'm going to later combine this via weak supervision with other heuristics to power my classifier.For reference, this is how the lookup lists looks like. Terms are automatically added while labeling spans (which is also why i had three labeling tasks, one for classification and two for span labeling), but I could also have uploaded a CSV file of terms.As I also already labeled a bit of data, I created a few active learners:With weak supervision, I can easily combine this active learner with my previous job search classifier without having to worry about conflicts, overlaps and the likes.Also I noted a couple of issues with just a link to play chess online:So i added a heuristic for detecting links via spaCy.Of course, I also wanted to create a GPT-based classifier, since this is publicly available data. However, GPT seems to be down while I'm initially building this :(After circa 20 minutes of labeling and working with the data, this is how my heuristics tab looked likeSo there are mainly active learners, some lookup lists and regular-expression like heuristics. I will add GPT in the comments section as soon as I can access it again :)Now, I weakly supervised the results:You can see that the automation already nicely fits the distribution of trolls vs. non-trolls.I also noticed a strong difference in confidence:So I headed over to the data browser and configured the confidence so I only see the records with above 80% confidence.Notice that in here, we could also filter by single heuristic hits, e.g. to find records where different heuristics vote different labels:In the dashboard, I now filter for the high confidence records and see that our classifier is performing quite good already (note, this isn't even using GPT yet!):  Next stepsI exported the project snapshot and labeled examples into the public repository (twitter_default_all.json.zip), so you can play with the bit of labeled data yourself. I'll continue on this topic the next days, and we'll add a YouTube video for this article for a version 2 of the classifier. There certainly are further attributes, we can look into, such as taking the length of the body into account (I already saw that shorter bodys typically are troll-like).Also, keep in mind that this is an excellent way to benchmark how power GPT can add for your use case. Simply add it as a heuristic, try a few different prompts, and play with excluding or adding it from your heuristics in the weak supervision procedure. For instance, here, I excluded GPT:I'm really thrilled about Twitter going open-source with their algorithm, and I'm sure it will add a lot of benefits. What you can already tell is due to the nature of Twitter's community, issues are often written by trolls. So finding detecting such will be important for the dev team of Twitter. Maybe this post here can be of help for that :)"
906,"Today’s quote by Filipe Fortes perfectly captures the complexity and frustration of sussing out the bugs in your code and figuring our how to solve them by tracking down the root cause. It can be a difficult and time-consuming task with many twists and turns, but the feeling of satisfaction you get when you finally solve the problem is worth it. Debugging is like being the detective in a crime movie where you are also the murderer. Share your debugging stories and tips with us! How do you approach debugging, and what strategies have you found to be effective? Let's help each other become better detectives and murderers (of our own code, of course)."
907,"I know we shouldn't feel defensive. But we do, don't we?"
908,"It’s a somewhat of a tradition in the tech industry to use April Fools’ Day as an opportunity to showcase our unique sense of humor and creativity 🥸 Many companies have a history of playing elaborate pranks on their users and customers with fake product announcements, humorous updates to existing products, new features, and temporary changes to brand assets. Some of the jokes are funny, some are clever, some are…oof. So tell us: do you have any successful (or failed) stories to share about past April Fools’ mischief that you’ve participated in, witnessed, or been on the receiving end of? Tell us about it. Thank you for your cooperation and we look forward to seeing your Pig Latin code in action!"
909,"Atomic: of or forming a single irreducible unit or component in a larger system.Also available on my blog.  Knowing VS Actually KnowingI remember when my first mentor told me about Test-Driven Development. A great methodological approach to software engineering. It took me just a few minutes to understand what it was and how it worked.Then I spent the next six months actively not practicing it. TDD is hard when you start, so you just... don't.Half a year later, I was hitting my head against a wall trying to build a new feature. I forced myself for the first time to actually do TDD by the book. The wall that was blocking my progress disappeared instantly.In a previous article, I explained how many managers and tech leads often know exactly how to make our industry better... yet don't. There is always a good reason to not do things right. And somehow we still end up surprised when we're doing things wrong.This long introduction is here to illustrate a point: you can know what you should do, but you might not know how important it is to actually do it. So many people out there, just like I did before, know how TDD is great... yet still don't use it.The simplest concepts can often completely change the way you work... if you would only apply them. Introducing: the atomic git commits.  What's an atomic git commit?Working with atomic git commits means your commits are of the smallest possible size. Each commit does one, and only one simple thing, that can be summed up in a simple sentence.The amount of code change doesn't matter. It can be a letter or it can be a hundred thousand lines, but you should be able to describe the change with one simple short sentence.Ideally, you also want your test suite to be in the green when you commit. Your changes might be ""atomic"", i.e the smallest possible, but they should also be ""complete"", which means your test suite always follow through.As small as possible, but complete: this is an atomic git commit.  Why should you write atomic git commits?There are a few great advantages to practicing atomic git commits, and we'll briefly detail them. But the last one really is the most important. It might completely change the way you approach your work, increase your productivity by an order of magnitude, and make your job much more enjoyable.  Reason number 1: An atomic change is a reversible changeWe all know this simple truth about software: the requirements are always changing. By writing atomic git commits, we allow ourselves to revert any changes by a simple commit revert. This already increases your productivity tremendously.  Reason number 2: A clean git historyWhen shit hit the fan, a clean git history means the difference between pain and salvation. It's like insuring your house: seems useless, until there's a fire.  Reason number 3: Pull requests are much easier to reviewYour team will absolutely love you for this.  Reason number 4: A much, much better workflowThis is by far the most important reason to practice atomic git commits: it completely alters the way you approach problem-solving.If you're like me, you might have a tendency while developing a feature, to just... do it. Entirely.Then you realize how you did not think everything through.You need to change more that you expected. Some edge cases aren't taken into account. You broke some unrelated tests, they need fixing. Soon, you end up in a maze of your own making. You're lost. Your head hurts. You can't make any progress without being entirely focused. Now, this is the wrong way to do things. And worse, you already know the right way, because it's so obvious.The well-known method to complete a big, complex task: cut it down into smaller, manageable, tiny steps. Each step -its own simple problem to solve. This is obvious advice that you probably already heard many times... But are you actually practicing it in your daily job?Well, here's a great way to actually practice it: write atomic git commits.By forcefully working in atomic commits, you're approaching the work the right way, by simplifying it into smaller steps. After all, simplifying complexity is the very core of our job. So why aren't we always consciously doing it?Of course this advice might sound obvious. But if my past experience proves anything, it's that the obvious really bears repeating, and even more importantly, it bears practicing.Make your work simpler, better, more manageable, and most importantly: make it easier. Take small steps. Write small commits. Atomic commits. You will love them."
910,"This requires a recommendation algorithm to distill the roughly 500 million Tweets posted daily down to a handful of top Tweets that ultimately show up on your device’s For You timeline.The pipeline above runs approximately 5 billion times per day and completes in under 1.5 seconds on average. A single pipeline execution requires 220 seconds of CPU time, nearly 150x the latency you perceive on the app.Along side with OpenAI, I personally think this is one of an important moment in the computing community as no one would ever guess a global-scale algorithm such as Twitter's Recommendation becomes open-sourced. Based on their engineer blog post, it is not out of reach to say the code base literally costs hundred thousands if not millions a day to run. How do you feel about this moment?Twitter's engineer blog          Twitter's Recommendation Algorithm                  Twitter Apache Thrift is an open-source, standalone, lightweight, data encoding library. In this blog post, we share the library we built so iOS developers outside Twitter can start using Thrift data.                blog.twitter.com      GitHub repository        twitter       /         the-algorithm            Source code for Twitter's Recommendation Algorithm    Twitter Recommendation AlgorithmThe Twitter Recommendation Algorithm is a set of services and jobs that are responsible for constructing and serving theHome Timeline. For an introduction to how the algorithm works, please refer to our engineering blog. Thediagram below illustrates how major services and jobs interconnect.These are the main components of the Recommendation Algorithm included in this repository:TypeComponentDescriptionFeatureSimClustersCommunity detection and sparse embeddings into those communities.TwHINDense knowledge graph embeddings for Users and Tweets.trust-and-safety-modelsModels for detecting NSFW or abusive content.real-graphModel to predict likelihood of a Twitter User interacting with another User.tweepcredPage-Rank algorithm for calculating Twitter User reputation.recos-injectorStreaming event processor for building input streams for GraphJet based services.graph-feature-serviceServes graph features for a directed pair of Users (e.g. how many of User A's following liked Tweets from User B).Candidate Sourcesearch-index…View on GitHub"
911,I'm sure there are plenty out there.
912,"How does the old Winston Churchill quote go?Those who fail to learn from history are doomed to repeat itAlthough a more ironic addendum might add.Those who study history are doomed to stand by while everyone else repeats it.In the past few weeks, we've seen the culmination of a build of excitement around the revival of fine-grained reactivity, being referred to as Signals, across the front-end world.For a history of Signals in JavaScript check out my article:The Evolution of Signals in JavaScriptRyan Carniato for This is Learning ・ Feb 27 ・ 7 min read#webdev#javascript#reactivity#signalsThe truth is Signals never went away. They lived several years in obscurity as third-party libraries or hidden behind frameworks' plain object APIs. Even though the common rhetoric that came in with React and the Virtual DOM condemned the patterns as unpredictable and dangerous. And they weren't wrong.        Devon Govett              @devongovett            Easy to forget, but the debate about signals is the same one we had about 2-way data binding vs unidirectional data flow 10 years ago. Signals are mutable state! They’re bindings with a new name. The simplicity of UI as a function of state is lost when updates flow unpredictably.          17:54 PM - 25 Feb 2023    But there is more to it than a 10 year old debate. So I want to talk about how things have changed over the years and offer SolidJS as a foil.  ""Fixing"" Front-end        дэн      @dan_abramov@thdxr there’s an assumption that people with React brain are unfamiliar with other approaches. that’s probably true for some. but i also invite to consider that some of us have been through this before and even *started* our careers with setup/render split. to us, React was the “fix”.          19:49 PM - 26 Feb 2023    At the core of this conversation is understanding what React is. React is not its Virtual DOM. React is not JSX. To this date one of my explanations on the subject came from one of Dan Abramov's earliest articles You're Missing the Point of React, where he state React's true strengths are:composition, unidirectional data flow, freedom from DSLs, explicit mutation, and static mental model.React has a very powerful set of principles that guide it that are more important than any implementation detail. And even years later there is this notion from the thought leaders around React that they fixed front-end.But hypothetically, what if they didn't? What if there were other ways to address the problems of the day that didn't involve such drastic re-alignment?  A Solid AlternativeThe concept behind Solid is equally simple. It even shares ideas like composition, unidirectional data flow, and explicit mutation that made React feel like a simple answer to UI development. Where it differs is outside the world of reactivity everything is an Effect. It's almost the antithesis of React which treats everything you do as being pure (as in having no side effects).When I think of creating a Counter button with Signals without any templating I'd do this:function MyCounter() {  const [count, setCount] = createSignal();  const myButton = document.createElement(""button"");  myButton.onclick = () => setCount(count() + 1);  // update the text initially and whenever count changes  createEffect(() => {    myButton.textContent = count();  });  return myButton;}Enter fullscreen modeExit fullscreen modeI'd call my function and get a button back. If I need another button I'd do it again. This is very much set and forget. I created a DOM element and set up some event listeners. Like the DOM itself, I don't need to call anything for my button to update. It is independent. If I want a more ergonomic way of writing I use JSX.function MyCounter() {  const [count, setCount] = createSignal();  return <button onClick={() => setCount(count() + 1)}>    {count()}  </button>}Enter fullscreen modeExit fullscreen modeSignals are not the same Signals as yesteryear. Their execution is glitch-free. They are push/pull hybrids that can model scheduled workflows like Suspense or Concurrent Rendering. And mitigate the leaky observer pattern with automated disposal. They have been leading benchmarks for several years not only for updates but for creation.   ImmutabilitySo far so good? Well maybe not:        дэн      @dan_abramov@thdxr it’s one of those “does it scale” things. i am finding it difficult to believe that the approach where (a) it’s easy to add init-only rendering logic and (b) making it reactive requires refactorings, composes just as well. it’s what we had *before* React and what React solved.          19:34 PM - 26 Feb 2023    Apparently, this is something React solves. What did they solve exactly?Putting Dan's specific concerns aside for a moment, it comes down to immutability. But not in the most direct way. Signals themselves are immutable. You can't modify their content and expect them to react.const [list, setList] = createSignal([]);createEffect(() => console.log(JSON.stringify(list())));list().push(""Doesn't trigger"");setList(() => [...list(), ""Does trigger""]);Enter fullscreen modeExit fullscreen modeEven with variants from Vue, Preact, or Qwik that use .value you are replacing the value not mutating it by assignment. So what does it mean that Signals are ""mutable state""?The benefit of having a granular event-driven architecture is to do isolated updates. In other words, mutate. In contrast, React's pure render model abstracts away the underlying mutable world re-creating its virtual representation with each run.How important is this distinction when looking at two declarative libraries that drive updates off state if the data interfaces are explicit, side effects managed, and the execution well-defined?  Unidirectional FlowI am not a fan of 2-way binding. Unidirectional Flow is a really good thing. I lived through the same things that are referenced in these tweets. You may have noticed Solid employs read/write segregation in its primitives. This is even true of its nested reactive proxies.If you create a reactive primitive you get a read-only interface and a write interface. The opinion on this is so ingrained into Solid's design that members of the community like to troll me, abusing getters and setters to fake mutability.        Alexis Munsayac 🇵🇭      @lxsmnsyc      A secret @solid_js trick to allow writeable propsplayground.solidjs.com/?hash=-1684153…      02:09 AM - 25 May 2022    One of the important things I wanted to do with Solid's design was to keep the locality of thinking. All the work in Solid is done where the effects are which is where we insert into the DOM. It doesn't matter if the parent uses a Signal or not. You author to your need. Treat every prop as reactive if you need it to be and access it where you need it. There is no global thinking necessary. No concerns with refactorability.We re-enforce this by recommending when writing props you access the Signal's value rather than pass it down. Have your components expect values rather than Signals. Solid preserves reactivity by wrapping these in getters if it could be reactive.<Greeting name={name()} />// becomesGreeting({ get name() {  return name() })<Greeting name={""John""} />// becomesGreeting({ name: ""John"" })Enter fullscreen modeExit fullscreen modeHow does it know? A simple heuristic. If the expression contains a function call or property access, it wraps it. Reactive values in JavaScript have to be function calls so that we can track the reads. So any function call or property access, which could be a getter or proxy, could be reactive so we wrap it. The positive is that for Greeting regardless of how you are consumed you access the property the same way: props.name. There is no isSignal check or overwrapping unnecessarily to make things into Signals. props.name is always a string. And being a value there is no expectation of mutation. Props are read-only and data flows one way.  Opt-In vs Opt-Out        дэн      @dan_abramov      which way, framework author           01:47 AM - 26 Feb 2023    This might be the crux of the discussion. There are a lot of ways to approach this. Most libraries have chosen reactivity for Developer Experience reasons because automatic dependency tracking means not needing to worry about missing updates.It isn't hard to imagine for a React developer. Picture Hooks without the dependency arrays. The existence of the dependency arrays in Hooks suggests React can miss updates. Similarly, you opt into client components (use client) when using React Server Components. There are other solutions that have been automating this via compilation for years, but at times there is something to be said about being explicit.It isn't generally a singular decision. You have things you opt into and things you opt out of in any framework. In reality, all frameworks are probably more like this:        Michael Rawlings      @mlrawlingstwitter.com/dan_abramov/st…      20:59 PM - 27 Feb 2023                дэн          @dan_abramov        which way, framework author https://t.co/ZWFlX1XaRI      A frameworks ideals can be beyond reproach but the reality is not so clear cut.This brings me to this example:         Devon Govett              @devongovett            With signals, you have to think about how each individual value is propagated. For example, in Solid, these components do different things! Thinking about whether each individual prop can change or not requires global reasoning rather than local.           18:15 PM - 25 Feb 2023    These are 2 very different functions from Solid's perspective, because of Solid's JSX handling and the fact they only run once. This is not ambiguous and easily avoided once you are aware. And there is even a lint rule for that.It's like expecting these to be the same:const value = Date.now();function getTime1() {  return value;}function getTime2() {  return Date.now();}Enter fullscreen modeExit fullscreen modeMoving the expression doesn't change what Date.now() does but hoisting changes the function's behavior.Maybe it is less than ideal, but it isn't like this mental model isn't without its own benefits:        ThePrimeagen      @theprimeagen@acdlite its funny, the first time i ever used signals wasn't for perf, it was for understanding where change happens easier.  plus you get LSP references to change.just seems.... most rational          20:47 PM - 24 Feb 2023      Can this be ""Fixed"" for real?That's the logical follow-up. This is very much a language problem. What does fixed even look like? The challenge with compilers is that it is harder to account for edge cases and understand what happens when things go wrong. It is largely the reason historically React or Solid has been pretty careful about keeping clear boundaries.Since the first introduction of Solid we've had people exploring different compilation because Signals as primitives are very adaptable and very performant.In 2021, I took a stab at it.The Quest for ReactiveScriptRyan Carniato for This is Learning ・ Nov 23 '21 ・ 11 min read#javascript#webdev#reactivityReact team also announced they were looking at this too.There are rules being imposed on both systems. React wants you to remember not to do impure things in your function bodies. That is because if you do you can observe abstraction leaks if they were ever to optimize what is under the hood. Including potentially not re-running parts of your component.Solid is already optimized without the need for the compiler or extra wrappers like React.memo, useCallback, useRef, but like React could benefit from some more streamlined ergonomics like not having to worry about indicating where Signals are read.The end result is almost the same.  Final ThoughtsThe oddest part of all of this is that the React team when looking at Reactivity doesn't feel like they are looking in the mirror. By adding Hooks they sacrificed part of their re-render purity for a model approaching that of Signals. And that by adding a compiler to remove the hooks concerned with memoization they complete that story.Now it should be understood these were developed independently. Or atleast no acknowledgement was ever given which is not surprising given the sentiment of the old guard:        Pete Hunt 🚁              @floydophone      @acdlite I think you guys should be way more aggressive in pushing back against this stuff. Throwing out the react programming model and adopting something like signals (or worse, signals plus a dsl) is a huge step backwards and most people haven’t internalized that          06:43 AM - 24 Feb 2023    Fortunately React today is not the React of 10 years ago either.React changed the front-end world by teaching us the important principles that should guide how to build UIs. They did so by strength of conviction being a unique voice of reason in a sea of chaos. We are where we are today due to their great work and countless have learned from their lessons.        Andrew Clark              @acdlite      @youyuxi @trueadm When @Huxpro introduced Forget at React Conf we focused on the auto-memoizing part, but the plan all along has involved compiling to a lower level reactive runtime. We like the perf characteristics of signals. We don't like the code you have to write to get it.          01:30 AM - 24 Feb 2023    Times have changed. It is almost fitting that the paradigm that was ""fixed"" away would resurface. It closes the loop. Completes the story. And when all the noise and tribalism fade what remains is a tale of healthy competition driving the web forward.It is arguably never polite to construct a narrative by sewing together quotes out of context. Time moves on, and perspectives change. But this is a long and strongly held sentiment from React's thought leadership. One they've been vocal about since the beginning. I was able to grab all these quotes over conversations from just the last couple of days with very little effort.For more on React's early history watch:"
913,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   Circular Text With CSSIf you wanted to form your text into a circle, how would you do it? Each method comes with its own hurdles, so @jh3y will run you through each one so that you can shape your text with ease. Circular Text with CSS?Jhey Tompkins ・ Mar 23#webdev#tutorial#css#javascript  LLMs Will Fundamentally Change Software EngineeringLarge Language Models like ChatGPT4, Bing, GPT3 are super popular now and for good reason. @wesen talks through how LLMs can be a paradigm shift for the pragmatic programmer and how we might be at the ground zero of a revolution in how developers write code.LLMs will fundamentally change software engineeringManuel Odendahl ・ Mar 23#programming#ai#productivity  Using TypeScript Without CompilationOver the past couple of days, an article about the latest major version of Svelte blew up on Twitter and caused lots of discussion. @thepassle explains how Svelte will be switching their underlying code from TypeScript to JavaScript and what that means about type checking. Using Typescript without compilationPascal Schilp ・ Mar 26#typescript#jsdoc  The Easy Approach to Learning Object-Oriented Programming in JavaScriptThe core idea in object-oriented programming is to divide a program into smaller pieces and make each piece responsible for managing its own data. In this article, @efkumah provides a comprehensive, but easy-to-understand approach to learning OOP. The easy approach to learning Object-Oriented Programming in JavaScriptEmmanuel Fordjour  Kumah ・ Mar 21#javascript#oop#webdev#beginners  From Problems to Solutions: Understanding Design PatternsDesign patterns are a systematic approach for addressing recurring problems that programmers face. Here, @earthcomfy walks us through the basics of 6 common patterns so we'll be better prepared to solve whatever problems come our way. From Problems to Solutions: Understanding Design PatternsHana Belay for Documatic ・ Mar 26#programming#beginners#tutorial#designpatterns  What is Strict Mode in React?In this article, @codeofrelevancy dives into the details of what strict mode is, how it works, and why you should consider using it in your applications.What is Strict Mode in React?Code of Relevancy ・ Mar 24#react#javascript#nextjs#beginners  100 Crucial Keyboard Shortcuts for VS Code UsersIn the world of software development, time is a precious commodity. With deadlines looming and projects piling up, anything that can save time and improve productivity is crucial. That’s why @devland goes over 100 of the most useful VSCode shortcuts that will help any user become more efficient and productive.100 Crucial Keyboard Shortcuts for VS Code Users.Thomas Sentre ・ Mar 22#programming#webdev#vscode#productivityThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
914,"Well, we were a nostalgic bunch this month! Top CodeNewbie Daily Discussion posts in March included reminiscing about our first jobs in tech, considering what might have been with alternate career paths, and thinking back to what we wish we’d known when we were just starting out. It’s not too late to join these discussions:What Was Your First Job in the Tech Industry?Ben Halpern for CodeNewbie ・ Mar 23#beginners#codenewbie#discussAlternate Career Paths: If You Weren’t A Coder or Developer, What Would You Be Instead?Ben Halpern for CodeNewbie ・ Mar 15#discuss#beginners#codenewbieWhat Do You Wish You’d Known When You First Started Programming?Ben Halpern for CodeNewbie ・ Mar 3#discuss#beginners#codenewbieWhether we're looking back on the evolution of technology, imagining what might have been, or simply reminiscing about the good old days, there's value — and comfort — in feeling nostalgic. Nostalgia can be a powerful motivator, reminding us of our roots, our passions, and our dreams. It can also help us stay connected to our colleagues and the broader tech community as we share stories and memories of the early days. But it's important to remember that the future is still unwritten, and that it's up to us to shape it in the best way we can. And on that note, let’s welcome April and a whole new month of CodeNewbie Daily Discussions. We hope you’ll weigh in and stay connected to our community. Thanks for being here.❣️"
915,"I have been trying to write my resume recently. I have been in IT (working in service based currently) for 5 years now and I am planning to switch to something new. Through out my 5 years I have worked as Service Support analyst, Developer and as DBA but now I kinda of conflicted on what should I try for next. How do I figure out what I am good at ?Every time I watch people on linkedin and think about it I feel like I haven't had expertise in anything throughout these 5 years, I have always adapted to the role which was presented to me. But now that I have to present what I have done so far and what I need to aim for next I feel very hesitant, confused, conflicted. Would appreciate any advice."
916,The social media platforms that are most used by people in the tech industry vary depending on their specific interests and needs (obvs). But some of the most popular social media platforms — and the ones that provide the most resources and networking opportunities to tech professionals right now — seem to be:LinkedInTwitterRedditGitHubYouTubeMastodon? What else? Tell us which platforms do you rely on the most to stay informed in your industry and which are down for the count.
917,"I was just about to write a blog post on my current experiences in trying to find a new job. I wanted to write about the frustrations and how it feels ridiculous that developers and recruiters aren't best friends. And then I remembered that Microsoft Edge now comes with a HUGE Bing icon that promised ChatGPT functionality right in the browser.So I pressed the b, went to the Compose tab, entered Developers and Recruiters should be friends, selected professional, blog post and medium length and this is what came out of it:  Developers and Recruiters should be friendsIf you are a developer, you might have a love-hate relationship with recruiters. On one hand, they can help you find your dream job and negotiate a good salary. On the other hand, they can spam you with irrelevant offers and pressure you to accept a position that is not a good fit for you.But what if I told you that developers and recruiters can actually be friends? That they can work together to achieve their mutual goals and benefit from each other's expertise and network? That they can respect each other's time and preferences and communicate effectively?In this blog post, I will share some tips on how developers and recruiters can build a friendly and productive relationship that will help both parties succeed in their careers.  Tip #1: Be honest and transparentOne of the most important aspects of any relationship is honesty and transparency. Developers and recruiters should be honest and transparent about their expectations, skills, availability, interests, and feedback. This will help avoid misunderstandings, frustration, and wasted time.For example, if you are a developer, you should be honest and transparent about:Your current employment status and notice periodYour salary expectations and benefits requirementsYour preferred location, work environment, and company cultureYour technical skills, experience level, and portfolioYour career goals and learning objectivesYour feedback on the job opportunities and interviewsSimilarly, if you are a recruiter, you should be honest and transparent about:The details of the job opportunity and the hiring processThe salary range and benefits packageThe company's mission, vision, values, and cultureThe expectations and responsibilities of the roleThe feedback from the hiring manager and the next steps  Tip #2: Be respectful and professionalAnother key aspect of any relationship is respect and professionalism. Developers and recruiters should treat each other with respect and professionalism at all times. This means being courteous, polite, responsive, punctual, and constructive.For example, if you are a developer, you should:Respond to the recruiter's messages in a timely mannerInform the recruiter if you are no longer interested in the job opportunity or if you have accepted another offerShow up for the interviews on time and preparedThank the recruiter for their time and effortProvide constructive feedback on the job opportunity and the hiring processSimilarly, if you are a recruiter, you should:Respect the developer's time and availabilityTailor your messages to the developer's profile and preferencesProvide clear and accurate information on the job opportunity and the hiring processFollow up with the developer after each interview stageProvide constructive feedback on the developer's performance and potential  Tip #3: Be helpful and supportiveThe final aspect of any relationship is helpfulness and supportiveness. Developers and recruiters should help and support each other in achieving their goals. This means sharing useful resources, advice, tips, referrals, recommendations, and encouragement.For example, if you are a developer, you can:Ask the recruiter for tips on how to prepare for the interviewsShare your portfolio or GitHub profile with the recruiterRefer other developers who might be interested in the job opportunityRecommend the recruiter to your network or leave a positive review on their profileCongratulate the recruiter if you get hired or wish them good luck if you don'tSimilarly, if you are a recruiter, you can:Provide the developer with relevant information on the company and the roleShare your insights on the market trends and salary expectationsIntroduce the developer to other hiring managers or recruiters who might have suitable opportunitiesRecommend the developer to your network or leave a positive review on their profileCongratulate the developer if they get hired or wish them good luck if they don't  ConclusionDevelopers and recruiters should be friends. They should be honest and transparent, respectful and professional, helpful and supportive. By following these tips, developers and recruiters can build a friendly and productive relationship that will benefit both parties in their careers.Isn't this bonkers? It is well written, it gives really good advice, it even feels like it is written by someone with lots of experience and empathy for both sides of the argument. And it is well structured in headings and lists to be accessible (albeit probably not here as I put a blockquote around it) and SEO optimised. Sure, there is some repetition that betrays its origin, but with a bit of editing, you could have an article that looks good, feels great and is generic enough not to annoy anyone.And that is the issue, isn't it? When I started blogging in 2005, my blog was a scratchpad. I learned something, and I wanted to write it down so that I don't forget it. It was messy, it was at times plain wrong (but at the time OK) and I didn't give a damn about its SEO. I always made sure I do the most I can to be accessible, but all my Google juice came by accident and word of mouth.What does that mean for people who want to start writing and having their place on the web now? Personally, I think if you try to optimise for search engines or social share-ability you're in for a lot of frustration. Or you can do what I did and let the machine do the work. Black hat SEO (and those with a dirty grey hat) have been content farming for years and generating nonsense articles full of links and keywords. Some of that was automated, but now the floodgates are open and anyone could create a clever sounding blog or even online magazine with a few clicks.Instead, I think this is a great time to be, well, human. To write what you want to. To admit to your errors. To show what excites you and why and not write a ""7 ways to use XYZ to boost your ABC"". I've been around this for a long time, and the people I do remember, still follow and keep telling others about are those who allow themselves to be a person, and not a ""content creator"".Shine on, you fabulous whateverthehellyouare !"
918,"  IntroductionYour small healthy food-producing company is doing really well this season. Having an established line of customers throughout the year is driving the business stable and products are delivered to them without any delays. Your route for every customer is planned in advance, depending on the number of workers with pick-up cars who deliver the food. However, the summer season is approaching, and soon a lot of temporary seasonal customers are going to be ad hoc ordering healthy meals from your company. Suddenly the logistics are hectic and the routes are impossible to plan since the orders are coming in dynamically and stochastically. New suboptimal routes together with fuel costs are cutting the company's growth process and revenue, and you need to come up with a solution about how to organize your pick-up vehicles better. Luckily, this kind of problem is well known in optimization theory and it's called Vehicle Routing Problem. In this article, you'll learn more about the variations of the problem, how to model synthetic data to prepare for real-world scenarios, and of course, possible approaches for the solution.  Defining the problemWe can think of VRP as a generalization of TSP (Traveling Salesperson Problem), with additional entities, i.e. vehicles in this case. In the classic TSP, the salesperson must visit all the customers once and return to the starting position with a minimized route cost, while in VRP a fleet of vehicles is used in order to do the same. They usually start from the same spot which can represent a depot of production. The problem itself is NP-hard and therefore advises heuristics, approximation algorithms, or numerical optimization in order to reach a feasible solution. VRP has many variations of its problem and the main distinctions come with respect to the known information at the beginning. The basic one is called static VRP and this means that all the information about the locations of the customers, and their requests are known in advance. The advantage of getting to know all the information ultimately yields better results with shorter vehicle lengths passed, however, it doesn’t truly depict a real-world scenario. The more representative use case would be the Dynamic Vehicle Routing Problem (DVRP) which is featured by having at least one of its parameters time-dependent. Most commonly, that would be the arrival time of the request itself, making it unknown to the user when a certain immediate customer demand would need to be served. The end result would then be a feasible adaptation of the initially constructed routes.VRP can be modeled in additional ways in order to make it look more realistic. Most certainly one would want to work with time windows, and the problem would then be known as Dynamic Vehicle Routing Problem with Time Windows (DVRPTW). The time windows themselves symbolize the opening and closing hours of the service that ordered the product from the distribution company. If we define the reaction time as the time needed in the final solution from request arrival to service delivery finish, the solution goal would be minimizing reaction time with respect to service opening hours, as well as the initial one of minimizing the route length. Additional penalties can be introduced if service hours are not met.   Modeling the dataOne of the important things to verify the VRP solution is applying it to concrete data. Although there are a lot of open datasets online, the number of requests or degree of dynamism can strongly differ. The DIY approach would include distributing the arrival of immediate requests by the Poisson process since it is particularly used for modeling the rate that something occurs in a random manner. Location of the customers don’t actually have a particular distribution they are subordinate to, therefore a uniform distribution would suffice. The same goes for service opening and closing hours as well.  Modeling the problemUntil now we have just been adding features to our routing problem, it’s time to model the state itself to ensure the validity of every step throughout routing and re-routing the vehicles. The state with 2 modules, one representing the vehicle's information at a certain point in time, and the other representing a request pool that would serve as a routing module.  Vehicle state moduleTo precisely gain information about every vehicle in real-time, one would need several parameters for doing so. One of them would definitely be the location of the vehicle on the map, e.g. latitude and longitude or some other one in a different coordinate system. If the vehicle is having a finite amount of products in its trunk, one might add a capacity that might decrease with every request served, after which the vehicle needs to turn back to its depot for replenishing. That doesn’t need to be the case if, for example, the vehicle represents repairmen helping customers in need. The final parameter for modeling a basic vehicle state would be the current action the vehicle is performing – idle, driving (to a specific customer or going back to depot), and serving the customer.  Routing moduleThe routing module consists of a pool of incoming requests. In the beginning, there are only requests known in advance in the pool, which is being increased with immediate requests as time goes by and decreases with requests served over time.   Events and reroutingFrom the 2 modules, we can distinguish 2 types of events – a vehicle state change event, occurring if a particular vehicle changed its state, and request event, occurring when a new request appeared. The vehicle state change event would occur for example if the vehicle changed its coordinates, changed the action it is currently doing, or changed its capacity in the trunk. It does not require rerouting, however, that is triggered by a request event. Since a customer would need to be informed as fast as possible what would be a possible time for delivery, the route would need to be adapted in the most feasible way. Another thing to take into consideration is some hard constraints that need to be satisfied throughout the delivery. All the served requests in the solution have to stay in place, as going back in time is not “yet” possible. As for service opening hours, one can have soft or hard demands about meeting them, and sometimes the evaluation of the solution is modeled that slight delays do not affect the solution that much.   Possible approachesThe static vehicle routing problem has been already investigated in the late '70s, where Solomon [1] proposed an insertion heuristic of handling VRPTW. The insertion bases itself around minimizing the total delay on each customer request. However, in the case of streaming requests, one might find different approaches in scheduling further requests, so here are a few of them, described in another paper [2]: Nearest neighbor (NN) - out of all the remaining requests, always move to the nearest neighbor for every vehicleFirst come, first served (FCFS) - schedule requests based on the request arrival timePartitioning policy (PART) - the map is divided into subregions, in which the requests are taken in the FCFS orderStochastic Queue Median (SQM) - after delivering a request, the vehicle moves to the median of the locations of all requests and then proceeds to the next most feasible oneIt is easy to see that with more requests coming in at an intense rate, the route will become longer and eventually, suboptimal. However, it is a trade-off in dynamic environments, as the incoming request mostly needs to be processed immediately, so customers can be informed when the order is going to be completed. If the number of immediate requests is too high, one might consider using batching strategies in order to gain more information at the time re-optimization occurs. Most commonly, there are two types of batching strategies:Batch strategy by size - Perform routing every M incoming requestsBatch strategy by time - Perform routing every N minutes   SummaryAll things considered, the Vehicle Routing Problem is a very diverse one with respect to its scope and methods of solving, and it is easy to get confused when picking the right algorithm for a specific problem. If you want to check out more about VRP, stay tuned for upcoming blog posts as Memgraph updates its MAGE spells with the purpose of letting developers use the VRP Solver with ease!If you found this tutorial interesting, you should try out the many other graph analytics algorithms that are part of the MAGE library.Finally, if you've been working on your own graph algorithms in MAGE and want to share them with developers around the world, have a peek at the contributing guidelines. We'd be more than happy to help you, provide comments and add the module to the MAGE repository.References:[1] Solomon, M. (1987). Algorithms for the Vehicle Routing and Scheduling Problems with Time Window Constraints. Oper. Res., 35, 254-265.[2] Larsen, A. (2000). The dynamic vehicle routing problem. Technical University of Denmark. IMM-PHD No. 2000- 73"
919,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
920,"With the rapid advancement of AI technologies, we will see an increase in internet threats and exploitations. I've been thinking about the future of the internet and how we can make it more secure, decentralized, and user-focused while mitigating the negative effects of AI.I thought of an idea where we could use Hyperledger Indy for decentralized identity (DID) management and basically create a new protocol that requires DIDs for auth. This is an extension of another idea I had around DIDs and blockchains.I'd love to get your thoughts and feedback on this, or if you know if any other ideas like this being explored!The Idea:Create a new version of the hypertext transfer protocol that requires users to have a DID, managed through Hyperledger Indy. This DID would be checked for validity before allowing any transaction to go through, essentially creating a more secure and decentralized internet (Internet 3.0).How It Addresses AI-driven Threats:It hinders AI-generated phishing attacks, as every request would require a valid DID.It thwarts AI-powered bots and fake accounts, as the DID requirement would make it challenging to create and maintain large-scale automated systems for malicious purposes.It makes A.I generated or altered content more traceable, as content creators and distributors would have associated DIDs, promoting accountability and authenticity. This could be paired with hashing content for tracking.Perceived Strengths:Enhanced security and privacy through a robust PKI, selective disclosure, and zero-knowledge proofs.Decentralized and user-centric architecture.Greater interoperability and ease of integration with other web3 technologies.Encourages trust through transparent and tamper-proof DID management.Foreseeable Weaknesses/Challenges:Increased complexity for developers and users.Potential performance trade-offs due to the computational overhead of DID validation and zero-knowledge proofs.Adoption (browser vendors, web service providers, etc.).Scalability Educating users and businesses about the benefits and workings of the new protocol.Opportunities:Reduces reliance on centralized certificate authorities.Empowers users with more control over their data and identity.Fosters a more open and equitable internet ecosystem.Encourages the development of new web3 applications and services prioritizing security, privacy, and user empowerment.So, what do you all think? Are there any major concerns or potential improvements I've missed? What do you think about the items I've outlined already?I'd love to hear your thoughts, especially if you have experience with Hyperledger Indy, DIDs, or web3 technologies!"
921,"As a software developer, it's important to focus on developing both technical and interpersonal skills. While technical (hard) skills are necessary to succeed in the industry, soft skills (such as communication, collaboration, and teamwork) are equally important. Everyone has a unique strength, point of view, or way of approaching their work that helps them stand out: maybe it’s curiosity, adaptability, or maybe it’s your innate contrariness, which enables you to poke holes in weak code. 😠🤔 Once you identify and begin to develop that unique attribute, you can use it for good and continue to refine it as you progress in your career. What do you consider to be your greatest strength as a developer, and how has it helped you in your work?"
922,"OpenAI, chatGPT, DALL-E have excellent APIs but what are the best tools for building SaaS products based on them and offering services to end users? Products with a free tier are preferred."
923,"Hey y'all it's CodeNewbie Meme Monday! Woooo! We are happy to see you again over here on the DEV Community. As always, this is a humble call for NEWBIE-related memes! Drop your beginner-related, job-related, starting-a-new-career-related memes below! AND if it is your first time here welcome! Happy to have you in the thread!"
924,"Hello readers. Lately, I think that everything has a price.Prove me otherwise."
925,"One of the strongest heuristics for career progress (and personal growth) is how readily you change your mind about things. After all, everybody's wrong sometimes. If you don't change your mind now and then, you just keep on being wrong.This is a skill that's particularly relevant to developers; we're wrong all the time. When we troubleshoot a tricky bug, we start with a hypothesis (""I think the problem is X""). Then we find evidence to disprove the hypothesis, discard it, and come up with another one. This can happen tens or even hundreds of times before we find the right fix. My favorite developers to work with can turn on a dime: ""whoops, I was wrong. Let's try something else."" No embarrassment, no ego, no excuses. They're interested in finding the facts, no matter how many times they have to be wrong in the process.We should apply that mindset not just to the nuts and bolts of programming but to the ideas and beliefs that drive our careers. So tell me:Did you have a strong opinion as a junior developer that you've changed your stance on?Have you come to disagree with a blog post or DEV article that you wrote years ago?Virtual high-five! You're less wrong than you were. Let's hear about it.For my part, there are two things that come to mind.  NoSQLThe first time I had to write SQL, I immediately disliked it. SQL wasn't at all like the imperative code I was used to writing. Why was it so abstract and set-oriented? Why wasn't I supposed to use for loops? Why were we writing magic SQL strings instead of querying databases with a strongly-typed API?It's not hard to find SQL haters online. At first brush, it seems to go against everything programmers are taught. So I joined the crowd, settled on ""SQL is the worst possible thing,"" and went off to build a side project with MongoDB. I was sure it would be a slam dunk.A few months later, I looked over my half-baked side project and had a difficult realization: I'd spent an embarrassing amount of time trying to make MongoDB do things that SQL does out of the box—schemas, normalization, relational data, auto-incrementing primary keys, and so on. SQL would have been the right technology for my project (and I now believe it's right for most projects) but I'd failed to look beyond the first impression.Since that experience, I no longer shy away from SQL. Sure, it has its tradeoffs, and NoSQL databases are great for some situations. But most of the time SQL is safer and more reliable. Persistent data storage has a different set of problems from application code, and SQL is pretty darned good at it.  Anyone can codeI've been programming since I was a kid. It's been interesting to me—nay, captivating—since the first moment I knew what it was. Even when my long-term plan was to go to law school and become a politician, I was spending my free time playing with jQuery and reading CSS-Tricks.That means when I got my first programming job, I'd already been writing code for about a decade. That's a big advantage. Algorithmic thinking was second nature to me, and more importantly, I had a reliable sense of what programming languages could and couldn't do, so I knew what to Google and what to write by hand. Some things were still difficult to learn (async and Promises took me forever to figure out) but for the most part, things came easily, and the chaos of mid-2010s JavaScript was more exciting than intimidating.The mistake I made was projecting my experience onto everyone else. ""Code is simple and makes sense,"" I thought. ""Surely everyone can learn if they put in the time.""I was wrong about that. A handful of years in the industry has taught me that everyone is different. Sure, a lot of people can learn to code. But a lot of people can't, or at least not to the level of a marketable skill. Everybody's smart at something; that something usually isn't code. And even among the people who can learn to code, many of them wouldn't enjoy the solitary and repetitive nature of a programming job. I've left team anybody can code and joined team try it out first, see if you like it. This has helped me make far better recommendations to people who ask me about a career in tech.Your turn. What have you changed your mind about lately?"
926,"What's the first thing you do when you sit down at your desk in the morning? ☀️ (or night 🌛, or whenever you like to work).Do you check your email? Dive straight into your work? Or take a moment to plan out your day? Maybe you do some deep breathing, check your word-a-day calendar, or pick out a music mix to get you going.Share your morning routine with us in the comments! Let's get motivated and tackle this week together! 💪🏼"
927,"Imagine a world where you can have an AI-powered pair programmer that not only assists you with your code but also helps you throughout your entire development lifecycle.Well, guess what? Microsoft has just turned that dream into reality with their latest innovation: GitHub Copilot chat for Visual Studio 2022.  A New Era in Programming AssistanceWe all know how incredibly useful GitHub Copilot has been in auto-completing comments and code, saving us time and effort in our day-to-day programming tasks.But hold onto your hats, because Microsoft is taking it to a whole new level with their integrated AI-powered Copilot chat experiences in Visual Studio 2022.“We’ve been working to evolve Copilot to move beyond code completion and provide enhanced AI assistance that you can access throughout your development lifecycle, whatever task you happen to be doing at the time.” – MicrosoftCan you imagine having an AI assistant that understands what you’re working on and can quickly provide in-depth analysis, explanations, generate unit tests, and even fix bugs for you? That’s precisely what Microsoft is promising with Copilot chat.“This is no ordinary chat! With tight integration in Visual Studio, it understands what you’re working on.” – MicrosoftIt’s like having a personal tutor that knows exactly what you need help with and can provide relevant, useful answers on the spot.  How Does It Work?By integrating Copilot chat with Visual Studio, Microsoft has created an intelligent assistant that can grasp your intent and help you formulate the right questions to get the answers you need.“By gathering the right data from Visual Studio, Copilot grasps your intent and helps you form exactly the right question to get useful answers.” – MicrosoftAre you working on a code block and need an explanation? Simply ask Copilot chat. Did you encounter an error? Copilot chat is there to help fix it and generate unit tests. Stumped by an exception? Copilot chat can figure out possible causes and even suggest fixes.This groundbreaking technology will save you countless hours on manual tasks and troubleshooting, freeing you up to focus on the creative aspects of your work.“Using GitHub Copilot with Visual Studio gives you more time for creativity by spending less time on boilerplate manual tasks and diagnosis.”  Get Ready for the Private PreviewDo you feel that excitement in the air? That’s the anticipation of the private preview for GitHub Copilot Chat for Visual Studio, which will be available soon.“We’ll be sharing GitHub Copilot Chat for Visual Studio with a private preview soon – just sign up to be wait-listed.” – MicrosoftBut that’s not all. Microsoft has more in store for us as they continue to develop Copilot. Expect enhancements to pull requests, personalized documentation, and even a natural language way to run your CLI.“There’s a whole set of new ways Copilot will be able to help you with your development work, from enhancing pull requests to personalized documentation and even a natural language way to run your CLI.” – Microsoft  The Future of AI AssistanceGitHub Copilot chat for Visual Studio 2022 represents a significant leap forward in AI assistance for developers.With this innovative technology, the way we work on code will be forever transformed. It’s like having a virtual teammate who’s always there to help you out, making your development process smoother and more efficient.“This is just the start. Watch out for more AI assistance across your whole lifecycle as we continue to develop Copilot.” – MicrosoftThe implications of this powerful AI assistance go beyond just individual developers. This groundbreaking tool could reshape entire industries by streamlining workflows, reducing errors, and enabling faster development cycles.Can you imagine the impact this could have on software development, project management, and even education?Think about it: with an AI-powered assistant like Copilot chat, learning new programming languages or tackling complex projects becomes a lot less intimidating. It’s like having an experienced mentor guiding you every step of the way, making it easier than ever to learn and grow as a developer.“With GitHub Copilot chat, if you find yourself needing more information, you can ask it to explain the code you’re working on.” – MicrosoftAs we look towards the future, it’s exciting to see how AI advancements like Copilot chat will continue to revolutionize our lives. Who knows what other incredible tools and features Microsoft and other tech giants will bring to the table? The possibilities are truly limitless.Its tight integration with Visual Studio and advanced AI capabilities promise to make programming more enjoyable and efficient than ever before. With this innovative tool at our fingertips, the sky’s the limit for what we can achieve.So, don’t wait any longer to experience the future of AI-assisted programming. Sign up for the private preview and be among the first to explore the incredible potential of GitHub Copilot chat for Visual Studio 2022.  Are you ready to take the leap into the future of programming?Let’s join hands and embark on this exciting journey with GitHub Copilot chat for Visual Studio 2022. The world of software development will never be the same again!"
928,"I had made and launched fluenticons last year and it got acquired. So today I am launching a new one, Let's see if the magic works for this too.Introducing PostPerfect - Improve your tweets right from Twitter - I am launching it on Producthunt - do check it out and upvote, leave a comment if you like it.https://postperfect.xyzhttps://www.producthunt.com/posts/postperfect-aiIt is built with Vue, Vite, Crxjs, building a chrome extension was quite challenging for me, but this was such an interesting product to buildBeen using ChatGPT for everything and I finally thought of building something with it. I will keep building more things over time."
929,"Here's what Code GPT thinks about the quality of my React code:Your code is quite well written and structured. However, there are a couple of things that you could consider to improve it:1. Use meaningful variable names: Try to use descriptive variable names that reflect the purpose of the data that they hold. For example, instead of `exp`, you could name it `workExp` and instead of `k` and `n`, you could name it `index` or `keyIndex`.2. Use arrow functions in JSX: You can use arrow functions to make the code more readable and easier to understand. For example, instead of using a regular function like `(exp, k) => {...}`, you can use an arrow function (`(workExp, index) => {...}`).3. Apply consistent whitespace and formatting: Some parts of your code have inconsistent whitespace and formatting. For example, some tags have spaces between the tag name and the attributes, while others don't. To make your code more consistent and easier to read, apply the same formatting rules throughout the file.Enter fullscreen modeExit fullscreen modeRuthlessly punishing me for my lazyness with meaningful variable names inside array methods! 😅PS. It got a little confused by my arrow functions for some reason? Not sure what is going on there. The whitespace and formatting comment is also strange, since I use a default formatter for react/tsx..."
930,
931,"Hey, all you amazing code crusaders! 🚀 Are you ready to revolutionize your software engineering workflow and unleash the power of AI? Introducing ChatGPT-4, your new secret weapon to supercharge your productivity and leave your competition in the dust! Check out these 5 mind-blowing productivity hacks, and prepare for a future of coding domination. Let's do this! 💥  Hack #1: Instant Code Review Buddy 🧠🔍Tired of waiting for your teammates to review your code? ChatGPT-4 is here to save the day! With its powerful AI capabilities, it can quickly review your code, identify potential issues, and suggest improvements. Just give it access to your code and watch the magic happen. Say goodbye to long review cycles!  Hack #2: Code Snippet Generator ⚡🎯Struggling with a tricky problem and need a quick code snippet? ChatGPT-4 has your back! Just describe your problem, specify your programming language, and let the AI create a tailored snippet to help you tackle that pesky issue. This hack will have you coding like a pro in no time!  Hack #3: Programming Language Translator 🌐💬Can't remember the syntax for that obscure programming language? No worries! ChatGPT-4 can translate code from one language to another with jaw-dropping accuracy. Just input your code, specify the target language, and watch as ChatGPT-4 flawlessly converts your code. It's like having your very own babel fish for programming languages!  Hack #4: Instant Tech Support Guru 🧞‍♂️💡Stuck on a problem and can't find the answer in online documentation? ChatGPT-4 to the rescue! Just describe your issue, and the AI will search its vast knowledge base to provide a concise, helpful solution. It's like having a tech support guru in your pocket 24/7!  Hack #5: Creative Brainstorming Partner 🎨🌪️Need fresh ideas for your next project? ChatGPT-4 can be your creative brainstorming partner! Just provide some context, and the AI will generate a plethora of innovative ideas, helping you think outside the box and explore new possibilities. Let your creativity run wild!Well, fellow software engineers, the future is here, and it's looking brighter than ever! With these 5 ChatGPT-4 productivity hacks, you'll be ready to tackle any challenge that comes your way. Now it's your turn to weigh in! Have you tried any of these hacks? What's your favorite way to use ChatGPT-4 in your software engineering workflow? Share your thoughts, experiences, and wildest success stories in the comments below! Let's help each other level up and embrace the full potential of AI in our coding adventures! 🚀"
932,"There were several items on the agenda, this post focuses on feature proposals and their progress from the 95th TC39 meeting.Stage 3:Async Explicit Resource Management: Address a common pattern in software development regarding the lifetime and management of various resources (memory, I/O, etc.).import attribute: Import Assertions re-adanced to Stage-3. Proposal for syntax to import ES modules with options, e.g. for JSON modules.Stage 2:Async Context: proposal is to provide a mechanism to ergonomically track async contexts in JavaScript.Float16Array: Float16 on TypedArrays, DataView, Math.f16round.Iterator.range: A proposal for ECMAScript to add a built-in Iterator.range()Stage 1:Await Dictionary: A proposal to add Promise.ownProperties(), Promise.fromEntries()Class Method Parameter Decorators: Decorators for ECMAScript class method and constructor parametersPromise.withResolvers: Creates a Promise with the reject,resolveandpromise functions placed as methodson the promise object itself.Time Zone Canonicalization: TC39 Proposal (stacked on Temporal) to improve handling of changes to the IANA Time Zone Database.@gnumanthElections for the 2023 TC39 Chair Group are complete 🎉The Chairs this year are...🔸 @SoftwareChrisGo Chris de Almeida (IBM)🔸 @robpalmer2 Rob Palmer (Bloomberg)🔸 @ryzokuken Ujjwal Sharma (Igalia)— TC39 (@TC39) March 22, 2023"
933,LGTM - the scariest words to see as a CTO.  That means devs didn't spend enough time on a PR.
934,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
935,"In a way I am lucky as in the last 23 years I always worked as a self-employed service provide, never as an employee. So it was easier to negotiate an contract that separated the time I work for the client from the rest of my time. This made it easy to work on other things, including open source projects albeit unpaid.At most of my clients the employees were not contributing to open source projects, but I never really asked if it is lack of interest or if the corporation prohibits them from working on OS projects?It's time to ask it.Does your employer allow you to work on open source projects in your free time?Does you employer allow you to do so during company time?What are the rules you have to follow?If it is ok, please also share, which company?"
936,"  IntroductionGitHub has recently launched a new AI-powered coding tool, GitHub Copilot X. It is a collaboration between GitHub and OpenAI, and it is designed to help developers write better code, faster. The tool uses machine learning to provide suggestions and autocompletions for code as the developer types. In this blog post, we will discuss the features of GitHub Copilot X and its impact on the coding community.  Improved Code SuggestionsGitHub Copilot X offers improved code suggestions that are more accurate and context-sensitive. The tool uses machine learning algorithms to understand the context of the code and provides suggestions that are relevant to the current code. This means that developers can write code faster and with more confidence, as they don't have to spend time searching for the right code snippets or syntax.  Increased EfficiencyWith GitHub Copilot X, developers can write code more efficiently. The tool provides suggestions for code snippets, functions, and entire classes, making it easier to write complex code. It also helps developers to avoid common mistakes and typos by suggesting corrections as they type. This increases the efficiency of the coding process and allows developers to focus on the logic and functionality of their code.  Future of AI in CodingGitHub Copilot X is a significant step forward in the use of AI in coding. It demonstrates the potential for machine learning algorithms to assist developers in writing better code. As the tool continues to learn and improve, it has the potential to revolutionize the coding process, making it faster, more efficient, and more accessible to everyone.  ConclusionIn conclusion, GitHub Copilot X is a groundbreaking tool that has the potential to change the way we write code. Its improved code suggestions and increased efficiency make it a valuable addition to any developer's toolkit. As AI continues to advance, we can expect to see more tools like GitHub Copilot X that help us to write better code faster and with more confidence."
937,"In S23E6 of the CodeNewbie Podcast, Saron talks with Alice Goldfuss, Principal Software Engineer and Systems Programmer specializing in building resilient distributed systems at scale. Listen in at the link below!      codenewbie.org    Alice Goldfuss is a systems punk with years of experience working on cutting-edge container platforms, as well as an international speaker and community builder. She also enjoys building modern infrastructure at-scale and writing fiction on the weekends.Listen on Apple PodcastsListen on SpotifyOr, listen wherever you normally get your podcasts!Make sure to subscribe to the CodeNewbie podcast if you haven't yet!Happy coding! We hope you enjoy this season of the CodeNewbie Podcast 💜"
938,"Last year, in We've Been Here Since the Beginning, I wrote about how it felt to be constantly othered, assumed to be less competent, and assumed to be a diversity hire. This International Women's Day, I have regained a teensy bit of optimism, so it's all about how to support the women developers in your life. Basically, if you see something, say something.  1. Believe ThemWhat not believing them looks like:""He's never been like that with me.""""I don't see the problem with this one interaction.""Acting like having emotions discredits their complaint.What support looks like: Being aware there are always power dynamics - learn about intersectionality. Knowing victimizers can be subtle and good at finding vulnerable victims. Harassment is often death by a thousand cuts over a long period of time. Knowing if women are receiving blatant mistreatment, that usually indicates it's condoned at the highest level.Taking a harsh look at your own biases and assumptions. No one is immune from them. If you can, stage an experiment like changing your email signature.  2. Call Out OtheringWhat othering them looks like:Being surprised that a woman is successful in a technical role.Acting like the woman did something special to be the only woman hired.Pointing out they're the only woman in the room.Not including women in choosing team social activities.What support looks like:Taking the pressure off the one woman. It's not the woman in the room's job to prove that more women need to be in the room.Putting the pressure back on the employer to hire more women.Speaking up when someone implies it's weird a woman is involved. It's usually weird more women aren't involved.Making sure women are invited to meetings and social events. Choose activities that are welcoming to everyone.  3. Combat StereotypesWhat stereotypes about women in tech look like:""Wow! You're so good at this for a woman.""""Women aren't suited for these kinds of roles.""""Because you're a woman, you must be in a non-technical role.""What support looks like:Understanding stereotype threat.Calling out the assumptions being made based on stereotypes. Sometimes they are stated out right, but often it's more subtle.Asking why they assumed that her role should be non-technical and point out all the evidence to the contrary that they missed.  4. Give Them the Credit They DeserveWhat women not getting credit looks like:Women getting fewer opportunities to speak, talking less in meetings, and getting interrupted more.Credit stealingWhat support looks like: Advocating for your coworkers who often get interrupted or don't seem to get the credit they deserve.Amplifying women's ideas when they're talked over or ignored. Repeat the idea and give credit to whoever came up with the idea. ""Like Sally said, it would be a good idea to...""If someone is interrupting others constantly, calling it out.  5. Don't Assign Them Glue WorkWhat glue work being forced on women looks like:Only women are asked to take notes in meetings.Only women are writing the documentation at your company.Ever expecting a woman developer to order coffee or office supplies or take on the mental load that keeps the office running.What support looks like:Not doing that.Calling out people who do those things.  6. Apply the Rules EquitablyWhat not applying the rules equitably looks like:Code standards and practices that are only applied or applied more harshly to women's work.What support looks like:Noticing when it seems to take a lot longer for women to get their work pushed through.Documenting how something has been unevenly applied in the past and how the rule or process should be applied in the future. If anyone gets noticeably upset about you asking for it to be documented, they probably know they benefit from being able to apply it unevenly.Making sure someone owns the process and can ensure the rules are applied consistently.  7. Don't Tolerate Objectification/SexualizationWhat objectification/sexualization looks like:Commenting on a woman's appearance, unasked.Anything that implies women's primary role is reproduction.What support looks like: Not doing that.Calling out others who do.Understanding the difference between ""cool shirt"" or ""nice haircut"" and ""If you smiled more, you'd be prettier.""  8. Hire and Promote More WomenWhat it looks like when hiring and promoting women isn't a priority:""Women keep leaving because of other companies' diversity quotas.""Harsher performance reviews and moving goalposts for women looking to advance.Women being paid less than their male counterparts, regardless of experience.""We just didn't have any women apply.""What support looks like:Putting pressure on the company to investigate why women aren't being hired or keep leaving. Don't assume it only has to do with compensation.Openly sharing your salary with your coworkers.Putting pressure on the company to objectively review performance review and promotion processes and outcomes regularly.Sending the hiring team women in tech job boards.https://www.diversifytech.com/hirehttps://members.hiretechladies.com/jobshttps://www.womentech.net/jobshttps://mywit.org/jobs-listing/https://ladybirdtalent.com/blog/our-favorite-women-friendly-tech-job-boards/https://www.womenintechnology.org/career-center  ConclusionObviously, some of these things are easier to do the higher you rank in your organization. You may be thinking to yourself ""I'm not the CEO. Sure, I can say something, but that doesn't mean it'll change anything."" I can guarantee it will change women in your organization feeling like no one cares they have to put up with this.At the end of the day, that's what being a woman in the tech industry often boils down to: Why do I have to put up with this extra layer of hurdles? Why do people accept this as the status quo?You'd be surprised how much someone else pointing at the hurdle and saying ""this is ridiculous"" helps."
939,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by @brownrita460's Top 7 post, tonight’s topic is...the future of AI 🤖🔮What is the future of AI?Rita Brown ・ Mar 17#discuss#ai#productivity#programmingQuestions:How do you think the proliferation of AI will affect society over the next 10 years? How about 20 years? 100 years?How does this topic make you feel? Scared, excited, optimistic, cynical, or skeptical? Or something else?Any triumphs, fails, or other stories you'd like to share on this topic?"
940,"Like the last year, let's discuss together what could be announced. Are you going to participate?Starting the May 10 2023.Website ✨         Sundar Pichai              @sundarpichai            Excited that this year's #GoogleIO will be on May 10, live from Shoreline Amphitheatre in Mountain View and online at io.google/2023      22:23 PM - 07 Mar 2023    You can see the recap of Google I/O 2022 in this video."
941,"What are your goals for this week?What are you building? What will be a good result by week's end?Are you attending any events this week?Did you meet your goals last week?I'll start.Last Week's Goals[❌] Update Portfolio.[✅] Continue Job Search.Continue new project. Did some CSS challenges.[✅] Blog.[✅]Encourage and help members in our Virtual Coffee's February Challenge, Getting job ready.[✅]Attend AWSome Day on Wed. * Was webinar on their services. I was hoping for some hands on walk through. This Week's GoalsUpdate Portfolio.Continue Job Search.Continue new project.Blog.Encourage and help members in our Virtual Coffee's February Challenge, Getting job ready.Attend Job FairThis Month's GoalsGain more followers here. I would like to have more followers on DEV than I had on the bird site. You've read my goals so I'll throw that question back to you.What are your goals for the week?-$JarvisScript git pushEnter fullscreen modeExit fullscreen mode"
942,"Howdy! 🤠Hope everybody had a wonderful week and that y'all all enjoy your weekends. 😀Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugCelebrating a birthday 🎂"
943,"Exciting news in the React world: after years of hard work and refinement, the former React Docs Beta have been promoted to official React documentation and are now live at react.dev!         React              @reactjs            Today, we’re thrilled to launch react.dev, the new home for React and its documentation. It teaches modern React with function components and Hooks, and we’ve included diagrams, illustrations, challenges, and over 600 interactive examples. Check it out!          18:57 PM - 16 Mar 2023    With that, the original docs have been downgraded to legacy, although they are still accessible at legacy.rectjs.org.   HistoryThe React Docs Beta project was first published in late October 2021, led by Rachel Nabors and Dan Abramov, with the goal of updating the existing React documentation to reflect newer, more current ways of writing React. This was primarily focused on the use of Hooks (which were introduced as part of React 16.8, released in February 2019) and the associated shift to favor functional components instead of class components.         React              @reactjs            Two weeks ago, we published an early preview of the new React Docs Beta at beta.reactjs.org. If you’re learning React, check it out and let us know what you think! It’s still a work in progress and unfinished, but there are several reasons we are excited about it.           17:51 PM - 11 Nov 2021    Previously, the official React documentation was class-component forward because that was the only way to write stateful components. However, the introduction of Hooks – the useState() hook, in particular – allowed functional components to handle state as well. Since then, there’s been plenty of debate over whether Hooks were the right move and whether or not they accomplished the goal of simplifying state and state management. Regardless, the introduction of Hooks drastically changed the way we wrote React. To differentiate between the before and after of this development, many React tutorials and articles (including the introduction to the new official React docs) commonly refer to the post-Hooks era as “modern” React. However, this put new React learners in a difficult position. There was an abundance of writing and guidance about migrating from class components and traditional state management over to functional components and Hooks. Folks learning React for the very first time, though, found that there wasn’t strong documentation teaching Hooks from scratch. Over time, the official React docs only became more outdated and difficult to use.   What’s New?  Hooks and Functional Components as DefaultThe biggest change in the new documentation is the shift to be strongly opinionated toward the use of Hooks and teaching functional components as the standard approach for writing modern React – with the rare exception of the few remaining use cases where class components are still required. Otherwise, class components (while still supported) have been officially designated as “legacy”.   Interactive Demos and ChallengesThe new docs have greatly expanded the number of interactive code examples, as well as added new challenges to allow you to practice what you’ve just learned and test your knowledge. There are 600+ new interactive code examples, sandboxes, and demos – all of which can be forked to open in codesandbox.io for bigger, more extensive changes or to be easily adapted for use in your own work. This, along with the addition of more illustrations and diagrams, was done in the hopes of making the React docs more friendly and easy to understand.   Create React App No Longer the StandardOne of the most remarked-upon changes to the documentation is the removal of Create React App (CRA), the official Facebook-maintained React quick-configuration tool, from the Installation section of the new docs. The legacy docs had recommended CRA as “the best way to start building a new single-page application in React”. There have been several calls recently to remove the CRA recommendation, perhaps most notably from popular YouTuber Theo (t3.gg) whose pull request on the reactjs project recommending the replacement of CRA with Vite gained a lot of attention. This sparked heated criticism of CRA, including its perceived lack of features (such as native support for TypeScript or popular CSS library Tailwind), size, performance, and more.         Theo - t3.gg      @t3dotgg      Should I file a PR on the React docs to remove the Create React App recommendation?          22:58 PM - 21 Jan 2023    Ultimately, though, there is one deal-breaking fact about CRA that cannot be ignored: it is no longer actively maintained. With 1.5k current unresolved issues, over 400 open PRs, and the last release over a year old, it’s safe to call CRA a dead project.   Frameworks are the Official RecommendationFor users creating new apps or sites entirely in React, the updated docs now recommend React frameworks including Next.js, Remix, Gatsby, and Expo for React Native. In a click-to-expand “Deep Dive” section, they officially take the opinion that using a framework is the best way to build with React. They do, however, note that options such as Vite or Parcel exist for those who “like to roll [their] own custom setup, we can’t stop you – go for it!”. This is a notable difference from the legacy docs, which offered a quick sentence of description each for Next.js and Gatsby but focused heavily on CRA as the recommended approach.   New Domain NameThe now-legacy documentation could originally be found at reactjs.org; this now redirects to the brand-new react.dev domain. When the new docs were still in beta, they were hosted at beta.reactjs.org, which now also redirects to react.dev. The original documentation can still be found, for those who need it, at legacy.reactjs.org. This was done to make a fresh start and clear separation between the current vs. legacy documentation.   New Brand Color?        Borek Bernard      @borekb@dan_abramov Congrats!Also, a key question, what is the brand color now? 😄           21:58 PM - 16 Mar 2023    A less crucial (but still interesting) update: a keen-eyed Twitter user (@borekb) noted that the iconic teal brand color that’s historically been associated with React has changed slightly in the new documentation. The (now) legacy docs previously used the slightly brighter #61dafb, while this user noted that the new docs use #0a7ea4. However, I did some digging as well, and there’s actually a little more to it than that! In addition to #0a7ea4, the new docs *also* use #149eca as “React blue” – a slightly brighter shade of teal that’s closer to the original. Which one of these is used depends on whether or not the site is in light or dark mode, as we can see in this snippet I grabbed from their CSS via the inspect tool. Based on this info (without knowing the actual reason), my guess would be that the colors were adjusted slightly for accessibility purposes. The primary dark mode background color is #23272F, against which the lighter color will pass a color contrast check, while the darker color will not. On the other hand, the darker teal passes a color contrast check against a white background, while the lighter color does not. Based on this, I’d assume that the colors were changed from the original to be as accessible as possible in the new docs. Shoutout to the React team for their attention to accessibility!   Looking ForwardAs with all docs, the React documentation is constantly evolving and expanding. The “Introducing react.dev” blog article lists several new features that we can look forward to in the near future, including TypeScript examples, an updated accessibility guide, expanded language translations, and more.   FeedbackGot an opinion on the new docs? The React team has a few ways to offer feedback: Fill out a survey to offer general feedback.Log an issue to document problems, bugs, mistakes, etc.  An Exciting FutureI’m of the personal opinion that these new docs are a huge triumph for the React team and a massive improvement over the legacy offerings. They’re well-designed, easy to read, and generally incredibly user-friendly. It’s a shame that it took so long for them to feel comfortable removing the beta tag and transitioning this excellent new resource to the official React documentation – but better late than never! The introductory blog states: “We think there’s never been a better time to learn React” – I’m inclined to agree! I hope these fantastic new docs bring with them a burst of new and excited learners. Here’s to another 10 years of React!What do you think of the new docs? Were you happy to see the removal of Create React App? Excited to embrace Hooks? Let me know in the comments! "
944,"Ayo! 👋Hope y'all have wonderful weekends. 🙌Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugSharing a #wecoded post ✍️"
945,"With the release of GPT-4, there have been some incredible projects created or amplified. Which have you found most interesting?"
946,"Amidst all the conversation around Signals the recent weeks, I have forgotten to talk about arguably the most important topic. Why should you care? I've covered their evolution and opposition, but I haven't actually made the case for using them.There has been a narrative around them related to performance which is not without merit but it is so much more than that. It is more than about developer experience too. It is about flipping the current paradigm on its head.React famously popularized:view = fn(state)Which is a very powerful mental model for thinking about UIs. But more so it represents an ideal. Something to strive for. Reality is a lot messier. The underlying DOM is persistent and mutable. Not only would naive re-rendering be prohibitively costly, but it would also fundamentally break the experience. (Input's losing focus, animations, etc...)There are ways to mitigate this. We build ever-better constructs in hopes of reshaping our reality to fit. But at some point, we need to separate the implementation from the ideal to be able to talk about these things honestly.So today we look at Signals as they are and what they have to offer.  Decoupling Performance from Code OrganizationThis is the moment when you first realize that something really different is going on. There is more to it, though. This is not an invitation to litter your app with global state, but rather a way to illustrate state is independent of components.function Counter() {  console.log(""I log once"");  const [count, setCount] = createSignal(0);  setInterval(() => setCount(count() + 1), 1000);  return <div>{count()}</div>}Enter fullscreen modeExit fullscreen modeSimilarly, a console.log that doesn't re-execute when a counter updates is a cute trick but doesn't tell the whole story.The truth is this behavior persists throughout the whole component tree. State that originates in a parent component and is used in a child doesn't cause the parent or the child to re-run. Only the part of the DOM that depends on it. Prop drilling, Context API, or whatever it is the same thing.And isn't just about the impact of spreading state changes across components but also multiple states within the same component.function MoreRealisticComponent(props) {  const [selected, setSelected] = createSignal(null);  return (    <div>      <p>Selected {selected() ? selected().name : 'nothing'}</p>      <ul>        {props.items.map(item =>          <li>            <button onClick={() => setSelected(item)}>              {item.name}            </button>          </li>        )}      </ul>    </div>  );}Enter fullscreen modeExit fullscreen modePorting the example from Svelte Creator Rich Harris' Virtual DOM is Pure Overhead to SolidJS it is important to understand, with Signals, updating the selected state does not cause any execution other than changing the text in that <p>. There is no re-running the list or diffing it. That is even true if the name in one of the rows updates. With Signals, we can directly update the text of that one button.Note: It is customary in Solid to use <For> component instead of .map when rendering a loop so as to not recreate every row when entries of the items are inserted, removed, or moved.You might be thinking, ""I get it. It's fast. But I've never had trouble ensuring good performance in something like React."" But the takeaway is more than that.You no longer need to be concerned with components for optimal execution.You can put your whole app in one component or many components and get the same benefit. You can break apart components for your sake. How you want to organize your app. Not because you need to isolate some part of the UI that changes. If performance ever became a concern it wouldn't be due to the structure of your components necessitating costly refactoring.This is not an insignificant benefit to developer experience.  Separating Dynamic from Static        дэн      @dan_abramov@thdxr yeah i could see that. my frustration partially stems from — yes, there are a bunch of things where React gets confusing — but this is the clearest win React ever had, if it had one. erasing the distinction between first and next renders propelled it up. sad to see this forgotten          19:37 PM - 26 Feb 2023    There have been some conversations to suggest this is a bad thing. If you want more perspective see @dan_abramov's response to my previous article.I don't just want to talk about why this is a good thing, but how it is actually an amazing thing. Being able to optimize for each is beneficial. This is one of those places where aligning with the underlying platform pays off with dividends. Classically speaking there is a tradeoff with using a distributed event system like Signals vs something that runs top-down. While updates will be quicker for the event system, at creation it has the additional overhead of setting up subscriptions. This is even compounded by the fact that the web generally is a document-oriented interface. Even in Single Page Apps, you will be doing a lot of navigation which involves a lot of creation.Makes sense. However, the web platform is aware of this cost and has made it more efficient to create elements in bulk than individually. Extracting the static parts for mass creation makes a bigger impact than those subscriptions.And the benefits don't stop with the browser. With a Signals-based system the complexity, size, and execution of your code scale with how interactive your UI is rather than how many elements are in it.Consider a server-rendered page with few interactions. Maybe an eCommerce site. The static parts are server-rendered HTML. You don't even need the code for that to make it interactive. Just delete the static parts from the bundle.Steve from Builder.io (at 1:16) explains how this works in Qwik:Admittedly this is mostly a performance concern. It comes from the same motivation for Islands architecture and React Server Components. It addresses a very real pain point we are facing today with the trend towards ever-bigger JavaScript bundles and slow initial page loads.Overall, my position is this separation leads to a certain amount of transparency. It makes it easier to explain and reason about what is actually going on. While less simple than the ideal, it makes escape hatches, which are an important part of any system, more coherent.   Universalizing the Language of UIOne of the most powerful things about Signals is viewing their impact as a language. And I don't mean a compiled language. Signals are completely a runtime mechanism. There is no magic here. Just a Directed Acyclic Graph.While it seems clear there is a convergence in concepts of State, Derived State, and Effects, not all the mental models and implementations line up.Signals are independent of any component or rendering system. And only represent state relationships. Unlike something like React Hooks which have additional primitives to describe how to guard execution like useCallback, React.memo and concepts like stable references(useRef) to handle the coordination of effects.Both of Dan's articles listed at the bottom of the article are a really good exploration into how to effectively use these primitives in React.Additionally, Signals lend to traceability. They give you a way of understanding what updates and why.        thetarnav.      @thetarnav      Release day for @solid_js devtools!0.21.0 adds an essential way of inspecting reactivity: a Dependency Graph — it will display current (direct and indirect) sources and observers of the selected signal or computationgithub.com/thetarnav/soli…      17:00 PM - 13 Feb 2023    They encourage patterns that lead to more declarative code. By making organizing code around data instead of component flow we can see what data is driving change. (Thanks Dan for the example).// control flowconst count = videos.length;let heading = emptyHeading;let somethingElse = 42;if (count > 0) {  const noun = count > 1 ? 'Videos' : 'Video';  heading = count + ' ' + noun;  somethingElse = someOtherStuff();}// derived dataconst format = (count) => count > 1 ? 'Videos' : 'Video';const count = videos.length;const heading = count > 0 ? format(count) : emptyHeading;const somethingElse = count > 0 ? someOtherStuff : 42;Enter fullscreen modeExit fullscreen modeIt poses an interesting question about the purpose of code. Should we optimize it for making it easier to write or easier to read?  Ok, But What About the Tradeoffs?There are definitely tradeoffs. The most obvious one is that they make the data special instead of the application of that data. We aren't dealing with plain objects anymore, but with primitives. This is very similar to Promises or Event Emitters. You are reasoning about the data flow rather than the control flow.JavaScript is not a data flow language so it is possible to lose Reactivity. To be fair this is true of any JavaScript UI library or framework without the aid of tooling or compilation. For Signals, this is more emphasized as where you access the value is important.I call this Signal's (singular) Hook Rule. There are consequences to this. There is a learning curve. It pushes you to write code a certain way. When using things like Proxies there are additional caveats like certain mechanisms in JavaScript language (like spreading, destructuring) have restricted usage.Another consideration is around disposal. Subscriptions link both ways so if one side is long-lived it is possible to hold onto memory longer than desired. Modern frameworks are pretty good at handling this disposal automatically but this is inherent to Signal's design.Finally, historically there were concerns about large uncontrollable graphs. Cycles and unpredictable propagation. These concerns largely are in past due to the work that has been done over the past several years. I'd go as far as these problems are what Signals solve and why you would use them over other message/event systems.  Conclusion        Evan You              @youyuxi      @dan_abramov @RyanCarniato The React thought leadership had long cultivated the narrative of “our model is more correct”, almost becoming a dogma. In reality, many engineers are simply more productive with the signals mental model - arguing on a philosophical level is pointless when that happens.          00:30 AM - 02 Mar 2023    There are many ways to approach the challenge of creating great user interfaces. I've aimed at keeping this discussion grounded but I think there is a lot to get excited about here.When you are building with a foundation of primitives there is a lot you can do. The exploration into reducing JavaScript load overhead and incremental interactivity is an area that Signals naturally fits in.And thing is to use Signals to great benefit you do not need a compiler. Not even for templating. You can use Tagged Template Literals and do it all with no build step. We tend to use compilation though to make ergonomics smoother. But Signals are also a great choice for compilation.Compilers and language exploration become that much easier when you have efficient building blocks you can target. And that isn't just true of us but for AIs. We've seen this suggested to improve upon everything from using analytics to drive code splitting to optimize initial load to optimizing compilers ability to understand code intent.        Dominic Gannaway              @trueadm            What was interesting about the responses to this tweet is that people got hung up with signals and the fact I opted to use React’s APIs.Signals and React aren’t even that important really. It’s the compiler that is. Imagine a UI compiler that leverages AI to self-improve… twitter.com/trueadm/status…      21:36 PM - 01 Mar 2023                Dominic Gannaway                    @trueadm                I’ve been working on a new React-like framework in my spare time.It’s fully compiler driven, there’s no virtual DOM, or component re-rendering. There are signals, but they’re never exposed to the developer and they’re also fully compiled to avoid any runtime lookups.And…      Whether Signals are best suited to be held by developers or to be low-level primitives for machines, they appear to be an important step in the ever-evolving world of web front-end.Related Resources:A Hands-on Introduction to Fine-grained ReactivityThe Evolution of Signals in JavaScriptReact vs Signals: 10 Years LaterVirtual DOM is Pure Overhead By Rich HarrisComponents are Pure OverheadMetaphysics and JavaScript By Rich HarrisMaking setInterval Declarative with React Hooks By Dan AbramovBefore you memo() By Dan Abramov"
947,"It's always fun to imagine what our lives would be like if we had made different choices. So, if you weren't a coder or a developer, what would you be instead? A chef, a musician, a veterinarian? Are there opportunities to incorporate your alternate passions into coding career?Let's hear from you all! Share your thoughts in the comments below."
948,"We all know how challenging it can be to stay focused and energized during long coding sessions, long workdays, and long study sessions. So, let's hear it: what's your go-to drink when you need a little pick-me-up to power through? Is plain old black coffee or more like a Black Cherry Vanilla Bang? Maybe it’s a healthier option like green tea 🍵 or a smoothie 🍓🍌.Share your favorite drinks, recipes, or tips for staying energized and productive!"
949,"As our #WeCoded celebration comes to a close, I wanted to take some time to reflect on the stories, experiences, and learnings that our community has shared over the past week.Here's mine: even though I don't read or speak Brazilian Portuguese (PT-BR), with the help of Google Translate, I enjoyed reading this article from @vanessatelles:Neopets - Meu inicio não tão convencional na área da tecnologiaVanessa Telles ・ Mar 13#wecoded#shecoded#braziliandevs#htmlIt made me think about my own career trajectory and opportunities, which I shared in Google-Translated PT-BR:Erin Bensinger•    Mar 14  Adorei ler esta história! Eu também costumava brincar com HTML e CSS no Neopets quando criança, lembro de me divertir muito com fundos de azulejos e cursores brilhantes, haha. Eu definitivamente tive um perfil temático da Avril Lavigne em algum momento 😂Isso me faz sentir agridoce embora! Quando menina, meu interesse por programação não era apoiado pelos adultos e acabei seguindo um caminho diferente. Às vezes penso em como minha vida seria diferente se eu tivesse continuado estudando e construindo com HTML e CSS.PS, sou falante de inglês (e espanhol, jaja) e usei o Google Tradutor para traduzir para PT-BR, então peço desculpas por qualquer bobagem gramatical 😁Ok, your turn! What's something you learned through #WeCoded on DEV?"
950,"I am not posting a lot over dev.to, but I think this is a great opportunity to show something great 🚀For the last 15 years, I have been playing the role of a full-stack developer and a team/tech leader for various companies.I never stop trying new technologies, I wake up in the morning with a lot of passion to build great things. I recently started playing with chatGPT and some generative AI technologies, but as chatGPT API was released, it became a great opportunity to make some really cool things 😎The world is changing fast, and I believe that very soon, most of the jobs, as we know them, will not be the same - AI will have its share in our life, involved in almost everything that we do. I build a lot of web applications, writing dozens of components every week. So I was thinking, what if I could make my life really easier and just ask ChatGPT to make those components for me? It turns out it is easier than you may think. Check this out:https://ai2ui.co/I open sourced it, so you are more than welcome to contribure make it better!Here's a link to the repo:https://github.com/yuvalsuede/ai-component-generatorPlease give me a star so I know I did something good 🙌🏻Love you all :)"
951,"  About MeHey everyone. My name is Brian, I'm a Developer Marketing Associate here at DEV Community, and I'm a nonbinary person. More specifically, I would call myself agender, but nonbinary is the quickest way to get my point across. I don't really care about engaging in acts of femininity or masculinity. Retrospectively, I've only ever conformed to the masculine gender roles expected of me to garner praise from others, not because I actually felt connected to those roles. It took a while to realize that building my life around what others expect of me was just leading to anxiety and unhappiness.I use they/them pronouns because I want any conversation I have to start with others understanding that I don't identify with either binary gender. This isn't to say that there isn't a healthy way to be masculine or be feminine -- I think there definitely is and it's something each person has to carve out for themselves. I'm secure in my agender identity knowing that I have no interest in taking pride in my masculinity or carving out that space for myself. Using he/him pronouns doesn't bother me or give me dysphoria, rather I keep them available to use so people don't feel like they were ""wrong"" if they didn't use the right pronoun. I want others to take me as I come and judge me on the basis of my character and my actions. We're all people first, and that's how I want others to interact with me: not as a man or a woman, but as a person.Not everyone is going to be willing to share their reasons with you, and they don't have to. I'm here to share my reasoning so that others who relate can feel empowered to step up and share their experiences. I'm grateful to have colleagues now and in the past who have supported me and who have wanted to get to know me and were willing to drop their baggage or expectations that came with their perceived view of my gender. I’m valued, not only for the material or financial value I provide to the people around me, but also for who I am. I can only hope that everyone eventually gets the same opportunity. While my main role on DEV Community and at Forem is not as a developer (I'm still on my freecodecamp.org grind), I interact with developers on a daily basis and I want to do everything I can to advocate for them. It's important to make sure everyone's voices get heard, not just for the sake of productivity or innovation, but because everyone inherently deserves the same level of basic respect. We all need to get involved if we want things to get better. Collective activism is how we make change, so let's work together to make room for everyone. What is it going to take to make tech a more inclusive space for all?  Posts That Inspired MeI've had a role in the last three SheCoded events and played a significant role in making WeCoded up to be what it is this year. There's a lot I want to talk about, I could probably write a book or two on all the topics there are to cover in this field. Instead, I want to highlight some folks on DEV that have already covered some of the things I wanted to say. I hope these posts, as well as my own, inspire you to share your story or demonstrate your allyship this International Women's Day.   ""5 Things to Keep in Mind for IWD.""Nevertheless, WE code: 5 things to do in IWD and everydaySilvia España Gil ・ Mar 8 '22 ・ 4 min read#shecoded#theycoded Sometimes it's important to go over the fundamentals. I didn't want to repeat advice in this post that folks have probably heard a hundred times by now, but Silvia does a great job at hitting all of the essentials in order to be a good ally.   ""Being nonbinary in tech is kind of a weird place.""Ami Struggled but Nevertheless They Coded Ami Scott (they/them) ・ Mar 10 '20 ・ 4 min read#theycoded#nonbinary#mentalhealth#autism This was a huge read for me, so big thanks to @memitaru for sharing. I particularly relate with the feeling of not being one of the guys but not fitting in with the girls either. My entire life I've had this alien feeling of not belonging anywhere and it's something I'm still working on to this day. I've found that community typically ends up being the panacea to this kind of feeling. Having a large group of people beyond your close friends and family that you contribute to, have the same goals as, and celebrate wins with is so important to your overall mental health and sense of self.   ""Learning to be human through coding and tech""I feel like an impostor in tech. I'm still here.Ong Chin Hwee ・ Mar 8 '20 ・ 4 min read#shecoded#theycoded One of my biggest pulls from this post is the sentiment of "" I still feel very much like an impostor in tech, because I don't see enough of people like me in tech events and conferences."" This post highlights how important representation is to the motivation and inspiration of marginalized groups. A lot of people are waiting for someone else to speak up or make a mistake so they feel comfortable doing so as well. It takes a lot of courage to be the one to say ""it's okay to be imperfect and vulnerable.""  ""Trans/non-binary inclusive design""Navigating the internet as a non-binary designerSarah ・ Jul 16 '20 ・ 10 min read#theycoded#design#inclusion This is sort-of an honorable mention for me, but @fossheim shares so many great resources that it would be a shame not to highlight it here. Not only does the article share tons of resources on what being nonbinary is, it also talks about workplace etiquette and how to be inclusive when designing websites for trans, nonbinary, and gender non-conforming people. A must-read for any web designer.   Further ReadingFor those who are curious but don't know where to go next, I have some resources for you that can set you on the right path. If you'd like to learn more specifically about women's legal issues,  you can visit the website for the National Women's Law Center, which has resources on abortion, child care, the wage gap, health care discrepancies, and more. Reproductive rights are at risk in the United States. Access to safe and legal abortion and birth control methods are no longer guaranteed nationwide. These resources are important now more than ever. If you have the passion and/or the additional funds, look into how you can help the Center for Reproductive Rights.One of my favorite libraries for LGBTQ+ topics is the Resources page for the Human Rights Campaign. The HRC covers topics like being an ally, coming out, health equity, parenting, sexual health, and more. Not only does it cover advice for LGBTQ+ people, it also provides a basic understanding of gender theory for those who are unacquainted. If you want to know more about what being gender non-conforming or two-spirit means or what the difference between sex and gender is, this is a great resource. Those links above are the hors d'oeuvres. If you really want to tackle the heavy reading, I salute you. I highly recommend reading the Sixty-seventh session of the Commission on the Status of Women (CSW 67). The primary theme, “Innovation and technological change, and education in the digital age for achieving gender equality and the empowerment of all women and girls"", should be directly relevant and somewhat actionable to those who are developers or support developers as a career. If you'd like a more general overview of the scale of global gender inequity we're dealing with and the consequences it has on people worldwide, check out the United Nations 2022 Gender Snapshot report. If you've made it to the bottom of this post, thank you. If you clicked on any of the links on this post, you're the best. Please take some time to reflect on your experiences and how you can make a difference to the people around you. Let me know what you come up with. The DEV Team and I will be in the comments below to moderate any discussion. If you have a question about any of the above that you'd like to ask privately, I'm open to direct messages on Discord: @quoss#0777."
952,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   8 Ways to Support Women Developers@abbeyperini provides 8 thoughtful tips for supporting women developers in your workplace. From combating stereotypes to speaking up against unfair treatment and practices, there's so much we can do to offer support.8 Ways to Support Women DevelopersAbbey Perini ・ Mar 8#wecoded#womenintech#programming#career  How Atomic Git Commits Dramatically Increased My Productivity - and Will Increase Yours Too@samuelfaure discusses the benefits of writing atomic git commits, which are commits that make a single, simple change that can be described in one sentence. Atomic commits make code easier to revert, produce a clean git history, simplify code review, and improve your workflow by breaking down complex tasks into smaller steps.How atomic Git commits dramatically increased my productivity - and will increase yours tooSamuel-Zacharie FAURE ・ Mar 7#git#beginners#github#programming  5 Real-world Projects for Practicing With NextJSMastering Next.js requires practice, and what better way to do that than to work on real-world projects. If you need ideas for things to work on, @devland has you covered in this helpful post.5 Real-world Projects for Practicing With NextJSThomas Sentre ・ Mar 7#webdev#javascript#react#nextjs  Boosting Women's Participation in Open Source Projects: A Beginner's Guide to ContributingTired of hearing that tech bros rule the industry? Well strap in because @dellamora has great tips for those aspiring tech newbies looking to break in. Anyone can contribute to open source, so building up a solid number of contributions is a great way to prove your experience and growth. Boosting Woman Participation in Open Source Projects: A Beginner's Guide to ContributingFrancielle Dellamora  ・ Mar 10#wecoded#opensource#community#motivation  Why is Elm Such a Delightful Programming Language?The creator of Elm could have called it a pure functional programming language with immutable data structure, but instead, he called it “delightful”. In this article, @marciofrayze explores what makes Elm so dang delightful. Why is Elm such a delightful programming language?Marcio Frayze ・ Mar 8#elm#webdev#programming#javascript  Human-like AI Conversations: Giving a Voice to ChatGPT with MurfIn November of 2022, ChatGPT took the world by storm. Yet it was missing one thing - a voice. In this post, @devgeetech talks about how you can add a voice to your GPT responses using Murf's text-to-speech API.      01:47Human-like AI Conversations: Giving a Voice to ChatGPT with MurfJoel Gee Roy ・ Mar 10#chatgpt#ai#react#typescript  The Language We Use MattersSome people say perception is reality and while that might not be the case, it definitely makes a huge impact on our daily lives. Our perception of our target audience, our co-workers, our manager, and other people changes the way we speak about them which can be exclusive to certain groups. Learn more about the way speech shapes our behavior courtesy of @eevajonnapanula.The Language We Use MattersEevis ・ Mar 11#wecoded#womenintech#webdev#programmingThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
953,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
954,"ChatGPT is an excellent general-purpose example of how we can use AI to answer casual questions, but it could do better when the questions require domain-specific knowledge. Thanks to this ChatGPT starter kit, you can train the model on websites you define.header image was generated using midjourney        gannonh       /         gpt3.5-turbo-pgvector            ChatGTP (gpt3.5-turbo) starter app      What is gannonh/gpt3.5-turbo-pgvector?This starter app was put together by @gannonh and makes great use of the Supabase pgvectors and OpenAI Embedding feature. The app leverages Next.js to stand up a simple prompt interface. Live demo: https://astro-labs.app/docs  How does it work?This starter app uses embeddings to generate a vector representation of a document and then uses vector search to find the most similar documents to the query. The results of the vector search are then used to construct a prompt for GPT-3, which is then used to generate a response. The response is then streamed to the user. Web pages are scraped, stripped to plain text, and split into 1000-character documents.// Stripe text from HTML// pages/api/generate-embeddings.tsasync function getDocuments(urls: string[]) {  const documents = [];  for (const url of urls) {    const response = await fetch(URL);    const html = await response.text();    const $ = cheerio.load(html);    // tag based e.g. <main>    const articleText = $(""body"").text();    // class based e.g. <div class=""docs-content"">    // const articleText = $("".docs-content"").text();    let start = 0;    while (start < articleText.length) {      const end = start + docSize;      const chunk = articleText.slice(start, end);      documents.push({ url, body: chunk });      start = end;    }  }  return documents;}Enter fullscreen modeExit fullscreen modeOnce the URLs are stripped down to the text, they are sent to the Supabase after some embedding creation using the text-embedding-ada-002 model. The OpenAI docs recommend using text-embedding-ada-002 for nearly all use cases. Fun fact, this is the same embedding Notion's AI tool uses under the hood. It's better, cheaper, and simpler to use. text-embedding-ada-002 announcement// Create embeddings from URLs // pages/api/generate-embeddings.tsconst documents = await getDocuments(urls);for (const {    url,    body  }  of documents) {  const input = body.replace(/\n/g, "" "");   console.log(""\nDocument length: \n"", body.length);  console.log(""\nURL: \n"", url);  const embeddingResponse = await openAi.createEmbedding({    model: ""text-embedding-ada-002"",    input  });  console.log(""\nembeddingResponse: \n"", embeddingResponse);  const [{    embedding  }] = embeddingResponse.data.data;  // In production we should handle possible errors  await supabaseClient.from(""documents"").insert({    content: input,    embedding,    URL  });}Enter fullscreen modeExit fullscreen modegpt3.5-turbo-pgvector is an excellent starter for folks looking to try out OpenAI on their own data or sites. I see this being extremely useful in the documentation and now understand why OpenAI doesn't need to search in their docs (this is a joke, they should add search). Search in docs could be replaced by projects setting up their own embeddings. Share in the comments if you have a use case for this.  Also, if you have a project leveraging OpenAI or similar, leave a link in the comments. I'd love to take a look and include it in my 30 days of OpenAI series.Find more AI projects using OpenSaucedStay saucy. "
955,"The 1996 Summer Olympics were held in Atlanta, marking the 100th Anniversary of the modern Olympic Games. Dolly the Sheep became the first mammal to have been cloned from an adult somatic cell. Macarena, sung by Los del Río and remixed by The Bayside Boys, became a major dance craze and cultural phenomenon.And in 1996, the first version of CSS specification is published. The standard contains specification to select font style,size and colorThe standard allowed the user to select font style and size and change the colour of the text and background.  DIV P           { font: small sans-serif }  .reddish H1     { color: red }#x78y CODE      { background: blue }  DIV.sidenote H1 { font-size: large }Enter fullscreen modeExit fullscreen mode"
956,"This year's theme for International Women's Day at my employer was #EmbraceEquity, with a slate of women-led talks and panels and some truly inspiring stories of women rising in the ranks of Amazon and AWS.And I love that we're calling out the problem and (in theory) actively working on it, though we still have such a long way to go.In practice, though, my day-to-day interactions look like this:with the occasional(if you know, you know :sevh:)And then, inspired by a tweet from a colleague, I did the math on my actual team, the people I interact with 90% of the time at work:and all the hope and optimism IWD is supposed to inspire was brought crashing down by reality.Don't get me wrong: I am incredibly lucky to work on a respectful, collaborative team of allies, and I have never felt discriminated by my immediate coworkers - they're awesome dudes! But there is something incredibly lonely about never (or hardly ever, if you count Slack) interacting with another member of your gender in your role. I'm jealous of my colleagues that don't have to feel that loneliness, and in my experience, no amount of women in tech meetups can fill that day-to-day gap.  So what can we do about it?I realize that the bigger the company, the more that equity is a marathon, not a sprint. A startup can hire two new engineers and suddenly the numbers are much closer to 50/50. At a FAANG, this process takes years and requires not just desire from the bottom, but buy-in from the top. And the top... well, let's just say it's even lonelier than I am:SourceThis is compared to all corporate employees, which unfortunately are not broken down by job roles, as based on my experience over the past 1.5 years, the numbers for AWS specifically and all engineering roles are much worse:The good news is that the numbers are getting better! But for someone working day to day in a very male-dominated environment, that change still feels far too slow. AWS has shown numerous times that when something matters, leadership can act much faster in a concentrated effort. I can only hope that this pledge to #EmbraceEquity results in more action than words."
957,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Inspired by our ongoing #WeCoded celebration, tonight’s topic is...coding against bias!It will come as a surprise to very few that algorithms, user interface design, and other aspects of the technology we used are just as biased as the people who make them—often unintentionally so.For today's #DEVDiscuss, we want to uplift people, projects, and case studies that are coding against bias.This is a rich topic, so we encourage you to think on it, do some research, and bring some thoughtful considerations to the conversation. Take all the time you need!Questions:Who are some people or projects that are coding against bias?Do you know of any case studies to share?Have you ever used your technical skills to combat bias or other inequity?What are some things to keep in mind when coding against bias?Any triumphs, fails, or other stories you'd like to share on this topic?"
958,"Over my decorated 10-year career in development, I have seen some of the worst commit messages. I don't blame the developer on this either, because it is hard to remember what you just did at the time of the git commit. image was generated using midjourneyIn this 30 days of OpenAI series, I am looking at AI projects and their code to help demystify how any dev can build AI-generated projects.Find more AI projects using OpenSaucedThe last thing I want to do is traverse a git diff and figure it out after a productive day of coding. I love the Nutlope/aicommits.        Nutlope       /         aicommits            A CLI that writes your git commit messages for you with AI      What is Nutlope/aicommits?Aicommits is a CLI that writes your git commit messages for you with AI. During my 30 days of OpenAI, you will see projects from @nutlope frequently. He has been shipping cool projects and sharing them on Twitter.         Hassan El Mghari      @nutlope      I can't believe that my latest side project, AICommits, is at nearly 3,000 stars and 6,000 downloads after only 2 weeks!Version 2.0 is launching next week with many big features like conventional commits and a new UI.           15:51 PM - 01 Mar 2023      How does it work?This post is meant to focus on the AI part of the code, but as soon as I looked at the GitHub, I was surprised to see the use of TABS, jk. I was impressed by this CLI tool that caught my eye, cleye (cleverly named). I built a few CLIs back in my day, and this cleye is the chosen tool for building the aicommits interactions on the command line. I will take a deeper look at cleye in the future and perhaps make something with it.If you'd like to see the CLI implementation, it is a quick read in the src/cli.ts.// src/cli.tsconst request = https.request({  port: 443,  hostname: 'api.openai.com',  path: '/v1/completions',  method: 'POST',  headers: {      'Content-Type': 'application/json',      'Content-Length': postContent.length,      Authorization: `Bearer ${apiKey}`,  },  ...Enter fullscreen modeExit fullscreen modeI have not built anything with OpenAI as of yet, but this is a clean example of how someone could approach it. Now looking at the code src/utils/openai.ts, I can see OpenAI being invoked and using the /v1/completions path. Per the README, this is not the ChatGPT completions but regular GTP-3 text completions. After the REST call, there is some clean-up of the response and this clever error checker. This is required because of the frequent OpenAI downtime and server loads.// src/utils/openai.tsif (response.statusCode === 500) {    errorMessage += '; Check the API status: https://status.openai.com';}Enter fullscreen modeExit fullscreen modeFinally, taking a looking at the createCompletion function, this is the actual place the magic is made. I found this more understandable than reading the OpenAI documentation, which I found a little overwhelming. I wish it had the ability to search (why does it not have search?).I left comments below on what each line is doing.// src/utils/openai.tsconst completion = await createCompletion(apiKey, {    model, // text-davinci-003 - made for longer output, and consistent instruction    prompt, // promptTemplate provided by nutlope    temperature: 0.7, // higher the number, the more random the output    top_p: 1, // like temperature but different results    frequency_penalty: 0, // decreasing the model's likelihood of repeating the same line    presence_penalty: 0, // increasing the model's likelihood of talking about new topics    max_tokens: 200, // how much will this cost you?     stream: false, // partial message sending is off    n: completions, // How many chat completion choices to generate for each input message});Enter fullscreen modeExit fullscreen modeThere is a lot more I'd love to dig into, but I will leave the rest for you to take look. I do recommend installing aicommits locally to try it out. Just be sure to sign up for OpenAI to add your token.If I need to correct something, or if you have some insight into the code, please comment. I enjoyed walking through the code and learning how this works. Thanks to Nutlope for sharing this with us, and be sure to contribute back upstream. Open Source FTW!Also, if you have a project leveraging OpenAI, leave a link in the comments. I'd love to take a look and include it in my 30 days of OpenAI series.Stay saucy. "
959,"Ecommerce has evolved a lot since its start. It hasn’t always been well-designed stores with extensive features and carefully-planned user experiences. A lot of what is fundamental and basic today was revolutionary when discovered at its time.This article goes down the memory lane of ecommerce, uncovering some old-but-gold ecommerce websites, and highlighting the main difference from ecommerce today.  1979: Michael Aldrich and the First Attempt at EcommerceIn 1979, Michael Aldrich invented online shopping through televisions. This was way before the inventions of the Internet and the World Wide Web (WWW). He invented it by connecting a modified domestic TV to a transaction processing computer through a domestic telephone line.Michael Aldrich believed that Videotex was a revolutionary communication medium that was universally applicable and participative, and the first of its kind since the invention of the telephone.Following his invention, two businesses used Michael’s invention: Gateshead SIS with Tesco and Bradford Centrepoint with Wm. Morrison. This allowed consumers to open their TV and choose groceries from a local supermarket. The order would then be sent through the phone line to a local Tesco, where the ordered items would be packaged and sent to the consumer.  1984: CompuServe’s Electronic MallImage SourceCompuServe was one of the first businesses getting close to an ecommerce experience. It was a popular networking service that provided users with emails, message boards, and more. In 1984, CompuServe added a service called “Electronic Mall” that allowed users to buy items from over 100 online retailers through a simple CLI interface where customers could browse different vendors, product categories and even insert credit information for later purchases.You can see a demo of it all here.  1992: Book Stacks Unlimited, the Amazon PredecessorImage SourceContrary to popular belief, Amazon was not the first online bookstore. Book Stacks Unlimited was created in 1992, three years before Amazon. It began as a dial-up bulletin board. They then launched the website Books.com in 1994, which was eventually acquired by Barnes & Noble.Not only did Book Stacks Unlimited offer 500K titles, but they provided features such as editorial book recommendations, book summaries, RealAudio interviews with authors, book search, and more.  1994: NetMarket and the First Sale on the InternetImage SourceIn 1994, Dan Kohn created NetMarket, which would sell a variety of CDs and books. He then marked the first sale of a product over the internet using a credit card: a Ten Summoner’s Tale CD by Sting.According to the New York Times, which covered the story back then, this was the first retail transaction on the Internet using a readily available version of powerful data encryption software designed to guarantee privacy. Dan Kohn said about the purchase that “even if the N.S.A. was listening in, they couldn't get his credit card number.”  1994-1999: The Launch of Ecommerce Giants  1994: PizzaNet (PizzaHut)Image SourceIn 1994, PizzaHut created PizzaNet, their online ordering service. Not only did it allow customers to order from the menu, but it also allowed them to customize the pizza.In the skepticism of how the website might be used, the local restaurant would always call the customer to verify the order to minimize the risk of pranksters.  1995: AmazonImage SourceAmazon launched in 1995 as a book store. Although the design wasn’t too appealing, there were features that were advanced for its time: a virtual shopping cart, secure way of entering credit card details, an internal search engine, product reviews, and more.In the very beginning, Amazon’s engineers used C to code a lot of the features of the website, and used Berkeley DB to store the website’s data.  1996: eBayImage SourceeBay (initially Auction Web) was launched in 1996. It was one of its kind, being the first online auction website providing a person-to-person marketplace. Buyers would present their products, and customers bid on the items to eventually purchase it.eBay was free of charge at the start. However, as their traffic hugely increased, eBay’s founders were informed that they needed to upgrade their hosting account. This led them to take commissions on bids to fund the website.  1997: AppleImage SourceSteve Jobs returned to Apple in 1997. His first line-of-action was to improve Apple’s presence in the ecommerce world. Apple launched their new-and-improved ecommerce website at the end of 1997 aimed at improving customer experience.  1998-1999: NikeImage SourceNike created their first website in 1997. However, it was mainly focused on teaching their consumers more about Nike and their products, rather than selling these products online.In 1998, the Nike website improved to provide consumers the ability to customize their own Nike shoes. It wasn’t until 1999 that Nike moved from editorial content to an online store.  2000-2005: Dot-Com CrashIn the 1990s, the Internet garnered heavy attention and adoption. Web-based startups gained a lot of funding, and all companies suddenly needed to “move to the internet”. Later followed what is now known as the Dot-Com Crash in March 2000 where the Nasdaq index slipped ~77% over less than three years.The dot-com crash took down many ecommerce and internet-based companies that gained success during the 1990s. This affected even big companies like Amazon. Still, some companies like eBay thrived despite the headwinds.  SnowDevil and ShopifyIn 2004, SnowDevil was launched, which ended up being the spark that ignited Shopify. Tobias Lütke and Scott Lake wanted to sell snowboards online, but couldn’t find a software that would help them do that.They initially used a variety of tools and services such as Miva, OsCommerce, and Yahoo stores. However, they frequently ran into trouble when trying to bring their vision to life. According to Lütke they had a “great CSS-based layout done with all these new fanged ‘web standards’”. However, the lack of customization capability that Yahoo provided barely allowed him to change the background color of the top frame.So, Lütke and Lake set out to create a solution that would not only solve their problem, but solve the problems of businesses across the globe. They built Shopify in 2007 and transformed SnowDevil to a Shopify demo store, bringing their vision to life.Shopify now powers over 4.5 million websites worldwide.  Note on 2000s DesignsWhen looking back at some of the designs from the early 2000s, you’ll notice that there was a significant advancement from the HTML, almost only text and disarrayed images design that dominated that 1990s.Image SourceEven though the design was still clunky and crammed, there was a clear usage of layouts and different colors. Ecommerce websites at the time also started using some elements that are now basics to ecommerce, such as a navigation menu and a sidebar for categories.During that period, tech giants like Amazon and eBay continued to innovate with new features that are now core ecommerce features. Amazon added features like Search Inside the Book, allowing customers to search for words inside books. eBay also added a Live Chat feature to provide support for customers.Image Source  2006-2010: Rise of Ecommerce PlatformsAfter the dot-com crash, ecommerce companies and stores steadily regained momentum, and new ecommerce platforms emerged.In 2007, Magento was created by Varien, and it was later acquired by eBay. In the beginning, Varien were building their platform on osCommerce. However, they found it incapable of accommodating all the features and functionalities they had in mind. So, they decided to build a new open-source solution from scratch.With the passing years, Magento grew to be one of the top open source ecommerce platforms at its time. In its first year, it was downloaded over 500K times. Magento’s popularity is due to the customizability capabilities it provided, as well as its open source nature. This allowed businesses to break away from proprietary solutions and take full ownership of their store.Image SourceBigCommerce was launched in 2009, after its founders met in a programming online chat. BigCommerce initially wanted to provide a shopping-cart-only solution called Interspire. However, their consumers found it difficult to manually find, install, and update their software on a server, which lead to the change from Interspire to BigCommerce.BigCommerce gained popularity among businesses that didn’t want the hassle of handling the technical parts of ecommerce, but still wanted to have the customizability options that allowed them to grow and scale. By 2011, BigCommerce was powering almost 10K stores.Image Source  2010-2020: The Platform PuzzleAs the 2010s started, ecommerce saw a rapid uptake, and over the decade, global ecommerce sales grew 8-fold.During this period, ecommerce saw a lot of shifts in user behavior as new platforms emerged, effectively reshaping how users interacted with brands online.  Design ChangesThe 2010s show a big improvement in the design and functionalities that ecommerce stores provided. Many of the features that were carefully implemented in the 1990s and early 2000s became fundamentals that every ecommerce store had.With more businesses moving towards the ecommerce landscape, they each needed to stand out through unique branding and design. Ecommerce platforms that started emerging in the late 2000s provided more customizable options for the storefront.This also lead to newer technologies, concepts, and approaches rising that would reshape websites in general, including ecommerce storefronts. Concepts like Jamstack, coined by Netlify in 2015, and the launch of static-site generator frameworks like Gatsby or Next.js, allowed businesses to have more control over designing their storefront and provide a better user experience.  Mobile CommerceThe 2010s also marked the rise of mobile commerce. Ecommerce businesses started rolling out mobile apps that allowed their consumers to access the same web functionalities from their smartphones. This went through its own timeline of evolution, starting from a simple design and advancing to more sleek and user-experience tailored design.This elevated the development of ecommerce stores from only catering to a website to multiple platforms. Developers needed to design and build APIs within their existing systems to cater for mobile development.Image Source  Social CommerceIn the mid 2010s, social commerce started emerging. In 2015, Pinterest rolled out its first shopping capabilities through Buyable Pins. Users were able to purchase products from Pinterest. Instagram also announced Instagram Shop in 2018 which allows users to browse and purchase products from businesses without leaving Instagram.With the introduction of social commerce, businesses had now another platform to attract new customers. Businesses invested in social marketing strategies to ensure potential customers can discover their products through these platforms and, in turn, convert to purchasing customers.Image Source  Stripe and the Emergence of New Ecommerce InfrastructureWhile ecommerce platforms evolved, a new type of infrastructure started to emerge to further improve the commerce experience. From analytics and backend-focused tools, to new solutions solving complicated issues related to areas such as payment and distribution. The brothers Patrick and John Collison founded one of the most notable infrastructure solutions in this new commerce era in 2010. Through their side projects, they found it difficult to accept payment online and wanted to fix that. So, they developed a quick solution in 2 weeks and were able to process their first transaction. After making several iterations over the next few months, they launched Stripe under the name dev/payments.Image SourceAs indicated by its initial name, Stripe was aimed towards developers at first. The founders then realized that Stripe solves problems the entire internet faced. According to Patrick, existing solutions like PayPal and Google Checkout were “these confusing things,” and they wanted to solve what these existing solutions couldn’t.Stripe reshaped the payment landscape, making it easy for anyone to start selling online, while providing a payment infrastructure that facilitated building custom setups. A lot of startups afterward took it upon themselves to cover other areas of the ecommerce infrastructure with similar developer-first approaches.  2020s and Ecommerce ModularizationThe ecommerce landscape has evolved to include not only web as a sales channel, but also mobile apps, social apps, and more. This spawned the need for ecommerce solutions that provide omnichannel support, frontend flexibility, and an extensive feature offering.To accommodate those needs, the 2020s saw new and existing ecommerce solutions start to adopt headless and composable architectures.  As the demands for ecommerce heavily evolved, the previous methods used to create ecommerce applications, which were initially monolithic and tightly coupled, are now limiting. Developers now seek modular solutions that are less rigid and open to customizations. This would remove the restrictions on their businesses and the need for hacky workarounds.The rise of point solutions that focus on specific domains within ecommerce has enabled this move towards modular solutions. Developers can combine these services and create a modern product stack that meets businesses’ exact requirements without compromising scalability.As ecommerce, and the technology sector as a whole, is a rapidly growing landscape, new trends will continue to rise and fall. However, one thing remains consistent throughout the years: businesses will continue to strive to exceed their current potential. To ensure they can innovate and build unique experiences, ecommerce solutions must adopt a modular approach ensuring scalability and flexibility."
960,"Okay, so this post will basically be a rant about my experience working on a design system for almost 2 years now. I've failed to come up with a solution to this struggle, so I feel like I'll just write it out of myself and see if people out there are fighting the same thing and if they managed to solve it in any way.  The struggle cycleThe thing is I'm talking about is basically an endless cycle involving UX and engineering and it goes like this:You work with a UX designer on the design system team and you come up with a design for a component, let's say an Accordion where there's text on the left side and a chevron on the right, something like this:You go into your cave and implement this design with whatever fancy and cool stack your team is using for your design system. You come up with the best API ever, you feel very proud, UX approves your implemented component and you release it, you go to sleep.Next day you wake up, have some breakfast, brew that perfect coffee and open slack and you see the following message: The Accordion is not working, how can I place the chevron to be on the right side of the text? After you survived your heart attack, you start to wonder, why on earth would they want a chevron on the left side? That's not at all how the Accordion is designed, so you ask the developer. The answer is that they got handed a design in let's say Figma, and they saw that there was an Accordion with a chevron on the left side, so they imported your Accordion component and searched for a way to place the chevron on the left side, but it was nowhere to be found. Of course it was nowhere to be found, since it wasn't a requirement, but now you're in a place where you are right because you implemented what the design was, the developer is right, because they just want to implement a design the were handed, so where did it all go wrong?  Understanding where it goes wrong.Well, here's where it all goes wrong. In design tools like Figma, it's just too easy to customise a component. You pull the component in, you notice something you want to change, right-click, Detach and boom, you're free to do whatever you want to the design. You shift that chevron to the left-side (which by the way might be a valid change), you hand it off to your developer and onto the next one. Without proper organisation wide education on how to use the design system and a very disciplined approach from UX designers, this is bound to happen in every org. And by the time you, the developer on the design system team, catch this error, it's all too late. UX already spent a ton of time coming up with the design, they (understandably) feel attached to it, the developer on the product team also spent a bunch of time implementing that design and now you're faced with the following task.  The questions you have to deal withYou have to tell them that the Accordion is not supposed to be used like this, you have to involve your UX designer and you have to find the answer to a bunch of very tricky questions, usually in a short amount of time.Does this change make sense in the context of the system?Do you want to allow Accordions with chevrons on the left side company wide?Should you add some escape hatch so that this team can move forward with their feature and hack the chevron to the left side?If you add that, how do you make sure that it's not abused in other places and that your product(s) have a consistent UI?Do you tell them that they have to stop the feature work and redesign it and live with the chevron on the right side? Does your team even have the political power to say something like that?It's a big can of warms that get opened repeatedly, ultimately, because UX tools are not good at enforcing the constraints of the system on designers. If you faced this problem in the past, please leave a comment, I'm very interested in how other organisations solve this problem."
961,"Hola amigos.  It's been a long time since I last rapped at ya'.  (If you know what that's from, we're buddies for life)Today I've got another installment of the addendum to my ""SEO for Non-Scumbags"" series.  In this series-within-a-series, I'm walking in detail through applied keyword research tactics.  This may pickup steam, too, because we're starting to teach clients to do this, instead of just our staff.At any rate, today I'm going to talk about tool-user campaigns.  Like the last type of campaign, ""ownership,"" tool-user campaigns are pretty straightforward to execute.Tool-User Campaigns: A Quick DefinitionIn a sense, this content ideation tactic is as simple as ""if it's about {tool}, let's create a post about it.""  You're essentially looking for winnable keywords with volume that contain a specific term, where that term is a tool.From a segmentation perspective, you're reasoning that there's a pretty good chance anyone googling that tool would make a good user or customer.  Or, at the very least, someone you want to reach.For instance, Architect makes a continuous delivery platform, aimed to make life easier for developers doing devops-y things.  So if they create a piece of content about using the Terraform K8s provider, they're basically saying ""we're assuming that if someone is using and Googling Terraform (or K8s), it's probably someone we want on our site.""A tool-user campaign is when a site works a steady diet of content like that (targeting users of a tool, generally with tutorials).The Broader Goal of Tool-User CampaignsThere aren't quite as many wheels within wheels with a tools campaign as there are with ownership campaigns, where you have the brand impression consideration in SERPs as well as the traffic consideration.  A tools campaign is just ""get {tool} users onto the site.""The nuance here tends to occur a little further down the marketing funnel.Creating terraform tutorials that answer searcher questions will bring aspiring and current terraform users to a site.  But do those users stick around and continue interacting with your brand?  Do they eventually convert or recommend you to their friends?At some point you need to close the loop and confirm your hypothesis that the set intersection between users of that tool and your customers is not depressingly empty.  You need to confirm eventual conversions from this content.If you do that successfully and you have the budget, it's now time to put on your best poker face as you gleefully slam as many chips as possible into the metaphorical middle.How To Do the Keyword ResearchI'm going to use the same scenario as I did in the last post, which is to pretend I was interested in attracting search engine traffic for lead generation with Hit Subscribe.  However, this time, we need to think a little about segmentation up-front.1. Identify a Tool Your Target Persona Probably UsesThe first step is to think of who you want to attract, and to brainstorm what kind of tools they would use.  But you need to avoid going too broad or risk bad segmentation.  For instance, keyboards and mice are tools that your target market probably uses, but they're also tools that every target market uses.For Hit Subscribe, what would potential leads be likely to use that also segments decently?  We mostly deal with early-stage founders or people in the marketing org chat that interact with blog posts.So let's go with Wordpress as a tool.Not all Wordpress users would ever be Hit Subscribe customers by a long shot.  But a good cross section of the kinds of leads we want are likely to use Wordpress and possibly even google things related to it.  And we can further tighten segmentation at the individual keyword level by looking at the implied question.2. Do a Broad Search for Winnable KeywordsNow let's go out and track down some Wordpress keywords.There's just so many of them that I set an upper bound difficulty of 10 in ahrefs.  This ensures that Hit Subscribe's site can win any SERP I'll be looking at.Right from the jump, these keywords are trash for our purposes.  I'm not interested in creating content that answers whether ""Wordpress"" is down, nor am I interested in local Canadian or Australian searches about hosting.But there's no reason to get discouraged.  It's just a question of combing through, looking for things that people responsible for nascent programs might want to know.  After all, we have a ton of keywords to pick from.3. Filter by Segmentation, Asking Whether These are Questions Your Target Persona Would AskI gathered data on 9 keywords, shown in the screenshot below.  In doing that, I filtered out a whole lot of keywords, for a variety of reasons.A lot of the keywords had to do with hosting decisions, and the marketer probably isn't the one making the hosting decision.Many of the keywords were too technical in nature (questions about APIs, PHP code, etc), meaning it's more likely a Wordpress developer asking the question.Some were too beginner for a marketer.  The marketer is going to know what a CMS is and the very basics of how to use it.There were other, more granular reasons besides, but hopefully that communicates the gist.  You need to ask yourself, ""is there any chance that my experienced marketer or marketing-newbie-technical-founder would ask this question?""Here's what I've got:Look at these, and observe that they at least plausibly segment the audience based on the question they person is asking:How do I update a Wordpress theme?How do I (via a tool) add marketing automation to a Wordpress site?How do I embed videos in Wordpress?How do I change the domain with a Wordpress site?How do I get Google reviews going on my Wordpress site?How do I remove a Wordpress theme?How do I ""unpublish"" a Wordpress site?How do I edit the header of a Wordpress site?  (The fuzzy nomenclature here indicates they might not be familiar with marketing jargon -- i.e. could be a founder)How do I change my site title in Wordpress?Notice that these are all things that you squint and probably imagine someone responsible for content marketing doing in the early stages.4. Do a Sanity Pass for Gotchas and SERP FeaturesOnce you have the keywords, you're going to want to do a sanity pass to make sure you haven't miscalculated.The first thing that can commonly happen with tool-based keywords is you accidentally log navigational keywords.  For instance, imagine that I'd logged the keyword ""wordpress support"" in my list.Even if volume and difficulty look good, the click through rate is going to be nonexistent.  Those searchers are all looking for the contact info on Wordpress.com, not a blog post entitled ""What Is Wordpress Support, Anyway?""Another more subtle thing to look for is when the tool itself absolutely dominates the SERP.  One of the downsides of tool ideation is that you are almost always, almost by definition, teeing up an upper bound of second place.  All else being equal, if the tool vendor itself targets any given SERP mentioning their tool, they will win it in first place.That can be fine in most circumstances, especially if they're winning it with some deeply half-assed documentation.  But if they're targeting it from a lot of angles, with genuine intent, they can rank multiple times, often with sub-entries and schema, all of which serve to drive your article way down below the fold.5. Think of What To Do with the TrafficIf you look at the aggregates in section (3), I've just sketched out 9 posts and about 3K visitors per month to Hit Subscribe's site.  (It would actually be WAY more, since most of these keywords have rich synonym traffic potential).  That's not too bad, especially compared with the ownership campaign from the last post, which is always a case of playing on hard mode.But there's one current major issue with this plan.What on Earth do I do with this traffic?I mean, I'm not going to say, ""hope you enjoyed that tutorial on embedding videos in blog posts, wanna buy $50K worth of content?""  When you target someone who might be your persona, based on their use of a tool incidentally related to your offering, you don't have a strong call to action right out of the gate.This is why ownership campaigns are so popular.  The next step is dead simple: ""hey, you're googling the thing I do, wanna pay me to do that thing!?""Here we need more creativity.  We could do any number of things:Invite them to subscribe to our newsletter of tips for newbie Wordpress site owners.See if they'll sign up for a webinar about how to avoid SEO mistakes with new Wordpress sites.Pixel them and remarket to them through social media about blog posts or whatever.Start a line of business offering Wordpress administrative help.It can feel a bit ocean-boily.  And when you add to the mix that Hit Subscribe only has the current means for one of those options, it can feel even more discouraging.5. Recognize that a Plan Doesn't Mean Current Capability and Proceed AnywayBut don't let it discourage you.  It would probably take these articles 4 months to rank on Hit Subscribe's site, and more than that to drive meaningful traffic.So in the first place, we have time to build out supporting funnel assets.  And, even if we don't, having a steady stream of decently qualified traffic to the site is one of them good problems.  We can always figure out how to appeal further to the traffic at some later point.But what we can't do is go back in time in 6 months and write a blog post today.Recap and SummaryTool campaigns are among the easiest, from an ideation perspective.  I think that's because it tends to be more a matter of narrowing down than of having ex nihlo inspiration.Identify a tool or tools that there's a chance your target persona would use.Start out with a broad list of keywords, filtered lightly by volume and winnability.Cull that list heavily based on segmentation by asking whether each term is something your target person would ask.Delete or deprioritize any remaining keywords if they're navigational or dominated by the tool itself.Start thinking about what kind of call to action would appeal to this searcher, in parallel with planning and executing the content.Tool campaigns are great.  They're easy to ideate about and have much more traffic potential than ownership campaigns, letting you really drive a lot of traffic.  You'll also build topical authority through the ol' knowledge graph, making your articles even more likely to rank, and these tend towards the easy side for fulfillment of the content.But you can run into the competition with the tool itself, and there's a less obvious conversion path for the target persona.For my money, though, pros dramatically outweight the cons.  I'm a tool campaign fan."
962,"Humanity is always progressing. However the progression is not linear. We tend to experience periods of apparent slow progression in technology, followed by sudden explosions of innovation and growth.This is nothing new. We have had in recent history:the agricultural age,the industrial ageand most recently, the information age. Each time we enter these new eras, society changes drastically.I am here to argue that we have recently entered a new age, an age which I am coining as ""The creation age"".  The Creation AgeIf you are in any doubt whether we are entering a new age, just look at ChatGPT.2 months to reach 100 million users. But not only is the growth explosive, it is utilising a ""new"" technology and embracing it...AI.Now I say ""new"" as AI has been around for decades. The idea of a computer being intelligent is something that humans have considered for decades, even centuries.But where this is different to previous AI implementations is in adoption and acceptance.People are using AI regularly in their day to day lives, more importantly they are actively using it (not being at the mercy of it or passively using it, as is the case with feed algorithms and search engine results).This shift is monumental, I am just not sure many people realise just how significant it is.  Why is this a new age?A new age occurs when there is a rapid shift in society, often directly linked to an advancement in technology. The agricultural age meant that food scarcity was far less of an issue (in the developed world), and food abundance (or should I say efficiency in production) meant that more time (across the population as a whole) could be spent on other pursuits other than farming. Then came the industrial age, where analogue machines replaced a lot of manual labour. This allowed us to produce far more as a society with fewer people hours, yet again changing valuable skill sets.Most recently we had the information age. An age where people from around the world were able to share knowledge almost instantaneously and at next to zero cost. An age where information was no longer localised, resulting in rapid globalisation. And now we enter a new age. An age where ""digital brains"" are able to produce content at a decent level, comparable to that of an average human, in certain specialised disciplines. Artists are being displaced by AI image generators. Copywriters are soon going to be replaced by machines that write copy for them etc. etc. But more importantly, as with any change of age, more can be produced with less resources. One individual can now produce the same as 3 people could, and this will only accelerate. Also the skills required change. For example: I no longer need to spend years perfecting my skills as an artist, instead I need to spend time perfecting my skills at prompting and adjusting the output of AI, at curating the output to meet my needs.I need to be creative in a different way, but in a way that has a much lower barrier to entry and a much shallower and shorter learning curve.This is what heralds a new age. A shift in how society values skills, an increase in output and a great shift that results in new opportunities. A shift that results in old skills and old businesses no longer being as relevant, or even being replaced by those that can operate at the new required scale.  Why call it ""the creation age""?It is quite simple really, each age is defined by the key characteristic that drove societal change. Farming for the agricultural age, factories and production at scale (industry) for the industrial age, the internet (dissemination of information at reduced cost and increased speed and scale) for the information age.The age of AI is going to result in creation at an unprecedented scale. AI can write music (reasonably well), create art (pretty well), write a poem (well) and is already make great strides in video editing, video creation and more.AI takes previous computation (generation of data sets for example) and can create new visualisations, new analysis, new perspectives and even more variations of data and dare I say even new data.The very core of any AI is to take some inputs and generate something ""new"" from them, sometimes in a very rigid way (such as data analysis), and sometimes with an element of chaos (AKA ""creativity"") in the form of art or literature etc.But it is more than that. Humans have finally created something that is capable of ""creating""...albeit at a very simple level. And AI can do something that we cannot. It can create at a huge scale. We are confined by our physical form to have only so much creative ability due to the limited processing power of the human brain. AI does not have the same limitations, and although it may not think like us, or have the same breadth of skill, it can specialise in something and work at a much faster rate. Want more output? It can just utilise more computing power (up to current technical, energy and physical space limitations of course).   Be prepared for change.When a new age arrives, society adapts.Old jobs and skills become less relevant and valuable. New jobs and skills become more valuable and relevant.Tools and processes emerge that further increase the productivity of an individual. Those who embrace and utilise those tools flourish, those who refuse to adapt tend to fall behind.  What do you think?This was just a random thought I wanted to share. Do you believe we are entering a new age / era? Do you think society will change rapidly over the next few years? Or do you believe that AI will change very little?I would love to hear your thoughts! 💗"
963,"I've had it.  I've been quiet on this subject for far too long.  And now I feel compelled to finally crank out this angry diatribe.  If you're a web developer (and most of the people reading this article are web developers), then for the love of all that is holy, please STAHHP screening email fields against an ""approved"" set of Top Level Domains (TLDs).You may think that you're really clever with your super-advanced email validation.  You may think that you're forcing users to enter a ""valid"" email address.  But I've seen this done incorrectly sooooo many times that, by this point, I'd bet there's a good chance that you're screwing it up - and pissing off some subset of your users.  HistoryAlmost as soon as you start learning web development, you also learn that you should be validating user inputs.  Ideally, you're validating those inputs on the backend and the frontend.  (Because it's clunky as hell to submit a form to the server, only to have it spit everything back at you because something didn't look ""right"".)And even though frontend validation is only half of the equation, there is a ton of value that can be provided to the user by giving them immediate feedback, in the browser, about fields that don't pass muster.  It's elementary to warn a user that a required field is empty or that a given input is too short/long.  But for as long as I've been doing this (a quarter-century), it's always been something of a challenge to properly validate email fields.Originally, email validation was fairly straightforward.  Sometimes it was done with regular expressions.  Sometimes it was done with more ""manual"" checks.  But the basic validation went something like this:Ensure that there are no invalid characters in the email address.  (For example: a copyright mark - ©.  There is no valid email address that contains ©.)Ensure that even the allowed ""special"" characters do not repeat.  (For example: . is acceptable - and commonly used - in email addresses.  But there is no valid email address that contains ...)Ensure that there's one - and only one - @ character in the email address - and that there are non-empty strings on both sides of the @ character.Ensure that the portion to the right of the @ character contains at least one . character.  (The portion to the right of the last . character - after the @ character - is assumed to be the TLD.)Ensure that the email address's TLD is ""valid"".But it's that last point that causes all sorts of problems...I remember the early regular expressions that I'd see for email validation.  They usually took everything after the last . and checked it against a list of ""known"" TLDs.  And, for a little while at least, this was... workable.  Because there was a finite - and fairly static - list of valid TLDs.In the ""early days"", nearly all valid emails ended in .com or .net or .edu or .gov or .org or any of the country-specific TLDs (e.g., .uk).  So most email validation scripts tried to check the last portion of the email address against these ""known-good"" TLDs.  The TLD boomBut nowadays, there's a huge proliferation of valid, working TLDs that have nothing to do with the old stalwarts like .com or .net.  Your website can have a perfectly valid/functional TLD like .pizza or .health or .voyage.  And of course, if your web presence can use those TLDs, then it's entirely possible that your email address may also use those TLDs.Granted, the vast majority of all websites (and hence, all email addresses) still end in a ""common"" TLD like .com or .net or .org.  But every single day there are new websites - and new email addresses - coming online that do NOT use those common TLDs.There are still sooooo many sites out there that try to do a strict validation of your email address - and they attempt to do this by checking the TLD against a list of ""known-good"" TLDs.  The problem arises because almost none of these sites are fastidious about ensuring that their list of ""known-good"" TLDs are truly up-to-date with the actual list of real, live TLDs that are available.  My own private hellMy CV site is at https://adamdavis.codes.  My email address is also hosted under adamdavis․codes.  Obviously, it doesn't have a ""common"" TLD.  I've done that for two specific reasons:When I first setup my site, adamdavis.com simply wasn't available.Even if adamdavis.com was available, I'm extremely happy with adamdavis.codes.  I'm a coder.  The .codes TLD is a perfect choice for my CV.  And as such, it only makes sense that I'd have an email address under the same TLD.This isn't the only time I've delved into ""uncommon"" TLDs.  My latest project is https://paintmap.studio.  I also previously had an email address with a .voyage TLD.When I first started using these ""uncommon"" TLDs, I'd find that my email address would frequently get rejected from all sorts of online forms.  The form would give me a validation error, stating that my email address isn't ""valid"".  But... it absolutely IS valid!To be fair, I have found that email addresses, like my personal adamdavis․codes address, are indeed ""passing"" many more form validations nowadays.  But it's still far-too-often that I'm trying to submit an online form - and yet I'm stopped when the website tells me that my perfectly-valid email address is... ""invalid"".You know what happens when a website rejects my perfectly-valid email address?  Well, if the activity I'm trying to complete is in any way optional, I simply QUIT the process.  I've abandoned shopping carts that had hundreds of dollars of items merely because the jank-ass website claimed that my email address was invalid.  I've abandoned job applications for the same reason.Yes, I do have a Gmail account.  And in those scenarios where I feel compelled to complete the process, I switch out my preferred .codes email address with my Gmail address.  But I don't do this unless I feel that I simply must complete the process.  And whether I abandon the process or switch to my Gmail address, the whole failed-validation process simply infuriates me.When the ""new"" TLDs first started rolling out, I found this process to be annoying - but understandable.  It was easy to see how the web teams supporting these features simply weren't keeping up-to-date with the latest TLD specs.  But today?  In 2023??  I'm sorry, but it's downright unacceptable.  What do you think you're accomplishing?Frontend (i.e., JavaScript) form validation is, for the most part, a good thing.  The last thing you want to do is give the user a form that allows nearly any completely-illogical value to be submitted.  But there's a point where strict validation undermines the user experience.  And in some cases, it can downright alienate your users.Take email validation for example.  When I'm implementing email address validation in my forms, I tend to use this NPM package: https://www.npmjs.com/package/@toolz/looks-like-email.  (HINT: I wrote this package.)  It does exactly what the title implies:  It tells me if a given value looks like an email address.No, it's not an acid test designed to strictly filter out any potential string that could possibly be a bogus email.  It doesn't try to match against all known-good TLDs.  When I use this package, it's entirely possible that someone may still enter an invalid email address.  And you know what?  In most cases, I couldn't care less.Because, if someone manages to sneak an invalid email address past my @toolz/looks-like-email package, they're usually just hurting themselves.  For most systems that I build/maintain, an ""invalid"" email address will simply mean that they don't get the notices they might otherwise expect to receive.  But those edge cases would only occur if someone's trying, very hard, to find an invalid address that will pass my filter.  And if they're trying that hard to subvert the filter - I don't care.  Let them.There are also some times when you may not need to validate an email field at all.  (Or, at a maximum, simply validate that some value's been entered.)  We've all seen (or worked on) sites where you must verify your email address before the app will allow you to do anything meaningful.  In those kinda scenarios, is it really a tragedy if someone puts BS data in the email address field?  The only result will be that they won't be able to properly verify their account (and begin using the app) until they do enter a valid email.Of course, there are many other form elements that can suffer from being overly strict.  For example, I once worked at a company where the user was expected to enter first name and last name values.  In the interest of trying to provide ""complete"" frontend validation, someone set those fields to be invalid if either one contained less-than-three characters.  You probably know where this is going...Although it's fairly uncommon in the US to have a first-or-last name that consists of fewer than three characters, those names do exist.  In particular, there are many people, especially those of Asian descent, who have first-or-last names that consist of only two characters.  Once the app went live, we immediately started receiving complaints that some people could not complete the online form.I understand that we commonly set first-and-last name fields as being required - meaning that they must contain some type of value.  But if someone only puts, say, their first initial in the first-name field, is that really hurting anyone?  Is it really gonna crash the system?  Or is it just an overly-fastidious frontend developer deciding - on their own - that every user must enter first/last name values that are over a certain length?Another good example is phone fields.  I've seen an increasing number of phone fields that try to tightly restrict the purely-numeric values that you can enter.  But what happens if you don't have a direct phone line?  What happens if your phone number looks like this:+1 904-555-1234 ext. 42Enter fullscreen modeExit fullscreen modeYes, I have seen some online forms that provide a separate field for Extension.  But most don't.  So if the only way to reach this person is by entering an extension, and you don't let them enter an extension, you're forcing them to only enter the ""main"" number - which might connect the caller to the company's main line - and the person who answers may not even know how to forward the call to the user who completed the online form.Here's another example of user input for a phone field that many online forms will try to block:+1 904-555-1234 (ONLY BEFORE 5PM)Enter fullscreen modeExit fullscreen modeIn this example, the user is trying to tell you, in no uncertain terms, that you should not try to call this number after 5PM.  But if you've already decided, in your all-knowing form-developer mode, that no one should ever be allowed to enter alphanumeric characters in the Phone field, you're denying the user the ability to provide these sorts of valuable instructions.  Don't be cuteThe main lesson here is:  Don't be cute.  Yes, you should strive to provide useful form validation.  But if you're patting yourself on the back because you're certain that you've blocked every conceivable edge case... there's a good chance that you've also blocked some valid input.  And when you block valid input, you run a severe risk of alienating your users.Also, try to be realistic about just what risks exist if someone enters ""bad"" data in a given field.  Sure, you may believe that a phone number should only ever be numeric.  But is it really hurting anything if you allow letters in that field and store it on the backend as an alphanumeric?"
964,"I really enjoy reading posts where authors talk through a mistake that they have made and what they learned from it. I find these posts to be really relatable and enjoyable to read. It's nice to hear someone teach you something from a place of humility, and when folks are talking about the lessons they've learned from their own mistakes, they often have an empathetic, approachable tone.So, with that in mind, what's the biggest mistake you've ever made while coding? What problems did your mistake cause? How did it happen? And, what did you learn from it?"
965,"People of marginalized identities are no strangers to the concept of advocacy. We advocate for ourselves, for each other, for our work, for our community — sometimes all at once. It's exhausting, right?This is why we also look to allies (coworkers, colleagues, and friends who are not marginalized based on a particular identity, such as race or gender) to advocate for us and with us. And yet, sometimes allies get stumped: when they don't know how best to advocate for us, they freeze up and remain silent, which allows the status quo to continue.So let's talk about it.  What does effective advocacy in the workplace look like?Feel free to share ideas, lived experiences, questions, and concerns. All your intersecting identities are welcome in this conversation! And, of course, a reminder to abide by the Code of Conduct while we discuss. I promise to moderate the discussion swiftly and with nuance. ❤️@abbeyperini wrote an awesome article with some great, actionable ideas for advocating for women in the workplace specifically:8 Ways to Support Women DevelopersAbbey Perini ・ Mar 8#wecoded#womenintech#programming#careerIf you know of another good article on this topic, please drop it in the comments! "
966,"There is a before and after listening to these letters together: ZSH. You may wonder: Why did not I hear about this before? D'oh!ZSH (Z Shell) it's a real evolution, modernize terminal things with simple solutions. But the thing getting better when you discover Oh My ZSH! a framework for ZSH that boost your productivity and improve your workflow.  So, why?No more cd (change directory) command. Just use:CommandResultfolder/write the folder name with / at the end..go back one folder (parent dir)...go back two folders (parent from parent dir)......go back five folders/go to root~go to home-jump to previous pathtake the 3 in 1 command who create a directory and automatically change the path to itCommandResulttake <url_file>Download gzip file (.gz, .bz2, .xz) and uncompresstake <git_repo>Clone git repo from url (http, ssh)take <folder>Create a new folderJump between last and current path with - (like a TV remote control)zsh_stats will give you a list of the top 20 commands and how many times they've been runTab completion is another great feature. For example, typing ls - and pressing TAB will list all of the command's options, along with a helpful description of what they doAlias commands. List all with alias or filter it with grep for example alias | grep gitGlobbingCommandResultls *.txtlist all txt files in the current directoryls **/*.txtlist all txt files including subdirectoriesls **/(READ)*.*find for files that start with the word READls **/*(READ).*find for files that end with the word READls **/*(READ)*.*find for files that have the word READ anywherels **/*(.)search for files onlyls **/*(/)search for folders onlyExpanding File Names and DirectoriesCommandResulttouch name-{1..4}.txtcreate files name-1.txt, name-2.txt, name-3.txt, name-4.txttouch name.{css,js,test.js}create files with different extension name.css, name.js, name.test.jscp folder/name.js{,.bak}create a copy of the file ending .bakdiff folder/{new,old}/name.jsview differences between two filesmkdir -p {source,build,man,help{/pages,/yelp,/images}}create a complete folder structurewget http://site.com/folder{1,2}/pic{001,002}.jpgdownload multiple filesExpand environment variables $ENV followed by TABExpand kill command followed by TABRecursive path expansion. /u/lo/b expands to /user/local/binSpelling correction and approximate completion, automatic correct when having minor mistake typing a directory nameHistory substring search writing a command and pressing the up arrow cycles through previous usagesAutocomplete, jump between options with tab, and press return for selection. Works with directories, files, and commandsRun history command with ! followed by the number in history, like !137Entering !! will bring up the last command. This is handy if a command fails because it needs admin rights. In this case you can type sudo !!  PluginsThere are a lot of plugins to use. It's recommended to explore the options and use what is good for your needs.My recommendations are:sudo to easily prefix your current or previous commands with sudo by pressing esc twicecommand-not-found to provide suggested packages to be installed if a command cannot be foundextract that extracts the archive file you pass it, and it supports a wide variety of archive filetypesgit provides many aliases and a few useful functionshistory-substring-search a clean-room implementation of the Fish shell's history search feature, where you can type in any part of any command from history and then press chosen keys, such as the UP and DOWN arrows, to cycle through matchesweb-search adds aliases for searching with Google, Wiki, Bing, YouTube and other popular servicesz command that tracks your most visited directories and allows you to access them with very few keystrokesI've another extra from plugins from external repositories to add more functionalities:autosuggestions suggests commands as you type based on history and completions.syntax-highlighting Fish shell-like syntax highlighting for ZSHohmyzsh-full-autoupdate Automatic update of custom plugins and themes Oh My Zsh  ThemesThere are also a lot of themes, but my favorite is Powerlevel10k because is easy to set up and use  GitIncredible and complete aliases for GitZSH cheatsheet for git pluginCamilo Martinez ・ Apr 20 '21 ・ 3 min read#productivity#zsh#git#terminalGit Status Prompt can contain the following bits:segmentmeaningmastercurrent branch#v1HEAD is tagged with v1; not shown when on a branch@5fc6fca4current commit; not shown when on a branch or tag⇣1local branch is behind the remote by 1 commit⇡2local branch is ahead of the remote by 2 commits⇠3local branch is behind the push remote by 3 commits⇢4local branch is ahead of the push remote by 4 commits*5there are 5 stashesmergemerge is in progress (could be some other action)~6there are 6 merge conflicts+7there are 7 staged changes!8there are 8 unstaged changes?9there are 9 untracked files  Shortcuts  Edit long commandctrl+x+e open the command on an editor to easy edit, once save and close the editor it will be updated on the terminalYou can set your favorite editor, for example run export EDITOR=""code -w"" to use VSCode  Park a commandctrl+q ""parks"" the command you're currently typing and takes you back to the prompt, letting you start over and type another command. Once you run that other command, the original command is un-parked and refills the command line so you can continue.This is good for if you, say, forgot to do a command before a command.  Reveal aliasctrl+x a will transform the alias to the real command  Path historyZSH keeps the history of directories you visited so you can quickly switch to any of them.To see the list, type dirs -v. Switch to any directory in this list by typing ~# where # is the number of the directory in the list.  HooksYou can personalize actions (before and after a command) with ZSH HooksReveal the command behind an alias with ZSHCamilo Martinez ・ Feb 22 '21 ・ 2 min read#productivity#bash#tutorial#terminalCommand validations with ZSHCamilo Martinez ・ Mar 8 '21 ・ 3 min read#productivity#zsh#tutorial#terminalThat's All Folks!Happy Coding 🖖SourcesLearn the basics of the ZSH shellA Guide to Zsh Expansion with ExamplesHow to Use Brace Expansion in Linux's Bash Shell75 Zsh Commands, Plugins, Aliases and ToolsZSH Globbing as an Alternative to Find Commandhttps://opensource.com/article/18/9/tips-productivity-zsh"
967,"image created by Margaux Peltat for the Chilled Cow YouTube channelTime for #DEVDiscuss — right here on DEV 😎Learn How to Setup a CI/CD Pipeline from ScratchPavan Belagatti ・ Mar 1#tutorial#devops#go#kubernetesInspired by @pavanbelagatti's Top 7 post, tonight’s topic is...Continuous Integration and Continuous Delivery/Deployment (CI/CD) pipelines 🔁Questions:In your opinion, what are the pros and cons of using CI/CD in development?Which tools are you using for CI/CD?How is your pipeline set up? How could it be improved or simplified?Any triumphs, fails, or other stories you'd like to share on this topic?"
968,"I just got my six year badge. While I've been a member of DEV for six years, I lurked for the first few years and didn't really become active till the pandemic hit and I needed more community. Blogging here helps me cement what I am learning. One of the best way to learn is to explain it to someone else.It's been a great six years and I hope DEV continues to grow. I trying to help by being a DEV Trusted Member, where I can help point out great content.It been great to express ideas here and share things I build. There are a lot of great developers and content here.-$JarvisScript git push Enter fullscreen modeExit fullscreen mode"
969,"We’re hosting a virtual WeCoded meetup on the WeCoded Discord at 3pm ET / 12pm PST / 8pm UTC on Friday, March 10, 2023. We’d love for you to join us!The conversation will be a roundtable discussion on topics related to gender equity, diversity, and inclusion in the tech and software development industries. It will be moderated by a panel of excellent DEV Team members: @devencourt (they/them), @caroline (she/her), and @rachelfazio (they/them).The Discord is open, so join us! We can’t wait to chat, connect, and celebrate together.          WeCoded 2023                  Check out the WeCoded 2023 community on Discord - hang out with 133 other members and enjoy free voice and text chat.                discord.com      Please review the rules upon joining! The DEV Code of Conduct applies to conduct in the Discord, and your actions in the WeCoded Discord may have repercussions on your DEV account status as well."
970,"Heyo!Hope y'all all have fabulous weekends. 😀Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugWatching The Unbearable Weight of Massive Talent or some other awesome flick 🍿"
971,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   Why Oh My ZSH Is So Cool?If you’re looking to up your terminal game, consider checking out @equiman’s series terminal-helpful-tips. The most recent entry discusses Oh My Zsh, a framework for ZSH that offers new shortcuts, plugins, and themes that will boost your productivity and put a smile on your face.Why Oh My ZSH is so cool?Camilo Martinez ・ Mar 4#productivity#zsh#terminal#tooling  The Coolest JavaScript Features from the Last 5 Years@ppiippaa walks us through some of the most useful, interesting, and perhaps lesser known features added to JS in the last 5 years. The Coolest JavaScript Features from the Last 5 YearsPippa Thompson ・ Feb 27#webdev#javascript#beginners#codenewbie  How to Automatically Close Your Issues Once You Merge a PRIt can be super annoying to have to close each GitHub issue once a feature request or bug report has been completed. Why not let GitHub do it for you? Automation is your friend and @mishmanners shows ya how it works so you can be a little more efficient and a little less annoyed.How to automatically close your issues once you merge a PRMichelle Mannering for GitHub ・ Mar 3#github#opensource#management  Functions Are Killing Your React App's Performance@crutchcorn looks at some of the ways that functions often slow down React applications, why they do so, and how to combat them, providing us helpful insight into the world of React application performance improvements.Functions Are Killing Your React App's PerformanceCorbin Crutchley ・ Mar 1#javascript#webdev#react#reactnative  AI Generated Git Commit MessagesAicommits is a CLI that writes your git commit messages for you with AI. @bdougieyo digs into the AI part of the code, offering up thoughts on the implementation of OpenAI as part of his 30 days of OpenAI series.AI generated git commit messagesBrian Douglas ・ Mar 3#ai#openai#github#git  Learn How to Setup a CI/CD Pipeline from ScratchIn this tutorial, @pavanbelagatti uses an example Go application to walk us through setting up a CI/CD pipeline with Docker, Kubernetes, and Harness.Learn How to Setup a CI/CD Pipeline from ScratchPavan Belagatti ・ Mar 1#tutorial#devops#go#kubernetes  React vs Signals: 10 Years Later@ryansolid reflects on the last 10 years of JavaScript, comparing React and the idea of “Signals.” The fun part is that Dan Abramov showed up to have an in depth discussion on the topic in the comments. This is a very valuable read for any JavaScript developer!React vs Signals: 10 Years LaterRyan Carniato for This is Learning ・ Mar 1#webdev#javascript#react#solidjsThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
972,Meme Monday!Today's cover image comes from last week's thread.DEV is an inclusive space! Humor in poor taste will be downvoted by mods.
973,"Becoming a hobbyist coder can offer many benefits, from personal fulfillment to career development. Plus, it’s fun! There's always something new to learn and explore in the world of coding. So, tell us why you code. Is it personal interest? For career development? Flexibility or entrepreneurship? And what about community? Are you finding community and like-minded individuals on CodeNewbie and DEV?  If you’re a hobbyist coder and have ideas for what we can do to make your experience here more fulfilling, helpful, or enjoyable, drop a note in the comments!"
974,"The AI-powered photo-aging project's premise is either fun or highly morbid. Developer, @steventey, put together Extrapolate, a project that lets you see how well you will age using AI.Perhaps you are not on TikTok, but there is a TikTok filter that makes GenX users cry. You can see it here on YouTube. Extrapolate is the reverse of letting GenZ reduce FOMO and see what they look like old (joking).header image was generated using midjourney        steven-tey       /         extrapolate            Age transformation AI app powered by Next.js, Vercel, Replicate, Upstash, and Cloudflare R2 + Workers.      What is steven-tey/extrapolate?How will you look in 10 years? 20 years? When you're 90? Upload a photo to extrapolate.app to find out. It is free and privacy-friendly because all images are deleted after 24 hours.  How does it work?As I have done previously in the 30 days of OpenAI series, I walk through the AI code and talk through how it works.Similar to how the AI generated room designs was built, Extrapolate leverages Replicate. The model number is referenced in the code is ""9222a21c181b707209ef12b5e0d7e94c994b58f01c7b2fec075d2e892362f13c"", but there it does seem to be private or not searchable. If someone more familiar with Replicate wants to tell if I am wrong on this, please comment.Hosted models' privacy is an exciting feature for Replicate, considering not all models need to be discoverable. If I choose to build my own, I am even more intrigued about using Replicate to store my future models. I searched for other models that age photos and found the model named Sam to be pretty close. But looking at the code, you can see the fetch call to the replicate predictions endpoint from the pages/api/upload.ts.// pages/api/upload.tsfetch(""https://api.replicate.com/v1/predictions"", {  method: ""POST"",  headers: {    ""Content-Type"": ""application/JSON"",    Authorization: ""Token "" + process.env.REPLICATE_API_KEY,  },  body: JSON.stringify({    version: ""9222a21c181b707209ef12b5e0d7e94c994b58f01c7b2fec075d2e892362f13c"", // model version    input: {      image,      target_age: ""default"",    },    webhook_completed: `${domain}/api/images/${key}/webhook?token=${process.env.REPLICATE_WEBHOOK_TOKEN}`,  }),}).then((res) => res.json()),...Enter fullscreen modeExit fullscreen modeI was also curious about the 24hr photo deletion and which is referenced in the README. It appears to be handled by a service provided by Upstash (Serverless Data for Redis), and runs on a schedule using a tool called Qstash. Qstash is new to me, but it's a message queue and task scheduler designed for serverless runtimes (In this example, Cloudflare workers). I had not seen the Cloudflare R2 product in the wild prior. It provides similar unstructured bucket storage as S3 and is used for quick uploads. This work happens in the pages/api/images/[id]/delete.ts file.   Below is the code that manages the deletion, which is called on schedule.// pages/API/images/[id]/delete.ts...await Promise.allSettled([  fetch(`https://images.extrapolate.workers.dev/${id}`, {    method: ""DELETE"",    headers: {      ""X-CF-Secret"": process.env.CLOUDFLARE_WORKER_SECRET as string,    },  }),  redis.set(id, {    expired: true,  }),]);Enter fullscreen modeExit fullscreen modeMy takeaway from this implementation is that the AI interaction is abstracted away by Replicate. If you are a developer looking to ship a project leveraging AI quickly, this is an excellent project to dig deeper into. Today, Vercel did announce several AI starter kits, including the one we just looked at. I plan to cover the rest of the list. Take a look if you want to deploy and yry a project today.         Steven Tey      @steventey      The AI-native product generation is here.Here are 10 free, open-source AI projects that you can learn from, deploy to @vercel, and build the next big thing:          17:22 PM - 07 Mar 2023    Also, if you have a project leveraging OpenAI or similar, leave a link in the comments. I'd love to take a look and include it in my 30 days of OpenAI series.Find more AI projects using OpenSaucedStay saucy. "
975,"Openai just made a big announcement regarding its API.From the post:ChatGPT and Whisper models are now available on our API, giving developers access to cutting-edge language (not just chat!) and speech-to-text capabilities. Through a series of system-wide optimizations, we’ve achieved 90% cost reduction for ChatGPT since December; we’re now passing through those savings to API users. Developers can now use our open-source Whisper large-v2 model in the API with much faster and cost-effective results. ChatGPT API users can expect continuous model improvements and the option to choose dedicated capacity for deeper control over the models. We’ve also listened closely to feedback from our developers and refined our API terms of service to better meet their needs.Any new announcements related to this technology are notable because of the demonstrations we've seen on this technology so far. Evolutions on how developers can access this functionality is where we might see the most substantial impacts.  Links to the documentationChat completionsSpeech to textThese are technologies which may have a profound effect on our ecosystems. What are your thoughts on these advancements? Leave a comment!  Generative AI on DEVYou can follow some of these tags if you want to keep up:#openai Follow        OpenAI is an artificial intelligence (AI) research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-profit OpenAI Inc.      #chatgpt Follow         GPT models are capable of natural language processing tasks such as text generation, summarization, and analysis. ChatGPT interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer follow-up questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.      #whisper Follow         Whisper is a versatile speech recognition model that can transcribe, identify, and translate multiple languages.      I will also remind you that we have policies in place against the publication of unchecked AI-published posts on our community. If you publish here using assistive tools, you must check and verify your work. Using these tools to publish flawed information are things our admins, mods, and moderation tooling, are on the lookout for.Happy coding! ❤️"
976,"As AI becomes more accessible to every developer, we will continue to see the use cases for it expand. For example, when designing a new landing page or product, I use Tailwind, but what if you could apply Tailwind to your bedroom? Well, you can now. @nutlope gifted us another AI project example, RoomGPT.        Hassan El Mghari      @nutlope      48h update after launching roomGPT.io:◆ 145,000 rooms generated◆ 90,000 unique visitors◆ 1300 GitHub Stars30k users in the first 24h and 60k users in the next 24h. Showing no signs of slowing down 🤯           17:12 PM - 04 Mar 2023    header image was generated using midjourney  What is Nutlope/roomGPT?This project dreams up designs of your room using AI. It uses an ML model called ControlNet to generate variations of rooms. This application allows you to upload a photo of any room, which will be sent through this ML Model using a Next.js API route, and return your generated room.        Nutlope       /         roomGPT            Upload a photo of your room to generate your dream room with AI.      How does it work?The ML Model is hosted on Replicate and Upload is used for image storage. During my 30 days of OpenAI series, I have focused on OpenAI, but in this example, the developer uses Replicate.The project uses Next.js, and the AI power is in the api/generate.ts file. Similar to OpenAI, there is an API endpoint from Replicate. Replicate lets you run machine learning models with a cloud API without having to understand machine learning or manage infrastructure. You can run open-source models others have published or package and publish your own. Those models can be public or private. The nice part is a lot of them are open-source on GitHub, which makes it helpful for learning.Explore some hosted replicate cogsThe predictions endpoints take id, which in this example is pointed to the hosted version of ControlNet model. You can get an idea of how the prompt is being passed from the UI by taking a look at the default Game Room prompt.// pages/api/generate.ts  const {  imageUrl,  theme,  room} = req.body;// POST request to Replicate to start the image restoration generation processlet startResponse = await fetch(""https://api.replicate.com/v1/predictions"", { // predictions  method: ""POST"",  headers: {    ""Content-Type"": ""application/json"",    Authorization: ""Token "" + process.env.REPLICATE_API_KEY,  },  body: JSON.stringify({    version: ""854e8727697a057c525cdb45ab037f64ecca770a1769cc52287c2e56472a247b"", // Controlnet version    input: {      image: imageUrl,      prompt: room === ""Gaming Room"" ?        ""a room for gaming with gaming computers, gaming consoles, and gaming chairs"" :        `a ${theme.toLowerCase()} ${room.toLowerCase()}`,      a_prompt: ""best quality, extremely detailed, photo from Pinterest, interior, cinematic photo, ultra-detailed, ultra-realistic, award-winning"",      n_prompt: ""longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality"",    },  }),});Enter fullscreen modeExit fullscreen mode  OpenAI vs ReplicateI am making this comparison because I had the question instantly after looking at the code. After a brief look at projects using both APIs, my takeaway is that Replicate gives a more straightforward developer experience through the API. OpenAI provides an experience you can fine-tune if you know want you to. Replicate allows you to run models without having to understand the intricacies of machine learning or manage your infrastructure. OpenAI doesn't require expert knowledge of machine learning, but it allows those with the ability to fine-tune models.  If I need to correct something, or if you have some insight into the code, please comment. I enjoyed walking through the code and learning how this works. Thanks to Nutlope for sharing this with us, and be sure to contribute back upstream. Open Source FTW!Also, if you have a project leveraging OpenAI or similar, leave a link in the comments. I'd love to take a look and include it in my 30 days of OpenAI series.Find more AI projects using OpenSaucedAlso, check out my bedroom redesign.Stay saucy. "
977,"GitHub Copilot is nice for autocompletion, but 80% of the coding is debugging. @musabshakil shares a quick demo in his DEV post, which I encourage you to watch. Get Instant Error Solutions with GPTMusabShakil ・ Feb 21 ・ 3 min read#gpt3#ai#vscode#javascriptheader image was generated using midjourney  What is MusabShakeel576/quickfix.ai?The TLDR; is you can copy the error message and get a suggested solution from the AI. Quickfix AI is also in its alpha phase, so expect bugs and report them to the author via the GitHub repo.         MusabShakeel576       /         quickfix.ai            Two powerful AI-powered extensions to simplify your browsing and coding experience.    quickfix.ai is an ambitious project made up of two powerful AI-powered extensions, VS Code and chrome. Both simplify your developer experience and speed up debugging.VS Code ExtensionChrome Extension  How does it work?Quickfix AI uses GPT and Vector Index to provide instant solutions for errors in your code within the code editor using AI.The code seems straightforward, but I did not install and run the alpha build locally. I am going off the demo provided by the author in their post. I also focus on understanding the code, and the backend/src/gpt.py seems to be powered by a single python package to manage the model. Python has been the premier language to support NLP for some time, so it makes sense that the developer experience packaged through one interaction.# /backend/src/gpt.pyfrom pathlib import Pathfrom gpt_index import GPTSimpleVectorIndex, Documentdef generate_index(workspace):    file = workspace.name+'.json'    path = Path.cwd() / ""storage"" / file    if path.is_file():        index = GPTSimpleVectorIndex.load_from_disk(path)    else:        documents = [Document(document) for document in workspace.documents]        index = GPTSimpleVectorIndex(documents)        with open(path, 'w'):            pass        index.save_to_disk(path)    return indexdef generate_solution(workspace) -> str:    index = generate_index(workspace)    response = index.query(workspace.input)    return responseEnter fullscreen modeExit fullscreen modeIf you understand Python and are interested in supporting it, it is open-sourced. Support the author with feedback and a star on their GitHub project. Also, if you have a project leveraging OpenAI or similar, leave a link in the comments. I'd love to take a look and include it in my 30 days of OpenAI series.Find more AI projects using OpenSaucedStay saucy. "
978,"Some time ago the man, the myth, the legend Fabrício Buzeto asked this interesting question:It brought me some memories back. I was for a few years responsible for the Liferay Calendar and Kaleo Designer portlets. These were complex single-page apps, built in a fast pace when the concept of SPAs was still evolving. So, many choices called for a review.So I started writing JIRA tickets for technical debt. When one of those health issues made a bug fix or feature harder to implement, I’d convert that technical debt ticket into a sub-task of the demand. As I like to say, I was “billing the debt from the feature.”I commented that and he asked me a crucial question:Why, indeed? Well, at first, we tried! I would present the debt issues in our prioritization meetings. Having the problems written helped a lot to caught the managers’ attention, by the way.Technical debt is a hard sell, though. People are understandably wary about buying into something whose value they could not see. Nonetheless, changes took increasingly more time to deliver and regression bugs kept popping up. We needed to fix these health problems.That’s why I started to work on debt as part of value-adding tasks. Working on the debt to make a demand easier was a great evidence that extra work was worth it. It was not just some random idea we worked on to postpone duties: it delivered value.That is the first reason for handling technical debt as sub-tasks of value issues: By binding the debt to a value-adding task, it is easier to justify the extra effort to stakeholders.At first, this debt-billing was only a communication device. But there was a cool side effect: the most glaring issues kept being solved first. That makes sense: since we worked on them when they caused problems, the the ones causing more problems were solved first. Since prioritization is always a challenge (and prioritizing technical debt is even harder) it was a huge help.We still had a huge pile of technical debt tasks, but many of the pending tasks were not relevant. Some, already solved. Others were elegant ideas back then, but didn’t make sense anymore. In hindsight, a good part of the “debt” were personal preferences, or assumptions that weren’t true anymore after some product evolution.This is the second reason for debt-billing: Working on health issues as part of demand is an effective way to prioritize which technical debt to work on.See how great it is! Had we worked on technical debt by themselves — for example, in a task force —, we might apply changes that could actually make future evolution harder. Debt-billing let us confirm which requests were fit for our goals. And it has a subtler, more important consequence.We developers are are an opinionated lot, and this is good. We usually try to make these opinions into a goal. But it is hard to know if a goal is right. Once we use these ideas as helpers for something more clearly relevant, that goal turns into a tool. Tools are much easier to evaluate!This is a third reason for debt-billing: when technical debt is linked to value delivery, the creative force from the team works together with the organization’s objectives.Our experience is that this strategy was quite effective. Everybody knew their suggestions would be evaluated: health tasks wouldn’t be a chore to prioritize anymore, but a toolset that our colleagues would look for to help with their challenges. The debt backlog was not a wishing well anymore.The apps got better, too. When I started working on the Calendar, for example, it was presented as an example of an application that didn’t work. The first bug after the initial release was that it couldn’t save events! When I left that team, the Calendar had no bug of priority 3 or higher (the levels we have to fix). And we delivered quite a good amount of features, even including some that weren’t present in some leader competitors. Not bad for a product that, a few years before, was described as an example of non-working feature!It felt right to bill the technical debt from the demands, but I never thought deeply about why it felt right. So, thank you for asking that, Fabrício! It was a joy to think about it.EDIT: I just recalled Ron Jeffries wrote a great post about his approach to refactoring, which the one here is similar to. Totally worth reading!(Originally published as ""Billing the technical debt"" on Suspension of Disbelief.)"
979,"The use of personal data as well as data collection and analysis has left a lot of people concerned about privacy, especially when it comes to AI. How does the use of personal data by AI systems impact individual privacy, and what steps do you think should be taken to address these concerns?"
980,"Every Tuesday we round up the previous week's top posts based on traffic, engagement, and a hint of editorial curation. The typical week starts on Monday and ends on Sunday, but don't worry, we take into account posts that are published later in the week.   SvelteKit 1.0 - Building a personal blog, that shows your DEV posts 🦄Let’s take a tour of the latest version of SvelteKit with @lissy93. Here, you’ll build a developer portfolio and blog website that fetches data from your RSS feed, as well as the GitHub API.SvelteKit 1.0 - Building a personal blog, that shows your DEV posts 🦄Alicia Sykes ・ Feb 20#svelte#tutorial#opensource#webdev  All about Promises in JavaScriptA promise in JavaScript is an object that represents a value that may not be available yet, but will be in the future. Learn more about JS promises with @codeofrelevancy. All about Promises in JavaScriptCode of Relevancy ・ Feb 23#javascript#beginners#programming#react  Kubernetes 101, Part I, the FundamentalsKubernetes is an open-source system for automating and managing containerized applications. In short, it’s all about containers. Here, @leandronsp demonstrates the problem that K8s tries to solve. Kubernetes 101, part I, the fundamentalsLeandro Proença ・ Feb 23#kubernetes#k8#docker#containers  Thoughts on Dev Rel in the post-Twitter era@andypiper discusses how DevRel has evolved beyond relying on Twitter as the primary platform to connect with developer communities. Though it requires more effort, DevRel is adapting to how communities and technologies are changing.Thoughts on Dev Rel in the post-Twitter eraAndy Piper ・ Feb 22#devrel#twitter#community#mastodon  Coding your own AI in 2023 with FastAIIn this guide, @vincenius covers how to set up the ecosystem for developing an AI, create and train the model with FastAI, then deploy the model and use it in your own project. Coding your own AI in 2023 with fastaiVincent Will ・ Feb 27#python#deeplearning#ai#beginners  Announcing MiniBASICMiniBASIC is a clean, powerful new implementation of the classic 1980s BASIC programming language. Download @joestrout’s project on itch.io or fork the repo on GitHub!Announcing MiniBASICJoeStrout ・ Feb 26#beginners#programming#basic#minimicro  Debugging JavaScript Like a Pro: Tools and Techniques for Finding and Fixing BugsHere, @iayeshasahar shares some tools and techniques that can help you debug JavaScript like a pro so that you can live a bug-free life.Debugging JavaScript Like a Pro: Tools and Techniques for Finding and Fixing BugsAyesha Sahar ・ Feb 25#javascript#webdev#tutorial#testingThat's it for our weekly Top 7 for this Tuesday! Keep an eye on dev.to this week for daily content and discussions...and be sure to keep an eye on this series in the future. You might just be in it!"
981,"For 30 days, I plan to test open-source Ai projects on GitHub and learn how to build a project myself. These posts will be short and focus on understanding what things you can create with Ai and what needs to be prepared. image was generated using midjourneyI have been collecting a list of 30 projects created by developers like you and me to test out and look closely at the code. To name a few on my list:ExtrapolatePaint by TextTwitter BioFind more AI projects using OpenSaucedOh and OpenAi is in the title, but this series will also focus on other Ai tools. I plan update this post with links to all future posts, so if you want to bookmark this post for later, please do.Day 1: AI generated git commit messagesDay 2: AI powered search with OpenAI embeddingsDay 3: AI generated room designsDay 4: AI powered code debugging extensionsDay 5: AI powered photo agingDay 6: AI generated Twitter biosDay 7: AI powered movie recommendationsDay 8: AI powered census dataDay 9: Build your own ChatGPT starter kitFinally, comment links to yours and other projects I should look at. Bonus points if they are open sourced and viewable on GitHub. I aim to get enough exposure to integrate Ai into my projects and live stream.Stay saucy. "
982,"It's really annoying go through all your issues, and close each one once a feature request or bug report has been completed. The pull request gets merged and then you gotta go find the issue that it corresponds to... way too much time.Now GitHub has given you a way to automatically close your issues once a pull request has been merged. Let me show you how.  Step 1. Create a pull requestLike you usually do, open your pull request as normal.Go to your repository, make some changes and open a pull request, but don't click ""Create pull request"" yet:  Step 2. Tag the relevant issueBefore you click ""Create pull request"", we need to link the relevant issue to the pull request so that the correct issue is automatically closed.1. Write part of your commit message as usual:2. Add a ""linking"" keyword to your commit message:You can see above here, I've used ""closes"" (underlined). There are several keywords you can use including:closeclosesclosedfixfixesfixedresolveresolvesresolved3. Tag the relevant issue by typing `#` on your keyboard and selecting or typing in the number of the issue you want to link to:  Step 3. Merge and close your pull requestNow that you have all the necessary messages and tags, you can go ahead and merge the pull request as usual.1. Click ""Merge pull request"":2. You should see the message that your pull request has been successfully merged:You can delete your branch now if you like.  Step 4. Issue is automatically closedWhen you navigate back to the relevant issue, you'll see that it is now automatically closed:You'll also see the pull request is mentioned in the issue history, and there's a message at the top which reads ""Fixed by #96"". This means the issue has been resolved by pull request number 96.  Automatically closing issuesI hope this short tutorial gives you a little more control and automation over your repositories on GitHub.If you'd like to see this as a video, check out our YouTube Short:There are also other ways you can automatically close issues. Read up on them all in the GitHub Docs."
983,"Did you watch the React.js documentary released on YouTube a few weeks ago? Some of Facebook's tech engineers spoke about how React started in the company as Bolt.js and how some decisions were made around it. They also talked about how the community rejected the framework when they first introduced it, and how it has changed significantly in the months since.Even though React.js was created inside one of the biggest tech companies, it's interesting (and inspiring) to see how an idea can grow to become one of the most used libraries in the world of front-end development. From an initial idea to solve a specific problem to an open source modern project with the collaboration of many developers around the globe. An idea that spawned others, such as Redux.Watch the video and check out some key points below.  React documentary summary (spoiler alert)The year was 2011 when React started on Facebook - in a scenario where jQuery, Backbone, MooTools and other similar javascript tools dominated front-end development. They first called it Bolt.js, then thought about FBolt.js until it became React.js. Sometimes referred to as a framework, sometimes as a library.Based on the difficulties Facebook's front-end team was having in creating a complex UI at the time, two software engineers created Bolt.js, a client-side MVC framework that tied together some existing JS tools to handle with the complex interactivity of primitive Facebook timeline, chat, news feed and other advanced applications.But as the use of Bolt.js and also the team grew, Jordan Walk, a product engineer working in ads at the time, had some interesting ideas for changing Bolt, making it much more functional, removing its MVC architecture and adding the concept of re-rendering when something in the UI has changed - that's when React came into being, but with its initial name as FBolt (Functional Bolt). Later they also introduced JSX syntax and, through Jin Chen ideas, another great software engineer, they also introduced ways for handling states in React based on Flux architecture, which was a new chapter in the framework development process.But it was around 2012, when Facebook acquired Instagram, that the framework was renamed React and the web version of Instagram was the first full end-to-end application in production developed using this modern tool.The documentary also showed the risky decision they took after several business discussions to continue using React instead of its initial version called Bolt, as React had not yet been fully developed and its use would impact the company's business for a while.The next step was to make React an open source tool. And they did it by making this announcement at the US JSConf in 2013, a famous javascript-focused event. In an age where best practice was splitting HTML, CSS, and JS into separate files, the React way of creating components using JSX and mixing them all together was not well accepted by the community, and this announcement was a disaster.It was then that Sophie Alpert, a non-Facebook developer, saw React and decided to use it. She solved some technical details by rewriting about 2,000 lines of the library's code based on the project she was working on - and then made a pull request to the React repository. And as you can imagine, she became a member of Facebook's engineering team.And then, in the same year, 2013, they decided to announce React again at the UE JSConf, which took place in Berlin. From that point on, the community slowly started talking about the library and trying it out, realizing the simplicity of how React creates rich UIs. And companies have also started using React. In 2014, Netflix decided to use React to rewrite its platform, which contributed a lot to the library's popularity.2015 was the year of the first React.js Conf where they made React Native an open source project and started talking about GraphQL and Relay. It was a huge hit with the community and Facebook decided to convert all of their apps to React and remove all other JS frameworks. That's when a few other developers also showed up, including core team member Dan Abramov - famous for creating Redux.Some of the software engineers responsible for React's success no longer work at Facebook, but they certainly left their legacy there (and in the dev world). :)  Software engineers in the documentarySophie AlpertDan AbramovVladimir KoesnikovWill BaileyJin ChenJordan WalkSebastian MarkbågeShane O’SullivanLee ByronPete HuntTom OcchinoAdam WolffChristopher ChedeauDavid NolanAndrew Clark  Additional notesOne off-topic thing I think is amazing to note is that the documentary highlighted some diversity in IT. I believe there is much more to be done, but having LGBTQAI+ people as managers is inspiring. To be even more complete, I would also like to see more black people in the film.See you next time! 😁"
984,"Some of the best implementations of AI use existing knowledge basis and make them searchable through prompts. While scrolling through Twitter, I a tweet on paul-graham-gpt.        Mckay Wrigley              @mckaywrigley            I embedded all of @paulg’s essays.All 605,870 tokens worth.Use OpenAI’s new model to search & chat with them at paul-graham-gpt.vercel.app.Code & dataset is 100% open-source for anyone to use.GitHub: github.com/mckaywrigley/p…      16:19 PM - 02 Mar 2023    header image was generated using midjourneyIn this 30 days of OpenAI series, I am looking at AI projects and their code to help demystify how any dev can build AI-generated projects.Find more AI projects using OpenSaucedPaul Graham is best known for his work on the programming language Lisp and for cofounding the influential startup accelerator and seed capital firm Y Combinator. He also writes many essays that provide a lot of knowledge for current and future startup founders. Mckay Wrigley built a tool called paul-graham-gpt, you can use it live here, to navigate all of PaulG's essays, and I am excited to jump in and take a look on how he did this.        mckaywrigley       /         paul-graham-gpt            AI search & chat for all of Paul Graham’s essays.      How was mckaywrigley/paul-graham-gpt made?paul-graham-gpt is described as AI search & chat for all of Paul Graham’s essays. When looking closer at the code, it uses the embeddings API from OpenAI. _OpenAI’s text embeddings measure the relatedness of text strings. Embeddings are commonly used for:_This is my first look at embeddings, and if you read in my previous post on aicommits, that used completions. Based on my reading in the docs, embeddings are useful when traversing existing data and looking for relevancy. The code samples use Amazon food reviews as the example in the docs. You might be looking for reviews on condiments, and the relevance you are looking for is negative reviews. The embeddings check tone along with ratings.That is my best explanation after a first look, but check out the embeddings use cases for more context  How does it work?The project's README does a great job explaining the techniques. The author is looping over all essays and generating embeddings for each text chunk. This is done in the generateEmbeddings function.All essay content is stored in scripts/pg.json// scripts/embed.ts// this response is loop over using the essay content in the generateEmbeddings fnctionconst embeddingResponse = await openai.createEmbedding({  model: ""text-embedding-ada-002"",  input: content});...// This is parsing the essays from the JSON(async () => {  const book: PGJSON = JSON.parse(fs.readFileSync(""scripts/pg.json"", ""utf8""));  await generateEmbeddings(book.essays);})();Enter fullscreen modeExit fullscreen modeThen they take the user's search query to generate an embedding and use the result to find the most relevant passages from the essays.// pages/api/search.tsconst res = await fetch(""https://api.openai.com/v1/embeddings"", {  headers: {    ""Content-Type"": ""application/JSON"",    Authorization: `Bearer ${apiKey}`  },  method: ""POST"",  body: JSON.stringify({    model: ""text-embedding-ada-002"",    input  })});...Enter fullscreen modeExit fullscreen modeThe comparison is done using cosine similarity across our database of vectors.// pages/api/search.tsconst {  data: chunks,  error} = await supabaseAdmin.RPC(""pg_search"", {  query_embedding: embedding,  similarity_threshold: 0.01, // cosine similarity  match_count: matches});Enter fullscreen modeExit fullscreen modeThe Postgres database has the pgvector extension hosted on Supabase. This was just announced recently by Supabase last month. Results are ranked by similarity score and returned to the user.I enjoyed walking through the code and learning how this works. If I need to correct something, or if you have some insight into the code, please comment. Thanks to McKay for sharing this with us, and be sure to give them a follow and check out their other work in AI, Codewand AI-powered tools to help your team build software faster.Also, if you have a project leveraging OpenAI, leave a link in the comments. I'd love to take a look and include it in my 30 days of OpenAI series.Stay saucy. "
985,"I am currently affected by the wave of layoffs in the technology industry and this isn’t my first rodeo. The difference is that it feels worse this time as I am not only annoyed by losing my job, but I am starting to feel that the system is incredibly flawed. Instead of building a sustainable work environment with sensible compensation, the system favours continuous growth - something that isn’t possible in a world of limited resources.   Betting wrong on the pandemicI’d wager to say that 90% of the layoffs right now across the tech sector aren’t related to performance or productivity. The reasons are the troubles on the stock market and the general recession we are experiencing. We just barely survived a global pandemic and there is a war going on in Ukraine that could easily escalate into the next world war. During the pandemic all tech companies hired like mad as people who were quarantined at home needed tech much more than they did before. This turned out to be a premature celebration of growth as the pandemic hit a lot of people hard and the war made people wonder how they could pay the next gas bill rather than if they want to buy another laptop, game console or mobile. So whilst there is no massive decline, there isn’t a growth that warrants the number of people in the company. The stock market looks at profit per head in a company, and if profit goes down, and you need to act swiftly, heads must roll.  Why not use stocked resources instead of trying to add when nothing comes in?Maybe I am being naive here, but I don’t see how anyone can win in this situation. As the market gets better, companies will have to look into hiring again and there is already a serious lack of employees available in tech. Maybe, just maybe the better way would have been to plan for two years of no growth but sustained work instead. Every huge tech company has money - the layoffs right now aren’t cheap at all, after all. But instead of riding out a pandemic and the delivery issues it came with we still plan the old way with explosive growth in a short time frame.This fetish we have for growth is starting to annoy me. If your career doesn’t progress every half year, you’re a failure. If your product doesn’t double user numbers each quarter, it gets canceled. If you don’t show any interest in advancing up the career ladder, but instead focus on your job, you’ll get asked why that is and pushed into booster processes.  The missing HR process for happy employeesThis didn’t happen to me, but to one of my colleagues in the past. This person was amazing. A great technologist with tons of experience and liked by all. Thorough, documenting everything and patient with unreasonable demands, he was my go-to for new features. He also was family oriented and had a secondary income. So instead of a promotion with more money and more responsibilities, he asked for a four day week - even at the expense of a lowered income. There was no process for this, and the company back then was at a loss what to do. Instead of understanding that this was a decision by the person to get more peace of mind and time for the family, it was seen as not having a growth mindset. Instead of understanding that this could be a common demand in people who get older, he was refused the opportunity to work less and left the company.I am worried about this as there is no logic to thinking that everything has to grow, get better and more. Not everybody wants to go up the career ladder and there should be no shame in finding a place you are happy in and stay on that level. For some of us our needs are met at a certain level and anything else would bring more money in but also eat into the way of life that makes us happy and effective.   Back to the grind?Right now I am looking for new opportunities and I want to go into a lead role similar to the one I had. I would love to see if there are places that understand that people like my colleague earlier exist and could make up an incredibly effective team. And I would love to lead people like that, make sure they can concentrate on their work instead of being asked to think about advancing a career they do not care about. If companies want to continuously grow and have long term career employees, they need to make sure that there are enough senior roles and positions available. It feels odd that we have a very limited number of high-level career positions, and yet everybody is forced to think about advancing towards those, or not seen as a person who is eager enough to be in this market. I want to build excellent products for our end users, I don’t feel like I should spend a huge amount of my time competing with my peers for those few senior positions. How many more rounds of inflated hiring and short term layoffs do we need to go through before we understand that continuously shooting for unattainable goals isn’t as motivating as we think it is? Maybe with all the mess that is going on in the world right now, we should think smaller and more maintainable. I’m tired of companies telling me they aim to become a “unicorn” in the next quarter. I’d be more excited about companies aiming for a goal that makes them sustainable and keep their employees instead of having to deal with a one year churn. Maybe we should grow in our mindfulness and humanity and not only in numbers.If you agree and you're looking for a technical lead in your company, check me out on LinkedIn"
986,"When it comes to a successful career in tech, it's not just about technical skills. Non-technical skills are just as important, if not more so! Some examples of non-technical skills that can help you succeed in tech include:CommunicationLeadershipTime managementCollaborationCritical thinkingWhat other, maybe less obvious. non-technical skills do you think are important for a career in tech? Share your thoughts in the comments below!"
987,"What's up folks!Hope everyone enjoys their weekends. 🙌Looking back on this past week, what was something you were proud of accomplishing?All wins count — big or small 🎉Examples of 'wins' include:Starting a new projectFixing a tricky bugGrokking spaghetti code while eating spaghetti pasta 🍝"
988,"Recently I've started the course Practical Deep Learning for Coders. This course is great and I'd recommend it if you'd like to get deeper into the topic. But it's also quite time consuming as every lesson in this course is an 1h+ long video.This is why I've decided to create this guide, which focuses on the critical parts of the course. I'll cover how to  Set up the ecosystem for developing an AI  Create and train an AI model with fastai  Deploy the model and use it in your project  Create a Jupyter NotebookTo create the AI we will use fastai. This is a python library, which is build on top of pytorch. No worries, you don't need to know how to code python. We will learn how this stuff works along the way :)You could install and set up all the libraries yourself to run the code in a python file. But usually AIs will be coded in things called Jupyter Notebooks.There are two options for using a Jupyter Notebook. Use a free hosted service like Kaggle Run a notebook locally. You can find a guide on how to set up Jupyter on their documentationJupyter Notebooks have cells of either python code or markdown. You can run the code directly in your browser by pressing the ""Run"" button in the top navigation or next to the cell. It will give you the output of your code underneath the code cell.Now let's jump right into the code. The rest of this guide will also be available in this Kaggle notebook:https://www.kaggle.com/vincentwill/fastai-tutorialOn Kaggle, for the code to work you must activate the ""Internet"" switch in the sidebar menu first. To open the sidebar, click the small arrow on the bottom right. The Internet switch is only available if you've verified your phone number.  Preparing the data to train the AIIn this tutorial we will write an AI that will be able to recognize what's in a picture.For that we need some pictures to train the AI with first.The following function is a helper to quickly download pictures from duckduckgo. I won't go into detail here, because it's not crucial for training our AI. You could also download the pictures manually or use any other scraper to get the data.# import libraries | imports will be available in all following cells as wellfrom fastcore.all import *from fastai.vision.all import *import timeimport jsondef search_images(term, max_images=100): # define search_images function    url = 'https://duckduckgo.com/'    res = urlread(url,data={'q':term})    time.sleep(2)    searchObj = re.search(r'vqd=([d-]+)&', res)    requestUrl = url + 'i.js' # the duckduck go api url    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')    headers = dict( referer='https://duckduckgo.com/' )    urls,data = set(),{'next':1}    # loop through pages until we have enough images    while len(urls)<max_images and 'next' in data:        res = urlread(requestUrl, data=params, headers=headers)        data = json.loads(res) if res else {}        urls.update(L(data['results']).itemgot('image'))        requestUrl = url + data['next']        time.sleep(4)    return L(urls)[:max_images]`Enter fullscreen modeExit fullscreen modeI'd recommend to follow this guide first and then trying to train the AI with different images. We will start by testing our search_images function. The output will show a link.For this tutorial, I will create an AI that recognizes different types of dinosaurs.# ""search_images"" depends on duckduckgo.com, which doesn't always return correct responses.#  If you get a JSON error, just try running it again (it may take a couple of tries).urls = search_images('t-rex', max_images=1)urls[0] # 'https://preview.redd.it/dwthh8wdl9k21.jpg?auto=webp&s=e0af431550ed710c2ffb11eae6ca325806c9f46b'`Enter fullscreen modeExit fullscreen modeNow that we verified that the function is working correctly, we can use it to download and display the pictures.from fastdownload import download_urldest = 't-rex.jpg'download_url(urls[0], dest, show_progress=False)im = Image.open(dest) # open the downloaded imageim.to_thumb(256,256) # display the image in a 256x256 thumbnailEnter fullscreen modeExit fullscreen modeNow we need to fetch pictures of something different to let the AI know what's not a t-rex. We'll use the same function to fetch an image of a triceratops.download_url(search_images('triceratops', max_images=1)[0], 'triceratops.jpg', show_progress=False)Image.open('triceratops.jpg').to_thumb(256,256)Enter fullscreen modeExit fullscreen modeNow that we ensured that the search and save are working properly we can use them to download our dataset. The next function will loop through our categories and download 100 pictures of each.searches = 't-rex','triceratops' # define search termspath = Path('images')for o in searches:    dest = (path/o)    dest.mkdir(exist_ok=True, parents=True) # create folder for categories    download_images(dest, urls=search_images(f'{o}'))    time.sleep(5)    resize_images(path/o, max_size=400, dest=path/o) # resize to save time training the AIIt might happen that downloads fail. That's why we need to verify the images and delete the invalid ones.failed = verify_images(get_image_files(path))failed.map(Path.unlink)len(failed)Enter fullscreen modeExit fullscreen mode  Train the AITo train the AI we first need a Data block. It is like a blueprint on how to assemble your data. With this DataBlock we can then create a Data loader by calling its .dataloader function. I'll explain the different parameters in the code below. You can find a more detailed explanation of everything here.dls = DataBlock(    blocks=(ImageBlock, CategoryBlock), # input = images, output = categories    get_items=get_image_files, # Get image files in path recursive    splitter=RandomSplitter(valid_pct=0.2, seed=42), # split data into training / validation set randomly    get_y=parent_label, # label the items - in this case take the parent (folder) as label    item_tfms=[Resize(192, method='squish')] # method to transform the items - in this case resize).dataloaders(path, bs=32) # bs = size of batch# show an example batch of the items we loadeddls.show_batch(max_n=6)Enter fullscreen modeExit fullscreen modeNow we're already ready to train our AI with this data. First, we load a pre-trained model. In this case, the pre-trained model was trained to recognize photos. Afterward, we fine-tune this model on our dataset. We pass our Data Loader to the vision learner and then the pre-trained model, which we will use. In this case, it's resnet18.learn = vision_learner(dls, resnet18, metrics=error_rate)learn.fine_tune(3)Enter fullscreen modeExit fullscreen mode  Test and deploy the AINow our AI is ready to be tested. For that, we can use the photos we downloaded initially to test our download function.prediction,_,probs = learn.predict('t-rex.jpg') # run a predictionprint(f""This is a: {prediction}."")print(f""Probability it's a t-rex: {probs[0]:.4f}"")print(f""Probability it's a triceratops: {probs[1]:.4f}"")Enter fullscreen modeExit fullscreen modeIf we're happy with the result and the accuracy we can deploy the model. We do that by simply calling the export function of the learner.learn.export('model.pkl')Enter fullscreen modeExit fullscreen modeYou are now able to load and use the exported model. That means you can import it into any python application and use the .predict function.path = Path()path.ls(file_exts='.pkl') # double check if model existslearn_inf = load_learner('model.pkl')learn_inf.predict('t-rex.jpg')Enter fullscreen modeExit fullscreen modeBut there is an even easier way to use your model than to implement your own Python API. We can use Gradio and Hugging Face to easily create an API and use our model. For that, we need to write a function that will tell Gradio how to use our model.labels = learn.dls.vocab # read labels from Data Loaderdef predict(img):    pred,pred_idx,probs = learn.predict(img) # use passed image for prediction    return {labels[i]: float(probs[i]) for i in range(len(labels))} # return all resultsEnter fullscreen modeExit fullscreen modeNow we need to install gradio. Then we can already launch it by defining an Interface. To this interface, we pass our predict function and the input and output definitions. Then we can call the launch function, which will launch an interface to interact with our model.!pip install -Uqq gradioimport gradio as grgradio_interface = gr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=gr.outputs.Label(num_top_classes=3))gradio_interface.launch(share=True)Enter fullscreen modeExit fullscreen modeThis will create a UI to easily interact with our modelAt the bottom, you can see the text Use via API.If you click that, it will show you how to interact with your AI via API. You can create your own python microservice with Gradio. But the easiest way to host it is by using Hugging Face. So head over there and create an account. After confirming your email you are able to create a ""Space"".Click on the top right menu and then on ""New Space"". Enter the name of your project and select Gradio as SDK. Then choose a License and keep the other options as they are. Now you can create the Space.Afterward, we need to add our model and our code to the Hugging Face repository. If you are running your notebook locally you should have the exported model in your working directory. If you are on Kaggle, you have to click the small arrow on the bottom right. There you should see a ""Data"" tab with your exported model.pkl file.Now clone the repository of your Hugging Face Space. Then add the model.pkl file to the repository and create a file app.py. There we add the code we already used above to load the model and create a gradio interface.import gradio as grimport skimagefrom fastai.vision.all import *path = Path()learn = load_learner('model.pkl')labels = learn.dls.vocab # read labels from Data Loaderdef predict(img):    pred,pred_idx,probs = learn.predict(img) # use passed image for prediction    return {labels[i]: float(probs[i]) for i in range(len(labels))} # return all resultsgradio_interface = gr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=gr.outputs.Label(num_top_classes=3))gradio_interface.launch()Enter fullscreen modeExit fullscreen modeAnd lastly add a requirements.txt file to provide the libraries needed to run our model.fastaiscikit-imageEnter fullscreen modeExit fullscreen modeBefore commit we need to install git-lfs first, because our model.pkl file is too big. Follow the link and the instructions to install it for your operating system.Now we are able to use git-lfs for our model.pkl:git lfs installgit lfs track ""*.pkl""Enter fullscreen modeExit fullscreen modeAfterward, we are ready to commit and deploy our model.git add .git commit -m ""initial commit""git pushEnter fullscreen modeExit fullscreen modeIf you head back to your Hugging Face Space, you should see that your application is building. After a while, you should be able to see the same interface as in your jupyter notebook.Congrats! You successfully created and deployed your AI. You are now able to use the API of your Hugging Face Space in your applications.  Whats's next?  First I'd recommend to you to alternate the code in the jupyter notebook. Play around to get a better understanding how this stuff works.  Check the docs of fastai to understand how to: load .csv files and create an AI that analyses text train an AI with tabluar training for categorization  Let me know how you liked this guide and how I can improve it on Twitter or via Email: info@wweb.dev"
989,"I decided to read ""That's Not My Burnout"", as someone who has recently discovered the possibility of having ADHD and/or ASD, a lot of things about myself have started to make sense. Some of those things being, hyperfixations, stimming and autistic inertia. The last one is my biggest concern. Sometimes it is hard to stop, or in this case begin. It is not possible to find motivation to do somethiing or get simple or hard tasks completed, making completing tasks a complete gamble. And as the article mentioned, a lot of people felt the same way at the height of the pandemic. Burnout was a constant for me, I dropped all of my classes, and some days did not get out of bed at all. I had zero motivation to do a single thing except wake up, eat and sleep. But there were also some days where I could do one thing from sun up to sun down. I could write or draw all day, do my nails,  play video games, and on the rare occasion - clean. I am excited to learn how to code, I want to be in control of my schedule, make something I'm proud of, work from home and have a reliable paycheck for once. But the constant fear of having no motivation is intimidating. I don't know if anyone else feels this way, or if a successful developer has felt this way, and it makes me wonder how they pushed through it."
990,"image created by Margaux Peltat for the Chilled Cow YouTube channel Time for #DEVDiscuss — right here on DEV 😎Coding your own AI in 2023 with fastaiVincent Will ・ Feb 27#python#deeplearning#ai#beginnersInspired by @vincenius's Top 7 post, tonight’s topic is...building your own AI 🤖Questions:Have you tried to build your own machine learning model or AI-based application?What tools did you use to build it? What tools would you recommend, and which ones should devs stay away from?For you, is working with ML models and AI a career, a hobby/interest, both, or neither?Any triumphs, fails, or other stories you'd like to share on this topic?"
991,"It can be tough to navigate the world of coding, especially when you're a newbie. Figuring out where to start, dealing with imposter syndrome, and feeling overwhelmed by the amount of information out there. It’s...A LOT.But you're not alone! Let’s hear from those of you who are just starting out: what are your challenges? And for those of you who’ve made it (are making it): what tips can you share? "
992,"Frankie Nicoletti came onto our podcast this week and gave us so much wisdom about entering into the job market post coding-bootcamp. So, we gathered some of the things we learned to share them with you all. Take risks that will help you get to the places you want to be. Do not be afraid to switch gears when you find a job is not aligning with you.If you have the ability, treat applying to jobs as a full-time job.When you are exiting a coding bootcamp, ask for help from the people around you— this is not a solo journey. Apply to jobs where you are more likely to get a call back.Stay away from companies that do not have mentoring capacity if you are looking for an entry-level position.When you are job hunting for your first job, try to table learning new frameworks. Focus on what is ahead of you!If you listened— what did you learn? Do you have any tips for finding an entry-level job?Drop your thoughts below and don't forget to give it a listen (if you haven't already) via the link in our bio or wherever you listen to your podcasts! 💜 "
993,"It is sad to see that CSS Tricks is in a steady decline. Recently, Geoff Graham lost his job. Geoff was the editor of CSS Tricks for as long as I have been a reader,according to Geoff his tenure was 8 years. It was an abrupt end. In Geoff's own words:I woke up yesterday to the news that DigitalOcean has cut a bunch of jobs from the payroll. It sounds like a pretty big wave, and yes, my job was lopped off with it.Thankfully, Geoff was not left in a tough spot as he has other jobs on the go:This is my first rodeo with sweeping layoffs… or even losing a job. I always expected I’d feel devastated if something like this were to ever happen, but I’ve gotta admit it’s all good. Anyone who knows me well knows that I never have one job, but many eggs in a number of baskets. That might be influencing my feelings a wee smidge. I realize not everyone is in the same boat.  Why is Digital Ocean laying people off?It is endemic in business now that if there is economic slowdown, heads can roll to cut costs and keep profits up. You can set your watch by it in some regions.Digital Ocean acquired CSS Tricks in March of last year, presumably as a marketing move to increase its visibility to frontend developers. Digital Ocean announced on Feb 15th that they were laying off about 11 percent of employees, even though revenue is growing.DigitalOcean, in its fiscal 2022 Q4 financial filing, said it recorded $163 million in sales, up 36 percent year-on-year, during those final three months. The quarter ended with a $10 million loss, though, but better than the $12 million a year-ago.They are amongst other tech companies implementing layoffs this month including Wix, Twilio, and Udemy.In a comment on Hacker News, DigitalOcean co-founder Moisey Uretsky said the following on layoffs:As unfortunate as the layoffs are, they were really due to two CEO changes in the past 18 months and leadership changes that created competing directions in the business, which Yancey [Spruill] our new CEO, is now addressing.We are not running out of money, nor do we have an immediate need to raise capital, and the layoffs aren't related to any sort of 'cost-cutting'It is not cost-cutting - it is a change in direction? 😵‍💫They actually are not a profitable business. Back to Moisey to field that one:We are running at a modest loss now, which is OK because we are growing and also because whenever you launch a new product or feature the up-front costs are much higher to get the initial product built and there is no revenue contribution from it until it's launched and has ramped up.But even so we did manage a completely net profitable year in our history in 2017, which I'm very proud of, and have been at a slight loss in other years. We still have plenty of our Series B raise in our bank account.Hey, we had a profitable year once, in 2017! 😡And the good news is that they have plenty of cash in the bank and the stock price (DOCN) rose since the layoffs on Feb 15th! 😶‍🌫️The Register goes on to say this about the Digital Oceans plans:In a presentation to staff, led by CEO Yancey Spruill, DigitalOcean management said about half the company's staff are based outside the US and about 70 percent of revenue comes from abroad. Consequently, the IT rental biz intends to prioritize global hiring in places like Pakistan and Mexico where relevant talent is available, and works for low wages compared to folks in some other nations.Ouch! 🤕 How long before they hire again?Geoff alluded to this in his article by sharing a picture of an auto-reply email from a Digital Ocean colleague, which had a ""We're hiring"" link in the signature. Business can be brutal. 💔  The decline of CSS TricksWhen DigitalOcean acquired CSS Tricks last year, there was a small transition period where Chris Coyier helped to hand-over the reins, and then he stepped away. From the content side, CSS Tricks was a 3-person team of: Chris, Geoff, and Robin Rendle. Robin also left shortly after the acquisition.Geoff was the final link to the old establishment. If you have read any of Geoff's articles, or had him edit one of yours, it is hard not to be infused with his enthusiasm and curiosity for all things web development. He had a significant imprint on a lot of what CSS Tricks produced.Throughout the years, CSS Tricks has had lots of articles contributed by guest writers. If people continue to contribute, then maybe CSS Tricks can weather the storm and remain a source of education and inspiration for the frontend community.I have written a couple of articles for CSS Tricks, a couple being two! At the beginning of January, I was conscious that it has been a while since I contributed something. I thought ""Maybe, I should get into the habit of offering some articles to CSS Tricks again"". So, I submitted a proposal for an article on January 6th, I still have not heard back nearly 2 months later. In the past, I have heard back quicker than that.In September of last year, Digital Ocean announced that they would be migrating the content of the website to their homespun CMS, and shared a proposed redesign of the website. This has not been completed yet, but is meant to be done in the first half of this year.The frequency of publication has slowed down, Geoff mentioned that 390 articles were published in 2022, down from 890 in 2021. This downward trend is continuing into 2023, just 19 articles have been published so far this year.  Final thoughtsI hope that CSS Tricks can carry on and can retain the same spirit. The signs do not look promising.I would like to take this opportunity to thank Geoff for the positive contributions he has made to web development. 🙏You can subscribe to my RSS feed to get my latest articles."
994,"Are you tired of overcomplicating your React projects with excessive JavaScript? Well, so do I! After exploring countless codebases, One thing I've noticed as a web developer is the tendency to get caught up in the React way of doing things, I've named this as the ""React tunnel vision."" This phenomenon occurs when we become so focused on solving problems with React that we forget about other tools and solutions that may be better suited for certain tasks. This can lead to overcomplicating code, creating unnecessary abstractions, and sacrificing performance. As someone who has fallen victim to this tunnel vision, I've learned the importance of taking a step back and considering other options, such as using plain CSS for certain styling tasks, or using vanilla JavaScript for simple interactions.Whether you're a seasoned developer or just starting out, these tips can give you a real advantage and improve your project's performance.  Why does this happen?This tunnel vision is not entirely our fault. Many times, we have tight deadlines and we simply do not have the luxury of experimenting with different approaches to solve layout problems. However, when we take a step back and consider using CSS, we can create more efficient and elegant solutions.But that's not just it, for the sake of the readability and documentation of the codebase, having CSS being the only responsible of handling the styling and layouts can help a lot with the separation of concern.As someone who has struggled with separating business logic from styling, I understand how frustrating it can be to have a tangled mess of code that leads to unnecessary re-renders. It's crucial to keep concerns separate to make code maintainable, easy to read, test, and modify.In this post we are going to focus entirely on how CSS can help us solve many of the issues we tend to try solv  The mistakes we make along the wayAs someone who has worked with React components and CSS styling, I understand the struggle of trying to separate business logic from styling logic within the same component. It's all too easy to fall into the trap of using state and conditionals to toggle CSS styles, leading to tangled and hard-to-maintain code.One great example is the simple problem of accordionsImagine you have this page that may contain from one to several accordions, if you have more than 1 accordion, the accordions should show closed, but if only one accordion is being display then open it, there is no need for it to be hiddenThis would be the classic react way of solving this issueimport React, { useState } from 'react';import Accordion from './Accordion';const AccordionWrapper = ({ accordionItems }) => {  const [openAccordionIndex, setOpenAccordionIndex] = useState(null);  const handleAccordionClick = (index) => {    if (openAccordionIndex === index) {      setOpenAccordionIndex(null);    } else {      setOpenAccordionIndex(index);    }  };  return (    <div>      {accordionItems.map((item, index) => (        <Accordion          key={index}          title={item.title}          content={item.content}          isOpen={openAccordionIndex === index || (openAccordionIndex === null && index === 0)}          handleClick={() => handleAccordionClick(index)}        />      ))}    </div>  );};export default AccordionWrapper;Enter fullscreen modeExit fullscreen modeI've seen code like this through dozens of codebases, and it's okay, if you wrote solutions like this, chances are you this is not the code that is holding back your app from being blazingly fast and performant, but starting to identify and prevent this overuse of JavaScript can really improve your potential as a front end engineerNow... How should you really write this component?import React from 'react';const Accordion = () => {  return (    <div>      <input id=""accordion"" type=""checkbox"" name=""accordion"" defaultChecked />      <label htmlFor=""accordion"">Accordion</label>      <div className=""accordion-content"">        {/* Accordion content here */}      </div>    </div>  );};//And you can map this component without needing to pass any prop nor state!export default Accordion;Enter fullscreen modeExit fullscreen modeAnd simply use CSS.accordion-wrapper {  display: block;}input[type=""checkbox""] {  display: none;}label {  display: block;  padding: 10px;  background-color: #eee;  font-weight: bold;  cursor: pointer;}input[type=""checkbox""]:checked + label {  background-color: #ccc;}.accordion-content {  max-height: 0;  overflow: hidden;  transition: max-height 0.5s;}input[type=""checkbox""]:checked ~ .accordion-content {  max-height: 1000px;  transition: max-height 0.5s;}/* :only-child selector to open the only accordion by default */input[type=""checkbox""]:only-child:checked ~ .accordion-content {  max-height: 1000px;  transition: max-height 0.5s;}Enter fullscreen modeExit fullscreen modeAccordion is represented by an input checkbox and a corresponding labelLabel is styled like a button and toggles the checked state of the checkbox when clickedAccordion content is a div element with the class ""accordion-content""Adjacent sibling selector (+) is used to style the label when checkbox is checkedGeneral sibling selector (~) is used to style the accordion content when checkbox is checkedMax-height property controls height of accordion contentTransition property creates smooth animation when accordion is opened or closed:only-child selector styles accordion content when it's the only child of the wrapper elementCheckbox state determines if the accordion is open or closed by defaultSo, as you can see, we could manage both the open/close states for each individual accordion and also the condition that if we only rendered a single accordion, said accordion should be open by default. Little disclosure, I don't think you should handle every conditional rendering in react like this, obviously if you need to keep track of which accordions are open and then send that data over then a state is the obvious solution, but this is to prove that sometimes, you have to take a step back, try to get out of the react tunnel vision and reconsider if you can move some logic around and let CSS handle the rest.  The conclusionThere could be many arguments for writing the accordion in the React way, and I agree. However, I want to stress the importance of avoiding the React/JavaScript tunnel vision. Sometimes, it's worthwhile to take a step back and consider whether CSS already offers an efficient solution to a given problem. By doing so, you may be able to optimize your project's performance and make it more effective. In short, by being mindful of these considerations and striking a balance between the use of CSS and React, you can create effective, performant, and maintainable components anywhere you go."
995,"  Daily Challenge ReduxHey everyone! We're excited to announce a reimagining of our past Daily Challenge series. Daily Challenge #1 - String Peelerdev.to staff ・ Jun 28 '19 ・ 1 min read#challengeOur previous series focused more on shorter coding challenges that had a few decent solutions, depending on your language. Instead, we'll now focus on projects you can fully customize and make your own over the course of the week. Sharing your solutions will be less about finding the ""right"" answer and more about showing the community how creative you can be.Each Thursday, we will post a new coding challenge on DEV Community under the Code Newbie Team organization. These challenges are designed to help developers practice their skills and build confidence in a low-pressure, supportive environment. Experts often say the best way to learn to code is by building projects, so that's exactly what we'll do. The challenges will be fairly open-ended, so you can choose your level of difficulty and how much time you want to spend. Developers at all skill levels are encouraged to participate. Feel free to use any language that allows you to meet the requirements. After posting each challenge, I'll be in the comments to share some feedback and cheer you all on!  Challenge #1: A CalculatorFor the first challenge, we'll keep it relatively simple. This week, the challenge is to make a working calculator with a customized user interface. The first part of the challenge is simply to make a functional calculator, but the second part is to make it your own! Use your signature colors, change the background, give the buttons funny sound effects.Feel free to make the calculator in any language you'd like. You can use CodePen to share if you'd like to design it in JS. You can also go the Python route and build it with Tkinter or PyQt.We hope these challenges will motivate you to code more often and allow us to build connections as a community. Please let us know if you have any feedback or suggestions for future challenges. We look forward to coding with you!"
996,"Starting your journey in programming can be an exciting but daunting experience. One of the first decisions you'll make is choosing which programming language to start with.We want to hear from our newbies and from some of the more experienced community members, too: What was the first programming language you learned, and what programming language(s) are you currently studying? "
997,"Some of the situations may be familiar to you. Enjoy!When I show my boss that I finally fixed a bug: When the project manager enters the office: When I prepare the code for release: When I try to fix a bug at 3 am: When my regular expression worked exactly as expected: When my friend asked me to fix a Joomla site: When I was told that the module I had been developing all week would never be used: When code that I haven't tested works fine in the stable version of the project:  When the sellers reported that they had sold our software to a client: The first time I apply new CSS: When the sysadmin finally gave us root access: When I ran my script for the first time after hours of development: When I go on vacation while everyone else is trying to fix bugs:  When we released the beta and got notified about the first bug: When the boss is looking for someone to urgently fix a complex bug:  When code that works on Friday no longer works on Monday: When I asked a new colleague to continue working on the code:  When a bug was not noticed during the presentation of the product:  Share your favorite memes and situations in comments! Btw, you can support my work by buying me a coffee! I'll leave here a few links for you:) You can also support me on Coinbase"
998,"Engineers often try to get promoted by focusing on their technical skills. Like writing more unit tests. Or learning a new programming language.After all, the best engineers get promoted. Right?Being good at your job is different than advancing in your career. The people who get stuck only do what they’re told — and then wonder why they’re not getting anywhere.Me waiting to get promotedThe people who get promoted manage their careers like it’s a separate job. They don’t wait for opportunities to happen. They make them happen.In this article, I discuss the 3 most common career mistakes that cause engineers to get passed up for promotion.None of them involve getting better at your current job.  A Lesson from American PoliticsWhen a new US president gets elected, their first task is to hire the right people for their team. They have to pick their advisors and choose who to nominate to their cabinet.It’s during these political transitions that careers get made. When Joe Biden won the 2020 election, many politicians made huge strides in their political careers when he nominated them to his administration.Kamala Harris (VP) and Pete Buttigieg (Transportation Secretary) both got promoted after Biden was elected.These politicians got promoted when a political re-org happened. You have to pay attention when a corporate re-org happens. That’s when you have the highest chance of getting promoted.  Promotions Happen During Corporate Re-OrgsJust like in political transitions, departments get axed and new teams get created during corporate re-orgs.This paves the way for roles to open up — and that’s your chance to move up.You have to imagine ways that you can fit in this new org that align with your career goals. Then propose it.The key is to find win-win situations where you:advance the goals of leadershipdo it in a way that aligns with your career goalsDon’t make the mistake I made, where I ignored all the re-org emails that upper-management sent at Netflix. “If it doesn’t help me work faster, I don’t care,” I thought.Pay close attention to shifts in the team structure, because that could be your chance to get your dream role.Case Study: Spot the Promotion OpportunityImagine a team where a director splits their team into 3 squads under them.2 squads have a manager.1 squad has engineers who report straight to the director.Can you spot the promotion opportunity?Right now the director has too much on their plate.They have 2 managers + 3 engineers to manage = 5 people to manage. They have to play double duty — first as an engineering manager for the 3 engineers, and second as a director for the two other managers.If you’re in this org, this is the perfect time to become a manager. Ask the director if you could manage this 3rd squad. If you became a manager, everyone benefits:the director cuts their reports from 5 to 3the manager-less team has more directionyou advance in your careerYou’re the manager now.More opportunities to get a promotion can open up if there is a further re-org in this team. If:one of the squads splits furthera new squad gets createdthey will need new managers to manage those squads.And since there are 15 engineers now, you could make a case for a TPM/PM to manage all the infrastructure on this team as well.More roles created as the team expands.I’ve noticed while working at Netflix that many of my coworkers’ careers were made during re-orgs. My previous boss got promoted when the team split into 4. He raised his hand to manage one of the squads and got the job.Another re-org happened at Netflix where they moved the VP of Product into another org. He laid off the old product team and new engineering teams emerged.A coworker of mine saw this opportunity to ask if she could manage one of the new engineering teams. Now she has 10 engineers reporting to her.Re-orgs are opportunities. Pay close attention to org structure, and try to find ways that you could fit in a higher role when a new leader comes in.  Collecting the Wrong ExperienceAnother career mistake involves trying to collect more experience. “Only after I get 1 more certificate,” they say. “Then I’ll be ready to get promoted!”The problem with collecting more experience is that the skills required to get promoted to the next job are entirely different than the skills to be a superstar at your current job.You need to learn the skills to operate at the next level, not to operate better at your current one.So most people are learning the wrong set of skills that won’t help them get promoted.Some people collect experience like baseball cardsCase Study: Entry-Level vs Principal EngineersI talked to a friend recently who was starting their career in big tech. They wanted to move up the engineering ladder and asked what it would take to become a principal engineer.They stayed late at work often and worked weekends because they wanted to get promoted faster. By their logic, working more meant they could crank out more features and advance in their careers faster.I guarantee this will not get them promoted.Taking care of your health is taking care of your career.What my friend doesn’t understand is that principal engineers aren’t SDE 1’s on steroids.It’s not about cranking more features out — “the intern cranks out one feature per day, but the principal engineer cranks out a dozen.” The principal engineer operates on an entirely different level.SDE 1’s and interns are usually given small, independent tasks. Building features, writing test — things that they can do in isolation from the rest of the team.As you move up the ladder, you’re tasked less with completing individual tasks, but helping other engineers move faster. A principal engineer helps the entire company move faster.Migrating to AWS was one of the top priorities for engineering leadership at Netflix in the early 2010’s.Tasks that a principal engineer might work on involve:standardizing the way code is written in the companycentralizing duplicate work between teamsmigrating the company to the cloudThese tasks affect every engineer’s workflow — principal engineering level work. I have a saying for senior level engineers:If your work doesn’t help multiple engineers move faster at once, you’re not operating at a senior engineering level.So my advice to the entry-level engineer who wants to develop the skills to operate at the next level is to think less about completing your individual work faster. Instead, think more about how you can help your team move faster.This includes:making sure your team is on the paved path at your companysetting up alerting properly so issues are detected quicklysetting up continuous deployment so features get pushed out fasterThis work will reduce the operational load on your team. Your boss will notice and your teammates will thank you for it.  Expecting the Manager to Drive Your PromotionLastly, waiting for your manager to drive your promotion is the single biggest career mistake of all. You could waste years of your life waiting for a promotion that never comes if you expect others to drive it for you.Your Manager’s ViewpointThe issue is that managers have too much on their plate already.If you mapped out a pie chart of their attention, 99% of their time is spent thinking about their own job security, their own deadlines, and their own promotion.Your promotion at most will only take up 1% of their time.That 1% is everything to you though.It’s not your manager’s fault it’s this way — it’s an issue of incentives.If you can’t get fired for it, it’s not a priority. A manager will never get fired because you didn’t get promoted. So there is no incentive for a manager to prioritize your career growth.The career chicken and egg problem.The lesson here is that you need to take responsibility for your own promotion. You have to do your own research and figure out:how the promotion process works at your companywho will be at the promotion decision meetingwhat work can be used to build a promotion storyNot all work is created equally. You have to make sure you’re doing the work that will help you get promoted. This means revenue-generating features and work that moves needles.No one ever got promoted by being a scrum master. No one ever got promoted for writing a few extra unit tests. It’s up to you to find the work that will get you promoted.ConclusionGreat work alone will not get you promoted. It’s the career building work you do that will.Engineers tend to be very good technically, but lack the political savviness to notice openings before they arise. They focus too much on the wrong kind of technical expertise, and don’t take responsibility for their own career destiny.No one cares about your career success as much as you will. Don’t wait for things to happen. Take responsibility for your own career success, and watch your career flourish.  💡 If You Liked This Article...I publish a new article every Tuesday with actionable ideas on entrepreneurship, engineering, and life.Join 3,001 subscribers on my newsletter here."
999,"I had done coding before. I don't know if the little I had done in MS-DOS batch files and command line menus qualified as ""programming"" or ""development"" beyond just ""coding."" And I had made mistakes but didn't consider them bugs (at least I didn't call them that way.)My first bug (although some people may not consider it as such) was during Programming I in college. And it was the silliest thing that you could imagine. Still, it stuck, and I still remember the error because of the lesson that came with it.We were learning Turbo Pascal (I just aged myself with that, but I have to say, it is a phenomenal language to learn because it uses a more ""natural English"" than most others I've learned since). During our first lab, we had to create a small program, I don't remember what it was, but the general idea was to read some input, run some math calculations, and show the results on the screen.After fixing a couple of missing semi-colons, the program compiled and ran! It could read the inputs, pass the arguments to a function, run the calculations, and return the value... but the result would not display on the screen. I ran the program again and again—no problem reading the inputs. Still no result.After including some writeln I could confirm that the function ran just fine, but the result was not on the screen for some weird reason.I called the professor, who checked the code. It was not long, but longer than it should be –at the time, we enjoyed having the program with the highest number of lines possible, like that proved we were ""more of a developer.""I guess he expected a compilation error or something typical from new developers, but to his surprise, he couldn't find an obvious mistake.Then he did something that blew my mind (considering that I was a first-year CS student): he ran the debugger and executed the program step by step. We saw how the process ran as it should, observed the values being calculated correctly, exiting the function, the value was correct outside of the function... and no result on the screen.He rolled his eyes and looked at me, ""Alvaro... where are you writing the result on the screen?"" And as I pointed to the last line of code, I could see my error: I forgot to output the variable with the result!writeln('The result is ');Enter fullscreen modeExit fullscreen modeThe professor was unhappy about losing 5-10 minutes looking at such a ridiculous issue. Or maybe he was a little ashamed about not realizing sooner.Either way, he spent the last 20 minutes of the lab explaining how to debug in Turbo Pascal... and asking to please, please, please not ask him for help unless we had debugged the code before. A request that we ignored most of the time.Still, that was a great lesson and a great lab. And I remember it as one of the days that I fell in love with coding."
