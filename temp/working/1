2023-08-29 12:52:54.191905: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-08-29 12:52:54.242071: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-08-29 12:52:54.242514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-29 12:52:55.063563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Load article DataSet
   index                                               text  processed_text  sentiment
0      0  Hey y'all ðŸ‘‹Hope you all have wonderful weekend...             NaN        NaN
1      1  Do you actively contribute to open source proj...             NaN        NaN
2      2  Open Source thrives through shared efforts. Wh...             NaN        NaN
3      3  In the age of burgeoning data complexity and h...             NaN        NaN
4      4  We're thrilled to announce a powerful integrat...             NaN        NaN
Clean data set
   index                                               text                                     processed_text sentiment
0      0  Hey y'all ðŸ‘‹Hope you all have wonderful weekend...  hey hope wonderful weekends looking back past ...  positive
1      1  Do you actively contribute to open source proj...  actively contribute open source projects motiv...  positive
2      2  Open Source thrives through shared efforts. Wh...  open source thrives shared efforts whether new...  positive
3      3  In the age of burgeoning data complexity and h...  age burgeoning data complexity high dimensiona...  positive
4      4  We're thrilled to announce a powerful integrat...  thrilled announce powerful integration langcha...  positive
majority class before upsample: (909, 4)
minority class before upsample: (66, 4)
After upsampling
sentiment
positive    909
negative    909
Name: count, dtype: int64
(900,) (100,) (900,) (100,)
Vocabulary size=20896
Number of Documents=900
(900, 30) (100, 30)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 30, 300)           6269100   
                                                                 
 conv1d (Conv1D)             (None, 23, 64)            153664    
                                                                 
 max_pooling1d (MaxPooling1  (None, 11, 64)            0         
 D)                                                              
                                                                 
 dropout (Dropout)           (None, 11, 64)            0         
                                                                 
 dense (Dense)               (None, 11, 8)             520       
                                                                 
 dropout_1 (Dropout)         (None, 11, 8)             0         
                                                                 
 dense_1 (Dense)             (None, 11, 4)             36        
                                                                 
 dropout_2 (Dropout)         (None, 11, 4)             0         
                                                                 
 global_max_pooling1d (Glob  (None, 4)                 0         
 alMaxPooling1D)                                                 
                                                                 
 dense_2 (Dense)             (None, 1)                 5         
                                                                 
=================================================================
Total params: 6423325 (24.50 MB)
Trainable params: 6423325 (24.50 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/3
8/8 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.0678
Epoch 1: val_accuracy improved from -inf to 0.05000, saving model to ./best_model/best_model_cnn1d.h5
8/8 [==============================] - 3s 243ms/step - loss: 0.3349 - accuracy: 0.0678 - val_loss: 0.3366 - val_accuracy: 0.0500
Epoch 2/3
8/8 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.0678
Epoch 2: val_accuracy did not improve from 0.05000
8/8 [==============================] - 1s 96ms/step - loss: 0.2032 - accuracy: 0.0678 - val_loss: 0.2346 - val_accuracy: 0.0500
Epoch 3/3
8/8 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.0678
Epoch 3: val_accuracy did not improve from 0.05000
8/8 [==============================] - 1s 102ms/step - loss: 0.0787 - accuracy: 0.0678 - val_loss: 0.1258 - val_accuracy: 0.0500
29/29 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.0678
4/4 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.0500
Train: 6.78%, Test: 5.00%
================================================

4/4 [==============================] - 0s 5ms/step


              precision    recall  f1-score   support

           1       0.05      1.00      0.10         5
           2       0.00      0.00      0.00         7
           3       0.00      0.00      0.00        88

    accuracy                           0.05       100
   macro avg       0.02      0.33      0.03       100
weighted avg       0.00      0.05      0.00       100
